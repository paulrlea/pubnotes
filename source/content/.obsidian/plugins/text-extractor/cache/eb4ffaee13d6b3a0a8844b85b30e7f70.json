{"path":"Notes/@Fall 2025/Cosmology/cos.pdf","text":"Lecture Notes on Cosmology Kevin Zhou kzhou7@gmail.com These notes cover introductory cosmology, along with a brief overview of dark matter. The primary sources were: • Daniel Baumann’s Cosmology lecture notes. An exceptionally clean and clear set of notes, used at both Cambridge and Oxford. Has a theoretical bias, with little contact with experimentally measured quantities. These lecture notes closely follow Baumann’s. • David Tong’s Cosmology lecture notes. Another clear set of notes, at a more basic level. At Cambridge, Baumann’s notes are used for Part III while Tong’s are used for Part II. • Subir Sarkar’s Astroparticle Physics lecture notes. A broad, up-to-date overview of many current observational issues in astrophysics and cosmology. • Peter Graham’s Physics 362 course. There are no public lecture notes, but some of the wisdom of the course, especially for alternative scenarios and quick estimates, is baked into these notes. • Ryden, Introduction to Cosmology. A well-written undergraduate-level introduction to cosmol- ogy, assuming very little background; a bit vague, but good for a first pass to get intuition. • Mukhanov, Physical Foundations of Cosmology. An introduction to cosmology and astropar- ticle physics with a distinctly Russian flavor. Prerequisites are kept to a minimum; the text provides very brief but self-contained introductions to general relativity and field theory. Many calculations usually done numerically are performed analytically, with a deft hand. • Kolb and Turner, The Early Universe. A classic and clear textbook on cosmology and astropar- ticle physics, aimed at particle physicists. Contains extensive discussion of topics like GUT baryogenesis and axions. However, many observational statements are out of date. The most recent version is here; please report any errors found to kzhou7@gmail.com. 2 Contents Contents 1 Geometry and Dynamics 3 1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 The Metric . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.3 Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2 Inflation 18 2.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2.2 Slow Rolling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.3 Models of Inflation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 3 Thermal History 30 3.1 The Hot Big Bang . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 3.2 Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 3.3 The Boltzmann Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 3.4 Nucleosynthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 3.5 Models of Baryogenesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 4 Cosmological Perturbation Theory 57 4.1 Newtonian Perturbation Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 4.2 Relativistic Perturbation Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 4.3 Equations of Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 4.4 Structure Formation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 5 Initial Conditions From Inflation 80 5.1 Quantum Fluctuations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 5.2 Primordial Perturbations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 6 Dark Matter 88 6.1 History and Evidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88 6.2 Models of Dark Matter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92 6.3 Direct Dark Matter Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 6.4 Indirect Dark Matter Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 7 The CMB 109 3 1. Geometry and Dynamics 1 Geometry and Dynamics 1.1 Introduction We begin with some useful numbers from astrophysics. • The astronomical unit is the distance from the Earth to the Sun, 1 AU = 1.5 × 10 11 m. • One parsec is the distance at which an astronomical unit subtends an arcsecond, which is 1/602 of a degree, about the angular resolution of an amateur telescope. In particular, 1 pc = 3 × 10 16 m = 3 ly. • Distances between stars are on the order of parsecs. Galactic distances are in kpc, intergalactic distances are in Mpc, and galaxies are arranged into superclusters separated by voids, both of which have sizes on the order of 100 Mpc. The width of the observable universe is on the order of Gpc, as the age of the universe is measured in gigayears (Gyr). • The sun has mass M⊙ = 2 × 1030 kg, and the galaxy has mass about 1012M⊙. • The sun has luminosity L⊙ = 4 × 1026 W, and the galaxy has luminosity about 1010L⊙. Next, we consider some fundamental cosmological observations. • The cosmological principle states that the universe is isotropic and homogeneous at scales above 100 Mpc. These two conditions are independent; neither implies the other. This can be viewed as merely a convenient simplifying approximation, as structures on the 100 Mpc scale and larger have been observed. • For comparison, the observable patch of the universe has scale 3000 Mpc. This does not set a bound on the total size of the universe, which could be infinite. For instance, most inflationary theories predict a breakdown of homogeneity on scales much larger than 3000 Mpc, which are unobservable. As such, we’ll focus on our observable patch. • This is related to Olbers’ paradox: the night sky is not infinitely bright, though naively it would be assuming a homogeneous, infinite universe. The resolution is that the age of the universe is finite, so light from very distant stars can’t have reached us yet. • Light from distant galaxies is redshifted. The redshift is defined as z = λob − λem λem > 0 and Hubble’s law is the observation that, for nearby galaxies, z = H0 c r, H0 = 100h km s −1 Mpc −1 where today h has been measured from CMB observations to be h = 0.67 ± 0.01. However, there is an outstanding 3σ discrepancy with more nearby supernova measurements, which give h = 0.73 ± 0.02. 4 1. Geometry and Dynamics • In the nonrelativistic limit z ≪ 1, Hubble’s law means the galaxies are receding with velocity v = H0r. Note that while intragalactic distances can be measured with parallax, intergalactic distances must be measured by galactic luminosity or standard candles. • Hubble’s law is consistent with homogeneity and isotropy, as every galaxy observes recession obeying the law. In fact, it is the only expansion law consistent with homogeneity and isotropy, and as such remains unchanged when accounting for relativistic effects. • We take the convention that a zero subscript denotes the current time. If we naively assume the galactic velocities are constant, then Hubble’s law suggests all galaxies were at the same point in a “Big Bang” at time t = 0, where t0 = H −1 0 ≈ 14 Gyr. This is only a rough estimate, because we expect gravity to slow down the expansion, and dark energy to accelerate the expansion. • We’ve also measured the constituents of the universe. Baryonic matter consists mostly of protons and neutrons, though we also count electrons as “baryonic”, so the word really means “the stuff ordinary stuff is made of”. Baryonic matter is about 3/4 hydrogen by mass, and most of the rest is helium. About 2% consists of heavier elements, which cosmologists call “metals”. • Several independent measurements indicate dark matter, i.e. massive components of the universe which can’t be detected readily. Dark matter includes stellar remnants and substellar objects such as brown dwarfs, and possibly new particles. • Hubble’s law can also be explained by a “steady state” model, once advocated by Bondi and Gold. This model assumes the “perfect” cosmological principle, which imposes homogeneity in time; that means H is constant, and distances grow exponentially. The matter density can be kept constant by assuming that new matter is created at a constant rate per unit volume. • However, the universe also contains light with a blackbody spectrum at temperature T0 = 2.725 ± 0.001 K called the CMB. Its existence can be explained by the Big Bang model but not the steady state model, and was a key piece of evidence in the historical debate. • Specifically, suppose distance at time t are scaled by a(t), where we conventionally set a(t0) = 1. The cosmological redshift means the temperature of the CMB is T ∝ a−1, so the CMB points to an era where universe was much hotter than currently. • The redshift of distant galaxies can be derived from the scale factor; we have 1 + z = 1 a(t1) by cosmological redshift, where t1 is the emission time. Taylor expanding gives Hubble’s law, z ≈ H0d, H0 ≡ ˙a(t0) a(t0) where we have set c = 1 and will do so henceforth. 5 1. Geometry and Dynamics • The relatively recent observation that the acceleration of the universe is accelerating points to the presence of dark energy, which makes up about 2/3 of the energy density of the universe. Note. There are several ways to establish T ∝ a−1 for a photon gas. Formally, the geodesic equation for photons in the FRW metric shows they are redshifted by a factor of a. By Planck’s law, this maps a blackbody spectrum to another, with a temperature shrunk by a. A slick method is to consider consecutive wavecrests of light. Consider two wavecrests emitted at times t1 and t1 + δt1, and absorbed at times t0 and t0 + δt0. Since null paths in the radial direction obey dr/dt = 1/a, ∫ dr = ∫ t0 t1 dt a = ∫ t0+δt0 t1+δt1 dt a , δt0 = δt1 a(t1) which implies the frequency is redshifted by a(t1) as before. A final argument is from thermodynamics. For a photon gas, N ∝ V T 3, and in an adiabatic expansion, no photons are absorbed or emitted by the walls. Then V T 3 must be constant, so T ∝ a−1 as before. Physically, the photons are redshifted by bouncing off the walls. Note. The diagram above shows the standard cosmological story accepted today. In this picture, an early inflationary era occurred, with quantum fluctuations inflated into large-scale fluctuations in the matter density of the universe. Within the first three minutes, the temperature cooled enough to form nuclei. About 380 kyr afterwards, the universe cooled enough to form neutral atoms and became transparent to radiation, forming the CMB. The initial inhomogeneities were imprinted on the CMB and amplified by gravity, creating the large-scale structure of the universe. 1.2 The Metric We now introduce the Friedmann–Robertson–Walker (FRW) metric, beginning with spatial metrics. • Spatial homogeneity and isotropy mean that spacetime can be foliated into spatial hyper- surfaces, each of which are homogeneous and isotropic. Thus we begin by classifying these three-dimensional surfaces. • Such spaces must have uniform curvature, and there are only three options. – Zero curvature space is three-dimensional Euclidean space E3, dℓ2 = dx2. 6 1. Geometry and Dynamics – Positively curved space may be represented as a sphere S3 embedded in E4, dℓ 2 = dx2 + du 2, x2 + u 2 = a 2. Homogeneity and isotropy result from rotational symmetry of the sphere. – Negatively curved space may be represented as a hyperboloid H 3 embedded in Minkowski space with signature (− + ++), dℓ 2 = dx2 − du 2, x2 − u 2 = −a2. Then homogeneity and isotropy result from Lorentz symmetry. Note that the popular depiction of negatively curved space is a saddle in Euclidean space, but in this case the curvature is not uniform. • In the last two cases, we rescale x and u by a to get dℓ 2 = a 2(dx2 ± du 2), x2 ± u 2 = ±1. Then x and u are dimensionless while a carries units of length. • Next, we can eliminate the parameter u, which gives dℓ 2 = a2 (dx2 ± (x · dx)2 1 ∓ x2 ) for the last two cases. We can combine all three cases by writing dℓ 2 = a 2γijdxidxj, γij = δij + k xixj 1 − k(xkxk) , k =    0 Euclidean, 1 spherical, −1 hyperbolic. Now we don’t have extra coordinates, though the homogeneity and isotropy is less manifest. • To recover some of the manifest symmetry, we define spherical coordinates as usual, so dx2 = dr2 + r2dΩ2, x · dx = rdr. Then the metric simplifies to dℓ 2 = a2 ( dr2 1 − kr2 + r2dΩ 2) which at least makes isotropy manifest. • Finally, one may simplify the radial component by defining a new radial coordinate dχ = dr √1 − kr2 , dℓ 2 = a2 (dχ 2 + S2 k(χ)dΩ2) where integration yields Sk(χ) =    sinh χ k = −1, χ k = 0, sin χ k = 1. Note that while Sk(χ) is defined piecewise, the metric varies “smoothly” as the curvature is varied; we just can’t see this since we’ve factored out the curvature scale. 7 1. Geometry and Dynamics Note. Is the universe infinite in spatial extent? The naive answer is that it is if k = 0 or k = −1. The correct answer is that we have no idea. For example, an infinite k = 0 spatial universe is observationally equivalent to a finite k = 0 universe with nontrivial topology such as a torus, as long as the torus is very large. It is possible to test for finiteness by looking at the sky in opposite directions and trying to see repeated structures in the CMB, but it’s not possible to rule out finiteness. Since an infinite FRW universe fits all the observations, and is mathematically simpler than having, e.g. a torus structure (which would break isotropy), we’ll just use it as a default. Next, we introduce the FRW metric. • To get the FRW metric, we simply add a time dimension, ds 2 = dt 2 − a 2(t)γijdxidxj = dt 2 − a 2(t) ( dr2 1 − kr2 + r2dΩ2) where we allow the parameter a to depend arbitrarily on time. Note that we can rescale a → λa, r → r/λ, k → λ 2k while preserving the metric. Conventionally, we use this freedom to make a dimensionless with a(t0) = 1, so that r and k−1/2 gain dimensions of length. • This form is the most general form; we can always set g00 = 1 by rescaling the time coordinate. There are no cross terms g0i, as this would break isotropy. However, note that the FRW spacetime is not stationary or static. • In principle, we could also consider spacetimes that are not homogeneous and isotropic, but few exact solutions are known. As one example, the Lemaitre–Tolman–Bondi metric is isotropic but not homogeneous, describing an observer at the center of a large void or cluster. However, we will not consider these complications below. • The coordinates xi are called comoving coordinates. Physically, observers stationed at these coordinates will see the other observers moving away from them isotropically, and the time they measure is t. • More specifically, define the ‘physical’ coordinates xi p = a(t)xi, so differences in the physical coordinate better reflect physical distances. Then vi p = dxi p dt = a(t) dxi dt + da dt x i = a(t) dxi dt + Hxi p. These terms are called the peculiar velocity and Hubble flow, where we defined H = ˙a/a. Hence we have derived Hubble’s law. • Finally, it is convenient to work in conformal time. Letting dτ = dt/a(t), we have ds2 = a2(τ ) (dτ 2 − (dχ 2 + S2 k(χ)dΩ2)) . This is especially useful for analyzing the paths of light rays, since the overall scale factor doesn’t matter. We see that for a radial path, the conformal time elapsed is equal to the change in the (scaled) radial coordinate, ∆τ = ∆χ. It’s also obvious that two successive wavecrests for light separated by ∆τ arrive separated by ∆τ , giving δt ∝ a(t) as before. 8 1. Geometry and Dynamics • Note that FRW spacetimes with k = 0 are only spatially flat; the Riemann tensor does not vanish! However, the Riemann tensor pulled back to a slice of constant t does vanish. Next, we consider geodesics in the FRW spacetime. • We evaluate the Christoffel symbols in the coordinates where ds 2 = dt 2 − a 2(t)γijdxidxj. Some explicit calculation gives Γ 0 ij = a ˙aγij, Γi 0j = ˙a a δi j, Γ i jk = 1 2 γiℓ(∂jγkℓ + ∂kγjℓ − ∂ℓγjk) with Γi j0 related by symmetry. • We will use the slick form of the geodesic equation, pν∂νp µ = −Γ µ νρpνp ρ which will allow us to formally handle the massless and massive cases simultaneously. Here, the partial derivative on the left only makes sense if we imagine pµ (which is originally defined only on the geodesic) is extended to a full vector field. It turns out this is always possible, and moreover that the result does not depend on the extension. Now, since the FRW spacetime is homogeneous, it is possible to choose the vector field so that ∂ipµ = 0, giving p 0 dpµ dt = −Γ µ νρp νpρ = − (2Γµ 0j + Γµ ijpi) pj. This trick allows us to sidestep annoying issues with, e.g. parametrization of massless geodesics. • For massive particles at rest in the comoving frame, pi = 0, we have dpµ/dt = 0. For moving particles, consider the µ = 0 component, E dE dt = −Γ 0 ijpipj = − ˙a a p2. Since E2 = p2 + m2, we have E dE = p dp, so this equation reduces to p dp = da a p 2, p ∝ 1 a . Hence for a massless particle, we have derived E ∝ 1/a as anticipated earlier. • For massive particles, we instead have p = mv √1 − v2 ∝ 1 a where v2 is defined with respect to the spatial metric γij. This means that v2 decreases as a increases, so freely falling particles converge onto the Hubble flow. Note. The result that T ∝ 1/a2 for nonrelativistic matter can also be understood in the Newtonian picture. We imagine a population of particles exploding out from the origin. Once the particle cloud expands by a factor of a, the local dispersion in the velocities within a box of fixed size decreases by 1/a. Since this defines the temperature, T ∝ σ2 v ∝ 1/a2. 9 1. Geometry and Dynamics Note. Introductory textbooks often go out of their way to stress that the cosmological redshift is not a Doppler shift. But the fact is that there’s no real distinction between the two. In general, you can always use the geodesic equation to relate the frequencies of a photon as measured by the emitter and absorber, and this reproduces the Doppler shift, the cosmological redshift, and gravitational redshift in appropriate special cases. The reason textbooks make a distinction is because “Doppler shift” usually implies working in flat spacetime, which could get people confused. But cosmological redshift can also be calculated by combining the infinitesimal Doppler shifts as light travels through a set of overlapping patches, each of which are essentially flat. Sometimes students wonder if you have to add the effects of Doppler shift and cosmological redshift, but that doesn’t make sense; there’s only one redshift effect. It is tricky to define distance on cosmological scales, and we give a few ways below. • We consider the FRW metric in the form ds 2 = dt 2 − a 2(t) (dχ 2 + S2 k(χ)dΩ2) , Sk(χ) =    R0 sinh(χ/R0) k = −1, χ k = 0, R0 sin(χ/R0) k = 1, where we have rescaled so that a(t) is dimensionless and a(t0) = 1. • Consider a point at the origin and a point at coordinate χ. We define the comoving distance between them by χ, and the metric distance by dm = Sk(χ) and the two agree for k = 0. Neither can be directly measured. • The metric distance behaves a bit strangely; for example for k = 1 it hits a maximum and decreases. We introduce it because it is simply related to empirical distance measures, and because it is close to the comoving distance for scales less than the scale of the entire universe. • The comoving distance is the current proper distance between the points. Since a radial light ray satisfies dt = a(t) dχ, the comoving distance obeys χ(z) = ∫ t0 t1 dt a(t) = ∫ z 0 dz H(z) where H(z) is the Hubble parameter at the time when light with redshift z was emitted. • On solar system scales, we measure distances using the speed of light. Since galaxies are on the scale of parsecs, we can use parallax to measure galactic distances, since the angles involved are on the order of arcseconds. Cosmological effects are negligible on these scales. • For larger distances, we typically use standard candles. If a standard candle has luminosity L and the flux is F , we define the luminosity distance by F = L 4πd2 L where dL is the luminosity distance. 10 1. Geometry and Dynamics • For k ̸= 0, the flux is spread over a surface area 4πS2 k(χ). The rate of arrival of photons is redshifted by 1 + z, while the energy of each photon is also redshifted by 1 + z. Then dL = dm(1 + z). That is, dL overestimates dm because of the cosmological redshift. • Another option is to use a ‘standard ruler’ of known proper length D, defining the angular diameter distance dA = D δθ . If the ruler lies along the tangential direction at comoving distance χ, the FRW metric gives D = a(t1)Sk(χ)δθ, dA = dm 1 + z The expansion of the universe makes dA underestimate dm. Next, we briefly discuss how these distances are measured in practice. • Standard yardsticks are difficult to use. Galaxies and galaxy clusters have been candidates, but they don’t have well-defined borders, and their size can change over time. Instead, we mainly use standard candles. • Cepheid variables are supergiant stars about 400 to 40, 000 times more luminous than the sun. They pulsate radially, with a period on the order of days to months. By studying clusters of Cepheids in the Large Magellanic Cloud, a simple relationship between the mean flux and period was found, make them standard candles. • The main problem with Cepheids is calibrating the relationship: the closest Cepheid is hundreds of parsecs away, with a high distance uncertainty. Another problem is that they aren’t bright enough to go to the 100 Mpc scales where the universe is homogeneous and isotropic, so results from them must be corrected for local peculiar velocities. • Galaxies can be standard candles, since they are bright enough to go beyond 1 Gpc. However, their brightness is hard to predict; the Tully–Fisher relation gives some approximate information. • Type 1a supernova work as standard candles at very high distances; they are standardized because they are all produced by white dwarfs in binary star systems passing the Chandrasekhar limit. Studies of supernova in the late 90’s established that the expansion of the universe was accelerating, pointing to the existence of dark energy. 1.3 Dynamics Next, we consider the matter content of the universe. • We begin with a simpler case. Consider a set of particles with four-velocity uµ. We define the number current N µ, where n = N 0 is the number density and N i is the number flux. Then N µ = nu µ and the conservation law ∇µN µ = 0 implies n(t) ∝ a−3. 11 1. Geometry and Dynamics • Next, consider a perfect fluid, with energy-momentum tensor T µν = (ρ + p)u µu ν − pgµν. The components of the tensor with mixed indices are simple, T µ ν = diag(ρ, −p, −p, −p). • The conservation of the stress-energy tensor, ∇µT µν = 0, gives four conservation equations. The component ν = 0 gives the energy conservation equation ˙ρ + 3 ˙a a (ρ + p) = 0 in the FRW metric. This may also be derived using dU = −pdV , where U = ρV and V ∝ a3. • Most cosmological substances obey the equation of state p = wρ, where ρ ∝ a−3(1+w) by the above. Matter refers to anything with w ≈ 0, including baryonic matter and dark matter. Then ρ ∝ a−3, which can also be found using number conservation. • Radiation refers to anything with w ≈ 1/3, which holds for gases of ultrarelativistic particles, such as neutrinos in the early universe, and gases of massless particles, such as photons and gravitons; this result may be derived for photons by noting that T µν is traceless, because the Maxwell action is conformally invariant. Then ρ ∝ a−4, with the extra factor due to cosmological redshift. • An additional component with w < −1/3, known as dark energy, is required to account for the accelerating expansion of the universe; measurements indicate that w = −1.03 ± 0.03. A cosmological constant has w = −1, and hence a constant energy density ρ ∝ a0, and it may arise in QFT from vacuum energy density, which is not diluted by expansion. Other models of dark energy, such as slowly rolling scalar fields, can have w ≈ −1, but for concreteness we’ll take w = −1 exactly. • Fluids with p = wρ have linear dispersion relations, with a speed of sound of √w. Hence we require w ≤ 1 to preserve causality. Alternatively, the NEC requires |w| ≤ 1. • Evidently sound waves do not exist for w < 0, as the medium would be unstable; this is not a problem for vacuum energy since it doesn’t allow fluctuations in p and ρ in the first place. • Note that energy densities due to ordinary matter must be positive, since negative energy densities would imply that vacuum would be unstable against decay. On the other hand, given this fact, the vacuum energy can be negative, giving a negative dark energy, because by definition it cannot decay. In order to find how the scale factor evolves, we have to evaluate the Einstein tensor. • The calculation is simplified using symmetry. By isotropy, we know that Ri0 = 0, or else it would give a distinguished 3-vector. Similarly, Rij must be proportional to gij, since there are no distinguished tensors, and by homogeneity the proportionality constant must be the same everywhere. 12 1. Geometry and Dynamics • Using the Christoffel symbols computed earlier easily gives R00 = −3 ¨a a . • To compute Rij, we work at x = 0. The spatial metric is γij = δij + kxixj 1 − k(xkxk) = δij + kxixj + O(x 4) and we only need to maintain terms up to quadratic order in x, because the Ricci tensor only contains second derivatives of the metric. We then have Γ i jk = 1 2 γiℓ(∂jγkℓ + ∂kγjℓ − ∂ℓγjk) = 1 2 (δiℓ − O(x2))(2kδjkxℓ) = kx iδjk where we again threw away higher-order terms in x because the Ricci tensor only contains first derivatives of the connection. Straightforwardly plugging in gives Rij = − ( ¨a a + 2 ( ˙a a )2 + 2 k a2 ) gij. • Therefore, the Ricci scalar is R = −6 ( ¨a a + ( ˙a a )2 + k a2 ) . This implies the Einstein tensor with mixed indices is G0 0 = 3 (( ˙a a )2 + k a2 ) , G ij = ( 2 ¨a a + ( ˙a a )2 + k a2 ) δi j. • The Einstein field equations are the Friedmann equations, ( ˙a a )2 = 8πG 3 ρ − k a2 , ¨a a = − 4πG 3 (ρ + 3p). The second is also called the acceleration equation; we’ve already seen it in the context of the Raychaudhuri equation in general relativity, where energy density and pressure cause geodesics to contract. The first Friedmann equation is also called the Friedmann equation. Note. A Newtonian derivation of the Friedmann equation. Consider space filled with matter of density ρ, and a mass a distance r from an arbitrary center. Then conservation of energy gives 1 2 m ˙r2 − Gmρ r 4πr3 3 = E. Defining r(t) = a(t)R0, where R0 = r(0), we may eliminate r to find, ( ˙a a )2 = 8πG 3 ρ + 2E mR2 0 1 a2 13 1. Geometry and Dynamics which is simply the Friedmann equation up to some redefinitions. How could this approach work, when the expansion of space is a relativistic effect? In patches over which the curvature is negligible, Newtonian gravity gives the same results as relativity. And because the expansion of the universe is homogeneous, we can take a patch of any size, so we simply work in one sufficiently small for Newtonian gravity to hold. Of course, the derivation only works for matter-domination; radiation and dark energy have no natural Newtonian analogue. In the Newtonian picture, closed and open universes correspond to negative and positive total energy, which makes it clear that a closed universe can’t have a(t) → ∞. (This remains true when radiation is included, but is not true if there is dark energy.) Roughly speaking, the density determines the amount of potential energy, the current Hubble constant determines the amount of kinetic energy, and the critical density is where the total energy is zero. Note. Why does the expansion of the universe not expand ordinary matter, such as people, planets, or galaxy clusters? The usual answer is that the expansion of the universe is a force pulling everything apart, but objects can resist this force by attraction. However, this is misleading. To see why, consider the case of a matter-dominated universe. In the FRW metric, it doesn’t make sense to say the matter particles are being pulled apart, because they simply follow geodesics, which experience no force by definition. Thus, any statement about forces must implicitly be in the Newtonian picture. In the Newtonian picture explained above, which is valid on patches much smaller than the curvature scale, the expansion of the universe is simply due to an initial outward velocity, and does not correspond to a force. If you hollow out a sphere in an expanding Newtonian universe, and put two objects inside it at rest with respect to each other, they’ll stay that way forever. (Of course, the same result can be obtained in a fully relativistic calculation: hollowing out a sphere changes the metric, which changes the geodesics. It’s just that showing this explicitly would be totally intractable.) However, the usual answer is correct when dark energy is present. In the Newtonian picture, a positive dark energy density has the same effect as a uniform, omnipresent negative matter density. This creates a gravitational field that directly repels matter particles away from each other, and which must be balanced by an attractive force. Note. In a closed universe, the total electric charge must be zero, because the electric field lines have nowhere to end. Alternatively, one can cover the universe with two patches, and the electric flux going out of one patch equals the flux going into the other; then the total charge vanishes by Gauss’s law. One can also argue similarly that the total energy vanishes in a closed universe. To see this here, rearrange the Friedmann equation by multiplying by M a2 for M ˙a2 + M − 8π 3 GρM a2 = 0 where M is the total mass. Using M = ρV and V = 2π2a3, we have M ˙a 2 + M − 4 3π GM 2 a = 0. Then the Friedmann equation can be interpreted as the statement that the kinetic energy, mass energy, and gravitational potential energy sum to zero. We didn’t get this result in the Newtonian picture, because there we didn’t count the mass energy. Note. One needs to be careful to keep track of the dimensions. In our relativistic derivation of the Friedmann equation, the curvature term was −k/a2, the scale factor had dimensions of length, and 14 1. Geometry and Dynamics k ∈ {−1, 0, 1}. If we rescale the scale factor to be dimensionless, with a(t0) = 1, then the Friedmann equation must pick up factors of R0 to balance the dimensions, ( ˙a a )2 = 8πG 3 ρ − k R2 0a2 . which is just what we saw in our Newtonian derivation. We can thus either maintain k ∈ {−1, 0, 1}, or perform a further redefinition ˜k = k/R2 0 so that ˜k has dimensions. Unfortunately, many sources do this wrong and write down equations that are dimensionally inconsistent. Next, we consider the dynamics of some model universes, using dimensionless a(t) and k. • It is conventional to define H0 = 100 h kms−1Mpc −1 = 2.17 × 10 −20 s−1, h = 0.67 ± 0.01. A flat universe has the “critical density” ρc,0 = 3H 2 0 8πG = 1.9 × 10 −29h 2 g/cm3 = 8.5 × 10 −27 kg/m3 and universes with higher or lower density are closed or open, respectively. Note that the critical density is a function of time. • We define dimensionless density parameters by dividing by the critical density, giving H 2(a) = H 2 0 (Ωr,0a−4 + Ωm,0a −3 + Ωk,0a−2 + ΩΛ,0) . We conventionally drop the ‘0’ subscripts on the density parameters. Here Ωk is the effect of the curvature, Ωk = − k (a0H0R0)2 which we formally treat as a contribution to the density with w = −1/3, and Ωr + Ωm + Ωk + ΩΛ = 1. However, note that the total energy density is actually Ω = 1 − Ωk. • Rearranging, we have ˙a = H0√ Ωra−2 + Ωma−1 + Ωk + ΩΛa2. Thus for the purposes of intuition, we can use the Newtonian picture above, where Ωm behaves like Newtonian matter, and ΩΛ is a repulsive spring. • Note that we’ve defined the density parameters to be time-independent above for convenience. It’s also sensible to talk about time-dependent density parameters, by dividing by ρc(t). • Current observations indicate |Ωk| ≤ 0.01, Ωr = 9.4 × 10 −5, Ωm = 0.32, ΩΛ = 0.68 and the matter splits into baryonic and cold dark matter (CDM) as Ωb = 0.05, Ωc = 0.27. Only a small part of the radiation contribution is from stars; most is from the CMB and the cosmic neutrino background. 15 1. Geometry and Dynamics • We see the curvature parameter is unimportant now and hence was even less important in the past, so we will just set Ωk = 0 below. • The fact that ΩΛ has just recently passed Ωm is called the ‘cosmic coincidence problem’, since the ratio Ωm/ΩΛ ∝ 1/a3 varies by many orders of magnitude. • If we only have a single matter component, then ˙a a = H0√Ω a −(3/2)(1+w). This implies the following dependence: a(t) ∝    t2/3 matter t1/2 radiation eHt Λ a(τ ) ∝    τ 2 matter τ radiation −1/τ Λ This is often good enough, because the history of the universe can be divided into a time where radiation was dominant, a time where matter was dominant, and a time where the cosmological constant is dominant. We have only recently entered this third era, which is a minor theoretical puzzle. The matter-dominated case is known as the Einstein–de Sitter universe. • Note that in the case of Λ only, the universe would be infinitely old. This is the steady state theory of cosmology in another guise, replacing the spontaneously created matter replaced with dark energy. Example. Consider a universe, not necessarily flat, with matter and dark energy, which is a good model for our universe today. If ΩΛ > 0, then the expansion is accelerated; in particular, the scale factor can grow arbitrarily large even if the universe is closed. On the other hand, if ΩΛ < 0, then the scale factor will always reach a maximum and begin to decrease, regardless of whether the universe is open or closed, ending in a ‘big crunch’. For our universe, ΩΛ is high enough that, regardless of the sign of the small quantity Ωk, the universe will continue to expand forever. Example. Consider a flat universe with matter and radiation; this describes the crossover period in the early universe. The simplest method is to work with conformal time, where the Friedmann equations become (a′) 2 = 8πG 3 ρa 4, a ′′ = 4πG 3 (ρ − 3p)a3 which is convenient because radiation does not contribute to a′′ at all. The density is ρ = ρm + ρr = ρeq 2 (( aeq a )3 + ( aeq a )4) , aeq = Ωr Ωm ≈ 3 × 10 −4. Now the second equation can be simply solved, a′′ = 2πG 3 ρeqa 3 eq, a(τ ) = πG 3 ρeqa3 eqτ 2 + Cτ + D. We impose a(τ = 0) = 0, so D = 0, and by using the first Friedmann equation, a(τ ) = aeq (( τ τ⋆ )2 + 2 τ τ⋆ ) , τ⋆ = ( πG 3 ρeqa 2 eq )−1/2 = τeq √2 − 1 . Thus for low and high τ we recover the appropriate limits. 16 1. Geometry and Dynamics Note. All of our examples have a Big Bang singularity where the scale factor is zero. One might think this is just an artifact of demanding homogeneity and isotropy; however, cosmological singularity theorems indicate that a singularity is generic, assuming certain conditions on the matter. Of course this does not mean a singularity necessarily exists, since at this point quantum gravity takes over. Example. In the Einstein static universe, a(t) is constant. This requires the right-hand sides of both Friedmann equations to vanish, so ρ + 3p = 0. Assuming the pressure and density are nonzero, Einstein could satisfy this equation by letting ΩΛ = 1 2 Ωm. The resulting spatial curvature parameter k is nonzero. The Einstein static universe is not realistic, but it remains a useful tool for constructing conformal diagrams. Example. The Milne universe. Consider an open universe with k = −1 and nothing else. The Friedmann equation reduces to ˙a2 = 1, which has a solution a(t) = t. The metric is then ds 2 = dt2 − t 2(dχ 2 + sinh2 χ dΩ2). On the other hand, we would expect that an isotropic matter-free solution to Einstein’s equations must be Minkowski space. In fact, we can regard the Milne spacetime as a subset of Minkowski space. Starting with ds2 = dτ 2 − dr2 − r2dΩ 2 we arrive at the Milne universe if τ = t cosh χ, r = t sinh χ. To interpret this, consider observers which start from the origin in Minkowski space, each with constant velocity. For the observer with velocity v, v = r τ = tanh χ. The proper time elapsed for this observer is √ 1 − v2 τ = t. Then the Milne universe describes observers moving uniformly outward from the origin of Minkowski space, with proper time t and their velocity labeled by χ. Note that constant timeslices of the Milne universe have constant 3-curvature. However, since it is part of Minkowski space, it has vanishing 4-curvature. This is an important lesson to keep in mind: the 3-curvature is not determined by the spatial part of the 4-curvature. Stepping back, it seems strange that we could describe the same spacetime as either k = −1 with a(t) = t, or as Minkowski space, which has k = 0 and a(t) = 1. The reason this is strange is that homogeneity restricts the choice of foliation of a spacetime to those with uniform energy density. In this unusual case there is zero energy density, and hence much greater freedom; the other spacetimes above generally can’t be understood this way. 17 1. Geometry and Dynamics Example. A similar situation occurs for de Sitter space, which contains only a cosmological constant. By the acceleration equation alone, we have ¨a = H 2 0 a, H 2 0 = 8πGρ 3 . This gives the general solution a(t) = C1e H0t + C2e −H0t. Plugging this into the Friedmann equation, we have 4H 2 0 C1C2 = k. This means that the form of the solution is different for different k, ds 2 = dt 2 − H −2 0 (dχ 2 + S2 k(χ)dΩ2) ×    sinh 2(H0t) k = −1 e2H0t k = 0 cosh2(H0t) k = 1 . However, because the energy density due to the cosmological constant is constant in time, all three of these are merely different foliations of the same spacetime, by homogeneous and isotropic hypersurfaces with different curvatures. Another way to construct de Sitter space is to embed it as a hyperboloid in five-dimensional Minkowski spacetime, as shown in the notes on General Relativity. 18 2. Inflation 2 Inflation 2.1 Motivation To understand the motivation for inflation, we consider the causal structure of our universe. • We work in conformal time, so light rays are at 45◦ when plotting χ and τ . Let the initial and final conformal time of our universe be τi and τf . Note that τf may be finite even if the universe never ends in ordinary time; it is indeed finite for the standard model of our universe. • The particle horizon at time τ is bounded by χph(τ ) = τ − τi = ∫ t ti dt a(t) . Only events inside the particle horizon could have affected us. In other words, we can only see effects from events inside the particle horizon. (If we are interested in the furthest distance we could see light from, the lower bound should be the recombination time, as before this time the universe was opaque to photons; however, in practice this makes little difference.) • The event horizon at time τ is bounded by χeh(τ ) = τf − τ = ∫ tf t dt a(t) . It is analogous to the event horizon for black holes, and bounds the spatial regions we can affect in the future. A numerical calculation shows that for the concordance model, objects that we can just reach in the future currently have a redshift of about 1.8. • Note that we may write χph(τ ) = ∫ t ti dt a = ∫ a ai da a ˙a = ∫ log a log ai d log a aH . We call the comoving Hubble radius (aH)−1, and it defines a comoving Hubble sphere. • To understand its physical meaning, consider sending signals to an observer a comoving distance d away. If d is small, then the signal takes about time d to arrive, during which time the observer moves away by d2 ˙a. This is a small correction if d2 ˙a ≪ d, which implies d ≪ 1/ ˙a = (aH)−1. Hence the Hubble sphere contains observers we can actively communicate with “now”, sending messages back and forth in roughly less than a Hubble time. Then it is intuitive that χph is found by summing it over Hubble times. • For a perfect fluid, we have (aH)−1 = H −1 0 a(1+3w)/2. All familiar forms of matter obey the SEC, which states 1 + 3w > 0. Dark energy does not, but it is less important in the early universe. Hence the comoving Hubble radius should have monotonically increased in the early universe. 19 2. Inflation • In particular, the integral for χph is dominated by its upper bound. Explicitly, we have χph(a) = 2H −1 0 1 + 3w (a (1+3w)/2 − a (1+3w)/w i ) ≡ τ − τi where τi = 0 since ai = 0, giving χph ∼ (aH) −1 up to O(1) prefactors; the latter is sometimes called the “Hubble horizon”. • This leads to a problem, because then χph is too small for different regions of the CMB to have ever been in causal contact. To estimate the number of causal patches, note that χph(aCMB) χph(a0) ≈ √ aCMB a0 ≈ √1100 where we used the fact that the universe has been matter dominated since CMB formation. Then the angular extent of a patch is 1/ √1100 ≈ 1.7◦, giving about 104 causally disconnected patches. The horizon problem asks why they “know” to be at the same temperature. This problem is made even worse by modern CMB observations, which indicate correlations between points in the CMB at scales much larger than 1.7◦. These problems can be addressed by a shrinking Hubble sphere. • The essence of the problem is that we want to set χph ≫ (aH)−1, which means we need a shrinking Hubble sphere, which requires a fluid that violates the SEC. • Given an era with a shrinking Hubble sphere, it is perfectly possible for opposite ends of the CMB to have been in causal contact, because as a → 0, we have τ → −∞, giving a large range of conformal time to work with. • Inflation postulates such an era, occupying negative conformal time. The “Big Bang” corre- sponds to the end of inflation, conventionally zero conformal time, at which point the Hubble sphere begins to expand again. A Minkowski diagram of the situation is shown below. 20 2. Inflation Recently, the Hubble sphere has begun to shrink again due to dark energy. • A standard criterion to check if there is ‘enough’ inflation is (aI HI )−1 > (a0H0)−1 which means that anything we are in causal contact with now, we were also in contact with in the past. This is slightly weaker than (aI HI )−1 > χph, but easier to evaluate. • To estimate the amount of inflation needed, note that H ∝ a−2 during radiation domination; we focus on this period since most of the expansion occurred during it. Letting an E subscript stand for the exit of inflation, a0H0 aEHE = aE a0 = T0 TE ∼ 10 −28 where we assumed that after inflation ends, we reheat to a high (e.g. GUT) scale, TE ∼ 10 15 GeV, T0 = 10 −3 eV = 2.7 K. • For simplicity, suppose H is approximately constant during inflation. Then we require aEHE aI HI ≈ aE aI > 10 28 which implies at least Ntot > log 10 28 = 64 e-folds during inflation. A more accurate accurate comes from the largest scales observed in the CMB, which have to be created Ncmb = 60 e-folds before the end of inflation. 21 2. Inflation • This leads to the standard statement that inflation must last for at least 60 e-folds. However, many assumptions go into this result. We could get less strict bounds by assuming we reheat to substantially lower than TE, or, e.g. including a period of early matter domination. But 60 is a standard benchmark because the simplest models of inflation end up satisfying the standard assumptions. • Inflation can last for much longer than 60 e-folds, and indeed does in many simple models, but it is the last 60 e-folds which create the cosmological perturbations we see today. (More precisely, the scales we can observe in the CMB correspond to perturbations created around 50 to 60 e-folds before the end of inflation.) Note. The flatness problem is that the universe is observed to be very close to flat today, with |Ωk| ≪ 1. The severity of this problem is more apparent if we consider how the density parameters evolve in time. If the universe is very nearly flat, then Ωk ∝ 1 ˙a2 ∝ { t2/3 matter domination t radiation domination . That is, Ωk is constantly growing, so if we extrapolate back naively to the Planck scale, we must have an initial condition of Ωk ∼ 10−60, which seems unnatural. Inflation solves this problem because, during the period of inflation, Ωk shrinks exponentially. Note. Inflation doesn’t solve the horizon problem by letting the thermal plasma reach equilibrium during it. In most models of inflation, there isn’t a thermal plasma present at all during inflation; there’s just the energy in the inflaton field. (However, “warm inflation” does have such a plasma, which can significantly change the dynamics of the inflaton.) Inflation solves the horizon problem by making the inflaton field itself homogeneous, which then automatically produces a homogeneous plasma during reheating. Next, we consider some equivalent conditions for inflation. • We note that d dt (aH) −1 = d dt 1 ˙a = − ¨a ( ˙a)2 . Hence inflation corresponds to a period of accelerating expansion. • Alternatively, note that d dt (aH)−1 = − ˙aH + a ˙H (aH)2 = − 1 a (1 − ϵ), ϵ = − ˙H H 2 . Hence inflation occurs for ϵ < 1, which corresponds to a slowly decreasing Hubble parameter. In fact, as we’ll see below, we actually have ϵ ≪ 1 in most inflationary models. • In the case of perfect inflation, ϵ = 0, the scale factor increases exponentially, and ds2 = dt 2 − e 2Htdx2. Hence during inflation, the spacetime is approximately de Sitter. A bit more carefully, the very early, inflationary universe is approximately the same as a small slice of de Sitter space; the two have very different global structure. 22 2. Inflation • Using the continuity equation, we can show ϵ = 3 2 ( 1 + P ρ ) < 1 so inflation requires w < −1/3, as we saw earlier, and hence negative pressure. In most inflationary models we have w ≈ −1, which is needed to recover the observed primordial perturbations. • Again using the continuity equation, we can show ∣ ∣ ∣ ∣ d log ρ d log a ∣ ∣ ∣ ∣ = 2ϵ < 1 so for small ϵ, the energy density is nearly constant. • Let N be the cumulative number of e-folds. Using dN = d log a = H dt, we can rewrite ϵ in the useful form ϵ = − d log H dN . We already know ϵ < 1 during inflation, and that inflation requires about N = 60, so ϵ itself must also change slowly. That is, we require η = d log ϵ dN = ˙ϵ Hϵ , |η| ≪ 1. Our task below will be to construct a model with both ϵ and η appropriately small. Note. A notational subtlety. When we say the expansion of the universe is accelerating, we mean ¨a > 0, and equivalently the Hubble sphere is shrinking. However, this is not equivalent to ˙H > 0. In fact, at the current moment we have ¨a > 0 but ˙H < 0. The former means that a fixed object is moving away from us faster and faster, while the latter means that the objects present at a fixed distance will move away from us slower and slower. 2.2 Slow Rolling We now consider a simple explicit model of inflation. • We postulate a scalar field, called the inflaton ϕ, with potential V (ϕ) and stress-energy tensor Tµν = ∂µϕ∂νϕ − gµν ( 1 2 gαβ∂αϕ∂βϕ − V (ϕ) ) . By homogeneity, ϕ can only depend on t, so we have T 0 0 = ρϕ = 1 2 ˙ϕ2 + V (ϕ), T i j = −pϕδi j, pϕ = 1 2 ˙ϕ2 − V (ϕ). Therefore, if the potential energy dominates over the kinetic energy, the scalar field behaves like a fluid with w = −1, which may lead to accelerated expansion. (If kinetic energy dominates, we have w = 1, and an energy density redshifting as a−6. In homage to inflation, a period of kinetic energy domination is called “kination”.) 23 2. Inflation • Substituting this into the Friedmann equations and defining the (reduced) Planck mass Mpl = √ℏc/8πG = 2.4 × 10 18 GeV/c 2, and working in units where ℏ = c = 1, we have H 2 = ρ 3M 2 pl = 1 3M 2 pl ( 1 2 ˙ϕ2 + V ) , ˙H = − ρ + p 2M 2 pl = − 1 2 ˙ϕ2 M 2 pl . We note that ˙H is sourced by the kinetic energy alone. • Next, differentiating the first equation gives 2H ˙H = 1 3M 2 pl ( ˙ϕ ¨ϕ + V ′ ˙ϕ) where V ′ = dV /dϕ, and using the second Friedmann equation gives the equation of motion ¨ϕ + 3H ˙ϕ + V ′ = 0. The expansion of the universe adds “Hubble friction”. Intuitively this is because it is “diluting” the field momentum. • Substituting into the definition of ϵ, we have ϵ = ˙ϕ2/2 M 2 plH 2 so we again see that inflation occurs if the kinetic energy is small; this situation is called slow roll inflation. • For inflation to persist, we requires |η| ≪ 1, and it is convenient to define δ = − ¨ϕ H ˙ϕ which is the dimensionless acceleration per Hubble time. By rearranging our equations, we find η = 2(ϵ − δ), so |η| is indeed small if ϵ and |δ| are. In order to make more analytic progress, we take the slow roll approximation. • In the slow roll approximation, we take the Hubble parameter to be entirely determined by the potential energy because ϵ ≪ 1, so the Friedmann equation becomes H 2 = V 3M 2 pl . Also, since |δ| ≪ 1, we approximate the field’s equation of motion as 3H ˙ϕ ≈ −V ′. The initial ˙ϕ might not obey this, but it approximately will within O(1) Hubble time. 24 2. Inflation • Next, we use these assumptions to compute ϵ and δ. Combining the equations, we have ϵ ≈ M 2 pl 2 ( V ′ V )2 . Differentiating the equation of motion gives 3 ˙H ˙ϕ + 3H ¨ϕ ≈ −V ′′ ˙ϕ which implies that δ + ϵ ≈ M 2 pl V ′′ V . Therefore, the approximation is self-consistent as long as the slow roll parameters ϵv = M 2 pl 2 ( V ′ V )2 , |ηv| = M 2 pl |V ′′| V are both small. In this case, ϵv ≈ ϵ and ηv ≈ 2ϵ − η/2, so ϵ and |η| are both small as desired. These parameters are useful because they can be computed from the inflaton potential alone. • The number of e-folds of accelerated expansion is given by Ntot = ∫ d log a = ∫ H dt = ∫ H ˙ϕ dϕ = ∫ 1 √2ϵ dϕ Mpl . In order to simplify this, we replace ϵ with ϵv for Ntot = ∫ V M 2 plV ′ dϕ which may be computed from the inflaton potential alone. We take inflation to end when ϵv = 1, and take an initial field value ϕI . Example. Inflation driven by a mass term, V (ϕ) = 1 2 m2ϕ2. The slow roll parameters are ϵv = ηv = 2 ( Mpl ϕ )2 so inflation in this model requires super-Planckian values for the inflaton; one can show this also holds for power law potentials V ∝ ϕp. The number of e-folds is N (ϕI ) = ϕ2 I 4M 2 pl − 1 2 and the fluctuations observed in the CMB are created at ϕCMB ≈ 2 √NcmbMpl ∼ 15Mpl. We require the energy density to not be near the Planck scale, or else unknown quantum gravity effects will become relevant; this yields the constraint m ≪ Mpl/15. On the other hand, we always get super-Planckian field values, which can also be argued to be problematic from a UV perspective. For example, in the paradigm of effective field theory, one would expect additional Planck-suppressed operators to appear, which would significantly change the potential, e.g. increasing the inflaton’s mass. This is called the “eta problem”, and is analogous to the hierarchy problem for the Higgs. Another related problem occurs for ultralight axions, which receive quantum gravitational corrections to their potential. 25 2. Inflation Next, we briefly discuss what happens after inflation. • During inflation, most of the energy density of the universe is in the form of the inflaton potential. At the end of inflation, this energy has been mostly converted to the kinetic energy of the inflaton field. Reheating is the process by which energy is transferred from the inflaton field to the particles of the SM, thereby starting the hot Big Bang. • First, note that after inflation, the inflaton field begins to oscillate at the minimum of its potential. Approximating V (ϕ) = m2ϕ2/2 near the minimum, we have ¨ϕ + 3H ˙ϕ = −m2ϕ. The expansion timescale soon becomes much larger than the oscillation period, H −1 ≫ m−1, so we can neglect the friction term; the field then oscillates with frequency m. • The energy continuity equation gives ˙ρϕ + 3Hρϕ = −3Hpϕ = − 3 2 H(m 2ϕ2 − ˙ϕ2) and the right-hand side averages to zero over one oscillation period. Then the oscillating field behaves like pressureless matter, with ρϕ ∝ a−3. This is because a spatially uniform massive field can be viewed as a condensate of massive particles at rest. The fall in the energy density is reflected by a decrease of the oscillation amplitude. • Note that there are other possibilities, depending on the potential. For example, if the potential has the form V ∝ ϕn, then w ≈ (n − 2)/(n + 2). If the potential is convex, such as V ∼ log(|ϕ|/ϕc|), then we have w ≈ −1 even after slow roll ends. This is because the oscillating scalar field spends most of its time near the potential walls, where the kinetic energy is negligible. If the potential is exponential, then the slow roll conditions are either always or never satisfied, so such a potential is unsuitable. • In order to transfer energy to SM particles, the inflaton must couple to other fields, so it can decay. Supposing the decay is slow, we have ˙ρϕ + 3Hρϕ = −Γϕρϕ. However, if the inflaton can decay into bosons, the decay can be very rapid, involving a mechanism called parametric resonance due to Bose condensation effects. This kind of rapid decay is called preheating, since the bosons are created far from thermal equilibrium. • The next step is thermalization. The particles created by inflaton decay interact, and perform further decays, until we arrive at a thermal soup of particles at temperature Trh. This marks the start of the hot Big Bang. • Note that some particles, such as gravitinos, might never reach thermal equilibrium. However, as long as their energy density is high, they will behave like radiation regardless. We only require thermalization of the baryons, photons, and neutrinos. Note. Inflation also solves the monopole problem. Grand unified theories (GUTs) generally predict monopoles should be formed during the GUT phase transition in the early universe, as they are 26 2. Inflation topological defects. We expect one topological defect per Hubble sphere, which yields a huge amount in the naive Big Bang model; it implies most matter should be made of magnetic monopoles today. Inflation solves this problem because, if the GUT phase transition occurs before or during inflation, then the monopoles are diluted away. Note that this requires that reheating does not yield a temperature above the GUT scale, but this is not a strong constraint on most models. Of course, if one doesn’t believe in GUTs, then the monopole problem is not an issue. Note that all three problems that inflation solves can be phrased as naturalness problems, having to deal with initial conditions. The flatness problem is closely related to the cosmological constant problem and has a similar anthropic solution. If one doesn’t like naturalness problems, then the most compelling argument for inflation today is that it predicts the primordial perturbations observed in our universe, as we will show later. Note. We’ve been careful to avoid conflating dark energy, vacuum energy, and the inflaton. Dark energy is a hypothetical substance with w ≈ −1 that drives the current accelerating expansion of the universe. Vacuum energy is a natural candidate for dark energy, and has w = −1 exactly. However, there are also dynamical models for dark energy (such as quintessence) where it can be sourced by a slowly rolling scalar field. This is the same basic mechanism as inflation, though the inflaton field is likely not related. In this case, w would deviate slightly from −1. Currently, the value of w is not measured very precisely. Note. What is the inflaton? In the simplest models, it is simply a single new scalar field. It could also be a scalar condensate of fermionic particles. It is also possible to have Higgs inflation, where the inflaton is the Higgs field itself. Yet another possibility is an extension of general relativity. For example, in f (R) gravity, one replaces the term R in the Einstein–Hilbert action with a general function f (R). Often such theories are conformally equivalent to general relativity with an additional scalar field, which can serve as the inflaton. For example, in Starobinsky inflation we have f (R) = R + R2 6M 2 . Axion-like particles such as the QCD axion could serve as the inflaton. More generally, string theory also provides many inflaton candidates. 2.3 Models of Inflation First, we cover the historical development of inflation. • In Guth’s original model of inflation, now called “old inflation”, the inflaton begins trapped in a false vacuum, during which its energy density drives inflation. The field may tunnel through the barrier, leading to the growth of “bubbles” of true vacuum. If bubble nucleation is too rare, then inflation is eternal, because the space in between the bubbles continues to grow exponentially. If the nucleation rate is high enough, the bubbles eventually percolate through the universe, in analogy to how ice crystals grow through a freezing liquid. However, when the bubbles collide, they produce strong inhomogeneities that undo the solution to the horizon problem. This is the “graceful exit problem”. • Another way of saying this is that to achieve graceful exit, one needs a “clock” measuring the “amount of inflation left” throughout the universe. Yet another way is that, without a clock, one has perfect de Sitter space – and as we saw earlier, perfect de Sitter space has foliations where it is shrinking, not expanding! Without a clock, one can’t explain expansion at all. 27 2. Inflation • Old inflation was motivated by phase transitions in the SU (5) GUT. Generically, such GUTs have a Higgs field which has a global potential minimum at φ = 0 for high temperatures. For lower temperatures, this minimum becomes only a local minimum, leading to a first order phase transition. • In “new inflation”, which is the framework we’ve used above, inflation occurs during a phase of slow rolling, without the need for bubble nucleation. For example, it can occur if we start from a very flat maximum near φ = 0. The uniform field value functions as the clock. • In both cases, the universe was regarded as existing in thermal equilibrium throughout inflation, beginning with a standard Big Bang. In the case of new inflation, the inflaton ends up at the top of a maximum because of symmetry restoration due to high temperature. • The first models that broke away from this assumption were chaotic inflation models, which simply used polynomial potentials. For inflation to work, one requires very high initial field values, which are justified by postulating “chaotic” initial conditions with Planckian energy densities. For example, we assume V (ϕ) ∼ M 4 pl, ˙φ2 ∼ (∇φ) 2 ∼ M 4 pl, R ∼ M 2 pl where R is the Ricci scalar. This is the default way of thinking in inflation today. • Depending on who one asks, there might be an “initial patch problem”, i.e. one needs a Planckian patch which is already sufficiently homogeneous, so that it can get started inflating before collapsing. But assuming this process can begin, inflation could then the patch more homogeneous, extracting a set of homogeneous universes from the chaotic initial conditions. The dynamics of this murky initial period were divined by “quantum cosmologists”, a secretive sect which contemplated deep metaphysical notions such as “the wavefunction of the universe”. • Today, “chaotic inflation” and “new inflation” are typically used to describe the shape of the potential; they are pure polynomials or have an extended flat region, respectively. The graceful exit problem is solved by the theory of reheating. • A more recent distinction is between “small-field” and “large-field” inflation, depending on whether the field displacement of the instanton is less than or more than the Planck mass. New inflation and chaotic inflation are small-field and large-field respectively. Large-field inflation predicts larger, possibly soon observable tensor perturbations, but the inflaton potentials could be unstable against quantum gravitational corrections. • One elegant family of inflation models is natural inflation, where the potential takes the form V (ϕ) = V0 ( 1 + cos ϕ f ) . This often arises if the inflaton is taken to be an axion. This is useful in large-field inflation because the shift symmetry of the axion can be used to protect the potential from corrections. • Small-field inflation is a bit trickier, since for a single inflaton field, one needs to reliably produce a flat part of the potential. However, it is straightforward to realize small-field inflation using multiple fields. For example, in “hybrid inflation”, there is an inflaton ϕ and a “waterfall” field σ, and the potential is such that σ is still while ϕ rolls, until it suddenly begins to roll rapidly. 28 2. Inflation • Many models of inflation generically predict eternal inflation. To understand eternal inflation, we consider the fate of one Hubble patch during an e-fold of expansion, where the volume increases by a factor of e3 ∝ 20. Quantum fluctuations mean that some of the new patches have a higher value of the inflaton field than the original patch. Hence inflation can continue in these patches, and extends infinitely into the future. The universe acquires a ‘fractal’ structure. • To be more quantitative, we consider our explicit model above. During a Hubble time, ∆ϕ ∼ ˙ϕ H ∼ V ′ H 2 ∼ M 2 pl V ′ V ∼ M 2 pl ϕ . On the other hand, the scale of quantum fluctuations is |δϕ| ∼ H 2π ∼ mϕ Mpl . Therefore, the quantum fluctuations dominate when ϕ > Mpl √ Mpl m . Or, phrased in terms of the potential and H, this occurs when V ′ ≲ H 3. • We see that we can avoid eternal inflation if we simply take m small and postulate an appropriate initial condition. However, if we take chaotic initial conditions with Planckian energy densities, the inequality above is automatically satisfied, leading to eternal inflation. Depending on taste, one can ensure eternal inflation to facilitate anthropics or forbid it. • One could say that eternal inflation isn’t a problem because observable quantities depend on only the last 60 e-folds of inflation. However, the “measure problem” creates issues in calculating probabilities, since all denominators are infinite. The standard way around this in science is to declare a cutoff and compute probabilities within it, and then take the limit where the cutoff is removed, but this procedure is ambiguous. For example, naively 1/2 of the integers are even, but if one orders the integers in an alternate way, we can have any fraction of the first N integers be even. The same applies for the ‘pocket universes’ of eternal inflation; since they are spacelike separated, the time ordering is arbitrary, so predictions are arbitrary. • If one simply fixes a naive time ordering, e.g. in synchronous gauge, one runs into the youngness paradox: almost all universes are very young. For example, if one conditions on our existence, with a uniform prior on all universes created to date, then we should have evolved “as quickly as possible”, and there can be no older alien civilizations. One can avoid this by using a prior that weights on volume, or various others, but there is no canonical prescription. Next, we consider more recent news. • The CMB was mapped by COBE in the 1990s. COBE confirmed that the CMB spectrum was very close to a blackbody spectrum, and detected small anisotropies. • In the 2000s, WMAP measured the CMB more precisely, confirming more predictions of inflation. In particular, the CMB perturbations are consistent with being adiabatic (vs. isocurvature) and gaussian, with an approximately scale-invariant power spectrum. Curvature fluctuations, 29 2. Inflation which are measured by the multipole moments of the CMB’s fluctuations, were also found to be consistent with the inflationary paradigm. Finally, WMAP measured the parameters in the standard ΛCDM model and found the universe to be nearly flat, consistent with inflation. • Two parameters that describe the fluctuations in the CMB are the tensor-to-scalar ratio r and the primordial tilt ns, which quantifies scale-invariance. WMAP found that r < 0.6 and ns ≈ 1. Inflation generically predicts r ̸= 0 and ns ≈ 1, where r varies strongly between models. • A nonzero value for r indicates the presence of primordial gravitational waves, thought of as a unique signature of inflation. In 2012, the telescope BICEP2 reported a measurement of r ≈ 0.2, disfavoring r = 0 at 7σ, but the significance was removed once galactic dust was accounted for. • Note that there also exist more complicated inflationary models where the perturbations are not adiabatic, not gaussian, or not nearly scale-invariant. In fact, there even exist inflationary models that don’t predict flatness! However, these models are generally quite complicated; we’ll focus on the simpler models. • The Planck satellite measured the CMB in the 2010s, and found parameters that were uncom- fortable for the simplest models in inflation, involving V ∝ ϕp for a power p. Instead, concave potentials such as those in new inflation are favored. Simple models such as Starobinsky R2 inflation, historically the first model of inflation, and Higgs inflation, also fit well. • There are alternatives to inflation, such as cyclic cosmology, which involve a “big bounce”. All such theories run into the “singularity problem”. They cannot calculate what will happen at a cosmological singularity, where nonperturbative quantum gravity can play a role; instead they must use conjecture. One can have as many cosmological theories as one has conjectures about Planck-scale physics. To be fair, of course, one can also apply this criticism to chaotic/eternal inflation. Quantum gravity is a contentious subject. 30 3. Thermal History 3 Thermal History 3.1 The Hot Big Bang We begin with a basic overview of the first three minutes of the universe. First, we supply some useful general ideas. • Let Γ be the rate of interaction for a particle, and define timescales tc = 1/Γ and tH = 1/H. Then when tc ≪ tH , local thermal equilibrium is reached before the effect of the expansion becomes relevant, and when tc ∼ tH , the particle decouples from the thermal bath. Different particle species may decouple at different times. • The contribution to Γ due to scattering off another particle species is Γ = nσv where n is the number density of that species, σ is the scattering cross section, and v is the relative velocity. Note that almost all cross sections in cosmology are thought of in terms of σv, since they always appear together in this rate. • An important point is that the timescale tc doesn’t depend much on the current conditions. For example, consider a process χ + χ ↔ (particles in equilibrium). If the rate of this reaction forward and backward in equilibrium is Γ, then if χ initially is overabundant by a factor of N , then tc ∼ (log N )/Γ, because when N is high, the forward process occurs faster. This is why particles have a chance of remaining in equilibrium even as their equilibrium abundance begins to fall exponentially. • We focus on the case T ≳ 100 GeV, where all known particles are ultrarelativistic. Then v = 1, and by dimensional analysis we have n ∼ T 3 for every species, since the masses play no role. If we assume the scattering is primarily by tree-level exchange of a massless gauge boson, we have σ ∝ α2, and dimensional analysis gives σ ∼ α2/T 2. Therefore Γ ∼ α2T. • By using dimensional analysis again, we have H ∼ √ρ Mpl ∼ T 2 Mpl , Γ H ∼ α2Mpl T ∼ 1016 GeV T where we used α ≳ 0.01, valid for charged or strongly interacting particles. Hence when 100 GeV ≪ T ≪ 1016 GeV, all particles are ultrarelativistic and in local thermal equilibrium. • When a particle species is in equilibrium, it obeys the Fermi–Dirac or Bose–Einstein distribution, f (E) = 1 eE/T ± 1 . In particular, once the particles become nonrelativistic, the density falls exponentially since f ∼ e−m/T . Hence we can approximate the energy density by summing only over relativistic particle species, giving ρr = π2 30 g∗(T )T 4 where g∗(T ) is the number of relativistic degrees of freedom. It ranges from 106.75 at early times to 3.38 at the present day, where only photons and perhaps neutrinos are still relativistic. 31 3. Thermal History • To convert between times and temperatures during radiation domination, note that ρ ∼ T 4 and ρ ∼ H 2M 2 pl. Therefore, we have t ∼ 1/H ∼ Mpl/T 2. • It is also useful to estimate decay rates for particles. For a particle A which decays into two much less massive, distinct particles, through a vertex factor of g, Γ ∼ g2mA 8π where the mA appears on dimensional groups, g2 appears because Γ involves a squared matrix element, and 1/8π is the generic phase space factor. Because Mpl/T ≫ 1, this means that any particles that can decay in this way vanish almost immediately once T ≲ mA, i.e. once they stop being thermally produced. • Exceptions to this general rule can occur for decays that are substantially slower. For example, for neutron decay the amplitude picks up a factor of g2 W /m2 W from the intermediate W boson, Γ ∼ g4 W 128π3 (mn − mp)5 m4 W ∼ 1 15 min where 1/128π3 is the typical numeric factor of three-body decays, and the dimensional phase space must be taken to be (mn − mp)5 because mn ≈ mp. This slow neutron decay will be important when studying nucleosynthesis, as they only decay when H ∼ Γ, or T ∼ 100 keV. • If equilibrium persisted forever, all massive particles species would eventually be exponentially suppressed. However, consider a species of massive particle with an equal number of antipar- ticles, with a conserved charge. These particles must be removed by annihilation with their antiparticles, and at some point they “freeze out”, as the annihilation rate falls below H, leaving behind a ‘relic density’. The annihilation process is thus not in chemical equilibrium. • This is distinct from the question of ‘decoupling’, when a particle species is no longer in thermal equilibrium with the radiation bath. However, for most massive species decoupling and freeze- out happen at around the same time, at m ∼ T . Exceptions occur for particles that don’t interact strongly or electromagnetically. • For example, neutrinos decouple while they are still relativistic, because they only interact weakly. Electroweak symmetry breaking occurs at T ≤ 100 GeV, below which weak cross sections are suppressed as σ ∼ G2 F T 2, GF ∼ 10 −5 GeV−2. and hence we have Γ H ∼ G2 F MplT 3 ∼ ( T 1 MeV )3 . Thus the neutrinos decouple at around 1 MeV. • More speculatively, gravitons have σ ∼ G2 N T 2 and hence decouple when T ∼ Mpl, leaving a graviton background with temperature approximately 1 K today. Example. Consider a collection of photons with energy ω ≪ me, which thermalize by light-by-light scattering. The leading light-by-light interaction is 2γ → 2γ through an electron loop. Estimating 32 3. Thermal History the diagram is subtle, because the electron propagators can have powers of me. An easier route is to note that upon integrating out the electron, the leading term in the effective Lagrangian is L ⊃ α2 16π2m4 e F 4 where the powers of me follow by dimensional analysis. This leads to a cross section σ ∼ α4ω6 m8 e where the powers of ω follow by dimensional analysis. However, this process can’t thermalize the photons by itself, because the scattering is elastic. The leading nonelastic process is 2γ → 4γ, where L ⊃ α3 16π2m8 e F 6, σ ∼ α6ω14 m16 e . Note there are no odd powers of F in the effective Lagrangian, as they vanish by F ’s antisymmetry. Also note that gauge invariance forces the appearance of F , which pulls out factors of external momenta, making the loop diagrams converge; this is why there is no large logarithm. The events in the history of the universe are summarized in the table below. 33 3. Thermal History • The first event is baryogenesis, which seeks to explain why the universe has net baryon number. Note that one could simply postulate an initial baryon asymmetry, but that wouldn’t be satisfying. We will black box the process of baryogenesis since not much is known about it. Questions marks indicate that we have no idea when it happened: it could be as late as the start of Big Bang nucleosynthesis, or as early as the end of inflation. Similarly, we don’t know precisely when inflation ended. • All known particle species are in thermal equilibrium until the electroweak phase transition. Particles acquire masses from the Higgs mechanism at this point. • If dark matter is a WIMP with a mass around the electroweak scale, then around this time, dark matter freezes out. However, it doesn’t decouple from the thermal bath until around T ∼ 1 MeV, by the same argument as for neutrinos. This has observational consequences because it affects the temperature of the dark matter, which falls as 1/a2 while decoupled, but only as roughly 1/a when in equilibrium with a radiation-dominated thermal bath. • At a temperature of 150 MeV, the QCD phase transition occurs; the quark gluon plasma hadronizes into baryons and mesons. • The next event is neutrino and WIMP decoupling, which occur around T ∼ 1 MeV. Shortly afterwards, electrons and positrons annihilate. This energy heats up the photons but not the neutrinos, since they have decoupled, causing their temperatures to be different today. Incidentally, a useful mnemonic during radiation domination is t/1 s ∼ (1 MeV/T )2. • After about three minutes, at temperature T ∼ 100 keV, Big Bang nucleosynthesis (BBN) occurs, forming primarily deuterium, helium, and lithium. This is later than one would expect, given nucleon binding energies of about 1 MeV, because photons greatly outnumber nuclei, so photons in the high-energy tail tend to break them apart. • Not much happens until recombination, when neutral hydrogen forms by the reaction e− +p+ → H + γ, with the reverse reaction energetically disfavored. This again happens somewhat later than one would expect because of the relatively large number of photons. • Since photons mostly interact by Thomson scattering e− + γ → e− + γ at this point, photons decouple shortly afterward and “free stream” through the universe, forming the CMB. Note that we say the photons decoupled from matter, rather than vice versa, because by this point the universe has become matter-dominated. • Afterward, there is a period called the “cosmic dark ages”, named because the radiation background no longer contains visible light, and stars haven’t formed yet. Stars form at z ∼ 30, which causes most hydrogen gas to reionization at z ∼ 10. The ionization of the hydrogen gas over time can be measured through the 21 cm line, which only exists for neutral hydrogen. It should be noted that many elements of the story above rely on extrapolation; the earliest element with good direct support is BBN, which strongly constrains many alternative models. Any events before BBN might never have happened. 34 3. Thermal History 3.2 Equilibrium We now consider the equilibrium aspects of the story above, starting by reviewing basic equilibrium statistical mechanics. • For a gas in a box of volume V , the density of states is g/h3 in phase space, where g is the number of internal degrees of freedom. In natural units, this is g/(2π)3. • By homogeneity, the distribution in position space is uniform, leaving a distribution in momen- tum space; by isotropy it only depends on the magnitude of the momentum. If f (p) is this distribution function, then by definition, n = g (2π)3 ∫ dp f (p). • Ignoring interactions between the particles, ρ = g (2π)3 ∫ dp f (p)E(p), E(p) = √ p2 + m2. Finally, the pressure is p = g (2π)3 ∫ dp f (p) p2 3E . The factor of p2/3E is the usual ⟨pxvx⟩ = ⟨p · v⟩/3 factor from kinetic theory, with v = p/E. • The distribution function is f (p) = 1 e(E(p)−µ)/T ± 1 with the plus sign for fermions and the minus sign for bosons. • The chemical potential µ changes as the universe expands; its evolution may be fixed by the continuity equations for energy and entropy. • If species are in chemical equilibrium, then the chemical potential balances in every reaction. For example, if we have the reaction 1 + 2 ↔ 3 + 4, then µ1 + µ2 = µ3 + µ4. Photons can always be easily produced by, e.g. double Compton scattering e − + γ ↔ e − + γ + γ which sets µγ = 0. As a result, by considering the process X + X ↔ γ + γ we must have µX = −µX in just about any reasonable situation. Note that chemical equilibrium is distinct from thermal equilibrium, which is when the species are at the same temperature. Now we perform some explicit calculations. 35 3. Thermal History • At early times, the chemical potential of all species is approximately zero. Neglecting it, n = g 2π2 ∫ ∞ 0 dp p2 exp( √ p2 + m2/T ) ± 1 , ρ = g 2π2 ∫ ∞ 0 dp p2√ p2 + m2 exp( √ p2 + m2/T ) ± 1 . Defining x = m/T and ξ = p/T , we find n = g 2π2 T 3I±(x), ρ = g 2π2 T 4J±(x) defined in terms of the dimensionless integrals I±(x) = ∫ ∞ 0 dξ ξ2 exp(√ ξ2 + x2) ± 1 , J±(x) = ∫ ∞ 0 dξ ξ2√ ξ2 + x2 exp(√ ξ2 + x2) ± 1 . • To make progress, we use the standard integrals ∫ ∞ 0 dξ ξn eξ − 1 = ζ(n + 1)Γ(n + 1), ∫ ∞ 0 dξ ξne −ξ2 = 1 2 Γ((n + 1)/2) which are derived by geometric series and integration by parts respectively. • In the relativistic limit x → 0, we have I−(0) = 2ζ(3). As for the plus sign, note that 1 eξ + 1 = 1 eξ − 1 − 2 e2ξ − 1 , I+(0) = I−(0) − 2 ( 1 2 )3 I−(0) = 3 4 I−(0). Hence we have n = ζ(3) π2 gT 3 × { 1 bosons, 3/4 fermions. A very similar computation yields ρ = π2 30 gT 4 × { 1 bosons, 7/8 fermions where we used ζ(4) = π4/90. Doing the same computation for p gives the usual relation for a relativistic gas, p = ρ/3. The typical energies per particle are ρ n ≈ { 2.7 T bosons, 3.2 T fermions. • We may also account for a chemical potential in the ultrarelativistic case. This doesn’t make sense for massless bosons, since either n or n would diverge, but for massless or ultrarelativistic fermions, n − n = g 2π2 ∫ ∞ 0 dp p 2 ( 1 e(p−µ)/T + 1 − 1 e(p+µ)/T + 1 ) = gT 3 6π2 ( π2 ( µ T ) + ( µ T )3) which may be shown by shifting p → p + µ in the first integral and p → p − µ in the second, then performing some cancellations and a contour integral. 36 3. Thermal History • We can also work in the nonrelativistic limit x ≫ 1, where for both fermions and bosons I±(x) ≈ ∫ ∞ 0 dξ ξ2 e √ξ2+x2 . Taylor expanding the denominator gives I±(x) ≈ ∫ ∞ 0 dξ ξ2 ex+ξ2/2x = (2x) 3/2e −x ∫ ∞ 0 dξ ξ2e −ξ2 = √ π 2 x3/2e−x where we used our second standard integral, and Γ(3/2) = √π/2. Thus we have n = g ( mT 2π )3/2 e−m/T . This is intuitive: the prefactor (mT )3/2 ∼ p3 counts the number of accessible momentum states, while e−m/T is the Boltzmann factor for the rest energy. • As for the energy density, using E(p) = √ p2 + m2 ≈ mn + 3nT /2 gives ρ ≈ mn + 3 2 nT. One may also compute P = nT ≪ ρ, i.e. the ideal gas law, as expected. • It is also straightforward to restore finite µ, which gives an extra prefactor, n = g ( mT 2π )3/2 e−(m−µ)/T , n − n = 2g ( mT 2π )3/2 e−m/T sinh(µ/T ). Finally, we consider the effective number of relativistic species. • Let T be the temperature of the photon gas. We define the number of relativistic degrees of freedom g∗(T ), g∗(T ) = ∑ i gi ( Ti T )4 { 1 bosons, 7/8 fermions where the sum is over species with m < Ti, and Ti is the temperature of the species, which most of the time will just be equal to T . This definition is chosen so that ρ ≈ π2 30 g∗(T )T 4 during radiation domination, or equivalently, H 2M 2 pl ≈ π2 90 g∗(T )T 4. The factor of Mpl gives H ≪ T , in contrast to H ∼ T during inflation. • At high temperatures, the SM degrees of freedom are counted as follows. – Quarks have 2 spins and 3 colors; counting antiquarks gives another factor of 2. Hence they contribute 6 × 12 = 72 degrees of freedom. 37 3. Thermal History – Each massless gauge boson has two polarizations, so the gluons contribute 16. – Similarly, the photon contributes 2, while the W ± and Z bosons contribute 9. – The Higgs boson is a real scalar and contributes 1. – The charged leptons contribute 4 each, from 2 spins and antiparticles. The neutrinos contribute only 2 each, since all neutrinos have negative helicity and all antineutrinos have positive helicity. This gives a total of 28 bosonic degrees of freedom and 90 fermionic degrees of freedom, for g∗ = 106.75 for T ≥ 100 GeV. • The evolution of g∗(T ) in the early universe is shown below. Following the electroweak phase transition, the top quark is the first to annihilate, followed by the weak bosons, the Higgs, the bottom quark, the charm quark, and the tau. • After the QCD phase transition, the quarks condense into baryons and mesons, but only the pions (π±, π0) are relativistic, contributing 3 degrees of freedom. Hence we are left with pions, electrons, muons, neutrinos, and photons. The pions and muons annihilate next; then the neutrinos decouple and the electrons annihilate. The dotted line shows the effective number of degrees in entropy g∗S(T ), explained below. • Since these particles interact by the strong and electromagnetic forces, this annihilation process is quite efficient. Almost all pions and muons annihilate; those that don’t decay later, so we don’t see a relic density. The remaining matter is in the form of protons and neutrons. • The annihilation of antibaryons is especially efficient, due to the net baryon number created in baryogenesis, as the amount of baryons they have to annihilate against approaches a constant rather than zero. Note. More about the electroweak and QCD phase transitions. There are three possibilities for each of these: a violent first order transition driven by bubble nucleation, a second order transition, and 38 3. Thermal History a rapid “crossover”, which looks like a second order transition but is perfectly analytic. (Crossovers hence aren’t true phase transitions at all, though it’s conventional to include them in.) For the purposes of cosmology, the main concern is whether these transitions are first order or not. Such violent transitions would generate relics that we could see now, such as gravitational waves. Lattice calculations indicate that the QCD phase transition is also a crossover, and that the electroweak phase transition is a crossover for mH ≳ 80 GeV. However, extensions to the SM such as GUTs often generate first-order phase transitions. One can also calculate whether further minima occur in the Higgs potential for higher Higgs vevs, and remarkably the measured value of the Higgs puts the SM just on the boundary between metastability and absolute stability. We now discuss the conservation of entropy. • First, we derive a useful identity. Consider a comoving volume, and focus on a single particle species which is in thermal equilibrium. The first law of thermodynamics gives d(ρV ) = T dS − p dV + µ dN. • Now we switch to the intensive number and entropy, n = N V , s = S V . Plugging these results in gives (T s − p − ρ + µn) dV + (T ds − dρ + µ dn)V = 0. This has completely separated variation of intensive parameters and extensive parameters, so both terms must separately vanish. • We can show this more formally. Think about the entropy contained in an imaginary box of fixed physical volume, embedded in this comoving volume. The first term above vanishes, so T ds − dρ + µ dn = 0. But this is a relation among intensive variables, which holds regardless of the volume we are considering. Thus the second term always vanishes, so the first term always vanishes. • This gives the useful identity s = ρ + p − µn T . For multiple species, this is true if all quantities above are taken to be for that specific species. (Often, this equation is quoted with µ = 0, because it’s usually used when µ is negligible.) • Now think about the entropy due to all particle species, again in a comoving volume. We assume everything is in chemical equilibrium, so the ∑ i µi dNi terms don’t contribute anything, so dS = 1 T (dU + p dV ) = 1 T ((ρ + p) dV + V dρ). However, this vanishes by the continuity equation, ˙ρ + 3H(ρ + p) = 0, dρ + dV V (ρ + p) = 0. The conservation of entropy makes perfect sense, as everything within our comoving volume is in equilibrium, and there can’t be any heat transfer with anything outside. 39 3. Thermal History • We define the effective number of degrees of freedom in entropy by s = 2π2 45 g∗S(T )T 3. By similar reasoning to the above, we have g∗S(T ) = ∑ i gi ( Ti T )3 { 1 bosons, 7/8 fermions where the sum is over all relativistic species; the only difference is that there is a cubic dependence on T rather than a quartic dependence. • The conservation of entropy is useful when species annihilate, because this process is adiabatic, S ∝ g∗ST 3a3 = constant which implies T ∝ g−1/3 ∗S a−1. This reproduces the usual 1/a falloff, but when a species annihi- lates, the temperature has a different dependence, as the entropy of the annihilating species is transferred to other relativistic species. Specifically, the temperature continues to decrease, but more slowly, since annihilation is a gradual process that occurs as a changes by an O(1) factor. • Note that entropy is not conserved in nonequilibrium processes, such as WIMP freeze-out (or more generally the later stages of any annihilation process), structure formation, and the entire history of life. However, in the standard cosmological story, this doesn’t matter because relativistic species (i.e. photons) carry the vast majority of the entropy. However, it is possible to induce large changes in the entropy, e.g. in a first-order phase transition. • For a given species, we define the number of particles per comoving volume as Ni = ni s . This works because Ni = nia3/sa3, where the numerator is the number of particles in some comoving volume and the denominator is the conserved entropy in that comoving volume. Hence dividing by s just rescales this volume, and eliminates the explicit dependence on a. We now apply this to the case of neutrino decoupling. • When neutrinos decouple, they are ultrarelativistic. After decoupling, they don’t interact with anything, including each other, but they maintain a relativistic thermal distribution f (p, T ) with T ∝ 1/a since all neutrinos are redshifted equally, even when the “temperature” drops below the neutrino mass. The phase space distribution just shrinks towards p = 0. If there was a chemical potential at decoupling, then it also redshifts as 1/a. • A similar story holds for a species that decouples when it is nonrelativistic, with its momentum redshifting as 1/a and hence its kinetic energy redshifting as 1/a2. The phase space distribution remains thermal, with T ∝ 1/a2. Thus, e.g. we know that WIMP DM would have extremely low temperature by the time of structure formation. 40 3. Thermal History • There is a technicality. The number density of a nonrelativistic species at temperature T is n ∼ T 3/2e−(m−µ)/T . However, the number density of a decoupled species does not exponentially decay, but rather redshifts as 1/a3, which is completely accounted for by the T 3/2 prefactor. Thus the exponential has to stay constant, which can be done by introducing an artificial, growing chemical potential which keeps (m − µ)/T constant. • If a species decouples when it is semi-relativistic, its later distribution can’t be taken approxi- mately thermal at all, for any values of µ and T . In this case we have to fall back on using the phase space distributions directly. • Putting these annoying issues aside, this picture also gives a simple, intuitive reason S is conserved, for decoupled particles. The entropy depends on the available phase space volume. Now take a given comoving volume as the system. The number of particles inside is fixed, the physical volume grows as a3, and the accessible momentum space falls as 1/a3. • Neutrinos are coupled to the thermal bath by weak interactions, such as νe + νe ↔ e + + e−, e − + νe ↔ e− + νe. As we’ve seen, neutrinos decouple when T ∼ 1 MeV. However, despite this decoupling, they maintain roughly the same temperature as the photons since both fall as 1/a, until electron- positron annihilation warms up the photon bath. Without counting the neutrinos, the effective number of degrees of freedom in entropy is g′ ∗S = { 2 + 7 8 × 4 = 11 2 T > me, 2 T < me. Then the temperature of the photons increases by a factor of (11/4)1/3. • This ratio holds until the present day. One might imagine that the photon temperature should fall as 1/a2 rather than 1/a in the period of matter-domination preceding photon decoupling. However, in this period the photon energy is still much greater than the total kinetic energy of matter, even though it’s much less than the rest energy, so the temperature still falls as 1/a. Both photons and neutrinos always redshift as 1/a. • The results above are only approximate, since neutrino decoupling is a gradual process; in reality some of the energy ‘leaks’ to the neutrinos. As a result, today we have g∗ = 2 + 7 8 × 2Neff ( 4 11 )4/3 = 3.36, g∗S = 2 + 7 8 × 2Neff ( 4 11 ) = 3.94 where instantaneous decoupling would give Neff = 3, but more realistically Neff = { 2.99 ± 0.33 experiment, 3.046 theory. Refinements of the measurement of Neff by the Simons Observatory and CMB-S4, which will improve the uncertainty to about 0.06, can probe new light physics. 41 3. Thermal History • The number density of neutrinos is nν = 3 4 Neff × 4 11 nγ. The energy density depends on the neutrino masses. It used to be believed that neutrinos were massless, in which case the energy density is closely related to the CMB energy density, ρν = 7 8 Neff ( 4 11 )4/3 ργ. However, experiments indicate that neutrinos have mass, with ∑ i mν,i > 0.06 eV. • The temperatures of the CMB and “CνB” are T0 = 2.73 K = 0.24 meV, Tν = ( 4 11 )1/3 T0 = 1.95 K = 0.17 meV. This holds regardless of the neutrino masses, as the distribution remains formally relativistic. • If the neutrino masses were too large, then they would overclose the universe by themselves, just by virtue of their rest energy. This yields the constraint ∑ i mν,i < 15 eV. In fact, more stringent experimental tests show that ∑ i mν,i < 0.3 eV which indicates that while neutrinos likely have more energy than the photons, they still are a small contribution overall, Ων < 0.01. • Given the results above, it seems likely that no neutrino species remain relativistic today. However, it’s logically possible that one neutrino species is massless. • Note that we have implicitly assumed above that there is no neutrino asymmetry, nν = nν. In some models of baryogenesis, one ends up with such an asymmetry. A simple constraint on this is that too much asymmetry would lead to a measurable change in ρν and hence the total energy density of the universe; however, this constraint is extremely weak. Note. All light particle species could contribute to Neff. For example, there could be a “cosmic axion background” from relativistic axions thermally produced in the early universe. We have Γ ∼ n⟨σv⟩ ∼ T 3 f 2 a and setting this equal to H ∼ T 2/Mpl gives a freeze-out temperature T ∼ 10 6 GeV ( fa 1012 GeV )2 which is quite early. Future CMB experiments could therefore place strong bounds on axions. 42 3. Thermal History 3.3 The Boltzmann Equation Next, we introduce a simple form of the Boltzmann equation to describe nonequilibrium processes. • In the absence of interactions, the number density of a particle species i evolves as ˙ni + 3ni ˙a a = 1 a3 d(nia3) dt = 0 since the particles simply dilute with the expansion. The Boltzmann equation is 1 a3 d(nia3) dt = Ci[{nj}] where the collision term on the right-hand side accounts for all reactions. In general, both sides would have full phase space distributions, but for our calculations this will suffice. • Usually, reactions involving three or more particles are subleading, so we can restrict to decays or two-particle scatterings and annihilations. All reactions we study will be of the form 1 + 2 ↔ 3 + 4. In this case the Boltzmann equation for species 1 is 1 a3 d(n1a3) dt = −αn1n2 + βn3n4. • The coefficients are thermally averaged cross sections, α = ⟨σv⟩, and β may be related by β = ( n1n2 n3n4 ) eq α by detailed balance, where we use the equilibrium number densities calculated in the previous section. (More properly, we can think of α as the definition of ⟨σv⟩.) Hence we have 1 a3 d(n1a3) dt = −⟨σv⟩ ( n1n2 − ( n1n2 n3n4 ) eq n3n4 ) . In a more rigorous treatment, we would start from a microscopic treatment and use time reversal symmetry to derive detailed balance here. • It is useful to write this in terms of the number of particles per comoving volume Ni = ni/s, d log N1 d log a = − Γ1 H ( 1 − ( N1N2 N3N4 ) eq N3N4 N1N2 ) , Γ1 = n2⟨σv⟩. The quantity in parentheses expresses the deviation from equilibrium. Then when Γ1 ≫ H, N1 quickly approaches the equilibrium value, while for Γ1 ≪ H we get a constant value of N1, i.e. a relic density. • Many approximations have been made to arrive at the expression above. We have made the usual Boltzmann approximation of neglecting higher-body correlations, and we have further neglected any phase space structure of the species. Also, we have neglected the effects of quantum statistics, which is valid if the phase space occupancy is much less than 1. (Otherwise, we would have either Fermi blocking or Bose enhancement.) For a more complete treatment, see the notes on Undergraduate Physics. 43 3. Thermal History Note. A more careful derivation would show that the quantity v in ⟨σv⟩ is really the so-called Moller velocity, vM = √ (p1 · p2)2 − (m1m2)2 E1E2 . This has the property that vM n1n2 is Lorentz invariant. However, for most applications it’s good enough to take v to be the typical velocity. As a first example, we consider the freeze-out production of traditional WIMP dark matter, which occurs during radiation domination. • We consider a reaction of the form X + X ↔ ℓ + ℓ where ℓ is a light particle tightly coupled to the SM plasma, and thus always in thermal and chemical equilibrium. We also assume nX = nX . Then the Boltzmann equation becomes dNX dt = −s⟨σv⟩ (N 2 X − (N eq X )2) . We also assume that the interaction is strong enough so that the dark matter abundance reaches thermal equilibrium at some point in the early universe. • There are many variants on this, such as having nX ̸= nX or having the dominant reaction be 3X ↔ ℓ + ℓ, which lead to slightly different constraints, as we’ll discuss later. The case where the dark matter begins at zero density and never reaches thermal equilibrium due to extremely weak interactions is called “freeze-in”, because the abundance goes up during cosmological evolution rather than down. Here we just consider classic freeze-out. • If the dark matter can annihilate to multiple things, ℓi+ℓi, we just need ⟨σv⟩ to count all possible annihilation processes. The same Boltzmann equation, accounting for both DM annihilation and production, still works because each individual process obeys detailed balance. • It is most convenient to express the evolution in terms of x = MX /T , so the interesting dynamics occurs near x ∼ 1. To perform the change of variable, note that dx dt = − 1 T dT dt x = Hx where we used T ∝ a−1 during radiation domination. Furthermore, during radiation domination H = H(MX ) x2 . Plugging these into the Boltzmann equation, we have the Riccati equation dNX dx = − λ x2 (N 2 X − (N eq X ) 2) , λ = 2π2 45 g∗S M 3 X ⟨σv⟩ H(MX ) where λ is the dimensionless interaction strength. The pair creation/annihilation process becomes less effective as the universe expands; the opposite would be true for a decay process. 44 3. Thermal History • Note that λ depends on x, but it doesn’t vary too much during freeze-out, so we’ll treat it as constant. The reason is that usually s-wave annihilation dominates, and in this case the x- dependence of σ and v cancel; the contribution of p-wave annihilation is v2 smaller. The results can qualitatively change if this is upset, e.g. if p-wave annihilation is the leading contribution, or if one has Sommerfeld enhancement. (understand when s-wave annihilation is allowed) • The Riccati equation has no closed-form solution; numeric solutions are below. When λ ≫ 1, for a wide range of λ we find significant departure from equilibrium occurs near x ∼ 10 or x ∼ 20, depending on how strict you are, because N eq X depends on x exponentially. For concreteness we’ll take x ∼ 10 for estimates below. • At this point N eq X is very small, so in the subsequent solution dNX dt = − λ x2 N 2 X which integrates to 1 N ∞ X − 1 NX (xf ) = λ xf . Since typically NX (xf ) ≫ N ∞ X , we have the simple approximation N ∞ X ≈ xf λ ∼ 10 λ . • The remaining dark matter density today is ρX,0 = MX N ∞ X s0. Substituting our result for N ∞ X and s0 = s(T0), we have ρX,0 = H(MX ) M 2 X xf ⟨σv⟩ g∗S(T0) g∗S(MX ) T 3 0 . During radiation domination, the Hubble constant is H 2M 2 pl = π2 90 g∗(T )T 4. 45 3. Thermal History Plugging this in, using ρc,0 = 3M 2 plH 2 0 , and plugging in the currently measured values of H0, T0, and g∗S(T0) = 3.91, we find ΩX h2 ∼ 0.1 xf 10 ( 10 g∗(MX ) ) 10−8 GeV−2 ⟨σv⟩ . • This accounts for the observed dark matter density if ⟨σv⟩ ∼ (10−4 GeV−1)2 ∼ 0.01 GF ∼ 3 × 10−26 cm3/s. However, for s-wave annihilation through a weak gauge boson, and assuming that the phase space for annihilation is also given by the weak scale (e.g. if the mass is mX ∼ mW ), then ⟨σv⟩ ∼ 1 8π g4 W m4 W m2 W which matches! This is called the WIMP miracle. • The calculation above points to a weak-scale or TeV-scale WIMP. On the other hand, if we fix the cross section, then the WIMP mass can vary over a wide range. It could be much lower if the DM annihilates through a new mediator weakly coupled to the SM, which motivates searches in the MeV to GeV range. • In the other direction, the mass could be up to about 100 TeV before the required cross section runs into the s-wave unitarity bound, ⟨σv⟩ ≤ π m2v (2j + 1). This bound assumes only that we have point particles scattering (e.g. heavy composite particles would have cross sections instead set by their geometric size), and that the s-wave component of the partial wave expansion dominates; this is reasonable since higher partial waves are penalized by powers of v2. Most of the time we cannot even saturate the s-wave unitarity bound, because couplings will be small, as will v at freeze-out. • On the other hand, it’s possible to have much heavier DM with some model building. For instance, this paper shows that one can have DM of mass up to 1014 GeV by postulating a chain of approximately degenerate states “co-scattering” by χi + SM ↔ χj + SM. • Another situation would be a “hot relic”, where λ is small and decoupling occurs when the WIMPs are still relativistic, x ≲ 1. This is how neutrinos work, and as for neutrinos, it would give a huge density of dark matter particles, on the same order of magnitude as CMB photons. • Since the number density per comoving volume is fixed, the current DM density would be roughly proportional to the mass m. The right DM density would result for mDM ∼ 10 eV. To see this, note that we want mDM ∼ 5T where T is the temperature at matter-radiation equality, so that the DM density is about 5 times higher than the baryonic mass density. Such “hot DM” would still be relativistic during structure formation, and is observationally ruled out. On the other hand, “warm DM” with mDM ∼ 1 keV is a possibility. 46 3. Thermal History • Again, if we fix the cross section, the above reasoning places a weak lower bound on the WIMP mass. However, the Lee–Weinberg bound states that a WIMP cannot have a mass below about 2 GeV. This is because annihilation processes due to weak bosons get suppressed at such low energies: for mDM ≪ mW the weak gauge boson propagator becomes 1/m2 W , so roughly ⟨σv⟩ ∼ g4 W 8π m2 DM m4 W . The simplest way to evade this bound is if the DM annihilates through a new, non-SM interaction, which leads to the ideas of “dark sectors” and “light dark matter”, covered in more detail below. Note. Just how amazing is the WIMP miracle? Dropping all order-one constants, the WIMP freezes out at Tf ∼ mDM/10, where an f subscript denotes freeze-out. To get the correct final density, it must be on par with the radiation density at the time of matter-radiation equality, so T 4 eq ∼ mDMneq ∼ mDMnf ( T 3 eq T 3 f ) from which we conclude 10 nf T 2 f ∼ Teq. Now the abundance at freeze-out is determined by the interaction cross-section, nf ⟨σv⟩ ∼ Hf and we also know during radiation domination that T 2 f ∼ Hf Mpl, giving ⟨σv⟩ ∼ 10 MplTeq ∼ (10 −4 GeV−1)2 which is really just the statement that the scale associated with the cross section is midway between the Planck scale and the atomic scale, which the weak scale indeed is. The right-hand side “could have” ranged over about 20 orders of magnitude, so the WIMP miracle is perhaps a one-in-ten piece of evidence, which isn’t that strong. What really made weak-scale WIMPs so popular is the additional fact that you could get such particles automatically in many particle physics models motivated by new weak-scale physics, e.g. to solve the hierarchy problem. WIMP direct detection experiments have been improving rapidly for 20 years. However, we only know the annihilation cross-section of fast-moving WIMPs to any SM particles precisely, while what matters for such experiments is the scattering cross-section of slow-moving WIMPs with heavy nuclei, which is strongly model-dependent. The naive guess of Z-mediated elastic scattering was ruled out long ago, while Higgs-mediated scattering was probed more recently. However, one can easily make WIMPs that are much harder to detect by using, e.g. spin-dependence, velocity-dependence, or loop suppression. What is objectively true is that we have definitively ruled out WIMPs whose spin- independent elastic WIMP-nucleon cross section naively matches their annihilation cross section. Current generation WIMP experiments each use ∼ 10 ton detectors and cost $10 to $100 million. (For perspective, this is more than the total budget of all axion experiments ever performed, yet over a hundred times less than the total spent on the LHC.) They will soon run into the “neutrino floor”, where backgrounds from solar and atmospheric neutrino scattering will slow progress; there is thus much interest in novel detectors which can discriminate between WIMP and neutrino scatterings. 47 3. Thermal History Next, we consider recombination and photon decoupling. • In this case, we are concerned with the reaction e − + p+ ↔ H + γ which is in equilibrium for T > 1 eV. We begin with equilibrium considerations. Since all particles besides the photon are nonrelativistic, neq i = gi ( miT 2π )3/2 e (µi−mi)/T , µp + µe = µH . • To remove the dependence on the chemical potential, we consider the ratio ( nH nenp ) eq = gH gegp ( mH memp 2π T )3/2 e (mp+me−mH )/T . The first factor is 4/(2 × 2) = 1. The exponential factor is eBH /T where BH = 13.6 eV is the binding energy of hydrogen. Since the universe is charge neutral, we have ne = np, giving ( nH n2 e ) eq = ( 2π meT )3/2 eBH /T where we used mH ≈ mp. • Next, we define the free electron fraction Xe = ne nb where nb is the baryon density. We also define the baryon-to-photon ratio η = nb nγ = 5.5 × 10−10 ( Ωbh2 0.020 ) , nγ = 2ζ(3) π2 T 3. The total baryon density is approximately nb ≈ np + nH = ne + nH . Note that the baryon-to- photon ratio is constant after photon decoupling, since both nb and nγ dilute as 1/a3. Hence the quoted value above is measured from the CMB temperature and baryon density today. Furthermore, it is constant before photon decoupling because nb ∝ 1/a3 ∝ T 3 during radiation domination, and also during the short window of matter domination before photon decoupling because photons still hold most of the kinetic energy. • Since we have 1 − Xe X 2 e = nH n2 e nb the equilibrium value of the free electron fraction obeys ( 1 − Xe X 2 e ) eq = 2ζ(3) π2 η ( 2πT me )3/2 eBH /T . This is the Saha equation, which as expected predicts an exponential falloff of Xe at low temperature. We expect it should be reasonably accurate before Xe gets too small. 48 3. Thermal History • We conventionally define the recombination temperature as the temperature where Xe = 0.1. Plugging this in and solving for T , we find Trec ≈ 0.3 eV ≈ 3600 K, zrec ≈ 1320 which is, as expected earlier, much less than BH = 13.6 eV because η is large. • Now we consider photon decoupling. At this stage, photons are most strongly coupled to the thermal plasma by Thomson scattering, e − + γ ↔ e− + γ, Γγ = neσT = nbXeσT = ηnγXeσT where σT = (8π/3)(α/m)2 = 1.7 × 10−3 MeV−2 is the Thomson scattering cross section. • We define photon decoupling (roughly equivalent to the time of “last scattering” for a typical photon) to occur when Γγ = H. To evaluate this condition, note that Γγ may be evaluated in terms of quantities known at recombination, and since this time period is matter dominated, H(T ) ≈ H0√ Ωm ( T T0 )3/2 . Putting this all together and using the Saha equation, we find Tdec ∼ 0.27 eV, zdec ∼ 1100 by which point we have Xe ∼ 0.01. At this point, the CMB is formed. • Finally, there is a relic density of free electrons and protons, which may be computed with the Boltzmann equation applied to the reaction e− + p+ ↔ H + γ. This is fairly similar to the computation for the WIMP relic density. Note. A more accurate analysis of recombination. In reality, the Saha equation breaks down far before photon decoupling, because the photon field is not in equilibrium; the creation of a hydrogen atom in the ground state yields a photon of energy BH , significantly changing the high-energy tail of the distribution. This photon quickly reionizes another hydrogen atom, resulting in no net change. Most of the recombination is due to processes where a hydrogen atom is formed in an n = 2 excited state which decays to the ground state, releasing a photon of energy (3/4)BH = Lα in the process. The large population of Lα photons causes most hydrogen atoms to be in n = 2 states, signifi- cantly delaying recombination since the energy gap is only effectively 1/4 as large. The system can be investigated accurately numerically by taking 1s, 2s, and 2p hydrogen atoms, free electrons and positrons, and Lα photons as species in a set of coupled Boltzmann equations. Photon decoupling is irrelevant here, because there are effectively no thermal photons of energy Lα. The system is then in quasi-equilibrium, with a slow “leak” because the 2s → 1s decay emits two photons. Eventually the residual ions “freeze out” of this system, leaving a similar relic density to the one computed more naively above. Another complicating factor is that there is a sizable fraction of helium present at this time, due to nucleosynthesis. This doesn’t qualitatively change the result, but it increases the number of reactions we have to keep track of. 49 3. Thermal History 3.4 Nucleosynthesis Next, we move backwards in time to cover nucleosynthesis. The successful and precise calculation of its result is one of the great triumphs of standard cosmology. • Nucleosynthesis occurs at energy scales of T ∼ 1 MeV. By this time, baryons have long since decoupled, but electrons and positrons have not. Weak nuclear reactions convert neutrons and protons into each other, and strong nuclear reactions build nuclei from them. • We will concentrate on the light nuclei, which are H = p, deuterium D = pn, tritium 3H = pnn, 3He = ppn, 4He = ppnn. Note that for this discussion, “hydrogen” is short for a hydrogen nucleus, i.e. a proton. All heavier nuclei are produced in much small quantities. An overview is shown below. • We note that neutrons and protons are coupled by reactions like n + νe ↔ p + + e−, n + e+ ↔ p+ + νe. The chemical potentials of electrons and neutrinos are negligible at this stage because they are very light (assuming the lepton asymmetries are not too large), so µn ≈ µp. Then ( nn np ) eq ≈ ( mn mp )3/2 e−(mn−mp)/T ≈ e−Q/T , Q = 1.30 MeV. We assume that protons and neutrons are brought to equilibrium in the early universe. • Now, once we have T < 1 MeV, the equilibrium neutron density falls rapidly. Around the same time neutrinos decouple, shutting down the weak processes above and allowing the neutron 50 3. Thermal History density to freeze out. (This seems to be a coincidence, as neutrino decoupling is determined by the weak interaction while Q is determined by the strong and electromagnetic interactions.) Electron-positron annihilation also coincidentally occurs around here, which slows down the cooling a bit, but doesn’t have a qualitative effect. • For comparison, deuterium can be produced in the reaction n + p+ ↔ D + γ and since µγ = 0, we have µn + µp = µD. By the same reasoning as for the Saha equation, ( nD nnnp ) eq = 3 4 ( mD mnmp 2π T )3/2 e −(mD−mn−mp)/T since deuterium has spin 1 and hence gD = 3. Again we can approximate mD ≈ 2mp ≈ 2mn in the prefactor, but must preserve the difference in the exponential, ( nD np ) eq = 3 4 neq n ( 4π mpT )3/2 eBD/T , BD = 2.22 MeV. • To get an order of magnitude estimate, note that nn ∼ nb = ηnγ ∼ ηT 3, so ( nD np ) eq ∼ η ( T mp )3/2 e BD/T . Because of the smallness of η and BD, nD is negligible for T ≳ 0.1 MeV, so we can ignore everything except for protons and neutrons before this point. The intuition for the η suppression is that there are relatively many photons available to break apart D nuclei. • Heavier, more strongly bound nuclei such as 4He and 12C would already become significant at T ∼ 0.25 MeV assuming equilibrium, but this does not occur because BD is anomalously low. This is known as the “deuterium bottleneck”, and appears to be yet another coincidence. • Therefore, we will simply track the neutron fraction Xn = nn nn + np until T ∼ 0.1 MeV, at which point it will be used as an input for reactions producing heavier nuclei. We know that in equilibrium, X eq n (T ) = e−Q/T 1 + e−Q/T . Furthermore, as stated above, neutrons freeze out when neutrinos decouple at T ∼ 0.8 MeV, at which point X eq n = 0.17. We hence estimate X ∞ n ∼ 1/6. • At temperatures below 0.2 MeV, corresponding to t ≳ 100 s, we must account for the finite lifetime of the neutron, Xn(t) = X ∞ n e−t/τn = 1 6 e −t/τn, τn = 880.0 ± 0.9 s. As an aside, it’s a remarkable coincidence that the neutron lifetime is around the same time nucleosynthesis is occurring; if it were much shorter, as a naive dimensional estimate would give, than the universe would have essentially only protons, and hence no complex chemistry! 51 3. Thermal History • Now, heavier nuclei are primarily produced by two-body reactions, since the density is too low for three-body reactions. The primary ones are n + p+ ↔ D + γ, D + p+ ↔ 3He + γ, D + 3He ↔ 4He + p+ and D + D ↔ 4He + γ, D + D ↔ 3He + n, D + D ↔ 3H + p. To estimate the rates of these processes, note that the electromagnetic reactions are suppressed by ∼ 102, while the last three are suppressed by the relatively small amount of deuterium. • These reactions are sufficient to ensure that D tracks its equilibrium abundance. However, since BD is relatively small, and η is very small, the other interactions are not in equilibrium since there is too little deuterium; this is the deuterium bottleneck. • As a rough estimate, note that (nD/np)eq ∼ 1 at temperature Tnuc ∼ 0.06 MeV, tnuc ∼ 330 s, Xn(tnuc) ∼ 1 8 where the time is computed using the expression for T (t) in a radiation-dominated universe. At this point we account for the reactions that produce 4He. Since 4He has such a high binding energy, almost all the deuterium is quickly converted to it, and since each 4He requires two neutrons, we get nHe nH ∼ 1 16 or alternatively, the mass fraction of helium is about 1/4. (Real calculations solve the coupled Boltzmann equations numerically; it is intractable to do this analytically, because many reactions are happening at once, and electron-positron annihilation is happening simultaneously, changing the temperature time-dependence.) • The amount of 3He is smaller by a factor of about 104 because of its lower binding energy. Creation of heavier nuclei is slowed because there are no nuclei of atomic mass 5 or 8. The most common subsequent pathway is 4He fusion to create 7Li or 7Be. • By this time, this process is slow, as the temperature is falling to ∼ 10 keV, which is around the temperature one needs to fuse helium in hot stellar cores. The rate falls off rapidly as temperature decreases further, because it requires tunneling through the Coulomb barrier. Thus, one ends up with a relatively small amount of 7Li and 7Be, as shown. 52 3. Thermal History Nuclei heavier than 7Be are negligible and are instead created much later inside stars. • Experimentally, the primordial abundances of nuclei can be measured by observing dwarf galaxies, where little stellar nucleosynthesis has occurred, or very distant objects and hence younger objects, such as quasars. Within the context of BBN, the baryon to photon ratio is the only free parameter, but it has also been measured independently by CMB measurements. • Using this value, the measured abundances of 3He and 4He are as expected, but the amount of 7Li is lower than expected; this is called the lithium problem. Various solutions have been proposed, ranging from systematic astrophysical or nuclear physics errors, to a new negatively charged massive particle (CHAMP) which binds to nuclei to lower the Coulomb barrier, then decays well after BBN. Note. Why does the deuteron have spin 1? One way to see this is to use isospin symmetry, which relates protons and neutrons. All three members of the isospin triplet |nn⟩, (|np⟩ + |pn⟩)/ √2, |pp⟩ have similar energies, and |nn⟩ and |pp⟩ are known to not be stable, so neither is the third state. The lowest energy states are in the s-wave, so the spin wavefunction must be antisymmetric to ensure overall antisymmetry of the wavefunction, so the spin is zero. Hence the spin 0 deuteron is unstable. Note. Since there is a sizable amount of 4He, we should also account for helium recombination. This occurs much earlier than hydrogen recombination because the binding energies are much higher. For the first electron, the binding energy is 4 × 13.6 eV = 54.4 eV and recombination occurs at T ∼ 15000 K. The second electron has a binding energy of only 24.62 eV because of repulsion with the first, and recombines at T ∼ 5000 eV, at which point helium decouples from the photon bath. Note. The final helium abundance is an important parameter that is a useful probe of new physics. • The quantity g∗ determines the Hubble parameter by H ∼ √GN g∗T 2 and hence the neutrino freeze-out temperature. Using the simple criterion Γ ∼ H, (G2 F T 2 f )T 3 f ∼ √ GN g∗T 2 f , Tf ∝ g1/6 ∗ . A larger value of g∗ increases Tf , which increases the n/p ratio at freeze-out and hence increases the final helium abundance; this constrains models that change the number of light particles. • Changing GN and GF would also affect the helium abundance by the same mechanism of changing Tf . • A larger neutron lifetime τn would reduce the amount of neutron decay after freeze-out and hence would increase the final helium abundance. • A larger mass difference Q between neutrons and protons would decrease the n/p ratio at freeze-out and hence would decrease the final helium abundance. • A larger value for η allows synthesis of 4He to begin earlier and hence increases its final abundance. In general, it is quite hard to change any of these parameters substantially without ruining the result. Hence BBN places useful constraints on new physics. For instance, introducing new light particles in thermal equilibrium, as in some models of dark matter, would change g∗. 53 3. Thermal History 3.5 Models of Baryogenesis We now say a bit about baryogenesis, one of the outstanding puzzles of cosmology. The very basics are discussed in the notes on the Standard Model. • In the absence of a baryon asymmetry, almost all baryons and antibaryons would annihilate, leaving an equal and tiny amount of both, (nb + nb)/nγ ∼ 10−20, in strong contradiction to experiment. • Before the advent of inflation, one could simply postulate an initial baryon asymmetry. In this case, the focus was on explaining why η−1 was so large, i.e. where the large entropy per baryon came from, which could be explained by dissipative processes. However, in inflationary cosmology any initial baryon asymmetry is inflated away, in which case one has to explain how η = (nb − nb)/nγ arises after inflation ends. • Because η changes over time, a better quantity to explain is the baryon to entropy ratio, ηs = (nb − nb)/s. These quantities are related by a factor of g∗(T ), which is of order 200 at the GUT scale. • A subtlety is that electroweak sphalerons in the SM already violate baryon and lepton number, so we expect them to set B + aL to zero in equilibrium. Here, a is an O(1) number which depends on the right-handed fields in the SM, since the associated particles can interconvert with the ones corresponding to left-handed fields, which participate in sphalerons. A detailed calculation gives a = 28/51. • In the SM, B − L is conserved. Thus, if B − L = 0 after baryogenesis, then sphalerons set B = L = 0, so a baryogenesis mechanism actually has to generate B − L. • Following the Sakharov conditions, a generic route for baryogenesis is to imagine some new heavy particle that decays (nonequilibrium) with net baryon number (baryon number violation, C/CP violation). Then the universe cools down, so the heavy particle can’t be produced anymore, keeping the net baryon number around. • An alternative route to baryogenesis is leptogenesis, i.e. creating an imbalance in L that is converted into nonzero B by sphalerons. One possible mechanism could be if neutrinos are Majorana and acquire mass by the seesaw mechanism. Then leptogenesis could occur by out-of-equilibrium decay of the heavy sterile Majorana neutrinos. • Leptogenesis is popular since it works out nicely quantitatively, and it requires only minimal and well-motivated ingredients. However, it has the same problem as many other models of baryogenesis: it is difficult to test because it relies on new dynamics at very high energy scales. Because of this, baryogenesis mechanisms rarely supply direct tests, but rather motivate classes of models which allow such mechanisms to operate, which are then tested at low energies. • A more exotic route for baryogenesis would be to break CPT symmetry, because CPT ensures the equality of the masses of baryons and antibaryons; without it, baryons could just be lighter, and that alone would lead to an asymmetry. Breaking CPT would violate cherished notions of quantum field theory, and it also has been tested to extreme accuracy in the lab. However, as we’ll see, a rolling background field can effectively spontaneously break CPT in the early universe. 54 3. Thermal History As a simple model for baryogenesis, we consider an SU (5) GUT. • The GUT X bosons carry baryon number and lepton number. At the GUT phase transition, the X bosons freeze out, and subsequently decay out of equilibrium. We have X = X, but the decay X → qq is not balanced by the decay X → qq, due to C and CP violation. • More quantitatively, letting α be the GUT coupling, we have Γ(X → qq) ∼ αmX × { mX /T T ≫ mX , 1 T ≪ mX where the mX /T factor is due to time dilation, while the inverse decay rate is Γ(qq → X) ∼ Γ(X → qq) × { 1 T ≫ mX , (mX /T )3/2e−mX /T T ≪ mX . In principle, we also need to consider the scattering process qq → X ∗ → qq, Γ(qq → qq) ∼ nσv ∼ T 3α2 T 2 (T 2 + m2 X )2 ∼ α2 × { T T ≫ mX , T 5/m4 X T ≪ mX . For temperatures T ≫ mX , this process dominates. • As mentioned in the notes on the Standard Model, turning the CP violation into an asymmetry in decay branching ratios is nontrivial, and requires the interference of a tree-level diagram with loop-level diagrams. Moreover, the particles in the loops must have the possibility of going on-shell. (The reason this makes a difference, in the interference of phases, is that it brings the iϵ in the Feynman propagator into play.) We’ll ignore these subtleties and just parametrize the asymmetry in the decay by ϵ. • We can parametrize the decay rate in terms of the dimensionless quantity K = Γ(X → qq) 2H ∣ ∣ ∣ ∣ T =mX ∼ αMpl g1/2 ∗ mX . Since the decay rate is effectively set by the free parameter mX , K also parametrically determines the rates of the inverse decay and scattering processes. • In the case K ≪ 1, the X bosons decay slowly as T ≲ mX , and hence fall out of equilibrium. They drift along and decay much later, at which point inverse decay and scattering are negligible. This yields a baryon asymmetry of η ∼ ηs g∗(mX ) ∼ ϵ g∗(mX ) . We have η ∼ 10−10 and g∗(mX ) ∼ 200, so this model requires ϵ ∼ 10−8. Note that we already have ϵ ≲ 10−2 due to loop suppression. • However, this limit corresponds to having mX ≫ αMpl/g1/2 ∗ ≈ MGUT. This makes it difficult for the universe to have ever been at a high enough temperature to produce the X bosons thermally; if we have HI ≫ MGUT, then we run into bounds on CMB B-modes. 55 3. Thermal History • The more realistic limit is K ≳ 1, but this requires a detailed analysis using the Boltzmann equation. In this case, we expect a smaller η because the departure from equilibrium is smaller. It turns out that as K increases, the baryon yield decreases only as 1/K, corresponding to the smaller departure from equilibrium, but then begins to decreases exponentially for K ≫ 1. This latter feature is because qq → qq scattering remains effective when the X falls out of equilibrium, and erases the produced asymmetry exponentially in time. (Incidentally, this process also effectively damps out any preexisting baryon asymmetry, from before the X decay.) • This toy model doesn’t work because the SU (5) GUT conserves B − L through an accidental symmetry, as noted in the notes on Group Theory, so the baryon asymmetry is erased by sphalerons. However, more complicated GUTs based on, e.g. SO(10) and E6 do violate B − L. • Note that even in the extreme case K ≪ 1, the universe in this model is always close to equilibrium; the departure from equilibrium is quantified by 1/g∗ ≪ 1. One can also consider “way out of equilibrium” scenarios, where the decay of the X produces most of the entropy in the universe. This could occur, for example, if X decay caused both reheating and baryogenesis simultaneously. Next, we consider mechanisms involving rolling scalar fields. • In spontaneous baryogenesis, we consider a real scalar field ϕ with a derivative coupling to the baryon current, L ⊃ 1 f (∂µϕ)jµ B. This is quite reasonable, since this is a renormalizable interaction; the mechanism also works for generic combinations of couplings to currents, as long as one has baryon number. • Letting ϕ be spatially constant, this becomes L ⊃ 1 f ˙ϕ(nb − nb) so a moving field ˙ϕ produces a baryon chemical potential, µb = − ˙ϕ/f = −µb. • Therefore, if we have efficient baryon number violating interactions, then in thermal and chemical equilibrium, we have a baryon asymmetry, nB = nb − nb ∼ − ˙ϕT 2 f , nB s ∼ − ˙ϕ g∗(T )f T . At some point, we assume that the baryon number violating interactions become inefficient, and a baryon asymmetry is thus frozen in. • This looks strange because it seems to violate two of the Sakharov conditions: we have thermal equilibrium, and no apparent C or CP violation. Treating ϕ as a background field, it works because CPT is spontaneously broken. • If ϕ begins suitably large, then the final baryon abundance will be completely determined by when the baryon number violating interactions fall out of equilibrium, so the result is essentially independent of initial conditions: given the Lagrangian, there is a calculable final abundance. 56 3. Thermal History • In the Affleck–Dine mechanism, we consider a complex scalar field ϕ carrying baryon number. Now, this is ambiguous because “baryon number” is only initially defined on the Standard Model fields; we could always extend its definition to ϕ so that it has zero baryon number. What we really mean is that we include terms like L ⊃ ϕqψ where q is a quark field and ψ is a fermion with zero baryon number. Then to have a U (1) symmetry that reduces to U (1)B on the SM fields, we must have ϕ transform under it. • Letting ϕ carry baryon number Bϕ, we have a contribution to baryon number of nB ⊃ iBϕ( ˙ϕ∗ϕ − ϕ∗ ˙ϕ) = 2Bϕ(Re ϕ Im ˙ϕ − Im ϕ Re ˙ϕ). Expanding ϕ in polar coordinates, nB ⊃ Bϕr2 ˙θ, ϕ = r √2 e iθ. In other words, baryon number is present if ϕ has “angular momentum” in field space. • Now, suppose that the ϕ potential violates baryon number, e.g. V (ϕ) = m2|ϕ|2 + λ|ϕ| 4 + λ′(ϕ4 + ϕ∗4). The specific form of the potential depends on the model, but this shows the general idea. • Given initial conditions with ˙ϕ = 0, the field will begin rotating in field space as it decays through Hubble friction. Meanwhile, ϕ will decay into baryons, locking in the baryon asymmetry. The Sakharov conditions are satisfied: the ϕ field is not in thermal equilibrium, and the initial angle for ϕ spontaneously breaks C and CP symmetry. • The Affleck–Dine mechanism is particularly exceptional because it can operate at very low energy scales, as low as T ∼ 10 MeV. Many more options exist, many involving exotic decays. For instance, evaporating primordial black holes could also achieve baryogenesis. 57 4. Cosmological Perturbation Theory 4 Cosmological Perturbation Theory 4.1 Newtonian Perturbation Theory We now turn to the inhomogeneous universe. We use perturbation theory to describe the formation and evolution of large-scale structure. Since this theory is quite complicated, we begin with the Newtonian version, which applies for nonrelativistic matter on scales below the Hubble radius. • Consider a nonrelativistic fluid with mass density ρ, pressure P ≪ ρ, and velocity u. Mass conservation gives the continuity equation ∂tρ = −∇r · (ρu) while momentum conservation gives the Euler equation (∂t + u · ∇r)u = − ∇rP ρ − ∇rΦ where Φ is the gravitational potential, determined by the Poisson equation ∇2 rΦ = 4πGρ. • The fluid equations can be written more intuitively in terms of the convective derivative Dt = ∂t + u · ∇r which gives the rate of change of a quantity, following a fluid element as it moves. Then Dtρ = −ρ∇ · u, Dtu = − ∇rP ρ − ∇rΦ. • We now consider a small perturbation about a constant background, e.g. ρ(r, t) = ρ(t) + δρ(t, r), where u = 0. Linearizing the perturbed equations and neglecting gravity, we find ∂tδρ = −∇r · (ρu), ρ∂tu = −∇rδP. By combining these equations, we find ∂2 t δρ − ∇2 rδP = 0. • Defining δP = c2 sδρ, we find the wave equation, (∂2 t − c 2 s∇2 r)δρ = 0 where the parameter cs is the speed of sound; fluctuations oscillate with constant amplitude. For example, for an ideal gas with adiabatic fluctuations, we have cs = √γkBT /m. For a relativistic fluid, we have c2 s = wc2, though in this case our result does not technically apply. • Next we account for the effect of gravity. To do this, we can use the “Jeans’ swindle”, which is to perturb about zero gravitational potential, ∇2 r(Φ + δΦ) = ∇2 r(δΦ) = 4πGδρ. This is not valid, because ∇2 rΦ = 0 is not true for the unperturbed solution. However, as we will see below, this term is responsible for the expansion of the universe, so the Jeans’ swindle gives the right result as long as we consider small scales, where the expansion is negligible. 58 4. Cosmological Perturbation Theory • Accounting for gravity gives an extra term in the wave equation, (∂2 t − c 2 s∇2 r)δρ = 4πGρδρ. The dispersion relation is modified to ω2 = c 2 sk2 − 4πGρ for which the frequency is imaginary for wavenumbers between the Jeans wavenumber, kJ = √4πGρ cs . This indicates that fluctuations above the length scale λJ = 2π/kJ , called the Jeans length, grow exponentially. Note. A heuristic derivation of the Jeans length. Consider a collapsing object of radius R. By dimensional analysis, the collapse occurs on the timescale √ Gρ, independent of R. (This is also parametrically the same as the Hubble time.) Pressure builds up on the timescale R/cs, counteracting the collapse. The pressure builds up too slowly to avert collapse if this second timescale is larger. Note. The gravitational potential Φ in an infinite, uniform Newtonian universe is notoriously tricky. One might think, as Newton did, that by translational symmetry Φ is constant, leading to no gravitational force anywhere. This is incorrect because it doesn’t obey Poisson’s equation. The trap is that Φ is not defined without boundary conditions, and any possible choice of boundary conditions will break the translational symmetry. As a result, a Newtonian universe always has a privileged origin towards which everything collapses. The symmetry is restored when we go to general relativity, where we instead think of space itself expanding and contracting uniformly, with no privileged point. Now, we account for the expansion of the universe. • This can be handled in the Newtonian formalism by defining r(t) = a(t)x where x is a comoving coordinate. In other words, a Newtonian expanding universe really is a result of particles moving away from each other, in a fixed spatial background. • The velocity field is then u(t) = ˙r = Hr + v where v is the proper velocity. We would now like to rewrite our above equations in terms of x and v, and time derivatives at fixed x rather than at fixed r. • The gradients are related by ∇r = (1/a)∇x. To handle the time derivatives, note that by the chain rule, ∂t|r = ∂t|x + ( ∂x ∂t ) r · ∇x = ∂t|x − Hx · ∇x. From now on all time derivatives will hold x constant, and all gradients will be with respect to x, so we’ll suppress the subscripts. That is, in Fourier space the gradient pulls out a factor of the comoving wavevector k. 59 4. Cosmological Perturbation Theory • At zeroth order in all perturbations (including v), the continuity equation becomes ∂ρ ∂t + 3Hρ = 0 which simply recovers ρ ∝ a−3. Similarly, the zeroth order Euler and Poisson equations are ¨ax = − 1 a ∇Φ, ∇2Φ = 4πGa 2ρ. Combining these equations gives ¨a a = − 4π 3 Gρ which is the Newtonian version of the deceleration equation. As mentioned earlier, we can also derive the Friedmann equation in the Newtonian picture, but this derivation is even sketchier. • At first order, defining the fractional density perturbation δ = δρ/ρ, we find ˙δ = − 1 a ∇ · v. Similar manipulation of the Euler equations gives ˙v + Hv = − 1 aρ ∇δP − 1 a ∇δΦ. Note that if we neglect the fluctuations on the right, we recover the familiar result v ∝ a−1. • Finally, Poisson’s equation at first order is ∇2δΦ = 4πGa 2ρδ and there is no need for a “swindle”, since the zeroth order terms have been accounted for. • Deriving the wave equation as above gives ¨δ + 2H ˙δ − c2 s a2 ∇2δ = 4πGρδ. The essential differences are that we now have a Hubble friction term, and that both cs(t) and ρ(t) have time dependence. The result is that below the Jeans length, fluctuations oscillate with decreasing amplitude, while above the Jeans length, the fluctuations grow, but at a slower pace due to the expansion of the universe. Note that kJ defined above is a physical wavenumber, while here we’ve switched to comoving quantities, which is why a 1/a2 factor has appeared. • Remarkably, this result can also be slightly modified to work for relativistic fluids. The continuity equation must be modified with factors of 1 + w, ∂ρ ∂t + 3(1 + w)Hρ + 1 a (1 + w)∇ · (ρv) = 0. The Poisson equation receives a factor of 1 + 3w because pressure gravitates like energy, ∇2Φ = 4πGa 2ρ(1 + 3w). The resulting wave equation is ¨δ + 2H ˙δ − c2 s a2 (1 + w)∇2δ = (1 + w)(1 + 3w)4πGρδ. 60 4. Cosmological Perturbation Theory As a concrete example, we’ll consider dark matter and radiation. • Dark matter is special because it feels gravity but doesn’t interact significantly with itself or with other matter or radiation, so the pressure term above can be dropped, setting the Jeans length to zero. This means that dark matter behaves very differently from ordinary matter during structure formation, tending to clump up on smaller scales; this effect is required to match the observed results. • During matter domination, we have ¨δm + 2H ˙δm − 4πGρmδm = 0. Since a ∝ t2/3, we have H = 2/3t which implies ¨δm + 4 3t ˙δm − 2 3t2 δm = 0. Every term is the same power in t, so we guess a polynomial, giving solutions δm ∝ { t−1 ∝ a−3/2 t2/3 ∝ a . A generic perturbation will contain both modes; the growing mode is the latter one and the only one we see at late times. Hence dark matter perturbations grow like the scale factor during matter domination. Below, we will always refer to the larger mode as the “growing mode”, even if it is decaying. • Next, consider radiation perturbations. Since c2 s = wc2 with w = 1/3, the Jeans length and the horizon are parametrically equal, so there are only two cases. For subhorizon modes, δr oscillates, and hence doesn’t grow. For superhorizon modes during radiation domination, where a ∝ t1/2 and hence H = 1/2t, we have ¨δr + 1 t ˙δr − 1 t2 δr = 0 which has polynomial solutions, δr ∝ { t ∝ a2 t−1 ∝ a−2 . Thus, superhorizon radiation modes grow extremely quickly during radiation domination. The reason is that on superhorizon scales, the pressure of radiation doesn’t provide an effective restoring force, but it does contribute to the gravitational force. • Now consider matter perturbations during radiation domination. For subhorizon modes, the radiation perturbations oscillate rapidly, while pressureless matter only evolves over cosmological timescales. Thus the radiation perturbations can be ignored, giving ¨δm + 1 t ˙δm − 4πGρmδm ≈ 0. Because we are in radiation domination, the last term is negligible. This can also be seen quantitatively by noting that ∂t ∼ H and H ∼ √ρ/Mpl ∼ √ρG. 61 4. Cosmological Perturbation Theory • The equation can then be solved straightforwardly to get, for subhorizon modes, δm ∝ { const log t ∝ log a . That is, the rapid expansion due to the presence of radiation reduces the growth of δm to loga- rithmic. The growth of dark matter perturbations almost pauses during radiation domination. • For superhorizon modes, the situation is more complicated because we cannot ignore δr, which now grows significantly. Treating this as a source term, one can show that δm also grows as a2, pulled along with the radiation perturbations. • Finally, consider the Λ-dominated era. We don’t have to include a δΛ contribution to δΦ, because dark energy is always uniform by definition. Then we have ¨δm + 2H ˙δm − 4πGρmδm = 0. As in radiation domination, the final term is negligible. Since H is constant, the solutions are δm ∝ { const e−2Ht ∝ a−2 . Thus, matter fluctuations stop growing at this stage, so structure formation must go nonlinear before this point to be effective. This is indeed true in the standard cosmological model. • The result is summarized in the table below. RD MD ΛD subhorizon δm log a a 1 superhorizon δm a2 a 1 subhorizon δr 1 1 - superhorizon δr a2 - - The empty entries here aren’t physically relevant. For context, at z ∼ 103 we expect that the dark matter perturbations are δm ∼ 10−3, while primordial perturbations are of order 10−5. • In the ΛCDM model, the basic story is that fluctuations were sourced by inflation. Subhorizon dark matter perturbations grew slowly during radiation domination, and then after matter domination at Teq ≈ 1 eV, grew quickly. The baryons and photons remain tightly coupled and hence behave like a relativistic fluid (i.e. the photons set the sound speed), and hence their perturbations begin to oscillate, rather than grow, once they enter the horizon; these are called baryon acoustic oscillations. (sources differ on the description of this; does dark matter play a nontrivial role in these oscillations?) • At recombination at Trec ≈ 0.3 eV, the photons and baryons decouple. The baryons are stuck in whatever phase of the baryon acoustic oscillation they were in, then fall into the potential well created by the dark matter; the two matter perturbations then grow together. Our formalism then breaks down at z ∼ 30, where structure formation becomes significantly nonlinear. 62 4. Cosmological Perturbation Theory • This story can be tested by measurements of the CMB temperature, which reflect the potential and hence the matter power spectrum at the time of recombination, and measurements of the current matter power spectrum. Note that dark matter has an important structure enhancing effect because Trec < Teq, which appears to be a coincidence. • The fact that this story works places bounds on “hot” dark matter, i.e. dark matter that is relativistic at Teq. Such matter has a sizable pressure, but doesn’t exert it on itself, so our formalism above does not apply – instead its constituents “free stream”, wiping out density perturbations on scales smaller than ct, where t is the total time. • As a simple check, we can compute the Jeans mass after photon-baryon decoupling, where T ∼ 1 eV. Since the Jeans length is parametrically cs/H, we have MJ ∼ ρ ( cs H )3 . Since this is shortly after matter-radiation equality, we can crudely estimate the energy density as ρ ∼ T 4, and hence H ∼ √ρ/Mpl ∼ T 2/Mpl. The speed of sound is cs ∼ √ T /mp, so MJ ∼ Mpl M 2 pl m3/2 p T 1/2 ∼ 10 4M⊙ which is indeed on the scale of the smallest dwarf galaxies. Note. Treating perturbations larger than the Hubble scale properly requires general relativity, which we set up in the next section. These “superhorizon modes” become important when they enter the horizon, and also provide evidence for inflation. Without inflation, the (comoving) Hubble sphere only grows in the early universe, so there is no way to account for the origin of these superhorizon modes beyond simply specifying them as an initial condition. As we’ll see, within inflation they can be formed during inflation in a calculable way, get stretched out beyond the horizon, then reenter it. The main subtlety that appears in the relativistic case is that the apparent form of the results can depend on our choice of gauge. (This isn’t an issue for subhorizon modes, because we can restrict to comoving coordinates at such scales; the point is that extending this beyond the horizon is ambiguous, because the coordinates start to “feel the curvature”.) However, it turns out that the results we have derived above actually do apply on superhorizon scales, provided we work in comoving gauge. To avoid ambiguity, we will denote the comoving gauge perturbations by ∆ when working relativistically, and perturbations in a general gauge by δ. Finally, we connect these results to the observed power spectra. • We can distill the evolution of a perturbation in terms of a transfer function, δ(k, t0) = T (k)δ(k, ti) where ti is usually taken to be just after the end of inflation. • Using our previous results, we can infer the form of T (k) for matter perturbations. The main difference is that subhorizon and superhorizon modes grow differently during radiation domination. Thus, T (k) has nontrivial k-dependence only for modes that reenter the horizon during radiation domination. 63 4. Cosmological Perturbation Theory • The modes with wavenumber keq reenter the horizon at matter-radiation equality, keq = (aH)eq. For long wavelength modes with k < keq, we have T (k) = ( aeq ai )2 a0 aeq where we’ve ignored the slow logarithmic growth during radiation domination. But for k > keq, T (k) = ( aenter aeq )2 ( aeq ai )2 a0 aeq ∝ a2 enter where aenter is the scale factor at horizon reentry, k = (aH)enter. During radiation domination, we have a ∝ t1/2 and H ∝ 1/t ∝ 1/a2, so k ∝ 1/aenter. • Therefore, the transfer function has the form T (k) ∼ { 1 k < keq k−2 k > keq . One might also consider what happens for k so large that the mode never exits the horizon at all. However, perturbations in these modes are negligible, because the perturbations ultimately come from particle production effects associated with quantum field theory in curved spacetime, and on subhorizon scales the curvature has little effect. • The spatial structure of the perturbations can be characterized in terms of the two-point correlation function, ξ(|x − y|, t) = ⟨δ(x, t)δ(y, t)⟩ with a spatial average on the right-hand side. Note that isotropy tells us the correlation function depends only on |x − y|, while homogeneity tells us why it is a useful thing to compute at all. • We take the same Fourier transform convention as the notes on Quantum Field Theory. In momentum space, we have ⟨δ(k, t)δ(k′, t)⟩ = /δ(k + k′)P (k, t), P (k, t) = ∫ dr e ik·rξ(r, t) where P (k, t) is called the power spectrum. This is just the three-dimensional version of the Wiener–Khinchin theorem. More explicitly, expanding in spherical coordinates, we have P (k, t) = 4π k ∫ ∞ 0 dr r sin(kr)ξ(r, t). • The perturbations in our universe are predicted and observed to be approximately adiabatic and Gaussian, as we will see in detail in the following sections. Here, “adiabatic” means that the magnitudes of the perturbations of all species are simply related at the end of inflation, because 64 4. Cosmological Perturbation Theory they all result from the fluctuations of the inflaton; this is why we haven’t bothered putting subscripts on the fluctuations above. “Gaussian” means that the modes are independent, with P(δ(k)) ∝ exp ( − δ(k)2 2P (k) ) . This means that the modes are, statistically, completely characterized by the two-point correla- tion function, or equivalently the power spectrum; thus measuring higher-point correlators is a test of Gaussianity. • Currently, there are no observed deviations from adiabatic, Gaussian perturbations. This is in accordance with standard inflationary theory, where the non-Gaussianity (quantified by the three-point correlation function) is typically second order in the slow roll parameters, and hence quite small. If it were possible to measure this non-Gaussianity, we would gain information about the detailed dynamics of the inflaton. • In many models, the initial power spectrum at the end of inflation has the form P (k) ∝ kn where n is called the spectral index. This is equivalent to ξ(r) ∝ 1/rn+3. Note that n = 0 corresponds to masses being sprinkled at random in space, while n < −3 makes the correlation function diverge at large separation, violating the cosmological principle. • A particularly simple choice for the initial power spectrum is n = 1, which is known as the Harrison–Zel’dovich power spectrum. To see why this is a natural choice, first note that if we wanted to compute the total energy in perturbations, we would need to evaluate the integral ∫ d¯k P (k, t) = 4π (2π)3 ∫ dk k2P (k, t) = 1 2π2 ∫ d log k k3P (k). Thus, we are motivated to define the dimensionless power spectrum ∆(k) = k3P (k) 2π2 which measures the energy per logarithmic interval in k. • Next, it makes sense to think about perturbations in the gravitational potential Φ, because these are ultimately what lead to all other perturbations, in standard inflation. We can similarly define their power spectrum, ⟨δΦ(k)δΦ(k′)⟩ = /δ(k + k′)PΦ(k), ∆Φ = k3PΦ(k) 2π2 . The Poisson equation tells us that ∇2(δΦ) ∼ δ, which means PΦ(k) ∝ k−4P (k), P (k) ∝ k∆Φ(k). The Harrison–Zel’dovich spectrum thus corresponds to constant ∆Φ, and is hence described as scale invariant. In reality, n ≈ 0.97, as we’ll see below. 65 4. Cosmological Perturbation Theory • Putting this all together, the matter power spectrum today has the form P (k, t0) = T 2(k)P (k, ti) ∼ { kn k < keq kn−4 k > keq where a0keq ∼ 0.01 MPc−1. The matter power spectrum can be measured from the CMB at small k, and from the distribution of matter in the universe today at large k. Baryon acoustic oscillations can be observed at k somewhat above keq. • Measuring the matter power spectrum from matter itself is somewhat tricky. On cosmological scales, galaxies are effectively point masses, with infinite density; they are the products of nonlinear structure growth. To get a result that can possibly match with our linearized theory, we need to average the density over a cosmological scale. This is done by convolving it with a window function of radius R, δ(x; R) = ∫ dx′ W (x − x′; R)δ(x′), δ(k; R) = ˜W (k; R)δ(k). By symmetry, our ˜W (k; R) will only depend on kR, and we reflect this in the notation below. • The spherical top hat is a sharp cutoff in real space, W (x; R) = ( 4π 3 R3)−1 θ(R − |x|), ˜W (kR) = 3 (kR)3 (sin kR − kr cos kR). Another option is a sharp cutoff in momentum space, ˜W (kR) = θ(1/R − k), W (x; R) = 1 2π2r3 (sin r R − r R cos r R ) . Yet another option is a Gaussian in both real and momentum space, W (x; R) = 1 (2π)3/2R3 exp (− r2 2R2 ) , ˜W (kR) = exp (− k2R2 2 ) . In all cases, we have normalized to a unit integral over space, or equivalently ˜W (0) = 1. • Using a window function, we can define the mass within a sphere of radius R, M (R) = ∫ dx W (x; R)ρ(x). The smoothed density contrast on scale R is then δ(x; R) = δM (x; R) M (R) where δM = M − M , and the variance is σ2(R) = ⟨δ2(x; R)⟩. • Using the definition of the power spectrum, we have the relation σ2(R) = 1 2π2 ∫ d log k k3 ˜W (kR)P (k). 66 4. Cosmological Perturbation Theory The formal effect of the smoothing disappears as R → 0, as expected. Conventionally, σ2 is written as a function of M , which is related to R on the average by M = 4 3 πR2ργ, γ =    1 top hat 9π/2 sharp cutoff in k 3√ π/2 Gaussian . The standard choice of window function is the top hat with R = 8h−1 Mpc. The resulting variance is called σ2 8, where σ8 ≈ 0.8. • Using the simple asymptotic form of the matter power spectrum above, we have σ2(M ) ∼ { 1/R3+n ∼ 1/M (n+3)/3 k < keq 1/Rn−1 ∼ 1/M (n−1)/3 k > keq . 4.2 Relativistic Perturbation Theory We now use a full relativistic treatment, which can handle all length scales and relativistic fluids. • We consider small perturbations about the Friedmann metric, gµν = gµν + δgµν. The metric perturbations will be coupled to matter by the Einstein equations. For simplicity, we only expand about a flat FRW background, ds2 = a 2(τ )(dτ 2 − δijdxidxj). • Lorentz symmetry is broken by the background, but rotational symmetry is preserved, so it is useful to sort the perturbations by their rotational transformation properties. We write ds2 = a 2(τ ) ((1 + 2A)dτ 2 − 2Bidxidτ − (δij + hij)dxidxj) where A is a scalar, Bi is a vector, and hij is a tensor. We raise and lower the Latin spatial indices with δij, because we are linearizing about a rotationally symmetric background. • We can further decompose Bi into curl-free and divergence-free components, Bi = ∂iB + ˆBi where hatted quantities have zero divergence, ∂i ˆEi = 0. Similarly, hij can be decomposed as hij = 2Cδij + 2∂⟨i∂j⟩E + 2∂(i ˆEj) + 2 ˆEij where we have defined ∂⟨i∂j⟩E = (∂i∂j − 1 3 δij∇2) E and the symmetric tensor ˆEij is divergenceless and traceless, ∂i ˆEij = ˆEi i = 0. • We have thus decomposed the ten degrees of freedom of the metric into four scalars, A, B, C, and E, the two vectors ˆBi and ˆEi, and the tensor ˆEij, which carries two degrees of freedom. This is called the SVT decomposition. Furthermore, it turns out that the scalars, vectors, and tensor evolve independently under the linearized Einstein equation. It is useful to think of all these fields as propagating on top of a rotationally invariant background metric, rather than being part of the metric itself. 67 4. Cosmological Perturbation Theory • Scalar perturbations are rather generic. Simple models of inflation do not predict vector perturbations, though these would decay quickly anyway. However, inflation notably predicts tensor perturbations, though these have not yet been observed. Note. We would like to think of δgµν as an independent tensor field propagating on top of the background gµν, but how can we make this mathematically precise? We imagine two spacetime manifolds, a “physical” Mp with metric gµν and a “background” Mb with metric gµν, along with a diffeomorphism ϕ : Mb → Mp. Then δgµν may be defined as ((ϕ∗g) − g)µν. The gauge symmetry addressed below arises from the fact that the diffeomorphism ϕ is ambiguous up to composition with a diffeomorphism ψ : Mb → Mb. Before continuing, we need to account for the gauge symmetry remaining in the metric. • The metric perturbations depend on our choice of coordinates, or gauge choice. This can be interpreted as the combination of a choice of timeslicing for the spacetime, and a choice of spatial coordinates on those timeslices. Changing either can make fictitious perturbations appear, or make real perturbations vanish. • Concretely, consider the coordinate transformation X µ → ˜X µ = X µ + ξµ(τ, x), ξ0 = T, ξi = L i = ∂iL + ˆLi. The transformation of the metric is gµν(X) = ∂ ˜X α ∂X µ ∂ ˜X β ∂X ν ˜gαβ( ˜X) and we wish to compare the metric perturbations of gµν and ˜gµν. In practice, we will only be interested in coordinate transformations that take weakly perturbed metrics to other weakly perturbed metrics; other transformations exist, but then cosmological perturbation theory will not be applicable anymore. Hence we can take ξµ to be of the same order as the SVT parameters, and expand everything to linear order. • For example, we have g00(X) = ( ∂ ˜τ ∂τ )2 ˜g00( ˜X) where all other terms are higher order. Then we have a2(τ )(1 + 2A) = (1 + T ′) 2a 2(τ + T )(1 + 2 ˜A). As usual, a prime denotes a derivative with respect to conformal time τ . Defining H = a′/a and expanding everything to linear order, we find ˜A = A − T ′ − HT. Similarly, we have ˜Bi = Bi + ∂iT − L ′ i, ˜hij = hij − 2∂(iLj) − 2HT δij. 68 4. Cosmological Perturbation Theory • In terms of the SVT parameters, we have A → A − T ′ − HT, B → B + T − L ′, C → C − HT − 1 3 ∇2L, E → E − L and ˆBi → ˆBi − ˆL ′ i, ˆEi → ˆEi − ˆLi, ˆEij → ˆEij. In accordance with rotational symmetry, the scalars T and L′ can only affect the scalars, the vector ˆL can only affect the vectors, and there is nothing that can affect the tensor. • To avoid gauge problems, we can work in terms of the gauge-invariant Bardeen variables Ψ = A + H(B − E′) + (B − E′)′, Φ = −C − H(B − E′) + 1 3 ∇2E, ˆΦi = ˆE′ i − ˆBi, ˆEij. • An alternative solution is to fix the gauge. For simplicity, from this point on we’ll focus on only scalar perturbations, setting the rest to zero. We can set the values of only two scalar perturbations; other coordinate transformations will reintroduce the vector perturbations. • In Newtonian gauge, we set B = E = 0 in which case A = Ψ and C = −Φ, leaving a perturbed metric of the form ds 2 = a 2(τ ) ((1 + 2Ψ)dτ 2 − (1 − 2Φ)δijdxidxj) . This is a complete gauge fixing for perturbations that decay at spatial infinity. The advantage is its similarity to the weak-field limit of GR about Minkowski space, where Ψ plays the role of the gravitational potential. We will see later that in the absence of anisotropic stress, Ψ = Φ. • Another gauge is spatially flat gauge, C = E = 0, which fixes the spatial part of the metric; this will be useful when considering how perturbations are sourced by the inflaton. The next step is to parametrize perturbed matter. • We recall that for a perfect fluid, T µ ν = (ρ + P )U µU ν − P δµ ν . We use the mixed form of the metric because its components are slightly easier to interpret, and because the last term has a slightly simpler form. • Now we consider small perturbations, T µ ν = T µ ν + δT µ ν , δT µ ν = (δρ + δP )U µU ν + (ρ + P )(δU µU ν + U µδUν) − δP δµ ν − Πµν where Πµν is called the anisotropic stress, which obeys Πµν = Πνµ. It turns out that by redefining other variables, we may always choose Π ii = 0, U µΠµν = 0 and, working in a frame where U µ = a−1δ0 µ, the only surviving components of the anisotropic stress are Πij, representing shear forces. However, anisotropic stress will be negligible for all scenarios considered in these notes, so we will drop it later. 69 4. Cosmological Perturbation Theory • Perturbations in the four-velocity will induce nonvanishing energy flux T 0 j and momentum density T i 0 . To compute them, we need to parametrize the four-velocity. Note that δgµνU µU ν + 2U µδU µ = 0 since the four-velocity must always have unit norm. This implies δU 0 = −Aa−1, so U µ = a −1(1 − A, vi), vi = dxi dτ where vi is the coordinate velocity. By lowering both sides and keeping only linear terms, Uµ = a(1 + A, −(vi + Bi)). • Plugging this into our expression for δT µ ν we have δT 0 0 = δρ, δT i 0 = (ρ + P )vi, δT 0 j = −(ρ + P )(vj + Bj), δT i j = −δP δi j − Π ij. We hence define the momentum density qi = (ρ + P )vi. For multiple components, each with an independent velocity, the perturbations simply add. • Under coordinate transformations, we have T µ ν (X) = ∂X µ ∂ ˜X α ∂ ˜X β ∂X ν ˜T α β ( ˜X) which gives δρ → δρ − T ρ′, δP → δP − T P ′, qi → qi + (ρ + P )L ′ i, vi → vi + L′ i with Πij invariant under coordinate transformations. • Note that all of these quantities have SVT decompositions, such as vi = ∂iv + ˆvi. Since we will only be considering scalar perturbations, we may toss away the second term, so vi = ∂iv, qi = ∂iq. • We may define gauges in terms of the matter perturbation. In uniform density gauge, we can use the freedom in the time slicing to set δρ = 0. In comoving gauge, we set q = 0, where qi = ∂iq + ˆqi. In both cases, we have the freedom to set one further scalar metric perturbation to zero, and we choose B = 0. • One important gauge-invariant combination is ρ∆ ≡ δρ + ρ ′(v + B). Note that in comoving gauge, ρ∆ = δρ, so ∆ is called the comoving gauge density perturbation. 70 4. Cosmological Perturbation Theory • Simple, single-field inflation models predict initial fluctuations that are adiabatic, which means that the local state of matter at some spacetime point (τ, x) is the same as in the background universe at some slightly different time τ + δτ (x). We can view some parts of the universe as being “ahead” in evolution compared to others. • For a time shift δτ , we have δρI = ρ ′ I δτ (x). In particular, δρI /ρ′ I is the same for each species I. Assuming the energy continuity equation is conserved for each species separately, ρ′ I = −3H(1 + wI )ρI , we find δI 1 + wI is the same for every species, where we have defined the fractional density contrast δI = δρI /ρI . • For example, all radiation perturbations are related to all matter perturbations by δr = (4/3)δm. Since all the δI are on the same order of magnitude, the total density perturbation δρtot = ρtotδtot = ∑ I ρI δI is dominated by the dominant species. Also note that the δI are functions of x. • Perturbations that are not adiabatic are called isocurvature perturbations and parametrized by SIJ = δI 1 + wI − δJ 1 + wJ . All present observational data is consistent with SIJ = 0. Note. Anisotropic stress is negligible for perfect fluids, which are characterized by strong interactions which keep the pressure isotropic. Decoupled or weakly interacting species such as neutrinos cannot be described in this way, and hence we must account for their anisotropic stress. Decoupled cold dark matter is collisionless with a negligible velocity dispersion; we can hence describe it as a pressureless perfect fluid, even though it has almost no interactions, and hence without using anisotropic stress. 4.3 Equations of Motion Finally, we investigate the equations of motion. Since the calculations are tedious but straightfor- ward, we simply quote the final results. • We work in Newtonian gauge and continue to ignore vector and tensor perturbations, so gµν = a 2 ( 1 + 2Ψ 0 0 −(1 − 2Φ)δij ) . We set the anisotropic stress to zero, Πij = 0. As we will see later, this implies Ψ = Φ. • The perturbed connection coefficients are Γ0 00 = H + Ψ′, Γ 0 0i = ∂iΨ, Γ i 00 = ∂jΨ and Γ0 ij = Hδij − (Φ ′ + 2H(Φ + Ψ))δij, Γi j0 = Hδi j − Φ′δi j, Γ i jk = −δi j∂kΦ − δi k∂jΦ + δjk∂iΦ where, as usual, we raise spatial indices as ∂i = δij∂j. 71 4. Cosmological Perturbation Theory • Next, we consider the perturbed stress-energy conservation equation ∇µT µ ν = 0. At zeroth order, the zero component is ρ ′ = −3H(ρ + P ) which is the expected energy continuity equation. At first order, we have δρ ′ = −3H(δρ + δP ) + 3Φ′(ρ + P ) − ∇ · q. The first term is just the usual dilution due to the background expansion. The third term is familiar from Newtonian perturbation theory, while the second term is relativistic, corresponding to the density changes due to perturbations to the local expansion rate. • It is useful to rewrite this equation as δ′ + ( 1 + P ρ ) (∇ · v − 3Φ′) + 3H ( δP δρ − P ρ ) δ = 0 where we have defined the fractional overdensity δ = δρ/ρ. • Next, the spatial components give the Euler equation v′ + Hv − 3H P ′ ρ′ v = − ∇δP ρ + P − ∇Ψ. The second term on the left is the familiar redshifting due to expansion; the third term is an O(P /ρ) correction for relativistic fluids. The terms on the right are due to pressure gradients and gravitational infall, where the pressure gradient term again has a correction for the pressure. • Next, we approach the Einstein field equation. The Ricci tensor is R00 = −3H′ + ∇2Ψ + 3H(Φ′ + Ψ′) + 3Φ′′, R0i = 2∂iΦ′ + 2H∂iΨ and Rij = (H′ + 2H2 − Φ′′ + ∇2Φ − 2(H′ + 2H2)(Φ + Ψ) − HΨ ′ − 5HΦ′)δij + ∂i∂j(Φ − Ψ). The Ricci scalar is then straightforwardly a 2R = −6(H′ + H2) + 2∇2Ψ − 4∇ 2Φ + 12(H′ + H2)Ψ + 6Φ′′ + 6H(Ψ′ + 3Φ′). • By more straightforward manipulations, the Einstein tensor is G00 = 3H2 + 2∇2Φ − 6HΦ ′, G0i = 2∂i(Φ′ + HΨ) and Gij = −(2H′ +H2)δij +(∇2(Ψ−Φ)+2Φ′′ +2(2H′ +H2)(Φ+Ψ)+2HΨ ′ +4HΦ′)δij +∂i∂j(Φ−Ψ). The first-order terms come from three places: the change in Rij, the change in R, and the change in the metric gij that multiplies R. 72 4. Cosmological Perturbation Theory • Now we consider Einstein’s equations, Gµν = 8πGTµν. First, taking the trace-free part of the spatial components, we have ∂⟨i∂j⟩(Φ − Ψ) = 0 since we have assumed there is no anisotropic stress. Assuming the perturbations vanish at infinity, this implies Φ = Ψ, which dramatically simplifies the equations above. • The 00 component is H2 = 8πG 3 a2ρ at zeroth order, which is just the Friedmann equation. At first order, we have ∇2Φ = 4πGa 2ρδ + 3H(Φ ′ + HΦ) where we simplified using the Friedmann equation. • Finally, the 0i component is ∂i(Φ′ + HΦ) = −4πGa 2qi. Since the left-hand side is curl-free, this is only consistent if qi has only a scalar part, which is as expected; the vector part of qi would source vector perturbations. (right?) We hence may write qi = (ρ + P )∂iv. Assuming the perturbations decay at infinity, integrating both sides gives Φ′ + HΦ = −4πGa 2(ρ + P )v. • Substituting this into the 00 Einstein equation simplifies it to ∇2Φ = 4πGa 2ρ∆, ρ∆ ≡ ρδ − 3H(ρ + P )v where ∆ is defined in the same way as above, but specialized to Newtonian gauge. • Now consider the spatial trace part, Gii = 8πGT i i . Note that the indices on Gii are contracted with the full metric, so there is an additional term from the metric perturbation, and Gii = −3a−2 (−(2H′ + H2) + 2(Φ′′ + 3HΦ′ + (2H′ + H2)Φ ) . The trace of the energy-momentum tensor is T i i = −3(P + δP ). At zeroth order, 2H′ + H2 = −8πGa 2P which is just the second Friedmann equation. At first order, we get Φ′′ + 3HΦ′ + (2H′ + H2)Φ = 4πGa 2δP. • Of course, the equations of motion we have derived are redundant due to the Bianchi identity. For example, we know the zeroth-order second Friedmann equation can be derived from the first Friedmann equation and the energy continuity equation; the first-order second Friedmann equation can be derived in a similar way. One useful conserved quantity is the comoving curvature perturbation. 73 4. Cosmological Perturbation Theory • In an arbitrary gauge, the induced metric for hypersurfaces of constant time is γij = a 2((1 + 2C)δij + 2Eij), Eij = ∂⟨i∂j⟩E for scalar perturbations. A tedious but straightforward computation shows that the three- dimensional Ricci scalar for the hypersurfaces satisfies a 2R(3) = −4∇ 2 ( C − 1 3 ∇2E) . • We define the comoving curvature perturbation as R = C − 1 3 ∇2E + H(B + v). The point of this quantity is that it is gauge invariant, as can be seen by plugging in the gauge transformations, and in comoving gauge (B = v = 0) it reduces to C −(1/3)∇2E, which appears in the expression for R(3). • In Newtonian gauge, we have B = E = 0 and C ≡ −Φ, so R = −Φ + Hv. We can use the 0i Einstein equation to eliminate the peculiar velocity v, for R = −Φ − H(Φ′ + HΦ) 4πGa2(ρ + P ) . • To investigate the time-dependence of R, we take the time derivative of both sides and simplify using the Friedmann equation and Poisson equation, giving −4πGa 2(ρ + P )R ′ = 4πGa 2H δPnad + H P ′ ρ′ ∇2Φ. Here we have defined the non-adiabatic pressure perturbation δPnad = δP − P ′ ρ′ δρ which vanishes for adiabatic fluctuations. • Setting δPnad = 0, the right-hand side scales like Hk2Φ ∼ Hk2R, while the left-hand side is like H2R′ by the Friedmann equation. Rearranging, we have d log R d log a ∼ ( k H )2 which means that super-Hubble Fourier modes of R evolve slowly. • The quantity H decreases during inflation, then increases once inflation ends. Quantum fluc- tuations during inflation determine the value of Fourier modes of R, which are frozen in once their wavelengths become larger than 1/H. Once their wavelengths become smaller again, they may evolve again, growing to give rise to the structure observed in our universe. 74 4. Cosmological Perturbation Theory 4.4 Structure Formation Now we investigate relativistic structure formation. This is usually done numerically, but we will make approximations to get simple analytic results. We will start by considering R, which is useful because it is conserved and sourced by inflation; however, to get physical results we will determine the evolution of Φ, which in turn determines the evolution of the density contrasts δi. • First, note that by using the Friedmann equation, we have R = −Φ − 2 3(1 + w) ( Φ′ H + Φ) in Newtonian gauge, where we have assumed the background is dominated by a single component with equation of state parameter w. Sound waves in this component have c2 s ≈ w. • For adiabatic perturbations, Einstein’s equations imply the gravitational potential evolves as Φ′′ + 3(1 + w)HΦ′ + wk2Φ = 0. However, this equation only applies if w is constant; we must revert to the original Einstein equation when w changes. • On superhorizon scales, k ≪ H, the last term above is negligible, and the growing mode has Φ constant, regardless of the value of w. The decaying mode falls exponentially over a conformal timescale 1/H. • In Newtonian gauge, the Poisson equation reads δ = − 2 3 k2 H2 Φ − 2 H Φ′ − 2Φ where δ is the total density contrast. On superhorizon scales, both the first two terms are negligible compared to the third, for both the growing and decaying modes, so δ ≈ −2Φ = const. • During radiation domination, we have δr ≈ δ, and hence for adiabatic perturbations δm = 3 4 δr ≈ − 3 2 ΦRD. However, Φ changes when we transition to matter domination, even for k ≫ H. To track its change, we use the conservation of R. In the superhorizon limit we have R = − 5 + 3w 3 + 3w Φ by approximating the expression for R above. By conserving R, we have ΦMD = 9 10 ΦRD again on superhorizon scales. 75 4. Cosmological Perturbation Theory Now we consider the evolution of Φ when modes enter the horizon. • During radiation domination, w = 1/3, so the evolution equation is Φ′′ + 4 τ Φ′ + k2 3 Φ = 0. The general solution is given in terms of spherical Bessel and Neumann functions, Φk(τ ) = Ak j1(x) x + Bk n1(x) x , x = kτ √3 . Explicitly, the special functions above are j1(x) = sin x x2 − cos x x , n1(x) = − cos x x2 − sin x x . • Note that n1(x) blows up at early times (small x), so we reject it as a solution, Bk = 0. We match the value Ak to the primordial value of the potential, Φk(0) = (−2/3)Rk(0), giving Φk(τ ) = −2Rk(0) sin x − x cos x x3 . The quantity Rk(0) will be determined statistically by inflation. • The mode enters the horizon when x ∼ 1. For x ≫ 1 we have Φk(τ ) ≈ −6Rk(0) cos(kτ / √3) (kτ )2 . Hence during the radiation era, subhorizon modes of Φ oscillate with frequency k/√3 and decay as 1/τ 2 ∝ 1/a2. • In the matter era, w = 0, so the evolution equation is Φ′′ + 6 τ Φ′ = 0. The growing mode is constant, so the gravitational potential is frozen on all scales during matter domination. • The results are shown in the numeric plot below. Let keq be the value of the horizon scale at matter-radiation equality. 76 4. Cosmological Perturbation Theory For k < keq, the mode is frozen completely, except for the 10% decrease during the transition to matter domination. For k ∼ keq, the mode is somewhat suppressed during the radiation era, while for k ≫ keq, the mode is strongly suppressed. We will see that inflation predicts |Rk| ∼ k−3/2, explaining the choice of y-axis. • For tensor perturbations, it can be shown that during matter domination and zero anisotropic stress, ˆEij,k(τ ) ≈ kτ cos(kτ ) − sin(kτ ) (kτ )3 . This is constant on superhorizon scales, which is a general result independent of the matter content. It oscillates and decays on subhorizon scales; the same behavior also appears for radiation domination. Next, we consider the evolution of perturbations in the radiation density. • These perturbations dominate during the radiation era and hence determine the value of Φ, so the equation of motion is the Poisson equation, δr = − 2 3 (kτ ) 2Φ − 2τ Φ′ − 2Φ, ∆r = − 2 3 (kτ ) 2Φ. As a result, for x ≪ 1, δr is constant while ∆r ∝ τ 2 ∝ a2. Inside the horizon, δr ≈ ∆r = 4R(0) cos(kτ / √3). We thus see that δr oscillates inside the horizon with constant amplitude; it is the solution to δ′′ r − 1 3 ∇2δr = 0. The result δr ≈ ∆r above is essentially because they are equal in some gauge, and there are no gauge ambiguities for subhorizon modes. • During the matter era, radiation perturbations are subdominant, so their evolution is instead determined by conservation equations. On subhorizon scales, the energy continuity and Euler equations are δ′ r = − 4 3 ∇ · vr, v′ r = − 1 4 ∇δr − ∇Φ which combines to give δ′′ r − 1 3 ∇2δr = 4 3 ∇2Φ = const. Then δr oscillates on subhorizon scales with mean δr = −4ΦMD(k). • The acoustic oscillations in the perturbed radiation density give rise to peaks in the spectrum of CMB anisotropies, as we will see below. Now, we consider the evolution of perturbations in the dark matter density. 77 4. Cosmological Perturbation Theory • During radiation and matter domination, the Hubble parameter is H2 = H2 0Ω2 m Ωr ( 1 y + 1 y2 ) , y = a aeq . The energy continuity and Euler equations for matter are δ′ m = −∇ · vm, v′ m = −Hvm − ∇Φ. These combine to the equation of motion δ′′ m + Hδ′ m = ∇2Φ. • Note that Φ is sourced by both matter and radiation. From our work above, we know that subhorizon radiation density perturbations oscillate on a timescale τ ∼ 1/k during both radia- tion and matter domination. By contrast, the damping term above ensures that δm varies on a timescale τ ∼ 1/H. Hence for subhorizon modes, the δr vary rapidly and their effect averages out to zero. • This means that we may replace the right-hand side above with ∇2Φm = 4πGa 2(ρmδm − 3Hρmvm) by the Poisson equation. By the continuity equation, the second term is smaller by a factor of H2/k2 and hence negligible. • The equation of motion can be rewritten in terms of y, giving d2δm dy2 + 2 + 3y 2y(1 + y) dδm dy − 3 2y(1 + y) δm = 0 which is the Meszaros equation. The solutions take the form δm ∝    2 + 3y, (2 + 3y) log √1 + y + 1 √1 + y − 1 − 6 √1 + y. During radiation domination, y ≪ 1, the second solution is the growing mode, with δm ∝ log a. During matter domination, y ≫ 1, the first solution is the growing mode, with δm ∝ a. These are precisely the same results we saw earlier with Newtonian perturbation theory. • Alternatively, during matter domination, we can solve for δm given our expression for Φ during matter domination and the Poisson equation. This gives ∆m = ∇2Φ 4πGa2ρ ∝ { a a−3/2 which is just what we saw in the Newtonian treatment, as ∆m ≈ δm for subhorizon scales. On superhorizon scales, δm is constant, but evidently ∆m ∝ a. 78 4. Cosmological Perturbation Theory • At late times, we need only account for matter and dark energy. However, only matter appears in the Poisson equation since dark energy doesn’t have fluctuations, ∇2Φ = 4πGa 2ρm∆m. The trace part of the Einstein field equation is Φ′′ + 3HΦ′ + (2H′ + H2)Φ = 4πGa 2δP ≈ 0 since pressure fluctuations are negligible. • To convert this to an evolution equation for ∆m, note that the Poisson equation implies Φ ∝ a2∆mρm ∝ ∆m/a. Plugging this in and simplifying with the Friedmann equations gives ∆′′ m + H∆′ m − 4πGa 2ρm∆m = 0. We found a very similar result using Newtonian perturbation theory. • The simplest way to solve this equation is to work in terms of u = ∆m/H, in which case d2u da2 + 3 d log(Ha) da du da = 0. Then the decaying and growing modes are ∆m ∝ H, ∆m ∝ H ∫ da (aH)3 respectively. During matter domination, we have ∆m ∝ a again, while ∆m approaches a constant during dark energy domination. These are consistent with our earlier results, but now also valid for superhorizon scales. Note. The net effect of all the evolution above is that the primordial perturbations are “post- processed”. We can express this in terms of a transfer function, ∆m,k(z) = T (k, z)Rk for the matter fluctuations, where z is the redshift. The observed matter power spectrum is P∆(k, z) = |∆m,k(z)| 2 ∼ { k k ≪ keq, k−3 k ≫ keq. Here the primordial perturbations satisfy |Rk|2 ∝ 1/k3, and the asymptotic behavior follows from the exact same logic as in our Newtonian formalism. A numerical plot of the matter power spectrum is shown below. 79 4. Cosmological Perturbation Theory The dashed line shows nonlinear corrections. On small scales, we can see baryon acoustic oscillations. The story behind these is as follows. We have seen that dark matter perturbations grow once matter domination begins. However, baryon perturbations cannot grow until decoupling, as until this point they are strongly coupled with the photons via Compton scattering. After decoupling, the baryons intuitively fall into the potential well generated by the dark matter, with δb rapidly rising to match the dark matter density contrast δc. This results in some oscillatory behavior as a function of k. 80 5. Initial Conditions From Inflation 5 Initial Conditions From Inflation 5.1 Quantum Fluctuations Now we explain how primordial fluctuations are sourced by the quantum fluctuations of the inflaton. This requires background on quantum field theory in curved spacetime, provided in the notes on General Relativity. • The key intuition is that the inflaton field ϕ acts as a local “clock” reading off the amount of infla- tionary expansion still to occur. However, since ϕ is a quantum field, it necessarily has spatially varying fluctuations, which change when inflation ends, causing adiabatic perturbations. • During inflation, fluctuations are stretched in physical size while the Hubble radius stays the same; equivalently, in terms of comoving coordinates, fluctuations have constant wavelengths, but the comoving Hubble radius shrinks. Hence fluctuations will generally exit the horizon at some point during inflation, and reenter it much later. • At horizon exit (k = aH, for comoving wavenumber k), we match the quantum fluctuation ⟨|δϕk|2⟩ to a classical stochastic field ⟨|Rk|2⟩, which is then conserved. This conservation law allows us to connect quantities during and long after inflation, despite the large amount of unknown physics at play in between. • The point here is that a quantum wavefunction differs from a stochastic mixture only because it can display interference effects – but once modes exit the horizon, such effects can’t occur, so a stochastic treatment is acceptable. That is, the modes decohere upon horizon exit. • Upon horizon re-entry, we can feed ⟨|Rk|2⟩ into cosmological perturbation theory, as we did in the previous section. These perturbations are the seeds of large-scale structure, and become imprinted as temperature fluctuations in the CMB, which are measured today. • The matching at horizon exit is simplest in spatially flat gauge, where R = − H ϕ′ δϕ. The variance of curvature perturbations is therefore ⟨|Rk| 2⟩ = ( H ϕ′ )2 ⟨|δϕk|2⟩. The gauge invariance of R becomes extremely useful here, as we can switch back to Newtonian gauge to handle horizon re-entry. Note. Before diving into the details, we give a heuristic overview of how inflationary perturbations of the inflaton affect observables today. A naive guess would be that changes in ϕ result in changes of the potential, so δρ ρ ∼ δV V ∼ V ′ V δϕ. This is incorrect; the real effect is that changes in ϕ result in changes of when inflation ends. Different regions will reheat to the same temperature once inflation ends locally, so regions where inflation 81 5. Initial Conditions From Inflation ends earlier will end up at a lower temperature because they have more time for the thermal bath to dilute. Parametrically, we have δρ ρ ∼ δa a ∼ ˙a a δt ∼ H δt ∼ H ˙ϕ δϕ ∼ H 2 ˙ϕ . This effect is thus stronger the slower ϕ rolls. Indeed, as we’ll see below, the resulting power spectrum is proportional to 1/ϵ. To understand the fluctuations δϕk further, we need to investigate the dynamics of the inflaton field in an FRW background. This will be quite similar to what we did in the notes on General Relativity, though in that case we considered a free massive field with no vev. • We start from the inflaton action in conformal time, S = ∫ dτ dx √−g ( 1 2 gµν∂µϕ∂νϕ − V (ϕ) ) where the x are comoving coordinates. We write the perturbed inflaton field as ϕ(τ, x) = ϕ(τ ) + f (τ, x) a(τ ) . The normalization of f is chosen to account for Hubble friction, so that it will not have a friction term in the Lagrangian below; this will help us think about the quantization. • In order to derive the linearized equation of motion for f (τ, x), we need to expand the action to second order in it. One complication is that ϕ also affects the geometry. However, in spatially flat gauge, the metric perturbations δg00 and δg0i are suppressed relative to the inflaton fluctuations by a factor of the slow roll parameter ϵ. Hence at leading order in the slow roll expansion, we may take the metric to be the unperturbed FRW metric, giving S = ∫ dτ dx ( 1 2 a2((ϕ′) 2 − (∇ϕ)2) − a 4V (ϕ) ) ≡ ∫ dτ dx L. • At first order in f , we have L (1) = aϕ′f − a′ϕ′f − a3∂ϕV f. Integrating the first term by parts, we have L (1) = − (∂τ (aϕ′) + a′ϕ′ + a3∂ϕV ) f. Setting this to zero gives the zeroth order equation of motion for f , i.e. the equation of motion for the background field, ϕ′′ + 2Hϕ′ + a 2∂ϕV = 0. This is a familiar result, now written in comoving coordinates. 82 5. Initial Conditions From Inflation • The terms quadratic in f are L (2) = 1 2 ((f ′) 2 − (∇f )2 − 2Hf f ′ + (H2 − a 2∂2 ϕV )f 2) . Integrating the f f ′ = (f 2)′/2 term by parts gives L (2) = 1 2 ( (f ′) 2 − (∇f ) 2 + ( a′′ a − a 2∂2 ϕV ) f 2) where we used H′ = a′′/a − H2. • During slow roll inflation, we have ∂2 ϕV H 2 ≈ 3M 2 pl∂2 ϕV V = 3ηv ≪ 1. Since a′ = a2H with H approximately constant, a′′ a ≈ 2a′H = 2a2H 2. • Hence the ∂2 ϕV term in L(2) is negligible, giving L (2) = 1 2 ( (f ′) 2 − (∇f ) 2 + a′′ a f 2) . The equation of motion for the Fourier modes, f ′′ k + ( k2 − a′′ a ) fk = 0 is called the Mukhanov–Sasaki equation, and is simply the Klein–Gordan equation with a time-varying mass. As expected, on subhorizon scales the effective mass term is negligible. • If we account for the metric fluctuations, we get the more accurate result f ′′ k + (k2 − z′′ z ) fk = 0, z2 = 2a 2ϵ which has some dependence on ϵ and its derivatives. Next, we quantize the field f using the standard techniques. • The conjugate momentum is π = f ′, and the canonical commutators are [ ˆf (τ, x), ˆπ(τ, x′)] = iδ(x − x′). We use the symmetric Fourier transform convention ˆf (τ, x) = ∫ dk (2π)3/2 ˆfk(τ )e ik·x. As a result, we have [ ˆfk(τ ), ˆπk′(τ )] = ∫ dx (2π)3/2 ∫ dx′ (2π)3/2 [ ˆf (τ, x), ˆπ(τ, x)]e −ik·xe−ik′·x′ = iδ(k + k′). 83 5. Initial Conditions From Inflation • We take the mode expansion ˆfk(τ ) = fk(τ )ˆak + f ∗ k (τ )a† k and the equations of motion imply that the modes fk(τ ) and f ∗ k (τ ) satisfy the Mukhanov–Sasaki equation. • As usual, if we normalize the Wronskian of the mode functions to W [fk, f ∗ k ] = −i(fk∂τ f ∗ k − (∂τ fk)f ∗ k ) = 1 then the creation and annihilation operators satisfy the usual commutation relations, [ˆak, ˆa† k′] = δ(k + k′). Note that the conventions here differ slightly from the notes on General Relativity. • As usual for quantum field theory in curved spacetime, the vacuum state is ambiguous. However, during inflation, where the background is approximately de Sitter, there is a preferred vacuum state called the Bunch–Davies vacuum, corresponding to the ground state of the Hamiltonian. • We note that every mode is a subhorizon mode in the distant past, τ → −∞. Furthermore, subhorizon modes do not “feel the curvature”, so we may treat them as if they are in Minkowski space. In this case there is a distinguished set of modes, which are just complex exponentials. We hence define the mode functions in the Bunch–Davies vacuum to satisfy lim τ →−∞ fk(τ ) = e−ikτ √2k where the normalization factor is from the Wronskian. • In de Sitter space, the Mukhanov–Sasaki equation is f ′′ k + (k2 − 2 τ 2 ) fk = 0 which has the exact solution fk(τ ) = α e−ikτ √2k ( 1 − i kτ ) + β eikτ √2k ( 1 + i kτ ) . For the Bunch–Davies vacuum, we hence have α = 1 and β = 0, giving fk(τ ) = e−ikτ √2k ( 1 − i kτ ) . • Finally, we can easily compute the fluctuations of ˆf from its mode expansion, ˆf (τ, x) = ∫ dk (2π)3/2 (fk(τ )ˆak + f ∗ k (τ )a † k)e ik·x. Plugging this in, we have ⟨| ˆf |2⟩ ≡ ⟨0| ˆf †(τ, 0) ˆf (τ, 0)|0⟩ = ∫ dk (2π)3 fk(τ )f ∗ k′(τ )⟨0|[ˆak, ˆa † k′]|0⟩. 84 5. Initial Conditions From Inflation Using the commutation relations gives ⟨| ˆf | 2⟩ = ∫ dk (2π)3 |fk(τ )| 2 = ∫ d log k k3 2π2 |fk(τ )| 2. It is also useful to define the dimensionless power spectrum in the usual way, ∆2 f (k, τ ) = k3 2π2 |fk(τ )|2. • Scaling back to the original field, using the mode functions, and τ = −1/aH, we have ∆2 δϕ(k, τ ) = a −2∆2 f (k, τ ) = ( H 2π )2 ( 1 + ( k aH )2) which approaches the scale-invariant result (H/2π)2, as each mode goes well outside the horizon. • More precisely, the universe during inflation is not perfectly de Sitter, as H changes over time. In order to find the corrected result, we would in principle have to expand everything, from the very beginning, order by order in the slow-roll parameters. However, a decent approximation is to evaluate H for each mode k at the moment it leaves the horizon, giving ∆2 δϕ(k) ≈ ( H 2π )2 ∣ ∣ ∣ ∣k=aH . • In the approximations we have used, the distribution of each Fourier mode ˆfk(τ ) is exactly Gaussian. To see this, note that ⟨ ˆfk(τ )2n⟩ = ⟨(fk(τ )ˆak + f ∗ k (τ )ˆa† k) 2n⟩ = |fk(τ )|2n⟨(ˆak + ˆa † k)2n⟩ which shows that all nonvanishing moments scale by factors of |fk(τ )|. Since the modes are initially Gaussian distributed in the Bunch–Davies vacuum (because the ground state wave- function of a quantum harmonic oscillator is), they remain so. Furthermore, modes of different k are uncorrelated. These two results lead to the observed “Gaussian” perturbations. • Corrections to the Gaussian perturbations would have appeared if we had expanded to higher order in the perturbation f above, leading to nontrivial interactions. This is rather technical, as it also requires expanding in the metric perturbations. 5.2 Primordial Perturbations We now relate the fluctuations found above to measurable parameters. • Relating the inflaton fluctuations to the conserved curvature perturbation as described above, ∆ 2 R(k) = ( H ϕ′ )2 ∆2 δϕ(k) = 1 2ϵ ∆2 δϕ M 2 pl where we used ϵ = ( ˙ϕ2/2)/M 2 plH 2. Using our previous result and the slow roll approximation, ∆2 R(k) = 1 8π2 1 ϵ H 2 M 2 pl ∣ ∣ ∣ ∣ k=aH = 1 12π2 V 3 M 6 pl(V ′)2 where V is evaluated at the value that ϕ takes when the mode k leaves the horizon. Since we are only dealing with scalar perturbations, the left-hand side is also called ∆2 s. 85 5. Initial Conditions From Inflation • We hence expect that ∆2 R(k) will be roughly independent of k, and hence scale-invariant. There will be small deviations from scale invariance due to the rolling of the inflaton, and hence we expect that near a reference scale k∗, ∆2 R(k) ≈ As ( k k∗ )ns−1 , ns − 1 = d log ∆2 R d log k . The amplitude As is of order 10−10, since density perturbations are of order 10−5. • We may compute ns − 1 in terms of the slow roll parameters by noting that d log ∆2 R d log k = d log ∆2 R dN dN d log k = (2 d log H dN − d log ϵ dN ) dN d log k . The quantity in brackets is simply −2ϵ − η. For the second term, note that the horizon crossing condition k = aH gives log k = N + log H so that dN d log k = ( d log k dN )−1 = ( 1 + d log H dN )−1 = (1 − ϵ) −1. • Expanding to first order in the slow roll parameters, we hence have ns − 1 ≈ −2ϵ − η. Alternative, we may write this in terms of the inflaton potential in the slow roll approximation, ns − 1 ≈ −3M 2 pl ( V ′ V )2 + 2M 2 pl V ′′ V = −6ϵV + 2ηV . Next, we consider tensor perturbations to the metric. • The tensor perturbations take the form ds2 = a2(τ ) (dτ 2 − (δij + 2 ˆEij)dxidx j) . This gives a second-order action variation of L (2) = M 2 pl 8 a2 (( ˆE′ ij) 2 − (∇ ˆEij) 2) . • For concreteness, consider fluctuations with k ∝ ˆz. Then ˆEij can be expanded as Mpl 2 a ˆEij = 1 √2  f+ f× 0 f× −f+ 0 0 0 0   . Then the second-order Lagrangian is L (2) = 1 2 ∑ I=+,× (f ′ I )2 − (∇fI )2 + a′′ a f 2 I . This is simply two copies of the Lagrangian found for f = a δϕ above. 86 5. Initial Conditions From Inflation • Therefore, we can simply reuse the result to compute the power spectrum of tensor modes, ∆2 t ≡ 2∆ 2 ˆE = 2 ( 2 aMpl )2 ∆2 f = 2 π2 H 2 M 2 pl ∣ ∣ ∣ ∣ k=aH . Note that unlike the scalar modes, we didn’t have to convert to R and convert back, because ˆEij is already in the form of a metric perturbation, which is conserved on superhorizon scales. • Tensor modes are a robust, highly model-independent prediction of inflation, and measuring their amplitude would give direct information about the inflationary scale H. (By contrast, the scalar modes are easier to measure, but only give indirect information, because they depend on ϵ.) For instance, we generically have the Lyth bound (derive) ∆ϕ Mpl ∼ √ r 0.01 where ∆ϕ is the total field excursion during inflation. • We define the scale-dependence of the tensor spectrum by ∆2 t (k) = At ( k k∗ )nt where scale-invariance corresponds to nt = 0, and define the tensor to scalar ratio r = At/As. In the slow roll approximation, we have r = 16ϵ, nt = −2ϵ. In particular, the ratio r/nt = −8 is independent of the slow roll parameters, so its value when measured can provide a consistency check. • The latest observations of the CMB power spectrum from the Planck satellite indicate As = (2.196 ± 0.060) × 10 −9, k∗ = 0.05 Mpc−1, ns = 0.9649 ± 0.0042. The results are shown graphically below. 87 5. Initial Conditions From Inflation The observed magnitude of the scalar perturbations points to an inflationary energy scale of H ≲ ϵ1/41016 GeV. • Tensor perturbations are detected in the CMB by the pattern of light polarization. (understand in more detail) Such a pattern can be decomposed into “E-modes” with vanishing curl, and “B-modes” with curl, named in analogy to electrostatic and magnetostatic fields; tensor perturbations result in B-modes. These have not been detected; instead the tensor-to-scalar ratio is bounded by r ≲ 0.07. We can also check the spectrum of scalar perturbations by evolving them in time with cosmo- logical perturbation theory, and measuring the matter power spectrum. Note. A collection of identities to perform the calculations above. The equations of motion are H 2 = V 3M 2 pl , 3H ˙ϕ ≈ −V ′. The slow roll parameters are ϵ = − ˙H H 2 = − d log H dN = ˙ϕ2/2 M 2 plH 2 , η = d log ϵ dN = ˙ϵ Hϵ , δ = − ¨ϕ H ˙ϕ , η = 2(ϵ − δ). There are also parameters defined in terms of the potential, ϵv = M 2 pl 2 ( V ′ V )2 , ηv = M 2 pl V ′′ V which are related by ϵv ≈ ϵ, ηv ≈ δ + ϵ = 2ϵ − η 2 . In order to convert to conformal time, we have dτ = dt a , H = aH, a′ = a2H. Second derivatives are handled by ˙H = ¨a a − H 2, H′ = a′′ a − H2. For a de Sitter universe we have constant H, so a(t) = eHt, τ = − 1 Ha = − 1 H . Slow roll parameters are related to H and H′ by ϵ = 1 − H′ H2 , η = ϵ′ Hϵ . 88 6. Dark Matter 6 Dark Matter 6.1 History and Evidence We now consider the evidence for dark matter (DM). For lack of space, the history below is drastically oversimplified; for more of the story, see A History of Dark Matter . We begin with one of the most straightforward pieces of evidence, galaxy rotation curves. • In typical galaxies, we infer from the galactic luminosity distribution that the mass is strongly concentrated at the center. So away from the center, stellar velocities should fall off as v ∝ 1/√r. • We can measure the function v(r) by measuring redshifts in galaxies tilted relative to us. The result is that v(r) is flat at high distances, or can even increase. Historically, such observations were made in 1939 for the Andromeda galaxy and extended to larger radii in the 1970s by Rubin and Ford. Later, similar measurements were done at radii well beyond the visible disk by measuring 21 cm line emission. • One should also account for interstellar gas in the calculation of ρ(r), which extends beyond the stars. This can be measured from 21 cm line emission, but in any case is not nearly enough. In addition, there have been decades of searches for baryonic massive compact halo objects (MACHOs) which were just too dim to see, such as cool red and white dwarfs, brown dwarfs, black holes, and rogue planets. But none are present in nearly enough quantity to account for the discrepancy, supporting a nonbaryonic “dark” contribution. • The curves can be fit by assuming a spherically symmetric DM halo. The halo extends far beyond the galactic disk, with significant density up to order 100 kpc from the center. The density functions ρ(r) can be computed by numerical simulations; at the simplest level, they simply solve the collisionless Boltzmann equation. Some commonly used profiles are ρ(r) = ρ0 ×    1/˜r(1 + ˜r2) Navarro–Frenk–White (NFW) 1/˜rγ(1 + ˜r3−γ) generalized NFW 1/(1 + ˜r)(1 + ˜r2) Buckert exp(−2(˜rα − 1)/α) Einasto where ˜r = r/rs and rs is the scale radius, where rs ≃ 20 kpc for our galaxy. Generally, these expressions can’t be derived from any analytic model; they empirically fit the results of simulations. Note that a constant v(r) at large radii corresponds to ρ(r) ∝ 1/r2. • Such a wide DM distribution occurs naturally: objects can only gravitationally collapse if they can radiate away energy, while DM only weakly interacts. The collapsing visible matter then becomes a disc, because of the angular momentum barrier, while the DM halo remains spherical. • We can also infer our local DM density by measuring the local vertical distribution of stars; however, this method is quite noisy and gives a value that could be consistent with zero. • There are subtleties with modeling galaxies numerically. For example, simulated halo density profiles are often “cuspy” (with a sharp increase at small radii, like the NFW or Einasto profile), but observations suggest “cored” density profiles (flat at small radii, like the Buckert profile). 89 6. Dark Matter • However, most DM simulations completely neglected the effects of the baryons, since they are a subdominant fraction of the mass, and have much more complex interactions. But near the center of a galaxy, the baryonic density becomes very high, so they might affect the DM halo. – Adiabatic contraction. As the baryons slowly collapse, they also pull in the DM (as can be computed using adiabatic invariants). This makes the DM profile more cuspy. – “Bursty” outflows of baryonic matter, e.g. from supernova and active galactic nuclei, could carry DM outward, coring the profile. – The DM halo could also be affected by DM self-interactions. These simulations are difficult, and many parameters must be determined empirically. So far, there’s no definitive resolution to the problem, because the uncertainties are large. • In addition, ΛCDM simulations seem to indicate more small scale structure than is actually observed, specifically more dwarf galaxies bound to the Milky Way; this is called the “too big to fail” or “missing satellites” problem. On the other hand, others argue that this is just observation bias; the satellite galaxies might just be too dim to see, and more are being discovered regularly. Almost all problems with DM are galactic in nature (see this recent review), but galactic dynamics is extraordinarily complex and uncertain. Note. MOND is an alternative hypothesis that explains galaxy rotation curves well. Here, the gravitational acceleration due to a mass takes the limiting value lim r→∞ g = √ GM a0 r2 for a constant a0. This explains flat rotation curves, because we expect v2 r = √ GM a0 r2 at large distances, and the factors of r cancel. It also provides a direct explanation of the empirical Tully–Fisher relation L ∝ v4, assuming that M ∝ L. There are several options for g at intermediate values of r which can be adjusted to fit observations at intermediate radii. In general, MOND seems to do a better job of fitting rotation curves, requiring fewer parameters than galaxy simulations with DM, but completely fails to match evidence from galaxy clusters and the CMB; the only MOND models that work here also use DM. Moreover, galaxy simulations are steadily improving with time, reducing the benefit that MOND provides. This explains the comparatively little interest in MOND: it only gives a minor benefit to the modeling of only one of many aspects of the universe. (However, there are theories of superfluid DM which reduce to MOND on galactic scales. Also, to be fair, one can get the right CMB power spectrum with MOND as long as one puts in a precisely chosen, bumpy initial power spectrum; in this case DM plus inflation has the advantage of working with generic initial conditions, i.e. being more predictive.) For a deeper look at the debate from a philosophical perspective, see this review. Evidence for dark matter also comes from observing clusters of galaxies. • Historically, this was the first evidence for dark matter, proposed in 1933 by Fritz Zwicky to explain observations of the Coma cluster. 90 6. Dark Matter • Regarding each galaxy as a point mass, we can show the virial theorem, ¨I = 2T + V, I = 1 2 ∑ i miri · ri where I is the virial, T is the total kinetic energy, and V is the total potential energy. In the steady state, ¨I averages to zero and we have T = − V 2 which allows us to estimate the mass of a cluster of galaxies from the observed ⟨v2⟩. • In practice, we can estimate ⟨v2 ⊥⟩ from redshifts, and multiply by 3 assuming spherical symmetry. We also assume ρ(r) is proportional to the luminosity L(r), allowing us to estimate the average potential energy. Combining these gives a total mass several times higher than the stellar mass inferred by a “census” estimate using luminosity. • One also needs to know the distance to the cluster. Zwicky did this using the overall Doppler shift and Hubble’s law. Though he used an incorrect value for the Hubble constant, overestimating the amount of DM, he did find the right qualitative conclusion. • The common ground between cluster observations and rotation curves is that they use “tracers”, visible collisionless objects that respond to the DM density. Stars are generally excellent tracers because they are very sparse, and hence collisionless. • DM is also responsible for presence of the hot intracluster gas, which emits X-rays; if DM were not present, most of the gas would be gone. Assuming the gas is in hydrostatic equilibrium and obeys the ideal gas law, dP dr = − GM (r)ρ(r) r2 , P = ρkT m we find that M (r) = kT (r)r Gm (− d log(ρT ) d log r ) so that M (r) can be inferred from the functions T (r) and ρ(r), which are measured by X-ray emission. This was done in the 1990s and indicate the same result. Note. A proof of the virial theorem. We simply differentiate to find ˙I = ∑ i ri · pi, ¨I = ∑ i vi · pi + ri · Fi. The first term in ¨I is simply 2T . To handle the second term, note that ∑ i ri · Fi = − ∑ i̸=j ri · ∇iVji = − ∑ i<j ri · ∇iVji − ∑ i>j ri · ∇iVji. Swapping the index names on the second term, we get − ∑ i<j ri · ∇iVji + rj · ∇jVij = − ∑ i<j (ri − rj) · ∇iVji 91 6. Dark Matter where we used the fact that Vij = Vji is a function of ri − rj. Now, for any power law potential Vij ∝ (ri − rj)n, the term simplifies using the power rule to −nV , giving the result ¨I = 2T − nV. But as long as we work in the CM frame, we expect ˙I to be roughly constant over time, giving ⟨T ⟩ = n 2 ⟨V ⟩. Using the virial theorem, we can also estimate the speed of dark matter in the galactic halo, v ∼ √ GMhalo Rhalo ∼ √ G 1012M⊙ 100 kpc ∼ 200 km/s. That is, we have v/c ∼ 10−3. Note. For generic initial conditions, we estimate the virialization time to be on the order of the gravitational collapse timescale t ∼ 1/ √Gρ, which is on the order of the time it takes the galaxy to rotate; the Milky Way has rotated about 100 times since its formation. There is the possibility of a nonvirialized subcomponent to dark matter. For example, dark matter that has recently been pulled off a satellite galaxy is part of a “stream” with low velocity dispersion. We can also see evidence for dark matter through gravitational lensing. • Galaxies and galaxy clusters deflect light. This can be used to measure their masses, giving results in agreement with the observations above. • Lensing observations can also be used to constrain the nature of dark matter. Baryonic DM could come in the form of MACHOs (massive compact halo objects), i.e. stellar remnants and brown dwarfs. When a MACHO passes exactly between the Earth and a distant star, we see a bright ring around the star. If the object is slightly off center, we instead get a bright arc. • In practice, these arcs and rings are small enough that we can only detect a momentary brightening of the star. Surveying the sky for these brightening events gives us an estimate of the number of MACHOs in the galaxy. The result is a small fraction of the DM density. • Gravitational lensing was also used to analyze the Bullet cluster, which was formed by the collision of two large galaxy clusters. It indicated that the interstellar gas, as measured by X-ray spectroscopy, lagged behind most of the gravitational mass, indicating the presence of weakly-interacting DM. (The stars are effectively collisionless and kept going, mostly following the DM.) This was regarded by many as the “nail in the coffin” for MOND. • However, note that there also are “anti-Bullet cluster” systems, such as the “train wreck cluster” Abell 520, where the DM is in the middle with the interstellar gas; it’s not clear how these are to be interpreted, though the data are in some doubt. The Bullet cluster is also unusual, as it has exceptionally high velocity dispersion. Finally, bounds on DM self-interaction from the Bullet cluster are in tension with the self-interaction needed to explain galaxy anomalies. Finally, cosmological observations give us crucial independent data. 92 6. Dark Matter • We can infer the mass density of stars by measuring luminosities, and assuming that a large population of stars has the same mass-to-luminosity ratio as a typical population near us. Additional mass comes from nonluminous stellar remnants, such as white dwarfs, neutron stars, and black holes, as well as brown dwarfs. • Galaxies also contain significant amounts of interstellar gas, which accounts for 10% of the mass of the Milky Way. For rich clusters of galaxies, the mass of the intergalactic gas can be larger than the mass in the galaxies. This gas is extremely hot and is detected by X-rays using the Sunyaev–Zel’dovich effect. • By combining all these measurements, a total baryonic density of Ωb = 0.05 is found, while redshift measurements in the concordance model indicate Ωm is much larger; in the model the difference is accounted for by DM. • Stringent independent constraints on Ωb come from the baryon acoustic oscillation peaks in the CMB, and from the results of BBN, which both yield the same number. • The DM density also plays an important role in structure formation in the early universe, as we’ve seen above. Measurements of the matter power spectrum yield yet another independent, consistent value for Ωm. • Various modified gravity theories which reduce to MOND in the nonrelativistic limit, such as TeVeS, have also been applied to cosmological scales. However, they currently do a much worse job of fitting the observations than the standard cosmological model. For instance, TeVeS does not produce stable stars. 6.2 Models of Dark Matter We now summarize the little that is known about dark matter. • DM candidates can be divided into “cold” and “hot”, depending on their typical velocities. Since the 1990s we have known that most, if not all DM must be cold, as hot DM could “free- stream” to smooth out small mass fluctuations. Concretely, with cold DM one can first form small structures that merge into larger ones; with hot DM one would first form large structures that fragment into smaller ones. Observations allow only 1% of the DM to be hot. • One could also consider warm DM, which only suppresses small structures; one could test for this by looking for a cutoff in the matter power spectrum. Other constraints on warm DM come from Lyman α-forest absorption, which provides a map of nearby (z ∼ 5) hydrogen gas. • If it’s assumed that DM is in thermal equilibrium with the SM thermal bath, then lighter DM particles would automatically be hot. However, there are many nonthermal DM production mechanisms, such as the misalignment mechanism for axions. • The interactions of DM with the SM are so far consistent with being purely gravitational. Any interactions present must be weak, as they would otherwise contradict, e.g. Bullet cluster observations, and so on. A rough limit for the scattering cross section is σ/m ≲ (100 MeV)−3. However, adding weak interactions may improve the accuracy of numerical galaxy simulations. 93 6. Dark Matter • Decay of DM must be slow. At the simplest level, it must decay slowly enough to still be present today; if the decay is to visible particles, one has stronger constraints from the non-observation of such particles, while if the decay is invisible, one also has stronger constraints due to bounds on how much the DM density can change over time. However, a small amount of decay or annihilation could be used to explain some standing anomalies involves excess detections of energetic SM particles. These should be taken with a grain of salt, because many such anomalies exist, and they frequently vanish. • DM must have a very small charge, if any at all. The simplest reason is that we can’t see it, but stronger constraints come from, e.g. the requirement that the DM be completely decoupled from the thermal bath at recombination. Depending on the mass range, the bound on charge is about 10−6e. Such a small charge could result from a normal-sized charge under a U (1)A′ which weakly kinetically mixes with U (1)A. • To fit with CMB observations, DM must be present by z ∼ 1000, eliminating many candidates that form by collapse at late times, such as ordinary black holes. (There aren’t enough anyway; they are currently estimated to be about 0.1% of DM.) However, “primordial” black holes, assumed to form early in the universe, are a possibility. • One generic bound on fermionic DM comes from the exclusion principle. We have n p3 ∼ ρDM/mDM (mDMv)3 ≲ 2 which yields mDM ≳ 1 keV. This is the Tremaine–Gunn bound. However, bosonic DM can be substantially lighter. On the other hand, composite DM can range up to planetary masses, above which there are lensing bounds, leaving a range of many orders of magnitude in mass. • The DM does not experience as much dissipation as SM particles, because our galaxy’s DM halo seems to be roughly spherical. It’s still possible that part of the DM could have collapsed into a “dark disk”, and some claim its destabilizing effect could have killed the dinosaurs, though this may have been ruled out with Gaia data. We now briefly consider some dark matter candidates. • Many DM candidates fall into one of two classes: light cold bosonic DM (below keV scale) and heavy WIMP-like DM (above MeV scale) produced by freeze-out. Some of these candidates are covered in more detail in the notes on the Standard Model. • The lightest stable supersymmetric particle, typically a neutralino (but also possibly, e.g. a “mixed sneutrino” or a gravitino), is the canonical example of a WIMP. Many experiments have tried to directly detect WIMPs recoiling on nuclei by the weak force, and have now ruled out most of the “natural” parameter space. • Neutrinos could account for the DM density if their mass was around 10 eV, and they came into thermal equilibrium. This made neutrinos a leading DM candidate in the 1980s, when neutrino oscillations established that they were massless. However, such neutrinos would be hot, and so could not make up the DM by themselves. Today, upper bounds on the neutrino masses from cosmological measurements show that neutrinos are cold DM, but only about 1% of it. 94 6. Dark Matter • Sterile neutrinos that don’t come into thermal equilibrium could account for the DM density if their mass is on the keV scale; they can be produced via neutrino oscillations in the Dodelson– Widrow or Shi–Fuller mechanisms. Resonant scattering off such sterile neutrinos has been used as an explanation for a deficit of 3.5 keV photons emitted from galaxy centers. But they are also strongly constrained, as their decay to normal neutrinos would produce X-rays that haven’t been detected. • Axions are typically extremely light, but can become cold DM because they have a nonthermal production mechanism, the misalignment mechanism. This produces axions in a BEC-like state, with very low velocity dispersion. • One could also consider axions in a supersymmetric theory, in which case they are part of a chiral supermultiplet. There is another real scalar field, the saxion, and a fermion called the axino. If the axion is the phase of a complex scalar field, the saxion can be thought of as the magnitude. The saxion decays quickly, but the axino can be another WIMP-like DM candidate. • Some call Primordial black holes (PBHs) the “least speculative” DM candidate, because they don’t have nongravitational interactions. But they must be formed by the collapse of large density perturbations in the early universe, which don’t appear in the simplest inflation models. • These perturbations could appear if the inflaton potential had a plateau (the “ultra slow-roll” regime), or in multi-field inflation, where different fields are responsible for the perturbations on small scales and cosmological scales. They could also be formed more violently, such as by the collapse of cosmic strings, bubble collisions from a first-order phase transition, or even by collapse of “dark stars” made of dark sector particles. • More generally, we could have “macroscopic DM”, i.e. DM that comes in discrete chunks, which could have formed through a phase transition or dissipative process. Such objects can have masses ranging from the Planck mass (about a microgram) up to many solar masses. Compared to PBHs, macroscopic DM can be much less compact and doesn’t emit Hawking radiation, but it can have nongravitational interactions with the SM. • Here we overview constraints on ultraheavy DM, including PBHs and macroscopic DM. – Above mDM = 103M⊙, the gravitational effects of individual DM objects would measurably warp structures by tidal effects. – The lifetime of a black hole before it evaporates by Hawking radiation is τ ∼ G2M 3 ℏc4 ∼ 10 64 ( M M⊙ )3 yr. Below mDM ∼ 1012 kg ∼ 10−18M⊙, PBHs would have already decayed. (But there is a loophole since extremal BHs are obstructed from decaying.) Black holes above 10−7M⊙ aren’t evaporating at all; they’re actually gaining mass because the CMB is hotter. – The formation of PBHs requires large density perturbations, which are strongly constrained by the CMB. However, these CMB constraints are only well-measured on large scales, so the small-scale perturbations which would form sub-solar mass PBHs are not constrained. They could be probed in the future by observations of primordial gravitational waves. 95 6. Dark Matter – PBHs are also strongly constrained up to 10−16M⊙ because of X-rays that would be produced by Hawking radiation, and above 10−11M⊙ by lensing constraints. A small window is left in between the two, where PBHs could be all of the DM. (Previously, it was thought much of this range was ruled out by “femtolensing” constraints, but it turns out these are invalidated by finite source size effects.) People also consider cases where PBHs could be a small subcomponent of the DM. – Macroscopic DM is a bit more complicated, because it is characterized by both a mass and a SM interaction cross section. It is also constrained by lensing above 10−10M⊙, and below 103 kg or so, there are bounds from terrestrial experiments. But there is a huge “asteroid” range where large interactions with the SM are allowed. We now list some twists on the collisionless cold dark matter (CCDM) paradigm. • Warm DM, as mentioned above, smooths out small scale structure. • Self-interacting DM (SIDM) makes the later stages of structure formation significantly more complicated. Scattering can alleviate the cusp-core problem, and also strips the halos from small clumps of DM orbiting larger structures, reducing their number. It has also been invoked to explain the “train wreck cluster”. • In particle physics, SIDM can also stand for strongly interacting DM. The reason is that the cross sections needed to make self-interacting DM work are of order σ/m ∼ Λ−3 QCD, which is typical for a particle interacting under the strong force. • Self-annihilating DM, as mentioned above, can explain standing anomalies and helps alleviate the cusp-core problem, as does decaying DM. • Fuzzy DM is extremely light bosonic DM with a de Broglie wavelength on the order of the galaxy size; this would provide an additional “poofiness” to DM halos, which could help alleviate the cusp-core problem. Using the uncertainty principle ∆x∆p ≳ 1 with ∆p ∼ mDMv and ∆x the size of a dwarf galaxy halo gives the standard quoted estimate mDM ≳ 10−22 eV. However, over the past ten years, improved data and modeling have pushed up the constraints, which now lie around mDM ≳ 10−21 eV, depending on who you ask. • Repulsive DM is light bosonic DM which forms a condensate with a repulsive self-interaction, also addressing the cusp-core problem. The idea of “superfluid DM” falls in this category. • These options are distinguished by their detailed predictions. For example warm DM, fuzzy DM, and repulsive DM all pick out preferred length scales, while decay DM picks out a time scale, and self-interacting and self-annihilating DM pick out densities. There are many DM production mechanisms beyond freeze-out, and we list some here. • In the freeze-in scenario, we suppose that the DM is never in thermal equilibrium, but rather has zero abundance in the early universe; the abundance rises monotonically to the desired value throughout cosmological history. Such an initial condition can be achieved if the DM interaction with the SM is very weak, and it is not produced during reheating. • The freeze-in scenario has different parametrics (the final abundance increases with interaction strength, as opposed to decreasing for freeze-out) and accommodates a wide range of masses. The relevant DM particles are called feebly interacting massive particles (FIMPs). 96 6. Dark Matter • Note that if the production rate Γ is set by a dimensionless coupling g ≪ 1 rather than a suppression by a mass scale, then we have Γ ∼ g2T . Since H ∼ T 2, this means production gets more important later in cosmological evolution. This is nice because the final abundance isn’t determined by the reheat temperature, which is free. • One can modify the freeze-out scenario by considering other DM interactions. – Coannihilation: there are two DM species, χiχj → ϕϕ, where ϕ is some generic other particle, and χi and χj are in chemical equilibrium but have different masses. Now the lightest species is the DM, but freeze-out only fixes the cross section for χiχj annihilation, which has absolutely no relation to the cross section for χi scattering in WIMP experiments. – Elastic scattering: χ + SM ↔ χ + SM. This isn’t an annihilation process, but it can transfer energy between the DM and SM baths, so its rate can play an important role in some of the more elaborate mechanisms mentioned below. – Coscattering: χϕ → ψϕ, where the DM converts to another particle in scattering. – Zombie/pandemic DM: the DM is all converted to another species in reactions like χϕ → ϕϕ, which causes the amount of ϕ to increase exponentially. – Self-annihilation: nχ ↔ χχ with n ≥ 3. These couplings could emerge in a theory with, e.g. χ3 or χ4 vertices. (This typically also implies DM self-interactions χχ ↔ χχ, which have astrophysical consequences.) This gives a qualitatively different annihilation rate. – The above reaction is also called “cannibalization”, because for an isolated DM bath, it slows the cooling as rest energy is cannibalized to kinetic energy. In the standard WIMP freeze-out scenario, self-annihilation isn’t present. The abundance is fixed by when the annihilation process decouples. In several newer ideas, the annihilation process is weak and decouples early, while the other processes continue to be effective. • In strongly interacting massive particle (SIMP) DM, the SM and DM baths are kept in thermal equilibrium by an elastic scattering process, and the DM has a 3 → 2 self-annihilation process. Over time, energy is removed from the dark sector by elastic scattering, until the self-annihilation process decouples. The final DM abundance is sensitive to the DM mass and the self-annihilation rate, with typical target masses of mDM ∼ 100 MeV, motivating “light dark matter”. • In elastically decoupling relic (ELDER) DM, the elastic scattering process decouples before self- annihilation. Self-annihilation then keeps the DM bath at approximately a constant temperature for a long period, until it too decouples. It turns out this makes the final DM abundance sensitive to only the elastic scattering cross section, leading to different parametrics. • Ultralight bosonic DM can be produced nonthermally through the misalignment mechanism, with its abundance thus fixed by initial conditions, or by inflationary fluctuations. Other nonthermal production mechanisms include the decay of heavy particles or topological defects. • Asymmetric DM is the idea that the relic DM abundance arises from an asymmetry between DM and DM. (For example, in “cogenesis”, this asymmetry arises simultaneously with the baryon-antibaryon symmetry.) This is a tempting idea since the DM and baryon densities are equal up to an O(1) factor. In the simplest version of the idea, nDM and nB could exactly cancel, with mDM ≈ 5mp. 97 6. Dark Matter Example. More about SIMPs, ELDERs, and cannibals, focusing on a 3 → 2 annihilation process. (finish) • The rates for DM annihilation, elastic scattering with the SM, and DM self-annihilation are Γann ∼ nDM⟨σv⟩ann, Γkin ∼ nSM⟨σv⟩kin, Γ3→2 ∼ n2 DM⟨σ3→2v2⟩. We can parametrize these rates in terms of couplings, where generically ⟨σv⟩kin ∼ ⟨σv⟩ann ≡ ϵ2 m2 DM , ⟨σv2⟩3→2 ≡ α3 eff m5 DM where the mDM dependence enters by dimensional analysis. We don’t have to include powers of T because we have assumed the relevant rates are not dependent on the typical velocity v. This is just the usual assumption of s-wave annihilation for the two-body processes, and its analogue for the three-body annihilation. • The story of SIMP DM holds as long as Γkin ≳ Γ3→2 ≳ Γann until freeze-out. Assuming this is true, freeze-out occurs at Γ3→2 ∼ HF ∼ T 2 F Mpl and by similar reasoning to the usual WIMP freeze-out calculation, this means mDM ∼ αeffT 2/3 eq M 1/3 pl . For strong DM self-interactions, αeff ∼ 1, this points to masses mDM ∼ 100 MeV. The mass scale of the strong force, rather than the weak force, emerges, motivating the name. • Next, we check the bounds above. After freeze-out, we have ρDM = mDMnDM ∼ T 4 Teq T since the DM density and radiation density are on the same order at Teq. Then at freeze-out, nSM ∼ T 3 F , nDM ∼ nSM Teq mDM which gives Γann ∼ ϵ2T 3 F m2 DM Teq mDM , Γkin ∼ ϵ2T 3 F m2 DM , Γ3→2 ∼ α3 effT 6 F T 2 eq m7 DM . • By using TF ∼ mDM/20 and plugging in our expression for mDM above, our bounds become α1/2 eff ( Teq Mpl )1/3 ≲ ϵ ≲ αeff ( Teq Mpl )1/6 . For αeff ∼ 1 this gives a possible range of three orders of magnitude for ϵ. 98 6. Dark Matter • Incidentally, if we instead assumed an n → 2 self-annihilation process dominates, then a similar calculation gives mDM ∼ αeff(T n−1 eq Mpl)1/n, so we can further lower the mass. We now say a bit more about the relatively new paradigm of dark/hidden sectors. • In the standard WIMP paradigm, we think of the DM as part of a sector that interacts strongly with the SM, such as the superpartners in SUSY. By contrast, a “dark sector” is a group of related particles, one of which is the DM, which interacts only weakly with the SM. • In principle, a dark sector doesn’t have to interact with the SM at all, except gravitationally. This is the worst-case scenario; on the other hand, there is reason for optimism, because many concrete production mechanisms require nongravitational interactions. • For concreteness, let’s suppose that pairs of DM particles couple to a mediator, which in turn couples to pairs of SM particles. In this scenario we can have freeze-out production, where the mediator takes the place of the weak boson for WIMPs. • The relic abundance scales as m2 DM/ϵ2g2 D, where ϵ is the mediator’s coupling to the SM, and gD is its coupling to DM. Taking gD to be O(1) and adjusting ϵ, we can accommodate a range of DM masses, from the keV to TeV scale. In SUSY, which in this context is just a concrete way to construct the hidden sector, this was called the “WIMPless miracle”. In principle gD can be adjusted too, but lowering it just increases ϵ, so taking a strong dark sector coupling is a conservative assumption. • For mDM ≲ MeV, DM annihilates after neutrinos decouple, which would be detected through Neff. Thus, the window for “light” DM is MeV to GeV. • Light DM is difficult to search for in direct detection experiments, because such particles deposit little energy in a collision. And since the couplings are low, it is difficult to see the production of such DM in the collider “energy frontier”. Instead, for colliders one needs to go to the “intensity frontier”, e.g. in beam dump experiments. • Stepping back, we can ask which interactions between the hidden sector and the SM are “generic”. One answer is that it corresponds to the lowest-dimension allowed operators: – For a vector, there is the dark photon coupling (ϵ/2 cos θW )BµνF ′µν where F ′ is the gauge field strength of a dark photon, and B is the U (1)Y gauge field strength; after electroweak symmetry breaking it is (ϵ/2)FµνF ′µν + (ϵ/2) tan θW ZµνF ′µν, where Fµν and Zµν are the photon and Z boson field strengths. The first term is the most important at low energies. – To understand the phenomenology clearly, we need to refine the fields to remove the kinetic mixing. There are two possibilities. First, we can keep the interactions with other particles the same by setting A′µ → A′µ + ϵA, in which case we get a mass mixing between the photon and dark photon, allowing them to oscillate into each other. Alternatively, we can remove the mass mixing too, in which case all charged particles pick up a small coupling to the dark photon. – More general possibilities are also possible with more model building; for example, there are several motivations to gauge U (1)B−L: it is non-anomalous in the SM provided sterile neutrinos are introduced, and it can be used to construct R-parity in SUSY models. However, the standard dark photon is distinguished by its minimality. 99 6. Dark Matter – There is nothing similar for an axial vector, because the SM has no conserved axial currents; coupling to a nonconserved current would yield issues with unitarity. Of course, a dark axial vector can be accommodated with further model building, which is used for the X17 boson to explain the Beryllium anomaly. – For a pseudoscalar, there are again no options in the SM. However, if we allow dimension 5 operators, we have the axion couplings (a/fa)Fµν ˜F µν, (a/fa)Gµν ˜Gµν, and (∂µa/fa)ψγµγ5ψ. Since the axion is so well-motivated, this is usually included in the standard list. – For scalars, we have the dark Higgs couplings, (µS + λS2)H †H, where the first term isn’t allowed for complex scalars. This leads to couplings to SM fermions proportional to their mass. If we allow dimension 5 operators, we can multiply the scalar with any marginal SM operator; in this context, the scalar is often called a “dilaton” in analogy to string theory, since in both cases its value shifts fundamental constants. – For fermions we have yN LHN , where N is called a sterile neutrino, or heavy neutral lepton. The dark photon, axion, dark Higgs, and sterile neutrino are the “portals”. For concreteness, we’ll focus on dark photons. • The dark photon coupling kinetically mixes the SM photon and the dark photon. Upon diagonalizing the kinetic terms with a field redefinition, we can show that the physical degrees of freedom are the familiar photon, along with a massive vector which couples strongly to DM particles, and to SM particles proportional to ϵeQ. • The way we would search for such a dark sector depends on the mass of the dark photon. – If it’s in the same “light” mass range as the DM particle, then we could look for its production in a collider experiment. In this case the identity of the DM particle isn’t so important, except that it sets a target for the dark photon coupling. – If it’s light, then we can integrate it out. The result is that the DM particles effectively have very small “millicharges”. The dark photon itself can also be searched for directly, e.g. through fifth force searches. – The dark photon itself could be the DM, produced by a nonthermal production mechanism like the axion. This “ultralight” DM could be searched for through precision experiments, such as DM Radio. • To get a specific target for ϵ, note that if there is a heavy particle that couples to both the photon and dark photon, then it can induce this coupling at one loop. Integrating it out gives ϵ ∼ 1/16π2 ∼ 10−3, which gives a mass right in the middle of the light DM range. • A U (1)B−L gauge boson would be searched for in much the same ways as an ordinary dark photon, but the details of the couplings would be different, e.g it would couple equally strongly to neutrons and protons. We could also break family symmetry, e.g. by gauging U (1)Lµ−Lτ , which would produce no coupling to electrons. On the other hand, these exotic dark photons still pick up a mixing with the SM photon at one loop, albeit a smaller one. • A similar story holds for a “dark Higgs”. In the simplest models, it would couple to SM fermions proportionally to their mass, so it is best probed by the decays of heavy mesons. 100 6. Dark Matter • In the standard hidden sector freeze-out scenario, we assume the DM is heavier than the mediator. Forbidden DM is a variant on freeze-out where the DM can only annihilate into heavier particles. In this case, we have ⟨σv⟩ ∼ e−2∆m/T /m2 DM at freeze-out, which can accommodate very light dark matter if ∆m is chosen correctly. (To avoid the final particles themselves being a relic, they need to either be SM particles or a decaying hidden sector particle.) • Another twist is if the DM is heavier than the mediator, but pairs of DM particles couple to pairs of mediator particles. Then DM can annihilate to the mediator, which later decays to SM particles. In this case, the relic density scales as m2 DM/g4 D, where gD is the mediator-DM coupling. This is called “secluded” annihilation because the extra step means there are much weaker constraints on mDM and g. • Things could of course be much more complicated. There could be composite objects in the dark sector, resulting from dissipation, phase transitions, or strong interactions. We could have dark atoms, dark molecules, dark mesons and baryons, dark nuclei, or even dark glueballs, leading to a rich phenomenology. As one of infinitely many possible examples, dark pions automatically have a quintic vertex due to the Wess–Zumino–Witten term, providing the self-annihilation process needed for several mechanisms above. 6.3 Direct Dark Matter Detection Next, we briefly consider dark matter detection. • The three main paradigms for DM detection are shown below. The amplitudes for all three are related by crossing symmetry. • In a direct detection experiment, one watches for recoils of SM particles (e.g. atomic nuclei) off DM particles. Such experiments are placed deep underground to shield cosmic rays. They were first explored in the mid-1980s by Goodman and Witten. Many experiments have been done since then, placing stringent bounds on WIMP-nucleon cross sections. • A single experiment, the DAMA collaboration, has seen a significant annual modulation in scattering events, which could be due to the seasonal variation of the Earth’s velocity through the DM halo. However, the results are not taken seriously due to possible systematic effects. Since DAMA uses a different material than other experiments, it can be consistent with other experiments if the DM coupling is strongly spin-dependent. • Astrophysicists typically use indirect detection methods, searching for the produces of anni- hilating DM. Such signatures include an excess of antimatter, mono-energetic gamma rays, and high-energy neutrinos. The sensitivities of these experiments tend to be complementary to direct direction experiments, e.g. they are more sensitive to higher masses. 101 6. Dark Matter • TeV scale DM could also be produced at the LHC, with the classic signal being missing energy or momentum, such as in the production of a “mono-X” event, where X is a photon, jet, W , Z, h, t or so on. Here, one can take a “top-down” approach, computing results from a full theory such as the MSSM. Alternatively, one could use a simplified model, which gives more generic constraints but which may miss peculiarities that can occur in more complex models. This is done starting from a full model by just removing irrelevant particles, or setting couplings equal or to zero. • For practicality, LHC results are often phrased in terms of these simplified models, which include the DM particle and the most important mediator. This leaves a reasonable number of parameters, primarily the DM mass, the mediator mass, and, e.g. the mediator’s coupling to quarks, which fix the rates for processes such as mono-jets, mediator pair production, or qq scattering via a mediator. • Various combinations are then possible for the spin and parity of the DM and mediator. For example, a typical figure caption is “axial mediator, Dirac DM, gq = 0.25, gχ = 1.0” with the masses of the mediator and DM on the axes. Next, we consider direct detection in more detail. • Standard WIMP direct detection experiments consist of looking for recoils of WIMPs off nuclei. An exclusion plot is shown below. The basic intuition is that at higher masses, the sensitivity to the cross section falls as 1/m simply because there are fewer DM particles. At lower masses, the sensitivity falls off because the energy deposited by each DM particle is smaller, so not all impacts can be seen; the curve here depends on the details of the high-velocity tail. 102 6. Dark Matter • Since the WIMPs would rotate along with the galaxy, there is both a daily modulation of the event rate, due to the spin of the Earth, and a yearly modulation, due to the orbit of the Earth. This is an important way to confirm a WIMP signal, as there are many possible backgrounds, such as radioactivity and cosmic rays. One can also directly measure the WIMP “wind” if the detector is directionally sensitive. • Suppose a WIMP with mass mχ and speed v hits a stationary nucleus with mass M . If the nucleus recoils at an angle θ from the original velocity of the WIMP, then some basic classical mechanics gives a recoil energy of E = 2µ2v2 cos2 θ M , µ = M mχ M + mχ . The maximum recoil energy has the limits Emax ∼ M v2 min(1, m 2 χ/M 2) For a standard weak-scale WIMP recoiling off a heavy nucleus, the two arguments above are of the same order. Taking v ∼ 10−3, we have Emax ∼ 10 − 100 keV. • Depending on the search, the impact is detected by the resulting ionization, light emitted, calorimetry (i.e. energy deposited into phonons/heat), or a combination of these options. These have varying advantages; for instance, calorimetry reliably gets all the deposited energy, but it is by far the slowest. • Calculating the differential event rate dR/dE uses input from several fields of physics. – First, compute the amplitude for WIMPs to scatter off quarks or gluons. This is highly model-dependent. – Next, use results from nuclear physics to compute the scattering amplitude for protons and neutrons. Usually, we take these to be the same for simplicity; the final experimental bound will get reported in terms of that quantity. – Infer the amplitude for scattering off the heavy nuclei by summing over the nucleons. At finite momentum transfer, this requires using nuclear form factors, such as the standard simple Helm form factor. – Compute the scattering rate using the WIMP number density and velocity distribution, e.g. using the standard halo model f (v) = 4 √π v2 v3 0 e−v2/v2 0 . This is not exactly true, especially in the high velocity tail; for example, one crude correction would be to set it to zero for velocities greater than the escape velocity of the Milky Way. There is a great variety of halo models, which mostly differ in the tail. One can substantially change the results by upsetting some of the assumptions made above; this can be used to make the DAMA results consistent with other exclusions. 103 6. Dark Matter • An important distinction is between spin-independent and spin-dependent scattering. For spin- independent scattering, in the limit of low momentum transfers, the amplitude contributions of the nucleons add coherently, enhancing the cross section by A2 where A is the atomic mass number. This works for a decent range of momentum transfers because of the low WIMP velocity. (However, for higher momentum transfers, we must account for a form factor suppression.) The standard WIMP exclusion plots assume spin-independent scattering. • On the other hand, for spin-dependent scattering, the contributions of nucleons with opposite spins cancel. Since heavy nuclei generally have spin much less than A, this leads to a huge suppression. (DAMA’s NaI target is much more sensitive to spin-dependent couplings than other targets, which is why its positive result is not flatly impossible.) • In general, it’s important to have good resolution at low energies, because dR/dE is always monotonically decreasing. It is especially important for experiments detecting light DM, which require light targets and very low energy thresholds. Example. Suppose the WIMP χ is a Majorana fermion, e.g. the lightest neutralino in a SUSY model. There are two possible leading couplings to quarks: the spin-independent scalar coupling L ⊃ χχqq which could arise from Higgs exchange, and the spin-dependent axial-vector coupling L ⊃ χγµγ5χqγµγ5q which could arise from Z exchange. If χ is a Dirac fermion, we could also have the spin-independent vector coupling L ⊃ χγµχqγµq. One can extend this discussion to spin 0 or spin 1 WIMPs. Standard WIMP exclusion plots assume a spin-independent scalar coupling. 6.4 Indirect Dark Matter Detection Next, we consider indirect detection in more detail. • The standard WIMP miracle calculation fixes the two-body annihilation rate during freeze-out, which can be used to guess the present day annihilation rate. Of course, there are many caveats. Many of the more elaborate DM production mechanisms discussed above completely break this relation: DM relying on 3 → 2 self-annihilation might have no 2 → 2 annihilation process at all, and coannihilating DM would not have anything to annihilate against today. • Even if standard 2 → 2 annihilation is the dominant process, the annihilation cross section could be effectively different today than during freeze-out, since DM is now more nonrelativistic. – If s-wave annihilation is forbidden, the leading contribution is usually p-wave annihilation, which has ⟨σv⟩ ∝ v2, which is much lower today. – If the DM interacts by a light mediator, its annihilation rate can be higher today due to the Sommerfeld enhancement, a nonperturbative effect due to the exchange of many mediators. – There could be resonances which enhance the annihilation rate, for appropriate DM velocity. 104 6. Dark Matter • We could also consider a one-body decay. It differs qualitatively from annihilation, since it scales only linearly with the density. However, we don’t have a solid benchmark for how fast the decay should be. • One could get rough estimates using an EFT approach with GUTs. For example, if a weak-scale WIMP decays by a dimension 5/6/7 operator from the GUT scale, we would have τ ∼    m2 GUT/m3 DM ∼ 0.1 s dimension 5 m4 GUT/m5 DM ∼ 1025 s dimension 6 m6 GUT/m7 DM ∼ 1051 s dimension 7 which are definitely ruled out, possibly observable, and completely unobservable. • There are a few qualitatively distinct options for the decay/annihilation products. If colored particles or taus are produced, they hadronize and produce many pions, which in turn decay to produce a continuum spectrum of gamma rays. If electrons or muons are produced, we end up with charged leptons and neutrinos, with only a few photons. Photons can be produced directly, giving a sharp spectral peak, but the branching ratio is expected to be small. Neutrinos can also be produced, but they’re very hard to detect. • Charged particles get strongly deflected by galactic magnetic fields, so experiments looking for such particles are effectively direction blind. Photons and neutrinos aren’t deflected, but the detection rates are generically expected to be lower. • Historically, many indirect detection experiments have reported anomalies which could be explained by DM, but then have been explained by astrophysical effects. This is especially difficult for charged particles, since they could be produced by essentially any nearby new astrophysical phenomenon, such as an unseen population of pulsars. For the uncharged particles, these sources can be localized and ruled out. Now we focus on detection of uncharged particles. • Consider DM annihilation in a volume element dV at a distance R from the observer. If the spectrum produced per annihilation is dN/dE, then the spectrum produced per time is 1 2 ρ2 m2 DM ⟨σv⟩ dN dE dV where ρ is the DM density and the 1/2 avoids overcounting. Alternatively, if DM comes in particles and antiparticles symmetrically, then we lose the 1/2, but we convert ρ2 to (ρ/2)2, making the result 1/2 again as large. • The spectrum per unit time incident on a detector per unit area dA is found by dividing by 4πR2 and integrating over dV . This quantity splits neatly into a “particle physics” part and “astrophysics” part, dNobs dE dt dA = 1 8πm2 DM ⟨σv⟩ dN dE ∫ ρ 2 dR dΩ where the integral is called the J-factor. For decaying DM, a similar argument gives dNobs dE dt dA = 1 4πmDM 1 τ dN dE ∫ ρ dR dΩ 105 6. Dark Matter where the integral is called the D-factor. Note, however, that conventions differ on where to put the factors of 1/8π or 1/4π, and whether to include the angular integral in the J or D-factor. • Here we have assumed that the cross-section does not depend too strongly on the velocity; otherwise we have to put the ⟨σv⟩ under the integral. Also, if we look at distant targets, one should also account for redshift; the line of sight integral dR should be recast as a dz integral. • Computations of the J-factor depend on the halo model used, especially whether it is cuspy or cored. This makes a significant difference for annihilation because scales quadratically with the density, and hence dominates in the galactic center region. One can estimate local DM densities using oscillations of stars above and below the galactic plane, but this is difficult at the galactic center because one must subtract off a large baryonic matter background. • For concreteness, plugging in typical WIMP numbers with a cuspy NFW profile gives dNobs dE dt ∼ 10 −9 cm−2s−1 for the galactic center. We need about a year with a 100 cm2 detector to see one photon. • There are several places that one could look, with various advantages and disadvantages. – Dwarf galaxies are nearby and have low background, and thus often give the strongest constraints on annihilation. – The galactic center has high signal, giving it a high potential for discovery. However, it has high background, and the J-factor is uncertain. – The galactic halo is large and nearby, but has complex backgrounds. – Other galaxies and galaxy clusters carry a huge amount of DM and also hold redshift information, but are further away. Since they contain a huge total amount of DM, they often give the strongest constraints on decay. However, the J-factor is uncertainty since it depends on DM substructure in the cluster. – Seemingly empty space could produce a signal, depending on the DM substructure, but it’s hard to know where to look. – Extragalactic background radiation also carries substantial redshift information and aver- ages over a huge region. • For gamma rays, there are a variety of experiments providing exclusion bounds. – From 100 MeV to 1 TeV: Fermi and DAMPE. These are in space, with a relatively small area but wide field of view. – From 100 GeV to 10 TeV: HESS, VERITAS, MAGIC. These are ground-based telescopes, with a narrow field of view. – From 1 TeV to 100 TeV: HAWC, and later CTA and LHAASO. These ground-based apparatuses have a wide field of view, since they search for the Cherenkov radiation produced when the gamma rays pass through a tank of water. • For neutrinos, there’s also a variety of experiments. – SuperK probes neutrinos from a few MeV to 1 TeV. 106 6. Dark Matter – ANTARES reaches 100 GeV to 100 TeV. – IceCube reaches 100 GeV to 109 GeV. • The strongest constraints on GeV-scale DM that annihilates to photon-rich channels come from Fermi looking at gamma rays from dwarf galaxies. The analysis is done by fitting “templates” (i.e. Poisson distributions due to background and candidate signal) using maximum likelihood. A combined analysis rules out thermal relic WIMP DM for masses up to ∼ 100 GeV, subject to standard assumptions, though the precise bound depends on the annihilation channel. • Constraints on decaying DM can can probe DM masses up to 1010 GeV, or even Hawking radiation from primordial black holes. We can also cover masses down to the keV range using X-ray telescopes such as Chandra, XMM-Newton, INTEGRAL, HXMT, Astrosat, NuSTAR, and Suzaku, or the proposed XRISM, XPoSat, STROBE-X, Athena, and Lynx. • According to Fermi data, there is a highly significant excess of GeV-scale photons from the galactic center, first noticed by Goodenough and Hooper in 2009. Particle explanations of this excess would have masses in the range 7 − 10 GeV and are generally called “hooperons”, but the excess could also be explained by a large population of pulsars. Emission from pulsars would be more “clumpy”, but whether the data reflects this is a matter of current controversy which depends on fine statistical details. • There is also an outstanding 4σ excess of 3.5 keV photons from galaxy clusters, found by XMM- Newton in 2014, which has been confirmed by other experiments. The simplest DM explanation is a decaying 7 keV sterile neutrino, but that hypothesis is in tension with other constraints. In addition, there are many possible non-DM sources in this energy range. Next, we consider detection of charged particles. • Charged cosmic rays diffuse through the galactic magnetic field, losing energy as they propagate and escaping at the boundaries; both of these effects soften the spectrum. Protons are usually in the “diffusion-dominated” regime, while electrons and positrons are in the “loss-dominated” regime, sampling only a local regime of about 1 kpc. In practice, one uses specialized programs such as GALPROP or DRAGON, or pregenerated results such as PPPC4DMID. • It is generally better to look for antimatter because DM decay should produce it equally as often, but the background should be much lower; examples include antiprotons, antideuterons, and positrons. Antimatter can be distinguished from matter by how it curves in a magnetic field. If we’re using matter, we can still distinguish signal from background, but we need to use spectral features. In general, the backgrounds for charged particles are much harder to model than for photons, so while the bounds tend to be stronger, systematic uncertainties are high. • The leading experiment for cosmic rays of GeV energies and up is AMS-02, on the International Space Station, and for the purposes of DM detection its sensitivity to antiprotons and positrons is most important. • Some surprisingly strong limits for sub-GeV cosmic rays come from the Voyager spectrometer. These cosmic rays are usually deflected by the solar wind, but Voyager can see them since it is beyond the heliopause. This provides the best limits on 10 MeV to 1 GeV DM annihilating or decaying to electrons and positrons. 107 6. Dark Matter • Even just considering AMS-02, there are many outstanding anomalies. – There is a very large, long-standing excess of TeV-scale positrons, which was also seen by AMS-02’s predecessor Pamela. But it’s so large that it’s hard to explain with DM, so it’s likely due to a nearby population of pulsars. – There is an excess of antiprotons around 100 GeV at 4.5σ, but the statistical significance is disputed because of possible correlations between energy bins. – There are tentatively a few events with antihelium, which is supposed to be extremely rare from astrophysical sources. However, it’s also tough to get an antihelium signal from DM. We can also consider “very indirect” DM detection. • Annihilating or decaying DM would have steadily injected energy into the universe throughout its history. This can modify the results of BBN, and also change the ionization and temperature history, which affects the CMB and 21 cm radiation. Such limits are clean because they don’t depend on galactic astrophysics. • Extra ionization during the cosmic dark ages (z ∼ 10 − 1000) acts as a “screen” for CMB photons. To estimate the resulting bound, note that during radiation domination and after freeze-out, the fraction of DM that annihilates per Hubble time is n⟨σv⟩H ∝ T and this quantity is order 1 at freeze-out itself. • Thus, at recombination the fraction is small, Trec/Tf ∼ 10−9. On the other hand, the mass- energy of one DM particle is enough to ionize (1 GeV)/(13.6 eV) ∼ 108 hydrogen atoms, assuming all the energy goes into ionization, so at matter-radiation equality a tiny fraction of the DM particles annihilating gives a large effect. • Planck is sensitive to changes in the ionization of order ∼ 10−4, so ionization provides a strong bound, especially for lower DM masses. Planck rules out the thermal relic benchmark for masses below 10 GeV, though the precise bound depends on the annihilation channel. Ionization also places constraints on decaying DM, which are especially strong from MeV to GeV. • Annihilation can also heat the universe, and energy injection during recombination distorts the blackbody spectrum of the CMB. However, at matter-radiation equality the change in temperature would be of order Trec/Tf ∼ 10−9, which is too small for Planck to probe. More promisingly, the energy can also go into heating the baryons in the form of hydrogen gas, which are vastly outnumbered by the photons. • We can measure the gas temperature over time by measuring the redshifted 21 cm line, with more emission corresponding to a higher temperature. Without a DM effect, we expect the gas to be colder than the CMB after recombination, since nonrelativistic matter cools down more quickly, then heat back up at the cosmic dark ages; DM would appear as a higher temperature at earlier times. • This line is currently probed by EDGES, HERA, LOFAR, MWA, PAPER, SARAS, SCI-HI, and will be probed further by DARE, LEDA, PRIZM, and SKA. EDGES has seen a deep absorption trough at z ∼ 17, which is extremely surprising, but the measurement is very difficult and has not yet been confirmed by other experiments. 108 6. Dark Matter • The Lyman-alpha forest is a set of emission lines due to the Lyman-alpha transition in neutral hydrogen. It can thus be used to probe the amount of neutral hydrogen. While the CMB is better for probing extra ionization near the beginning of the cosmic dark ages, the Lyman-alpha forest is better for probing extra ionization near the end, before the usual reionization starts. It is not as useful for earlier times because when most hydrogen is neutral, such photons are very efficiently absorbed. 109 7. The CMB 7 The CMB We now consider the CMB more closely. • It is difficult to measure the full CMB spectrum on the ground due to absorption by water molecules in the atmosphere. The first accurate measurement over all wavelengths was performed by the COBE satellite in 1989, which found that the CMB’s spectrum in all directions was very close to that of an ideal blackbody. • The CMB’s temperature was found to be anisotropic due to the Earth’s peculiar velocity. By subtracting off Earth’s velocity about the Sun, the Sun’s velocity in the galaxy, and the galaxy’s motion velocity relative to the Local Group, we can measure the peculiar velocity of the Local Group; it is moving quickly towards the nearest supercluster. • Subtracting off this dipole distortion gives much smaller fluctuations, with ⟨T ⟩ = 2.725 K, (δT /T )rms = 1.1 × 10 −5. Thus the CMB is very nearly isotropic, providing strong evidence for the Big Bang. • The temperature variations can be used to infer the matter distribution on the surface of last scattering, and hence the matter power spectrum at that time. However, this is somewhat subtle. Matter and radiation perturbations are related, since we have adiabatic perturbations, δr = 4 3 δm, δr = δρr ρr = 4 δT T which tells us that δT T = 1 3 δm. • However, we must also account for the fact that the photons redshift when they climb out of the gravitational potential. Naively, we would have δT /T = δΦ/c2, where Φ is the potential, and we restored factors of c. However, part of this is cancelled by the simultaneous expansion of the universe, giving δT T = δΦ 3c2 . This is called the Sachs–Wolfe effect. • Setting c = 1 again, δΦ and δm are related by the Poisson equation, δΦ(k) = − 4πG k2 ρa2δm(k) which means the Sachs–Wolfe effect dominates for modes with k ≲ aH at last scattering, i.e. superhorizon modes. • Isotropy tells us that it is useful to expand δT /T in spherical harmonics, δT (ˆn) T = ∞∑ l=0 l∑ m=−l almYlm(θ, ϕ), Ylm(θ, ϕ) = NlmeimϕP m l (cos θ) where the Nlm make the spherical harmonics normalized on the sphere. Intuitively, the spherical harmonics have O(1) values on the sphere, but vary on angular scales θ ∼ π/l. The Sachs–Wolfe effect dominates for l ≲ 50. 110 7. The CMB • If we have Gaussian perturbations as stated above, the coefficients alm will be uncorrelated, ⟨alma∗ l′m′⟩ = Clδll′δmm′ where the multipole moments Cl have no m-dependence by isotropy. • To relate this to the two-point correlation function of the temperature, note that for two directions with ˆn · ˆn′ = cos θ, ⟨δT (ˆn)δT (ˆn′)⟩ T 2 = ∑ lml′m′⟨almal′m′⟩Ylm(0, 0)Yl′m′(θ, 0) = ∑ l 2l + 1 4π ClPl(cos θ) where we used P m l (1) = δm0 and Nl0 = √ (2l + 1)/4π. • For some intuition, the functions Pl(cos θ) are about 1 for θ ≲ 1/l, and oscillate rapidly with lower magnitude for θ ≳ 1/l. Thus, the temperature correlation function above is parametrically l2 0Cl0 where l0 ∼ 1/θ. Alternatively, the variance of the temperature goes roughly as ∫ l2Cl d log l. We now relate this to the observed CMB data. • As motivated above, we plot the combination l(l + 1)Cl. Note that the error bars are larger at small l. This “cosmic variance” effect is because there are fewer of the coefficients alm available to average over. • For small l, the Sachs–Wolfe effect dominates. By decomposing δΦ(k) into spherical harmonics, one can show that Cl = 16πT 2 9 ∫ dk k2PΦ(k)j2 l (kr) where jl(kr) is a spherical Bessel function. For the Harrison–Zel’dovich spectrum, this implies that Cl ∼ 1/l(l + 1), which is indeed observed in the left part of the plot above, where the curve is flat. The slight tilt of the curve can be used to establish ns ≈ 0.97, in agreement with direct measurements of the matter power spectrum. • At higher l, we see a pattern of peaks and troughs, associated with baryon acoustic oscillations. The first peak at l ≈ 200 represents an acoustic wave that had time to undergo a single compression before decoupling. Its l value gives us information about the curvature of the universe, and hence tells us that the universe is nearly flat. • Historically, this was known by the 1990s, and at the time, it was regarded as a puzzle because the amounts of matter and radiation did not add up to the critical density. Thus, CMB observations lent early evidence to dark energy, which was regarded as established by supernova redshift measurements in 1998, though the CMB itself doesn’t directly say anything about it. • The next two peaks represent oscillations that decoupled at the first rarefaction, and the second compression, respectively. (Oscillations that decoupled in between a rarefaction and a compression, i.e. when at uniform density, correspond to the troughs.) These give information about the amount of baryonic and dark matter in the universe. More dark matter lowers all of the peaks, while more baryonic matter enhances the odd-numbered peaks (why?) . • For high l ≳ 103, the power spectrum is suppressed. This is because photon decoupling takes a finite time, and during this process, photon diffusion wipes out small-scale fluctuations. 111 7. The CMB • Additional information can be extracted from the polarization pattern of the CMB, which is decomposed into E-modes and B-modes, as mentioned earlier. The E-modes arise automatically from Thomson scattering in an inhomogeneous plasma, and are in accordance with the standard theory of inflationary perturbations. The B-modes are expected to be much weaker, and haven’t been observed yet, but would give information about the scale of inflation. Note. More about the discovery of dark energy. Type Ia supernova begin as white dwarfs, which slowly siphon matter from a companion star. When the mass passes the Chandrasekhar limit, a supernova occurs. Since the initial masses of all type Ia supernova are similar, they can be used as standard candles. Strictly speaking, they don’t all have the same luminosity, but much of the variance can be accounted for by examining how the luminosity changes over time, in a so-called light-curve shape analysis. Supernova are detected by looking for momentary brightenings of distant galaxies. Their Doppler shift can be used to compute a redshift, while their luminosity can be used to compute a distance. In a uniformly expanding universe, these two are proportional. Each data point is quite noisy. However, in the 1990s, supernova surveys investigated about 100 supernova at redshifts up to about z = 1.0, and observed a deviation from linearity at 5σ, indicating accelerating expansion due to our current period of dark energy dominance. (Note that these observations take place substantially later in the universe than anything else covered in these notes!) Dark energy can be distinguished from a systematic effect, such as absorption of distant light by dust (i.e. a “tired light” hypothesis), because ΛCDM predicts that for z ≳ 1.0 we have matter domination, during which the expansion decelerates. However, measurements at such huge distances are extremely difficult, and ongoing. Another line of evidence for dark energy is that the accelerated expansion stunts the growth of galaxies late in the universe, which is indeed observed. These results remain rather controversial to many. To theorists, dark energy appears difficult to account for in ordinary quantum field theory without tuning, leading to the cosmological constant problem, and it appears difficult to embed into string theory, according to the dS Swampland conjecture. Philosophers are convinced that dark energy is objectionable because of a great variety of vague, metaphysical reasons. Some cosmologists have objected to the original dark energy discovery papers, on the grounds that their analyses overestimated their statistical significance. Finally, late-time measurements of the Hubble constant (including supernova Ia measurements, but also measurements of quasars) indicate a higher value than that extrapolated from CMB measurements, leading to the “Hubble tension”. Note. None of the discussion above gives direct information about the topology of the universe as a whole. For example, it’s possible that the universe is toroidal (i.e. “wraps around”) on scales far larger than our Hubble patch. This is scientifically uninteresting, because it produces no observable consequences while making the math more complicated; hence the default assumption is a trivial topology. However, if the topology is on a smaller scale, predictions can be made. In 2003, it was conjectured that the small Cl at l ≲ 3 could be explained by a finite, “Poincare dodecahedral” space, whose volume would be too small for such perturbations to “fit in”. This leads to the prediction of “matched circles” in the temperature variations of the CMB, where we see the same part of the surface of last scattering in two different directions; however, a search in 2004 failed to find this.","libVersion":"0.5.0","langs":""}