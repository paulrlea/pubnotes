{"path":"Notes/Physics/Computing for Physicists/In Class 4/CFP_lec4_2024(1).pdf","text":"Lecture 4: Data â—¦Data files and types (munging data) â—¦Least squares and fitting Data Tabbed or simply delimited data can be read(or written) easily with np.loadtxt (or np.savetxt) Multiple data sets from different types of experiments or simulations Metadata: data about your data. simulation ~ compiler flags or libraries, input parameters, dates, etc. experiment ~ background readings of other equipment, instrumental settings, who took data, etc. Lots of different formats for data: structured: .csv, excel (.xlsx), .sql unstructured (markup for metadata): .xml or .json (pseudo)file-system : HDF5, zip (with metadata in .xml or .json) ?Stata, Clipboard, Pickle, Feather, SAS, â€¦? Pandas Library can read a large assortment of datafile types Structured vs. unstructured Structured: each entry has the same fields (csv, sql) id|code|name|area|area_land|area_water|population|population_growth|birth_rate|death_rate|migration_rate|created_a t|updated_at1|af|Afghanistan|652230|652230|0|32564342|2.32|38.57|13.89|1.51|2015-11-01 13:19:49.461734|2015-11-01 13:19:49.4617342|al|Albania|28748|27398|1350|3029278|0.3|12.92|6.58|3.3|2015-11-01 13:19:54.431082|2015-11-01 13:19:54.4310823|ag|Algeria|2381741|2381741|0|39542166|1.84|23.67|4.31|0.92|2015-11-01 13:19:59.961286|2015-11-01 13:19:59.961286 entry from SQL database, country demographics {'event_type':'started-mission', 'keen':{'created_at':'2015-06-12T23:09:03.966Z', 'id': '557b668fd2eaaa2e7c5e916b', 'timestamp':'2015-06-12T23:09:07.971Z'}, 'sequence':1} {'event_type':'started-screen', 'keen':{'created_at':'2015-06-12T23:09:03.979Z', 'id': '557b668f90e4bd26c10b6ed6', 'timestamp':'2015-06-12T23:09:07.987Z'}, 'mission':1, 'sequence':4, 'type':'code'} {'event_type':'started-screen', 'keen':{'created_at':'2015- 06-12T23:09:22.517Z', 'id':'557b66a246f9a7239038b1e0', 'timestamp':'2015-06- 12T23:09:24.246Z'}, 'mission':1, 'sequence':3, 'type':'code'}, .json (javascript object notation) file, events from visitors to a website .xml file (extensible markup language) Pandas Import data as a â€œDataFrameâ€ â—¦Collection of series (similar to ndarray, but not fixed length) â—¦Can be created from dictionary of arrays, lists, or series â—¦Gracefully handles missing or corrupt data â—¦Many numpy operations also work on dataframes (slicing, whole set manipulation/operations, Boolean logic, etc.) Wrangling Subsets of data: Boolean arrays: a Boolean array as an argument to an ndarray (or df) selects elements which are true Ingredients of a data fitting problem ï± A set of data Usually, ğ‘¥ğ‘–are measured with sufficient certainty, while ğ‘¦ğ‘–are subject to some uncertainty (i.e., error bars). ï± A model function ï± A figure-of-merit to be optimized The function depends on a set of adjustableparameters {ğ‘} For linear fitting, the function is simply ğ‘“(ğ‘¥;ğ‘,ğ‘ ) =ğ‘+ğ‘ğ‘¥ Or in a more common form ğ‘“ğ‘¥ =ğ‘+ğ‘ğ‘¥ Least squares: ğ‘†= [ğ‘¦âˆ’ğ‘“(ğ‘¥)] ğœ’ = ğ‘¦âˆ’ğ‘“(ğ‘¥) ğœ Chi-square: Least squares are special case of chi-square with all ğœequal. On the other hand, chi-square can be considered as weighted least squares. Measuring the acceleration of gravity, g, using free fall Why Least squares and chi-square? 2.01.81.61.41.21.0ğ‘¥(â„) 0.410.370.340.290.240.20ğ‘¦(ğ‘¡ ) Why do the measured points, ğ’šğ’Š, not fall on exactly a straight line? Because any experimental measurement has an error bar. ğ‘¥ğ‘“( )ğ‘¦âˆ’ exp âˆ’ 2ğœ 1 ğœ 2ğœ‹ ğ‘ƒğ‘¦ = Probabilityof finding ğ‘¦in the vicinity of its actual (or expected) value with ğˆbeing the standard deviation(or error bar). ïƒ˜ The goal of fitting is to find the set of {ğ‘} that maximizesthe probability for ALL measured points, i.e., âˆ ğ‘ƒğ‘¦ . ğ‘† = [ğ‘¦âˆ’ ğ‘“(ğ‘¥)] ğœ’ = ğ‘¦âˆ’ ğ‘“(ğ‘¥) ğœ ïƒ˜ This is equivalent to the minimizationof least squares or chi-square Linear fitting (or regression) 2.01.81.61.41.21.0ğ‘¥(â„) 0.410.370.340.290.240.20ğ‘¦(ğ‘¡ ) ğ‘¦=ğ‘“ğ‘¥ =ğ‘ğ‘¥+ğ‘ ğ‘†= [ğ‘¦âˆ’ğ‘“(ğ‘¥)] ğ‘†= [0.20 âˆ’ğ‘âˆ— 1.0 +ğ‘]2 +[0.24 âˆ’ğ‘âˆ— 1.2 +ğ‘]2 +[0.29 âˆ’ğ‘âˆ— 1.4 +ğ‘]2 +[0.34 âˆ’ğ‘âˆ— 1.6 +ğ‘]2 +[0.37 âˆ’ğ‘âˆ— 1.8 +ğ‘]2 +[0.41 âˆ’ğ‘âˆ— 2.0 +ğ‘]2 ğ‘†= 0.6023 âˆ’ 5.848ğ‘+ 14.2ğ‘ âˆ’ 3.7ğ‘+18ğ‘ğ‘+ 6ğ‘ ğœ•ğ‘† ğœ•ğ‘ = âˆ’5.848 + 28.4ğ‘+18ğ‘= 0 ğœ•ğ‘† ğœ•ğ‘ = âˆ’3.7 +18ğ‘+12ğ‘= 0 ğ‘= 0.213 ğ‘= âˆ’0.011 Linear fitting â€“ General formulation ğœ’ (ğ‘, ğ‘) = ğ‘¦âˆ’ ğ‘ğ‘¥âˆ’ ğ‘ ğœ = ğ‘¦ ğœ âˆ’ 2ğ‘¥ğ‘¦ ğœ ğ‘ âˆ’ 2ğ‘¦ ğœ ğ‘ + ğ‘¥ ğœ ğ‘ + 2ğ‘¥ ğœ ğ‘ğ‘ + 1 ğœ ğ‘ ğœ•ğœ’ ğœ•ğ‘ = âˆ’ 2ğ‘¥ğ‘¦ ğœ + 2ğ‘¥ ğœ ğ‘ + 2ğ‘¥ ğœ ğ‘ = 0 ğœ•ğœ’ ğœ•ğ‘ = âˆ’ 2ğ‘¦ ğœ + 2ğ‘¥ ğœ ğ‘ + 2 ğœ ğ‘ = 0 ğ‘¥ ğœ ğ‘ + ğ‘¥ ğœ ğ‘ = ğ‘¥ğ‘¦ ğœ ğ‘¥ ğœ ğ‘ + 1 ğœ ğ‘ = ğ‘¦ ğœ ğ¶ ğ¶ ğ¶ ğ¶ ğ¶ ğ¶ ğ¶ğ‘ + ğ¶ğ‘ = ğ¶ ğ¶ğ‘ + ğ¶ğ‘ = ğ¶ ğ‘ = ğ¶ğ¶âˆ’ ğ¶ğ¶ ğ¶ğ¶âˆ’ ğ¶ ğ‘ = ğ¶ğ¶âˆ’ ğ¶ğ¶ ğ¶ğ¶âˆ’ ğ¶ Can we estimate the error bars in ğ’‚ and ğ’ƒgiven the error bars of ğ’šğ’Š(i.e, ğˆğ’Š)? Errors (or uncertainties) in aand b ğ‘¥ ğœ ğ‘ + ğ‘¥ ğœ ğ‘ = ğ‘¥ğ‘¦ ğœ ğ‘¥ ğœ ğ‘ + 1 ğœ ğ‘ = ğ‘¦ ğœ ğ¶ ğ¶ ğ¶ ğ¶ ğ¶ ğ¶ ğ‘(ğ‘¦) = ğ¶ğ¶âˆ’ ğ¶ğ¶ ğ¶ğ¶âˆ’ ğ¶ ğ‘(ğ‘¦) = ğ¶ğ¶âˆ’ ğ¶ğ¶ ğ¶ğ¶âˆ’ ğ¶ For a function with independent variables ğ‘“(ğ‘¥, ğ‘¥, â€¦ ğ‘¥), the variancein ğ‘“, ğœ , is given by the variance of the variables, ğœ , through the error propagationformula: ğœ = ğœ•ğ‘“ ğœ•ğ‘¥ ğœ variance is the square of standard deviation Note: the variables here are ğ‘¦, not ğ‘¥! ğœ = ğœ•ğ‘ ğœ•ğ‘¦ ğœ = ğ¶ğ‘¥âˆ’ ğ¶ ğ¶ğ¶âˆ’ ğ¶ 1 ğœ ğœ is the short form for ğœ ğœ = ğœ•ğ‘ ğœ•ğ‘¦ ğœ = ğ¶âˆ’ ğ¶ğ‘¥ ğ¶ğ¶âˆ’ ğ¶ 1 ğœ = ğ¶ ğ¶ğ¶âˆ’ ğ¶ = ğ¶ ğ¶ğ¶âˆ’ ğ¶ = 1 âˆ† ğ¶ğ‘¥ âˆ’ 2ğ¶ğ‘¥ğ¶+ ğ¶ ğœ =ğ¶ğ¶âˆ’ 2ğ¶ğ¶ + ğ¶ğ¶ âˆ† =ğ¶âˆ† âˆ†=ğ¶ âˆ† = 1 âˆ† ğ¶ âˆ’ 2ğ¶ğ¶ğ‘¥+ ğ¶ ğ‘¥ ğœ =ğ¶ğ¶ âˆ’ 2ğ¶ğ¶ + ğ¶ ğ¶ âˆ† =ğ¶âˆ† âˆ† =ğ¶ âˆ† Summary of Linear Regression ğ‘ = ğ¶ğ¶âˆ’ ğ¶ğ¶ ğ¶ğ¶âˆ’ ğ¶ ğ‘ = ğ¶ğ¶âˆ’ ğ¶ğ¶ ğ¶ğ¶âˆ’ ğ¶ Fitting function: ğ‘¥ ğœ ğ‘ + ğ‘¥ ğœ ğ‘ = ğ‘¥ğ‘¦ ğœ ğ‘¥ ğœ ğ‘ + 1 ğœ ğ‘ = ğ‘¦ ğœ ğ¶ ğ¶ ğ¶ ğ¶ ğ¶ ğ¶ ğœ = ğ¶ ğ¶ğ¶âˆ’ ğ¶ ğœ = ğ¶ ğ¶ğ¶âˆ’ ğ¶ ğœ’ (ğ‘, ğ‘) = ğ‘¦âˆ’ ğ‘ğ‘¥âˆ’ ğ‘ ğœ Solve for a and b by minimizing ğœ’: ğœ•ğœ’ ğœ•ğ‘ = 0 and ğœ•ğœ’ ğœ•ğ‘ = 0 Error bars on for a and b: Solution for a and b: (linear fit) Goodness of fit, ğŸvalue , with General least-squares problem Linear regression: â—¦ ğ‘“ğ‘¥ =ğ‘+ğ‘ğ‘¥ (ğ‘“= 1,ğ‘“=ğ‘¥) Higher order polynomial (still considered linear regression): â—¦ğ‘“ğ‘¥ =ğ‘+ğ‘ğ‘¥+ğ‘ğ‘¥ +ğ‘ğ‘¥ + â‹¯ (ğ‘“= 1,ğ‘“=ğ‘¥,ğ‘“=ğ‘¥ ,ğ‘“= ğ‘¥ , â€¦ ) Nonlinear functions: â—¦ğ‘“ğ‘¥ =ğ‘+ğ‘sinğ‘¥ +ğ‘ğ‘’ (ğ‘“= 1,ğ‘“= sin (ğ‘¥),ğ‘“=ğ‘’ , ) ğœ’ = ğ‘¦âˆ’ğ‘“(ğ‘¥) ğœ ğ‘“ğ‘¥ = ğ‘ğ‘‹(ğ‘¥) (note, fitting function is still only linear in the parameters, ğ‘,ğ‘,ğ‘, â€¦) (ğ‘‹are basis functions) Minimize ğœ’to find ğ‘,ğ‘,ğ‘, â€¦ will be a set of linear equations in aâ€™s and nonlinear routines Non-linear routines may converge to â€œlocalâ€ minima, not the true optimum","libVersion":"0.5.0","langs":""}