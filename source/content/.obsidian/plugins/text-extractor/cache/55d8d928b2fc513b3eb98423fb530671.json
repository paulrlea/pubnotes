{"path":"Notes/@Fall2024/Stat Mech/PHYS-4940 (Independent Study) Fall 2024/stat_mech_pathria_3rd_ed.pdf","text":"Statistical Mechanics Third Edition Statistical Mechanics Third Edition R. K. Pathria Department of Physics University of California at San Diego Paul D. Beale Department of Physics University of Colorado at Boulder AMSTERDAM • BOSTON • HEIDELBERG • LONDON NEW YORK • OXFORD • PARIS • SAN DIEGO SAN FRANCISCO • SINGAPORE • SYDNEY • TOKYO Butterworth-Heinemann is an imprint of Elsevier Butterworth-Heinemann is an imprint of Elsevier The Boulevard, Langford Lane, Kidlington, Oxford, 0X5 1GB, UK 30 Corporate Drive, Suite 400, Burlington, MA 01803, USA First published 1972; Second edition 1996 © 2011 Elsevier Ltd. All rights reserved The right of R. K. Pathria to be identiﬁed as the author of this work has been asserted in accordance with the Copyright, Designs and Patents Act 1988. No part of this publication may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or any information storage and retrieval system, without permission in writing from the publisher. Details on how to seek permission, further information about the Publisher’s permissions policies and our arrangements with organizations such as the Copyright Clearance Center and the Copyright Licensing Agency, can be found at our website: www.elsevier.com/permissions. This book and the individual contributions contained in it are protected under copyright by the Publisher (other than as may be noted herein). Notices Knowledge and best practice in this ﬁeld are constantly changing. As new research and experience broaden our understanding, changes in research methods, professional practices, or medical treatment may become necessary. Practitioners and researchers must always rely on their own experience and knowledge in evaluating and using any information, methods, compounds, or experiments described herein. In using such information or methods they should be mindful of their own safety and the safety of others, including parties for whom they have a professional responsibility. To the fullest extent of the law, neither the Publisher nor the authors, contributors, or editors, assume any liability for any injury and/or damage to persons or property as a matter of products liability, negligence or otherwise, or from any use or operation of any methods, products, instructions, or ideas contained in the material herein. British Library Cataloguing in Publication Data A catalogue of this book is available from the British Library. Library of Congress Cataloging in Publication Data Pathria, R. K. Statistical mechanics–3rd ed. / R. K. Pathria, Paul D. Beale. p. cm. Includes bibliographical references and index. ISBN 978-0-12-382188-1 (pbk.) 1. Statistical mechanics. I. Beale, Paul D. II. Title. QC174.8.P38 2011 530.13–dc22 2010048955 Cover: The image was created using the opensource software CMBview (http://www.jportsmouth.com/code/CMBview/ cmbview.html) written by Jamie Portsmouth and used with permission. It was created using the WMAP seven-year Internal Linear Combination Map courtesy of the WMAP Science Team (http://lambda.gsfc.nasa.gov/product/map/dr4/ilc map get.cfm). For information on all Butterworth-Heinemann publications, visit our Web site at www.elsevierdirect.com Printed in the United States 11 12 13 14 15 10 9 8 7 6 5 4 3 2 1 Preface to the Third Edition The second edition of Statistical Mechanics was published in 1996. The new material added at that time focused on phase transitions, critical phenomena, and the renormalization group — topics that had undergone vast transformations during the years following the publication of the ﬁrst edition in 1972. In 2009, R. K. Pathria (R.K.P.) and the publishers agreed it was time for a third edition to incorporate the important changes that had occurred in the ﬁeld since the publication of the second edition and invited Paul B. Beale (P.D.B.) to join as coauthor. The two authors agreed on the scope of the additions and changes and P.D.B. wrote the ﬁrst draft of the new sections except for Appendix F which was written by R.K.P. Both authors worked very closely together editing the drafts and ﬁnalizing this third edition. The new topics added to this edition are: . Bose–Einstein condensation and degenerate Fermi gas behavior in ultracold atomic gases: Sections 7.2, 8.4, 11.2.A, and 11.9. The creation of Bose–Einstein condensates in ultracold gases during the 1990s and in degenerate Fermi gases during the 2000s led to a revolution in atomic, molecular, and optical physics, and provided a valuable link to the quantum behavior of condensed matter systems. Several of P.D.B.’s friends and colleagues in physics and JILA at the University of Colorado have been leaders in this exciting new ﬁeld.. Finite-size scaling behavior of Bose–Einstein condensates: Appendix F. We develop an analytical theory for the behavior of Bose–Einstein condensates in a ﬁnite system, which provides a rigorous justiﬁcation for singling out the ground state in the calculation of the properties of the Bose–Einstein condensate.. Thermodynamics of the early universe: Chapter 9. The sequence of thermodynamic transitions that the universe went though shortly after the Big Bang left behind mileposts that astrophysicists have exploited to look back into the universe’s earliest moments. Major advances in astronomy over the past 20 years have provided a vast body of observational data about the early evolution of the universe. These include the Hubble Space Telescope’s deep space measurements of the expansion of the universe, the Cosmic Background Explorer’s precise measurements of the temperature of the cosmic microwave background, and the Wilkinson Microwave Anisotropy Probe’s mapping of the angular variations in the cosmic microwave background. These data sets have led to precise determinations of the age of the universe, its composition and early evolution. Coincidentally, P.D.B.’s faculty ofﬁce is located in the tower named after George Gamow, a member of the faculty at the University of Colorado in the 1950s and 1960s and a leader in the theory of nucleosynthesis in the early universe.. Chemical equilibrium: Section 6.6. Chemical potentials determine the conditions necessary for chemical equilibrium. This is an important topic in its own right, but also plays a critical role in our discussion of the thermodynamics of the early universe in Chapter 9. xiii xiv Preface to the Third Edition . Monte Carlo and molecular dynamics simulations: Chapter 16. Computer simulations have become an important tool in modern statistical mechanics. We provide here a brief introduction to Monte Carlo and molecular dynamics techniques and algorithms.. Correlation functions and scattering: Section 10.7. Correlation functions are central to the understanding of thermodynamic phases, phase transitions, and critical phenomena. The differences between thermodynamic phases are often most conspicuous in the behavior of correlation functions and the closely related static structure factors. We have collected discussions from the second edition into one place and added new material.. Fluctuation–dissipation theorem and the dynamical structure factor: Sections 15.3.A., 15.6.A, and 15.6.B. The ﬂuctuation–dissipation theorem describes the relation between natural equilibrium thermodynamic ﬂuctuations in a system and the response of the system to small disturbances from equilibrium, and it is one of the cornerstones of nonequilibrium statistical mechanics. We have expanded the discussion of the ﬂuctuation–dissipation theorem to include a derivation of the key results from linear response theory, a discussion of the dynamical structure factor, and analysis of the Brownian motion of harmonic oscillators that provides useful practical examples.. Phase equilibrium and the Clausius–Clapeyron equation: Sections 4.6 and 4.7. Much of the text is devoted to using statistical mechanics methods to determine the properties of thermodynamic phases and phase transitions. This brief overview of phase equilibrium and the structure of phase diagrams lays the groundwork for later discussions.. Exact solutions of one-dimensional ﬂuid models: Section 13.1. One-dimensional ﬂuid models with short-range interactions do not exhibit phase transitions but they do display short-range correlations and other behaviors typical of dense ﬂuids.. Exact solution of the two-dimensional Ising model on a ﬁnite lattice: Section 13.4.A. This solution entails an exact counting of the microstates of the microcanonical ensemble and provides analytical results for the energy distribution, internal energy, and heat capacity of the system. This solution also describes the ﬁnite-size scaling behavior of the Ising model near the transition point and provides an exact framework that can be used to test Monte Carlo methods.. Summary of thermodynamic assemblies and associated statistical ensembles: Appendix H. We provide a summary of thermodynamic relations and their connections to statistical mechanical ensembles. Most of this information can be found elsewhere in the text, but we thought it would be helpful to provide a rundown of these important connections in one place.. Pseudorandom number generators: Appendix I. Pseudorandom number generators are indispensable in computer simulations. We provide simple algorithms for generating uniform and Gaussian pseudorandom numbers and discuss their properties.. Dozens of new homework problems. The remainder of the text is largely unchanged. The completion of this task has left us indebted to many a friend and colleague. R.K.P. has already expressed his indebtedness to a good number of people on two previous occasions — in 1972 and in 1996 — so, at this time, he will simply reiterate the many words of gratitude he has already written. In addition though, he would like to thank Paul Beale for his willingness to be a partner in this project and for his diligence in carrying out the task at hand both arduously and meticulously. On his part, P.D.B. would like to thank his friends at the University of Colorado at Boulder for the many conversations he has had with them over the years about research and pedagogy of statistical mechanics, especially Noel Clark, Tom DeGrand, John Price, Chuck Rogers, Mike Preface to the Third Edition xv Dubson, and Leo Radzihovsky. He would also like to thank the faculty of the Department of Physics for according him the honor of serving as the chair of this outstanding department. Special thanks are also due to many friends and colleagues who have read sections of the manuscript and have offered many valuable suggestions and corrections, especially Tom DeGrand, Michael Shull, David Nesbitt, Jamie Nagle, Matt Glaser, Murray Holland, Leo Radzi- hovsky, Victor Gurarie, Edmond Meyer, Matthew Grau, Andrew Sisler, Michael Foss-Feig, Allan Franklin, Shantha deAlwis, Dmitri Reznik, and Eric Cornell. P.D.B. would like to take this opportunity to extend his thanks and best wishes to Professor Michael E. Fisher whose graduate statistical mechanics course at Cornell introduced him to this elegant ﬁeld. He would also like to express his gratitude to Raj Pathria for inviting him to be part of this project, and for the fun and engaging discussions they have had during the preparation of this new edition. Raj’s thoughtful counsel always proved to be valuable in improving the text. P.D.B.’s greatest thanks go to Matthew, Melanie, and Erika for their love and support. R.K.P. P.D.B. Preface to the Second Edition The ﬁrst edition of this book was prepared over the years 1966 to 1970 when the subject of phase transitions was undergoing a complete overhaul. The concepts of scaling and universality had just taken root but the renormalization group approach, which converted these concepts into a calculational tool, was still obscure. Not surprisingly, my text of that time could not do justice to these emerging developments. Over the intervening years I have felt increasingly conscious of this rather serious deﬁciency in the text; so when the time came to prepare a new edition, my major effort went toward correcting that deﬁciency. Despite the aforementioned shortcoming, the ﬁrst edition of this book has continued to be popular over the last 20 years or so. I, therefore, decided not to tinker with it unnecessar- ily. Nevertheless, to make room for the new material, I had to remove some sections from the present text which, I felt, were not being used by the readers as much as the rest of the book was. This may turn out to be a disappointment to some individuals but I trust they will understand the logic behind it and, if need be, will go back to a copy of the ﬁrst edition for reference. I, on my part, hope that a good majority of the users will not be inconvenienced by these deletions. As for the material retained, I have conﬁned myself to making only editorial changes. The sub- ject of phase transitions and critical phenomena, which has been my main focus of revision, has been treated in three new chapters that provide a respectable coverage of the subject and essentially bring the book up to date. These chapters, along with a collection of more than 60 homework problems, will, I believe, enhance the usefulness of the book for both students and instructors. The completion of this task has left me indebted to many. First of all, as mentioned in the Preface to the ﬁrst edition, I owe a considerable debt to those who have written on this subject before and from whose writings I have beneﬁted greatly. It is difﬁcult to thank them all individually; the bibliography at the end of the book is an obvious tribute to them. As for deﬁnitive help, I am most grateful to Dr Surjit Singh who advised me expertly and assisted me generously in the selection of the material that comprises Chapters 11 to 13 of the new text; without his help, the ﬁnal product might not have been as coherent as it now appears to be. On the technical side, I am very thankful to Mrs. Debbie Guenther who typed the manuscript with exceptional skill and proof read it with extreme care; her task was clearly an arduous one but she performed it with good cheer — for which I admire her greatly. Finally, I wish to express my heartfelt appreciation for my wife who let me devote myself fully to this task over a rather long period of time and waited for its completion ungrudgingly. R.K.P. xvii Preface to the First Edition This book has arisen out of the notes of lectures that I gave to the graduate students at the McMaster University (1964–1965), the University of Alberta (1965–1967), the University of Waterloo (1969–1971), and the University of Windsor (1970–1971). While the subject matter, in its ﬁner details, has changed considerably during the preparation of the manuscript, the style of presentation remains the same as followed in these lectures. Statistical mechanics is an indispensable tool for studying physical properties of matter “in bulk” on the basis of the dynamical behavior of its “microscopic” constituents. Founded on the well-laid principles of mathematical statistics on one hand and Hamiltonian mechanics on the other, the formalism of statistical mechanics has proved to be of immense value to the physics of the last 100 years. In view of the universality of its appeal, a basic knowledge of this subject is considered essential for every student of physics, irrespective of the area(s) in which he/she may be planning to specialize. To provide this knowledge, in a manner that brings out the essence of the subject with due rigor but without undue pain, is the main purpose of this work.The fact that the dynamics of a physical system is represented by a set of quantum states and the assertion that the thermodynamics of the system is determined by the multiplicity of these states constitute the basis of our treatment. The fundamental connection between the microscopic and the macroscopic descriptions of a system is uncovered by investigating the conditions for equilibrium between two physical systems in thermodynamic contact. This is best accomplished by working in the spirit of the quantum theory right from the beginning; the entropy and other thermodynamic variables of the system then follow in a most natural manner. After the formalism is developed, one may (if the situation permits) go over to the limit of the classical statistics. This message may not be new, but here I have tried to follow it as far as is reasonably possible in a textbook. In doing so, an attempt has been made to keep the level of presentation fairly uniform so that the reader does not encounter ﬂuctuations of too wild a character. This text is conﬁned to the study of the equilibrium states of physical systems and is intended to be used for a graduate course in statistical mechanics. Within these bounds, the coverage is fairly wide and provides enough material for tailoring a good two-semester course. The ﬁnal choice always rests with the individual instructor; I, for one, regard Chapters 1 to 9 (minus a few sections from these chapters plus a few sections from Chapter 13) as the “essential part” of such a course. The contents of Chapters 10 to 12 are relatively advanced (not necessar- ily difﬁcult); the choice of material out of these chapters will depend entirely on the taste of the instructor. To facilitate the understanding of the subject, the text has been illustrated with a large number of graphs; to assess the understanding, a large number of problems have been included. I hope these features are found useful. xix xx Preface to the First Edition I feel that one of the most essential aspects of teaching is to arouse the curiosity of the students in their subject, and one of the most effective ways of doing this is to discuss with them (in a reasonable measure, of course) the circumstances that led to the emergence of the subject. One would, therefore, like to stop occasionally to reﬂect upon the manner in which the various developments really came about; at the same time, one may not like the ﬂow of the text to be hampered by the discontinuities arising from an intermittent addition of historical material. Accordingly, I decided to include in this account a historical introduction to the subject which stands separate from the main text. I trust the readers, especially the instructors, will ﬁnd it of interest. For those who wish to continue their study of statistical mechanics beyond the conﬁnes of this book, a fairly extensive bibliography is included. It contains a variety of references — old as well as new, experimental as well as theoretical, technical as well as pedagogical. I hope that this will make the book useful for a wider readership. The completion of this task has left me indebted to many. Like most authors, I owe con- siderable debt to those who have written on the subject before. The bibliography at the end of the book is the most obvious tribute to them; nevertheless, I would like to mention, in particu- lar, the works of the Ehrenfests, Fowler, Guggenheim, Schr¨odinger, Rushbrooke, ter Haar, Hill, Landau and Lifshitz, Huang, and Kubo, which have been my constant reference for several years and have inﬂuenced my understanding of the subject in a variety of ways. As for the preparation of the text, I am indebted to Robert Teshima who drew most of the graphs and checked most of the problems, to Ravindar Bansal, Vishwa Mittar, and Surjit Singh who went through the entire manuscript and made several suggestions that helped me unkink the exposition at a number of points, to Mary Annetts who typed the manuscript with exceptional patience, diligence and care, and to Fred Hetzel, Jim Briante, and Larry Kry who provided technical help during the preparation of the ﬁnal version. As this work progressed I felt increasingly gratiﬁed toward Professors F. C. Auluck and D. S. Kothari of the University of Delhi with whom I started my career and who initiated me into the study of this subject, and toward Professor R. C. Majumdar who took keen interest in my work on this and every other project that I have undertaken from time to time. I am grateful to Dr. D. ter Haar of the University of Oxford who, as the general editor of this series, gave valuable advice on various aspects of the preparation of the manuscript and made several useful suggestions toward the improvement of the text. I am thankful to Professors J. W. Leech, J. Grindlay, and A. D. Singh Nagi of the University of Waterloo for their interest and hospitality that went a long way in making this task a pleasant one. The ﬁnal tribute must go to my wife whose cooperation and understanding, at all stages of this project and against all odds, have been simply overwhelming. R.K.P. Historical Introduction Statistical mechanics is a formalism that aims at explaining the physical properties of matter in bulk on the basis of the dynamical behavior of its microscopic constituents. The scope of the formalism is almost as unlimited as the very range of the natural phenomena, for in principle it is applicable to matter in any state whatsoever. It has, in fact, been applied, with considerable success, to the study of matter in the solid state, the liquid state, or the gaseous state, mat- ter composed of several phases and/or several components, matter under extreme conditions of density and temperature, matter in equilibrium with radiation (as, for example, in astro- physics), matter in the form of a biological specimen, and so on. Furthermore, the formalism of statistical mechanics enables us to investigate the nonequilibrium states of matter as well as the equilibrium states; indeed, these investigations help us to understand the manner in which a physical system that happens to be “out of equilibrium” at a given time t approaches a “state of equilibrium” as time passes. In contrast with the present status of its development, the success of its applications, and the breadth of its scope, the beginnings of statistical mechanics were rather modest. Barring certain primitive references, such as those of Gassendi, Hooke, and so on, the real work on this subject started with the contemplations of Bernoulli (1738), Herapath (1821), and Joule (1851) who, in their own individual ways, attempted to lay a foundation for the so-called kinetic the- ory of gases — a discipline that ﬁnally turned out to be the forerunner of statistical mechanics. The pioneering work of these investigators established the fact that the pressure of a gas arose from the motion of its molecules and could, therefore, be computed by considering the dynam- ical inﬂuence of the molecular bombardment on the walls of the container. Thus, Bernoulli and Herapath could show that, if temperature remained constant, the pressure P of an ordi- nary gas was inversely proportional to the volume V of the container (Boyle’s law), and that it was essentially independent of the shape of the container. This, of course, involved the explicit assumption that, at a given temperature T , the (mean) speed of the molecules was independent of both pressure and volume. Bernoulli even attempted to determine the (ﬁrst-order) correc- tion to this law, arising from the ﬁnite size of the molecules, and showed that the volume V appearing in the statement of the law should be replaced by (V − b), where b is the “actual” volume of the molecules.1 Joule was the ﬁrst to show that the pressure P was directly proportional to the square of the molecular speed c, which he had initially assumed to be the same for all molecules. Kr¨onig (1856) went a step further. Introducing the “quasistatistical” assumption that, at any time t, 1As is well known, this “correction” was correctly evaluated, much later, by van der Waals (1873) who showed that, for large V , b is four times the “actual” volume of the molecules; see Problem 1.4. xxi xxii Historical Introduction one-sixth of the molecules could be assumed to be ﬂying in each of the six “independent” directions, namely +x, −x, +y, −y, +z, and −z, he derived the equation P = 1 3 n mc2, (1) where n is the number density of the molecules and m the molecular mass. Kr¨onig, too, assumed the molecular speed c to be the same for all molecules; so from (1), he inferred that the kinetic energy of the molecules should be directly proportional to the absolute temperature of the gas. Kr¨onig justiﬁed his method in these words: “The path of each molecule must be so irreg- ular that it will defy all attempts at calculation. However, according to the laws of probability, one could assume a completely regular motion in place of a completely irregular one!” It must, however, be noted that it is only because of the special form of the summations appearing in the calculation of the pressure that Kr¨onig’s argument leads to the same result as the one following from more reﬁned models. In other problems, such as the ones involving diffusion, viscosity, or heat conduction, this is no longer the case. It was at this stage that Clausius entered the ﬁeld. First of all, in 1857, he derived the ideal-gas law under assumptions far less stringent than Kr¨onig’s. He discarded both leading assumptions of Kr¨onig and showed that equation (1) was still true; of course, c2 now became the mean square speed of the molecules. In a later paper (1859), Clausius introduced the con- cept of the mean free path and thus became the ﬁrst to analyze transport phenomena. It was in these studies that he introduced the famous “Stosszahlansatz” — the hypothesis on the number of collisions (among the molecules) — which, later on, played a prominent role in the monu- mental work of Boltzmann.2 With Clausius, the introduction of the microscopic and statistical points of view into the physical theory was deﬁnitive, rather than speculative. Accordingly, Maxwell, in a popular article entitled “Molecules,” written for the Encyclopedia Britannica, referred to Clausius as the “principal founder of the kinetic theory of gases,” while Gibbs, in his Clausius obituary notice, called him the “father of statistical mechanics.”3 The work of Clausius attracted Maxwell to the ﬁeld. He made his ﬁrst appearance with the memoir “Illustrations in the dynamical theory of gases” (1860), in which he went much farther than his predecessors by deriving his famous law of the “distribution of molecular speeds.” Maxwell’s derivation was based on elementary principles of probability and was clearly inspired by the Gaussian law of “distribution of random errors.” A derivation based on the requirement that “the equilibrium distribution of molecular speeds, once acquired, should remain invariant under molecular collisions” appeared in 1867. This led Maxwell to establish what is known as Maxwell’s transport equation which, if skilfully used, leads to the same results as one gets from the more fundamental equation due to Boltzmann.4 Maxwell’s contributions to the subject diminished considerably after his appointment, in 1871, as the Cavendish Professor at Cambridge. By that time Boltzmann had already made his ﬁrst strides. In the period 1868–1871 he generalized Maxwell’s distribution law to poly- atomic gases, also taking into account the presence of external forces, if any; this gave rise to the famous Boltzmann factor exp(−βε), where ε denotes the total energy of a molecule. These investigations also led to the equipartition theorem. Boltzmann further showed that, just 2For an excellent review of this and related topics, see Ehrenfest and Ehrenfest (1912). 3For further details, refer to Montroll (1963) where an account is also given of the pioneering work of Waterston (1846, 1892). 4This equivalence has been demonstrated in Guggenheim (1960) where the coefﬁcients of viscosity, thermal conductivity, and diffusion of a gas of hard spheres have been calculated on the basis of Maxwell’s transport equation. Historical Introduction xxiii like the original distribution of Maxwell, the generalized distribution (which we now call the Maxwell–Boltzmann distribution) is stationary with respect to molecular collisions. In 1872 came the celebrated H-theorem, which provided a molecular basis for the natural tendency of physical systems to approach, and stay in, a state of equilibrium. This established a connection between the microscopic approach (which characterizes statistical mechan- ics) and the phenomenological approach (which characterized thermodynamics) much more transparently than ever before; it also provided a direct method for computing the entropy of a given physical system from purely microscopic considerations. As a corollary to the H- theorem, Boltzmann showed that the Maxwell–Boltzmann distribution is the only distribution that stays invariant under molecular collisions and that any other distribution, under the inﬂu- ence of molecular collisions, will ultimately go over to a Maxwell–Boltzmann distribution. In 1876 Boltzmann derived his famous transport equation, which, in the hands of Chapman and Enskog (1916–1917), has proved to be an extremely powerful tool for investigating macroscopic properties of systems in nonequilibrium states. Things, however, proved quite harsh for Boltzmann. His H-theorem, and the consequent irreversible behavior of physical systems, came under heavy attack, mainly from Loschmidt (1876–1877) and Zermelo (1896). While Loschmidt wondered how the consequences of this theorem could be reconciled with the reversible character of the basic equations of motion of the molecules, Zermelo wondered how these consequences could be made to ﬁt with the quasiperiodic behavior of closed systems (which arose in view of the so-called Poincar´e cycles). Boltzmann defended himself against these attacks with all his might but, unfortunately, could not convince his opponents of the correctness of his viewpoint. At the same time, the energeti- cists, led by Mach and Ostwald, were criticizing the very (molecular) basis of the kinetic theory,5 while Kelvin was emphasizing the “nineteenth-century clouds hovering over the dynamical theory of light and heat.”6 All this left Boltzmann in a state of despair and induced in him a persecution complex.7 He wrote in the introduction to the second volume of his treatise Vorlesungen ¨uber Gastheorie (1898):8 I am convinced that the attacks (on the kinetic theory) rest on misunderstandings and that the role of the kinetic theory is not yet played out. In my opinion it would be a blow to science if contemporary opposition were to cause kinetic theory to sink into the oblivion which was the fate suffered by the wave theory of light through the authority of Newton. I am aware of the weakness of one individual against the prevailing currents of opinion. In order to insure that not too much will have to be rediscovered when people return to the study of kinetic theory I will present the most difﬁcult and misunderstood parts of the subject in as clear a manner as I can. We shall not dwell any further on the kinetic theory; we would rather move on to the development of the more sophisticated approach known as the ensemble theory, which may in fact be regarded as the statistical mechanics proper.9 In this approach, the dynamical state of a 5These critics were silenced by Einstein whose work on the Brownian motion (1905b) established atomic theory once and for all. 6The ﬁrst of these clouds was concerned with the mysteries of the “aether,” and was dispelled by the theory of relativ- ity. The second was concerned with the inadequacy of the “equipartition theorem,” and was dispelled by the quantum theory. 7Some people attribute Boltzmann’s suicide on September 5, 1906 to this cause. 8Quotation from Montroll (1963). 9For a review of the historical development of kinetic theory leading to statistical mechanics, see Brush (1957, 1958, 1961a,b, 1965–1966). xxiv Historical Introduction given system, as characterized by the generalized coordinates qi and the generalized momenta pi, is represented by a phase point G(qi, pi) in a phase space of appropriate dimensionality. The evolution of the dynamical state in time is depicted by the trajectory of the G-point in the phase space, the “geometry” of the trajectory being governed by the equations of motion of the system and by the nature of the physical constraints imposed on it. To develop an appropriate formal- ism, one considers the given system along with an inﬁnitely large number of “mental copies” thereof; that is, an ensemble of similar systems under identical physical constraints (though, at any time t, the various systems in the ensemble would differ widely in respect of their dynam- ical states). In the phase space, then, one has a swarm of inﬁnitely many G-points (which, at any time t, are widely dispersed and, with time, move along their respective trajectories). The ﬁction of a host of inﬁnitely many, identical but independent, systems allows one to replace certain dubious assumptions of the kinetic theory of gases by readily acceptable statements of statistical mechanics. The explicit formulation of these statements was ﬁrst given by Maxwell (1879) who on this occasion used the word “statistico-mechanical” to describe the study of ensembles (of gaseous systems) — though, eight years earlier, Boltzmann (1871) had already worked with essentially the same kind of ensembles. The most important quantity in the ensemble theory is the density function, ρ(qi, pi; t), of the G-points in the phase space; a stationary distribution (∂ρ/∂t = 0) characterizes a sta- tionary ensemble, which in tum represents a system in equilibrium. Maxwell and Boltzmann conﬁned their study to ensembles for which the function ρ depended solely on the energy E of the system. This included the special case of ergodic systems, which were so deﬁned that “the undisturbed motion of such a system, if pursued for an unlimited time, would ultimately tra- verse (the neighborhood of) each and every phase point compatible with the ﬁxed value E of the energy.” Consequently, the ensemble average, ⟨f ⟩, of a physical quantity f , taken at any given time t, would be the same as the long-time average, f , pertaining to any given member of the ensemble. Now, f is the value we expect to obtain for the quantity in question when we make an appropriate measurement on the system; the result of this measurement should, there- fore, agree with the theoretical estimate ⟨f ⟩. We thus acquire a recipe to bring about a direct contact between theory and experiment. At the same time, we lay down a rational basis for a microscopic theory of matter as an alternative to the empirical approach of thermodynamics! A signiﬁcant advance in this direction was made by Gibbs who, with his Elementary Prin- ciples of Statistical Mechanics (1902), turned ensemble theory into a most efﬁcient tool for the theorist. He emphasized the use of “generalized” ensembles and developed schemes which, in principle, enabled one to compute a complete set of thermodynamic quantities of a given sys- tem from purely mechanical properties of its microscopic constituents.10 In its methods and results, the work of Gibbs turned out to be much more general than any preceding treatment of the subject; it applied to any physical system that met the simple-minded requirements that (i) it was mechanical in structure and (ii) it obeyed Lagrange’s and Hamilton’s equa- tions of motion. In this respect, Gibbs’s work may be considered to have accomplished for thermodynamics as much as Maxwell’s had accomplished for electrodynamics. These developments almost coincided with the great revolution that Planck’s work of 1900 brought into physics. As is well known, Planck’s quantum hypothesis successfully resolved the essential mysteries of the black-body radiation — a subject where the three best-established disciplines of the nineteenth century, namely mechanics, electrodynamics, and thermodynam- ics, were all focused. At the same time, it uncovered both the strengths and the weaknesses of these disciplines. It would have been surprising if statistical mechanics, which linked thermodynamics with mechanics, could have escaped the repercussions of this revolution. 10In much the same way as Gibbs, but quite independently of him, Einstein (1902, 1903) also developed the theory of ensembles. Historical Introduction xxv The subsequent work of Einstein (1905a) on the photoelectric effect and of Compton (1923a,b) on the scattering of x-rays established, so to say, the “existence” of the quan- tum of radiation, or the photon as we now call it.11 It was then natural for someone to derive Planck’s radiation formula by treating black-body radiation as a gas of photons in the same way as Maxwell had derived his law of distribution of molecular speeds for a gas of conventional molecules. But, then, does a gas of photons differ so radically from a gas of conventional molecules that the two laws of distribution should be so different from one another? The answer to this question was provided by the manner in which Planck’s formula was derived by Bose. In his historic paper of 1924, Bose treated black-body radiation as a gas of pho- tons; however, instead of considering the allocation of the “individual” photons to the various energy states of the system, he ﬁxed his attention on the number of states that contained “a par- ticular number” of photons. Einstein, who seems to have translated Bose’s paper into German from an English manuscript sent to him by the author, at once recognized the importance of this approach and added the following note to his translation: “Bose’s derivation of Planck’s formula is in my opinion an important step forward. The method employed here would also yield the quantum theory of an ideal gas, which I propose to demonstrate elsewhere.” Implicit in Bose’s approach was the fact that in the case of photons what really mat- tered was “the set of numbers of photons in various energy states of the system” and not the speciﬁcation as to “which photon was in which state”; in other words, photons were mutu- ally indistinguishable. Einstein argued that what Bose had implied for photons should be true for material particles as well (for the property of indistinguishability arose essentially from the wave character of these entities and, according to de Broglie, material particles also possessed that character).12 In two papers, which appeared soon after, Einstein (1924, 1925) applied Bose’s method to the study of an ideal gas and thereby developed what we now call Bose–Einstein statistics. In the second of these papers, the fundamental difference between the new statistics and the classical Maxwell–Boltzmann statistics comes out so transparently in terms of the indistinguishability of the molecules.13 In the same paper, Einstein discovered the phenomenon of Bose–Einstein condensation which, 13 years later, was adopted by London (1938a,b) as the basis for a microscopic understanding of the curious properties of liquid He4 at low temperatures. Following the enunciation of Pauli’s exclusion principle (1925), Fermi (1926) showed that certain physical systems would obey a different kind of statistics, namely the Fermi–Dirac statistics, in which not more than one particle could occupy the same energy state (ni = 0, 1). It seems important to mention here that Bose’s method of 1924 leads to the Fermi–Dirac dis- tribution as well, provided that one limits the occupancy of an energy state to at most one particle.14 11Strictly speaking, it might be somewhat misleading to cite Einstein’s work on the photoelectric effect as a proof of the existence of photons. In fact, many of the effects (including the photoelectric effect), for which it seems necessary to invoke photons, can be explained away on the basis of a wave theory of radiation. The only phenomena for which photons seem indispensable are the ones involving ﬂuctuations, such as the Hanbury Brown–Twiss effect or the Lamb shift. For the relevance of ﬂuctuations to the problem of radiation, see ter Haar (1967, 1968). 12Of course, in the case of material particles, the total number N (of the particles) will also have to be conserved; this had not to be done in the case of photons. For details, see Section 6.1. 13It is here that one encounters the correct method of counting “the number of distinct ways in which gi energy states can accommodate ni particles,” depending on whether the particles are (i) distinguishable or (ii) indistinguishable. The occupancy of the individual states was, in each case, unrestricted, that is, ni = 0, 1, 2, . . .. 14Dirac, who was the ﬁrst to investigate the connection between statistics and wave mechanics, showed, in 1926, that the wave functions describing a system of identical particles obeying Bose–Einstein (or Fermi–Dirac) statistics must be symmetric (or antisymmetric) with respect to an interchange of two particles. xxvi Historical Introduction Soon after its appearance, the Fermi–Dirac statistics were applied by Fowler (1926) to discuss the equilibrium states of white dwarf stars and by Pauli (1927) to explain the weak, temperature-independent paramagnetism of alkali metals; in each case, one had to deal with a “highly degenerate” gas of electrons that obey Fermi–Dirac statistics. In the wake of this, Som- merfeld produced his monumental work of 1928 that not only put the electron theory of metals on a physically secure foundation but also gave it a fresh start in the right direction. Thus, Som- merfeld could explain practically all the major properties of metals that arose from conduction electrons and, in each case, obtained results that showed much better agreement with exper- iment than the ones following from the classical theories of Riecke (1898), Drude (1900), and Lorentz (1904–1905). Around the same time, Thomas (1927) and Fermi (1928) investigated the electron distribution in heavier atoms and obtained theoretical estimates for the relevant bind- ing energies; these investigations led to the development of the so-called Thomas–Fermi model of the atom, which was later extended so that it could be applied to molecules, solids, and nuclei as well.15 Thus, the whole structure of statistical mechanics was overhauled by the introduction of the concept of indistinguishability of (identical) particles.16 The statistical aspect of the problem, which was already there in view of the large number of particles present, was now augmented by another statistical aspect that arose from the probabilistic nature of the wave mechanical description. One had, therefore, to carry out a two-fold averaging of the dynamical variables over the states of the given system in order to obtain the relevant expectation val- ues. That sort of a situation was bound to necessitate a reformulation of the ensemble theory itself, which was carried out step by step. First, Landau (1927) and von Neumann (1927) intro- duced the so-called density matrix, which was the quantum-mechanical analogue of the density function of the classical phase space; this was elaborated, both from statistical and quantum- mechanical points of view, by Dirac (1929–1931). Guided by the classical ensemble theory, these authors considered both microcanonical and canonical ensembles; the introduction of grand canonical ensembles in quantum statistics was made by Pauli (1927).17 The important question as to which particles would obey Bose–Einstein statistics and which Fermi–Dirac remained theoretically unsettled until Belinfante (1939) and Pauli (1940) discovered the vital connection between spin and statistics.18 It turns out that those particles whose spin is an integral multiple of ℏ obey Bose–Einstein statistics while those whose spin is a half-odd integral multiple of ℏ obey Fermi–Dirac statistics. To date, no third category of particles has been discovered. Apart from the foregoing milestones, several notable contributions toward the devel- opment of statistical mechanics have been made from time to time; however, most of those contributions were concerned with the development or perfection of mathematical techniques that make application of the basic formalism to actual physical problems more fruitful. A review of these developments is out of place here; they will be discussed at their appropriate place in the text. 15For an excellent review of this model, see March (1957). 16Of course, in many a situation where the wave nature of the particles is not so important, classical statistics continue to apply. 17A detailed treatment of this development has been given by Kramers (1938). 18See also L ¨uders and Zumino (1958). 1 The Statistical Basis of Thermodynamics In the annals of thermal physics, the 1850s mark a very deﬁnite epoch. By that time the science of thermodynamics, which grew essentially out of an experimental study of the macroscopic behavior of physical systems, had become, through the work of Carnot, Joule, Clausius, and Kelvin, a secure and stable discipline of physics. The theoretical conclusions following from the ﬁrst two laws of thermodynamics were found to be in very good agree- ment with the corresponding experimental results.1 At the same time, the kinetic theory of gases, which aimed at explaining the macroscopic behavior of gaseous systems in terms of the motion of their molecules and had so far thrived more on speculation than calculation, began to emerge as a real, mathematical theory. Its initial successes were glaring; however, a real contact with thermodynamics could not be made until about 1872 when Boltzmann developed his H-theorem and thereby established a direct connection between entropy on one hand and molecular dynamics on the other. Almost simultaneously, the conventional (kinetic) theory began giving way to its more sophisticated successor — the ensemble the- ory. The power of the techniques that ﬁnally emerged reduced thermodynamics to the status of an “essential” consequence of the get-together of the statistics and the mechan- ics of the molecules constituting a given physical system. It was then natural to give the resulting formalism the name Statistical Mechanics. As a preparation toward the development of the formal theory, we start with a few general considerations regarding the statistical nature of a macroscopic system. These considerations will provide ground for a statistical interpretation of thermodynamics. It may be mentioned here that, unless a statement is made to the contrary, the system under study is supposed to be in one of its equilibrium states. 1.1 The macroscopic and the microscopic states We consider a physical system composed of N identical particles conﬁned to a space of volume V . In a typical case, N would be an extremely large number — generally, of order 1023. In view of this, it is customary to carry out analysis in the so-called thermodynamic limit, namely N → ∞, V → ∞ (such that the ratio N/V , which represents the particle den- sity n, stays ﬁxed at a preassigned value). In this limit, the extensive properties of the system 1The third law, which is also known as Nernst’s heat theorem, did not arrive until about 1906. For a general discussion of this law, see Simon (1930) and Wilks (1961); these references also provide an extensive bibliography on this subject. Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00001-3 © 2011 Elsevier Ltd. All rights reserved. 1 2 Chapter 1. The Statistical Basis of Thermodynamics become directly proportional to the size of the system (i.e., proportional to N or to V ), while the intensive properties become independent thereof; the particle density, of course, remains an important parameter for all physical properties of the system. Next we consider the total energy E of the system. If the particles comprising the system could be regarded as noninteracting, the total energy E would be equal to the sum of the energies εi of the individual particles: E = ∑ i niεi, (1) where ni denotes the number of particles each with energy εi. Clearly, N = ∑ i ni. (2) According to quantum mechanics, the single-particle energies εi are discrete and their val- ues depend crucially on the volume V to which the particles are conﬁned. Accordingly, the possible values of the total energy E are also discrete. However, for large V , the spacing of the different energy values is so small in comparison with the total energy of the system that the parameter E might well be regarded as a continuous variable. This would be true even if the particles were mutually interacting; of course, in that case the total energy E cannot be written in the form (1). The speciﬁcation of the actual values of the parameters N, V , and E then deﬁnes a macrostate of the given system. At the molecular level, however, a large number of possibilities still exist because at that level there will in general be a large number of different ways in which the macrostate (N, V , E) of the given system can be realized. In the case of a noninteracting system, since the total energy E consists of a simple sum of the N single-particle energies εi, there will obviously be a large number of different ways in which the individual εi can be chosen so as to make the total energy equal to E. In other words, there will be a large number of different ways in which the total energy E of the system can be distributed among the N particles constituting it. Each of these (different) ways speciﬁes a microstate, or complexion, of the given system. In general, the various microstates, or complexions, of a given system can be identiﬁed with the independent solutions ψ(r1, . . . , rN ) of the Schr¨odinger equation of the system, corresponding to the eigenvalue E of the relevant Hamiltonian. In any case, to a given macrostate of the system there does in general correspond a large number of microstates and it seems natural to assume, when there are no other constraints, that at any time t the system is equally likely to be in any one of these microstates. This assump- tion forms the backbone of our formalism and is generally referred to as the postulate of “equal a priori probabilities” for all microstates consistent with a given macrostate. The actual number of all possible microstates will, of course, be a function of N, V , and E and may be denoted by the symbol \u0000(N, V , E); the dependence on V comes in because the possible values εi of the single-particle energy ε are themselves a function 1.2 Contact between statistics and thermodynamics 3 of this parameter.2 Remarkably enough, it is from the magnitude of the number \u0000, and from its dependence on the parameters N, V , and E, that complete thermodynamics of the given system can be derived! We shall not stop here to discuss the ways in which the number \u0000(N, V , E) can be com- puted; we shall do that only after we have developed our considerations sufﬁciently so that we can carry out further derivations from it. First we have to discover the manner in which this number is related to any of the leading thermodynamic quantities. To do this, we con- sider the problem of “thermal contact” between two given physical systems, in the hope that this consideration will bring out the true nature of the number \u0000. 1.2 Contact between statistics and thermodynamics: physical signiﬁcance of the number \u0000(N, V , E) We consider two physical systems, A1 and A2, which are separately in equilibrium; see Figure 1.1. Let the macrostate of A1 be represented by the parameters N1, V1, and E1 so that it has \u00001(N1, V1, E1) possible microstates, and the macrostate of A2 be represented by the parameters N2, V2, and E2 so that it has \u00002(N2, V2, E2) possible microstates. The math- ematical form of the function \u00001 may not be the same as that of the function \u00002, because that ultimately depends on the nature of the system. We do, of course, believe that all thermodynamic properties of the systems A1 and A2 can be derived from the functions \u00001(N1, V1, E1) and \u00002(N2, V2, E2), respectively. We now bring the two systems into thermal contact with each other, thus allowing the possibility of exchange of energy between the two; this can be done by sliding in a con- ducting wall and removing the impervious one. For simplicity, the two systems are still separated by a rigid, impenetrable wall, so that the respective volumes V1 and V2 and the respective particle numbers N1 and N2 remain ﬁxed. The energies E1 and E2, however, become variable and the only condition that restricts their variation is E(0) = E1 + E2 = const. (1) A1 (N1, V1, E1) A2 (N2, V2, E2) FIGURE 1.1 Two physical systems being brought into thermal contact. 2It may be noted that the manner in which the εi depend on V is itself determined by the nature of the system. For instance, it is not the same for relativistic systems as it is for nonrelativistic ones; compare, for instance, the cases dealt with in Section 1.4 and in Problem 1.7. We should also note that, in principle, the dependence of \u0000 on V arises from the fact that it is the physical dimensions of the container that appear in the boundary conditions imposed on the wave functions of the system. 4 Chapter 1. The Statistical Basis of Thermodynamics Here, E(0) denotes the energy of the composite system A(0)(≡ A1 + A2); the energy of inter- action between A1 and A2, if any, is being neglected. Now, at any time t, the subsystem A1 is equally likely to be in any one of the \u00001(E1) microstates while the subsystem A2 is equally likely to be in any one of the \u00002(E2) microstates; therefore, the composite system A(0) is equally likely to be in any one of the \u00001(E1)\u00002(E2) = \u00001(E1)\u00002(E(0) − E1) = \u0000(0)(E(0), E1) (2) microstates.3 Clearly, the number \u0000(0) itself varies with E1. The question now arises: at what value of E1 will the composite system be in equilibrium? In other words, how far will the energy exchange go in order to bring the subsystems A1 and A2 into mutual equilibrium? We assert that this will happen at that value of E1 which maximizes the number \u0000(0)(E(0), E1). The philosophy behind this assertion is that a physical system, left to itself, proceeds naturally in a direction that enables it to assume an ever-increasing number of microstates until it ﬁnally settles down in a macrostate that affords the largest pos- sible number of microstates. Statistically speaking, we regard a macrostate with a larger number of microstates as a more probable state, and the one with the largest number of microstates as the most probable one. Detailed studies show that, for a typical system, the number of microstates pertaining to any macrostate that departs even slightly from the most probable one is “orders of magnitude” smaller than the number pertaining to the latter. Thus, the most probable state of a system is the macrostate in which the system spends an “overwhelmingly” large fraction of its time. It is then natural to identify this state with the equilibrium state of the system. Denoting the equilibrium value of E1 by E1 (and that of E2 by E2), we obtain, on maximizing \u0000(0), ( ∂\u00001(E1) ∂E1 ) E1=E1 \u00002(E2) + \u00001(E1) ( ∂\u00002(E2) ∂E2 ) E2=E2 · ∂E2 ∂E1 = 0. Since ∂E2/∂E1 = −1, see equation (1), the foregoing condition can be written as ( ∂ ln \u00001(E1) ∂E1 ) E1=E1 = ( ∂ ln \u00002(E2) ∂E2 ) E2=E2 . Thus, our condition for equilibrium reduces to the equality of the parameters β1 and β2 of the subsystems A1 and A2, respectively, where β is deﬁned by β ≡ ( ∂ ln \u0000(N, V , E) ∂E ) N,V , E=E . (3) 3It is obvious that the macrostate of the composite system A(0) has to be deﬁned by two energies, namely E1 and E2 (or else E(0) and E1). 1.2 Contact between statistics and thermodynamics 5 We thus ﬁnd that when two physical systems are brought into thermal contact, which allows an exchange of energy between them, this exchange continues until the equilibrium values E1 and E2 of the variables E1 and E2 are reached. Once these values are reached, there is no more net exchange of energy between the two systems; the systems are then said to have attained a state of thermal equilibrium. According to our analysis, this hap- pens only when the respective values of the parameter β, namely β1 and β2, become equal. 4 It is then natural to expect that the parameter β is somehow related to the ther- modynamic temperature T of a given system. To determine this relationship, we recall the thermodynamic formula ( ∂S ∂E ) N,V = 1 T , (4) where S is the entropy of the system in question. Comparing equations (3) and (4), we conclude that an intimate relationship exists between the thermodynamic quantity S and the statistical quantity \u0000; we may, in fact, write for any physical system 1S 1(ln \u0000) = 1 βT = const. (5) This correspondence was ﬁrst established by Boltzmann who also believed that, since the relationship between the thermodynamic approach and the statistical approach seems to be of a fundamental character, the constant appearing in (5) must be a universal constant. It was Planck who ﬁrst wrote the explicit formula S = k ln \u0000, (6) without any additive constant S0. As it stands, formula (6) determines the absolute value of the entropy of a given physical system in terms of the total number of microstates acces- sible to it in conformity with the given macrostate. The zero of entropy then corresponds to the special state for which only one microstate is accessible (\u0000 = 1) — the so-called “unique conﬁguration”; the statistical approach thus provides a theoretical basis for the third law of thermodynamics as well. Formula (6) is of fundamental importance in physics; it provides a bridge between the microscopic and the macroscopic. Now, in the study of the second law of thermodynamics we are told that the law of increase of entropy is related to the fact that the energy content of the universe, in its natural course, is becoming less and less available for conversion into work; accordingly, the entropy of a given system may be regarded as a measure of the so-called disorder or chaos prevailing in the system. Formula (6) tells us how disorder arises microscopically. Clearly, disorder is a manifestation of the largeness of the number of microstates the sys- tem can have. The larger the choice of microstates, the lesser the degree of predictability and hence the increased level of disorder in the system. Complete order prevails when and 4This result may be compared with the so-called “zeroth law of thermodynamics,” which stipulates the existence of a common parameter T for two or more physical systems in thermal equilibrium. 6 Chapter 1. The Statistical Basis of Thermodynamics only when the system has no other choice but to be in a unique state (\u0000 = 1); this, in turn, corresponds to a state of vanishing entropy. By equations (5) and (6), we also have β = 1 kT . (7) The universal constant k is generally referred to as the Boltzmann constant. In Section 1.4 we shall discover how k is related to the gas constant R and the Avogadro number NA; see equation (1.4.3). 5 1.3 Further contact between statistics and thermodynamics In continuation of the preceding considerations, we now examine a more elaborate exchange between the subsystems A1 and A2. If we assume that the wall separating the two subsystems is movable as well as conducting, then the respective volumes V1 and V2 (of subsystems A1 and A2) also become variable; indeed, the total volume V (0)(= V1 + V2) remains constant, so that effectively we have only one more independent variable. Of course, the wall is still assumed to be impenetrable to particles, so the numbers N1 and N2 remain ﬁxed. Arguing as before, the state of equilibrium for the composite system A(0) will obtain when the number \u0000(0)(V (0), E(0); V1, E1) attains its largest value; that is, when not only ( ∂ ln \u00001 ∂E1 ) N1,V1; E1=E1 = ( ∂ ln \u00002 ∂E2 ) N2,V2; E2=E2 , (1a) but also ( ∂ ln \u00001 ∂V1 ) N1,E1; V1=V 1 = ( ∂ ln \u00002 ∂V2 ) N2,E2; V2=V 2 . (1b) Our conditions for equilibrium now take the form of an equality between the pair of parameters (β1, η1) of the subsystem A1 and the parameters (β2, η2) of the subsystem A2 where, by deﬁnition, η ≡ ( ∂ ln \u0000(N, V , E) ∂V ) N,E,V =V . (2) Similarly, if A1 and A2 came into contact through a wall that allowed an exchange of parti- cles as well, the conditions for equilibrium would be further augmented by the equality 5We follow the notation whereby equation (1.4.3) means equation (3) of Section 1.4. However, while referring to an equation in the same section, we will omit the mention of the section number. 1.3 Further contact between statistics and thermodynamics 7 of the parameter ζ1 of subsystem A1 and the parameter ζ2 of subsystem A2 where, by deﬁnition, ζ ≡ ( ∂ ln \u0000(N, V , E) ∂N ) V ,E,N=N . (3) To determine the physical meaning of the parameters η and ζ , we make use of equa- tion (1.2.6) and the basic formula of thermodynamics, namely dE = T dS − P dV + µ dN, (4) where P is the thermodynamic pressure and µ the chemical potential of the given system. It follows that η = P kT and ζ = − µ kT . (5) From a physical point of view, these results are completely satisfactory because, thermo- dynamically as well, the conditions of equilibrium between two systems A1 and A2, if the wall separating them is both conducting and movable (thus making their respective ener- gies and volumes variable), are indeed the same as the ones contained in equations (1a) and (1b), namely T1 = T2 and P1 = P2. (6) On the other hand, if the two systems can exchange particles as well as energy but have their volumes ﬁxed, the conditions of equilibrium, obtained thermodynamically, are indeed T1 = T2 and µ1 = µ2. (7) And ﬁnally, if the exchange is such that all three (macroscopic) parameters become variable, then the conditions of equilibrium become T1 = T2, P1 = P2, and µ1 = µ2. (8)6 It is gratifying that these conclusions are identical to the ones following from statistical considerations. Combining the results of the foregoing discussion, we arrive at the following recipe for deriving thermodynamics from a statistical beginning: determine, for the macrostate (N, V , E) of the given system, the number of all possible microstates accessible to the sys- tem; call this number \u0000(N, V , E). Then, the entropy of the system in that state follows from 6It may be noted that the same would be true for any two parts of a single thermodynamic system; consequently, in equilibrium, the parameters T , P, and µ would be constant throughout the system. 8 Chapter 1. The Statistical Basis of Thermodynamics the fundamental formula S(N, V , E) = k ln \u0000(N, V , E), (9) while the leading intensive ﬁelds, namely temperature, pressure, and chemical potential, are given by ( ∂S ∂E ) N,V = 1 T ; ( ∂S ∂V ) N,E = P T ; ( ∂S ∂N ) V ,E = − µ T . (10) Alternatively, we can write7 P = ( ∂S ∂V ) N,E ∕( ∂S ∂E ) N,V = −( ∂E ∂V ) N,S (11) and µ = −( ∂S ∂N ) V ,E ∕ ( ∂S ∂E ) N,V = ( ∂E ∂N ) V ,S , (12) while T = ( ∂E ∂S ) N,V . (13) Formulae (11) through (13) follow equally well from equation (4). The evaluation of P, µ, and T from these formulae indeed requires that the energy E be expressed as a function of the quantities N, V , and S; this should, in principle, be possible once S is known as a function of N, V , and E. The rest of the thermodynamics follows straightforwardly; see Appendix H. For instance, the Helmholtz free energy A, the Gibbs free energy G, and the enthalpy H are given by A = E − TS, (14) G = A + PV = E − TS + PV = µN (15)8 7In writing these formulae, we have made use of the well-known relationship in partial differential calculus, namely that “if three variables x, y, and z are mutually related, then (see Appendix H) ( ∂x ∂y ) z ( ∂y ∂z ) x ( ∂z ∂x ) y = −1.” 8The relation E − TS + PV = µN follows directly from (4). For this, all we have to do is to regard the given system as having grown to its present size in a gradual manner, such that the intensive parameters, T , P, and µ stayed constant throughout the process while the extensive parameters N, V , and E (and hence S) grew proportionately with one another. 1.4 The classical ideal gas 9 and H = E + PV = G + TS. (16) The speciﬁc heat at constant volume, CV , and the one at constant pressure, CP, would be given by CV ≡ T ( ∂S ∂T ) N,V = ( ∂E ∂T ) N,V (17) and CP ≡ T ( ∂S ∂T ) N,P = ( ∂(E + PV ) ∂T ) N,P = ( ∂H ∂T ) N,P . (18) 1.4 The classical ideal gas To illustrate the approach developed in the preceding sections, we shall now derive the various thermodynamic properties of a classical ideal gas composed of monatomic molecules. The main reason why we choose this highly specialized system for considera- tion is that it affords an explicit, though asymptotic, evaluation of the number \u0000(N, V , E). This example becomes all the more instructive when we ﬁnd that its study enables us, in a most straightforward manner, to identify the Boltzmann constant k in terms of other physical constants; see equation (3). Moreover, the behavior of this system serves as a useful reference with which the behavior of other physical systems, especially real gases (with or without quantum effects), can be compared. And, indeed, in the limit of high temperatures and low densities the ideal-gas behavior becomes typical of most real systems. Before undertaking a detailed study of this case it appears worthwhile to make a remark that applies to all classical systems composed of noninteracting particles, irrespective of the internal structure of the particles. This remark is related to the explicit dependence of the number \u0000(N, V , E) on V and hence to the equation of state of these systems. Now, if there do not exist any spatial correlations among the particles, that is, if the probability of any one of them being found in a particular region of the available space is completely independent of the location of the other particles,9 then the total number of ways in which the N particles can be spatially distributed in the system will be simply equal to the prod- uct of the numbers of ways in which the individual particles can be accommodated in the same space independently of one another. With N and E ﬁxed, each of these numbers will be directly proportional to V , the volume of the container; accordingly, the total number of ways will be directly proportional to the Nth power of V : \u0000(N, E, V ) ∝ V N . (1) 9This will be true if (i) the mutual interactions among particles are negligible, and (ii) the wave packets of individual particles do not signiﬁcantly overlap (or, in other words, the quantum effects are also negligible). 10 Chapter 1. The Statistical Basis of Thermodynamics Combined with equations (1.3.9) and (1.3.10), this gives P T = k ( ∂ ln \u0000(N, E, V ) ∂V ) N,E = k N V . (2) If the system contains n moles of the gas, then N = nNA, where NA is the Avogadro number. Equation (2) then becomes PV = NkT = nRT (R = kNA), (3) which is the famous ideal-gas law, R being the gas constant per mole. Thus, for any classical system composed of noninteracting particles the ideal-gas law holds. For deriving other thermodynamic properties of this system, we require a detailed knowledge of the way \u0000 depends on the parameters N, V , and E. The problem essen- tially reduces to determining the total number of ways in which equations (1.1.1) and (1.1.2) can be mutually satisﬁed. In other words, we have to determine the total number of (independent) ways of satisfying the equation 3N∑ r=1 εr = E, (4) where εr are the energies associated with the various degrees of freedom of the N par- ticles. The reason why this number should depend on the parameters N and E is quite obvious. Nevertheless, this number also depends on the “spectrum of values” that the vari- ables εr can assume; it is through this spectrum that the dependence on V comes in. Now, the energy eigenvalues for a free, nonrelativistic particle conﬁned to a cubical box of side L (V = L3), under the condition that the wave function ψ(r) vanishes everywhere on the boundary, are given by ε(nx, ny, nz) = h2 8mL2 (n 2 x + n 2 y + n 2 z ); nx, ny, nz = 1, 2, 3, . . . , (5) where h is Planck’s constant and m the mass of the particle. The number of distinct eigenfunctions (or microstates) for a particle of energy ε would, therefore, be equal to the number of independent, positive-integral solutions of the equation (n 2 x + n 2 y + n 2 z ) = 8mV 2/3ε h2 = ε∗. (6) We may denote this number by \u0000(1, ε, V ). Extending the argument, it follows that the desired number \u0000(N, E, V ) would be equal to the number of independent, positive- integral solutions of the equation 3N∑ r=1 n 2 r = 8mV 2/3E h2 = E∗, say. (7) 1.4 The classical ideal gas 11 An important result follows straightforwardly from equation (7), even before the number \u0000(N, E, V ) is explicitly evaluated. From the nature of the expression appearing on the right side of this equation, we conclude that the volume V and the energy E of the system enter into the expression for \u0000 in the form of the combination (V 2/3E). Consequently, S(N, V , E) ≡ S( N, V 2/3E). (8) Hence, for the constancy of S and N, which deﬁnes a reversible adiabatic process, V 2/3E = const. (9) Equation (1.3.11) then gives P = − ( ∂E ∂V ) N,S = 2 3 E V , (10) that is, the pressure of a system of nonrelativistic, noninteracting particles is precisely equal to two-thirds of its energy density. 10 It should be noted here that, since an explicit computation of the number \u0000 has not yet been done, results (9) and (10) hold for quan- tum as well as classical statistics; equally general is the result obtained by combining these, namely PV 5/3 = const., (11) which tells us how P varies with V during a reversible adiabatic process. We shall now attempt to evaluate the number \u0000. In this evaluation we shall explicitly assume the particles to be distinguishable, so that if a particle in state i gets interchanged with a particle in state j the resulting microstate is counted as distinct. Consequently, the number \u0000(N, V , E), or better \u0000N (E∗) (see equation (7)), is equal to the number of positive- integral lattice points lying on the surface of a 3N-dimensional sphere of radius √ E∗. 11 Clearly, this number will be an extremely irregular function of E∗, in that for two given values of E∗ that may be very close to one another, the values of this number could be very different. In contrast, the number 6N (E∗), which denotes the number of positive-integral lattice points lying on or within the surface of a 3N-dimensional sphere of radius √ E∗, will be much less irregular. In terms of our physical problem, this would correspond to the number, 6(N, V , E), of microstates of the given system consistent with all macrostates characterized by the speciﬁed values of the parameters N and V but having energy less 10Combining (10) with (2), we obtain for the classical ideal gas: E = 3 2 NkT . Accordingly, equation (9) reduces to the well-known thermodynamic relationship: V γ −1T = const., which holds during a reversible adiabatic process, with γ = 5 3 . 11If the particles are regarded as indistinguishable, the evaluation of the number \u0000 by counting lattice points becomes quite intricate. The problem is then solved by having recourse to the theory of “partitions of numbers”; see Auluck and Kothari (1946). 12 Chapter 1. The Statistical Basis of Thermodynamics than or equal to E; that is, 6(N, V , E) = ∑ E′ ≤E \u0000(N, V , E′) (12) or 6N (E∗) = ∑ E∗′ ≤E∗ \u0000N (E∗′ ). (13) Of course, the number 6 will also be somewhat irregular; however, we expect that its asymptotic behavior, as E∗ → ∞, will be a lot smoother than that of \u0000. We shall see in the sequel that the thermodynamics of the system follows equally well from the number 6 as from \u0000. To appreciate the point made here, let us digress a little to examine the behavior of the numbers \u00001(ε∗) and 61(ε∗), which correspond to the case of a single particle con- ﬁned to the given volume V . The exact values of these numbers, for ε∗ ≤ 10,000, can be extracted from a table compiled by Gupta (1947). The wild irregularities of the number \u00001(ε∗) can hardly be missed. The number 61(ε∗), on the other hand, exhibits a much smoother asymptotic behavior. From the geometry of the problem, we note that, asymp- totically, 61(ε∗) should be equal to the volume of an octant of a three-dimensional sphere of radius √ ε∗, that is, lim ε∗→∞ 61(ε∗) (π/6)ε∗3/2 = 1. (14) A more detailed analysis shows that, to the next approximation (see Pathria, 1966), 61(ε∗) ≈ π 6 ε∗3/2 − 3π 8 ε∗; (15) the correction term arises from the fact that the volume of an octant somewhat overes- timates the number of desired lattice points, for it includes, partly though, some points with one or more coordinates equal to zero. Figure 1.2 shows a histogram of the actual val- ues of 61(ε∗) for ε∗ lying between 200 and 300; the theoretical estimate (15) is also shown. In the ﬁgure, we have also included a histogram of the actual values of the corresponding number of microstates, 6′ 1(ε∗), when the quantum numbers nx, ny, and nz can assume the value zero as well. In the latter case, the volume of an octant somewhat underestimates the number of desired lattice points; we now have 6′ 1(ε∗) ≈ π 6 ε∗3/2 + 3π 8 ε∗. (16) Asymptotically, however, the number 6′ 1(ε∗) also satisﬁes equation (14). Returning to the N-particle problem, the number 6N (E∗) should be asymptotically equal to the “volume” of the “positive compartment” of a 3N-dimensional sphere of 1.4 The classical ideal gas 13 3200 2800 2400 2000 1600 1200 200 220 240 260 280 300 ´*\u00021(´*) 6 \u0003 8 3\u0003 (´*)3/2 1 ´* 6 \u0003 8 3\u0003(´*)3/2 2 ´*6\u0003(´*)3/2 FIGURE 1.2 Histograms showing the actual number of microstates available to a particle in a cubical enclosure; the lower histogram corresponds to the so-called Dirichlet boundary conditions, while the upper one corresponds to the Neumann boundary conditions (see Appendix A). The corresponding theoretical estimates, (15) and (16), are shown by dashed lines; the customary estimate, equation (14), is shown by a solid line. radius √ E∗. Referring to equation (C.7a) of Appendix C, we obtain 6N (E∗) ≈ ( 1 2 )3N { π 3N/2 (3N/2)! E∗3N/2} which, on substitution for E∗, gives 6(N, V , E) ≈ ( V h3 )N (2πmE)3N/2 (3N/2)! . (17) Taking logarithms and applying Stirling’s formula, (B.29) in Appendix B, ln(n! ) ≈ n ln n − n (n ≫ 1), (18) 14 Chapter 1. The Statistical Basis of Thermodynamics we get ln 6(N, V , E) ≈ N ln [ V h3 ( 4π mE 3N )3/2] + 3 2 N. (19) For deriving the thermodynamic properties of the given system we must somehow ﬁx the precise value of, or limits for, the energy of the system. In view of the extremely irreg- ular nature of the function \u0000(N, V , E), the speciﬁcation of a precise value for the energy of the system cannot be justiﬁed on physical grounds, for that would never yield well- behaved expressions for the thermodynamic functions of the system. From a practical point of view, too, an absolutely isolated system is too much of an idealization. In the real world, almost every system has some contact with its surroundings, however little it may be; as a result, its energy cannot be deﬁned sharply.12 Of course, the effective width of the range over which the energy may vary would, in general, be small in comparison with the mean value of the energy. Let us specify this range by the limits (E − 1 2 1) and (E + 1 2 1) where, by assumption, 1 ≪ E; typically, 1/E = O(1/ √N). The corresponding number of microstates, 0(N, V , E; 1), is then given by 0(N, V , E; 1) ≃ ∂6(N, V , E) ∂E 1 ≈ 3N 2 1 E 6(N, V , E), (17a) which gives ln 0(N, V , E; 1) ≈ N ln [ V h3 ( 4πmE 3N )3/2] + 3 2 N + { ln ( 3N 2 ) + ln ( 1 E )} . (19a) Now, for N ≫ 1, the ﬁrst term in the curly bracket is negligible in comparison with any of the terms outside this bracket, for lim N→∞ (ln N)/N = 0. Furthermore, for any reasonable value of 1/E, the same is true of the second term in this bracket. 13 Hence, for all practical purposes, ln 0 ≈ ln 6 ≈ N ln [ V h3 ( 4π mE 3N )3/2] + 3 2 N. (20) We thus arrive at the bafﬂing result that, for all practical purposes, the actual width of the range allowed for the energy of the system does not make much difference; the energy could lie between ( E − 1 2 1) and (E + 1 2 1) or equally well between 0 and E. The reason underlying this situation is that the rate at which the number of microstates of the system 12Actually, the very act of making measurements on a system brings about, inevitably, a contact between the system and its surroundings. 13It should be clear that, while 1/E is much less than 1, it must not tend to 0, for that would make 0 → 0 and ln 0 → −∞. A situation of that kind would be too artiﬁcial and would have nothing to do with reality. Actually, in most physical systems, 1/E = O(N −1/2), whereby ln(1/E) becomes of order ln N, which again is negligible in comparison with the terms outside the curly bracket. 1.4 The classical ideal gas 15 increases with energy is so fantastic, see equation (17), that even if we allow all values of energy between zero and a particular value E, it is only the “immediate neighborhood” of E that makes an overwhelmingly dominant contribution to this number! And since we are ﬁnally concerned only with the logarithm of this number, even the “width” of that neighborhood is inconsequential! The stage is now set for deriving the thermodynamics of our system. First of all, we have S(N, V , E) = k ln 0 = Nk ln [ V h3 ( 4π mE 3N )3/2] + 3 2 Nk, (21)14 which can be inverted to give E(S, V , N) = 3h2N 4π mV 2/3 exp ( 2S 3Nk − 1 ) . (22) The temperature of the gas then follows with the help of formula (1.3.10) or (1.3.13), which leads to the energy–temperature relationship E = N( 3 2 kT ) = n ( 3 2 RT ), (23) where n is the number of moles of the gas. The speciﬁc heat at constant volume now follows with the help of formula (1.3.17): CV = ( ∂E ∂T ) N,V = 3 2 Nk = 3 2 nR. (24) For the equation of state, we obtain P = −( ∂E ∂V ) N,S = 2 3 E V , (25) which agrees with our earlier result (10). Combined with (23), this gives P = NkT V or PV = nRT , (26) which is the same as (3). The speciﬁc heat at constant pressure is given by, see (1.3.18), CP = ( ∂(E + PV ) ∂T ) N,P = 5 2 nR, (27) 14Henceforth, we shall replace the sign ≈, which characterizes the asymptotic character of a relationship, by the sign of equality because for most physical systems the asymptotic results are as good as exact. 16 Chapter 1. The Statistical Basis of Thermodynamics so that, for the ratio of the two speciﬁc heats, we have γ = CP/CV = 5 3 . (28) Now, suppose that the gas undergoes an isothermal change of state (T = const. and N = const.); then, according to (23), the total energy of the gas would remain constant while, according to (26), its pressure would vary inversely with volume (Boyle’s law). The change in the entropy of the gas, between the initial state i and the ﬁnal state f , would then be, see equation (21), Sf − Si = Nk ln(Vf /Vi). (29) On the other hand, if the gas undergoes a reversible adiabatic change of state (S = const. and N = const.), then, according to (22) and (23), both E and T would vary as V −2/3; so, according to (25) or (26), P would vary as V −5/3. These results agree with the conventional thermodynamic ones, namely PV γ = const. and TV γ −1 = const., (30) with γ = 5 3 . It may be noted that, thermodynamically, the change in E during an adiabatic process arises solely from the external work done by the gas on the surroundings or vice versa: (dE)adiab = −PdV = − 2E 3V dV ; (31) see equations (1.3.4) and (25). The dependence of E on V follows readily from this relationship. The considerations of this section have clearly demonstrated the manner in which the thermodynamics of a macroscopic system can be derived from the multiplicity of its microstates (as represented by the number \u0000 or 0 or 6). The whole problem then hinges on an asymptotic enumeration of these numbers, which unfortunately is tractable only in a few idealized cases, such as the one considered in this section; see also Problems 1.7 and 1.8. Even in an idealized case like this, there remains an inadequacy that could not be detected in the derivations made so far; this relates to the explicit dependence of S on N. The discussion of the next section is intended not only to bring out this inadequacy but also to provide the necessary remedy for it. 1.5 The entropy of mixing and the Gibbs paradox One thing we readily observe from expression (1.4.21) is that, contrary to what is logi- cally desired, the entropy of an ideal gas, as given by this expression, is not an extensive 1.5 The entropy of mixing and the Gibbs paradox 17 (N1, V1; T ) (N2, V2; T ) FIGURE 1.3 The mixing together of two ideal gases 1 and 2. property of the system! That is, if we increase the size of the system by a factor α, keep- ing the intensive variables unchanged,15 then the entropy of the system, which should also increase by the same factor α, does not do so; the presence of the ln V term in the expression affects the result adversely. This in a way means that the entropy of this system is different from the sum of the entropies of its parts, which is quite unphysical. A more common way of looking at this problem is to consider the so-called Gibbs paradox. Gibbs visualized the mixing of two ideal gases 1 and 2, both being initially at the same temperature T ; see Figure 1.3. Clearly, the temperature of the mixture would also be the same. Now, before the mixing took place, the respective entropies of the two gases were, see equations (1.4.21) and (1.4.23), Si = Nik ln Vi + 3 2 Nik {1 + ln ( 2π mikT h2 )} ; i = 1, 2. (1) After the mixing has taken place, the total entropy would be ST = 2∑ i=1 [Nik ln V + 3 2 Nik {1 + ln( 2π mikT h2 )}] , (2) where V = V1 + V2. Thus, the net increase in the value of S, which may be called the entropy of mixing, is given by (1S) = ST − 2∑ i=1 Si = k [N1 ln V1 + V2 V1 + N2 ln V1 + V2 V2 ] ; (3) the quantity 1S is indeed positive, as it must be for an irreversible process like mixing. Now, in the special case when the initial particle densities of the two gases (and, hence, the particle density of the mixture) are also the same, equation (3) becomes (1S) ∗ = k [N1 ln N1 + N2 N1 + N2 ln N1 + N2 N2 ] , (4) which is again positive. 15This means an increase of the parameters N, V , and E to αN, αV , and αE, so that the energy per particle and the volume per particle remain unchanged. 18 Chapter 1. The Statistical Basis of Thermodynamics So far, it seems all right. However, a paradoxical situation arises if we consider the mix- ing of two samples of the same gas. Once again, the entropies of the individual samples will be given by (1); of course, now m1 = m2 = m, say. And the entropy after mixing will be given by ST = Nk ln V + 3 2 Nk {1 + ln ( 2π mkT h2 )} , (2a) where N = N1 + N2; note that this expression is numerically the same as (2), with mi = m. Therefore, the entropy of mixing in this case will also be given by expression (3) and, if N1/V1 = N2/V2 = (N1 + N2)/(V1 + V2), by expression (4). The last conclusion, however, is unacceptable because the mixing of two samples of the same gas, with a common initial temperature T and a common initial particle density n, is clearly a reversible process, for we can simply reinsert the partitioning wall into the system and obtain a situation that is in no way different from the one we had before mixing. Of course, we tacitly imply that in dealing with a system of identical particles we cannot track them down individually; all we can reckon with is their numbers. When two dissimilar gases, even with a common initial temperature T , and a common initial particle density n, mixed together the process was irreversible, for by reinserting the partitioning wall one would obtain two samples of the mixture and not the two gases that were originally present; to that case, expression (4) would indeed apply. However, in the present case, the corresponding result should be (1S)∗ 1≡2 = 0. (4a)16 The foregoing result would also be consistent with the requirement that the entropy of a given system is equal to the sum of the entropies of its parts. Of course, we had already noticed that this is not ensured by expression (1.4.21). Thus, once again we are led to believe that there is something basically wrong with that expression. To see how the above paradoxical situation can be avoided, we recall that, for the entropy of mixing of two samples of the same gas, with a common T and a common n, we were led to result (4), which can also be written as (1S) ∗ = ST − (S1 + S2) ≈ k[ln{(N1 + N2)! } − ln(N1! ) − ln(N2! )], (4) instead of the logical result (4a). A closer look at this expression shows that we would indeed obtain the correct result if our original expression for S were diminished by an ad hoc term, k ln(N! ), for that would diminish S1 by k ln(N1! ), S2 by k ln(N2! ) and ST by k ln {(N1 + N2)! }, with the result that (1S)∗ would turn out to be zero instead of the expres- sion appearing in (4). Clearly, this would amount to an ad hoc reduction of the statistical numbers 0 and 6 by a factor N!. This is precisely the remedy proposed by Gibbs to avoid the paradox in question. 16In view of this, we fear that expression (3) may also be inapplicable to this case. 1.5 The entropy of mixing and the Gibbs paradox 19 If we agree with the foregoing suggestion, then the modiﬁed expression for the entropy of a classical ideal gas would be S(N, V , E) = Nk ln [ V Nh3 ( 4π mE 3N )3/2] + 5 2 Nk (1.4.21a) = Nk ln ( V N ) + 3 2 Nk { 5 3 + ln ( 2πmkT h2 )} , (1a) which indeed is truly extensive! If we now mix two samples of the same gas at a common initial temperature T , the entropy of mixing would be (1S)1≡2 = k [(N1 + N2) ln ( V1 + V2 N1 + N2 ) − N1 ln ( V1 N1 ) − N2 ln ( V2 N2 )] (3a) and, if the initial particle densities of the samples were also equal, the result would be (1S)∗ 1≡2 = 0. (4a) It may be noted that for the mixing of two dissimilar gases, the original expressions (3) and (4) would continue to hold even when (1.4.21) is replaced by (1.4.21a).17 The paradox of Gibbs is thereby resolved. Equation (1a) is generally referred to as the Sackur–Tetrode equation. We reiterate the fact that, by this equation, the entropy of the system does indeed become a truly extensive quantity. Thus, the very root of the trouble has been eliminated by the recipe of Gibbs. We shall discuss the physical implications of this recipe in Section 1.6; here, let us jot down some of its immediate consequences. First of all, we note that the expression for the energy E of the gas, written as a function of N, V , and S, is also modiﬁed. We now have E(N, V , S) = 3h2N 5/3 4πmV 2/3 exp( 2S 3Nk − 5 3 ), (1.4.22a) which, unlike its predecessor (1.4.22), makes energy too a truly extensive quantity. Of course, the thermodynamic results (1.4.23) through (1.4.31), derived in the previous section, remain unchanged. However, there are some that were intentionally left out, for they would come out correct only from the modiﬁed expression for S(N, V , E) or E(S, V , N). The most important of these is the chemical potential of the gas, for which we obtain µ ≡ ( ∂E ∂N ) V ,S = E [ 5 3N − 2S 3N 2k ] . (5) 17Because, in this case, the entropy ST of the mixture would be diminished by k ln(N1! N2! ), rather than by k ln{(N1 + N2)! }. 20 Chapter 1. The Statistical Basis of Thermodynamics In view of equations (1.4.23) and (1.4.25), this becomes µ = 1 N [E + PV − TS] ≡ G N , (6) where G is the Gibbs free energy of the system. In terms of the variables N, V , and T , expression (5) takes the form µ(N, V , T ) = kT ln    N V ( h2 2π mkT )3/2  . (7) Another quantity of importance is the Helmholtz free energy: A = E − TS = G − PV = NkT  ln    N V ( h2 2πmkT )3/2   − 1  . (8) It will be noted that, while A is an extensive property of the system, µ is intensive. 1.6 The “correct” enumeration of the microstates In the preceding section we saw that an ad hoc diminution in the entropy of an N-particle system by an amount k ln(N!), which implies an ad hoc reduction in the number of microstates accessible to the system by a factor (N!), was able to correct the unphysical fea- tures of some of our former expressions. It is now natural to ask: why, in principle, should the number of microstates, computed in Section 1.4, be reduced in this manner? The phys- ical reason for doing so is that the particles constituting the given system are not only identical but also indistinguishable; accordingly, it is unphysical to label them as No. 1, No. 2, No. 3, and so on and to speak of their being individually in the various single-particle states εi. All we can sensibly speak of is their distribution over the states εi by numbers, that is, n1 particles being in the state ε1, n2 in the state ε2, and so on. Thus, the correct way of specifying a microstate of the system is through the distribution numbers {nj}, and not through the statement as to “which particle is in which state.” To elaborate the point, we may say that if we consider two microstates that differ from one another merely in an inter- change of two particles in different energy states, then according to our original mode of counting we would regard these microstates as distinct; in view of the indistinguishability of the particles, however, these microstates are not distinct (for, physically, there exists no way whatsoever of distinguishing between them).18 18Of course, if an interchange took place among particles in the same energy state, then even our original mode of counting did not regard the two microstates as distinct. 1.6 The “correct” enumeration of the microstates 21 Now, the total number of permutations that can be effected among N particles, distributed according to the set {ni}, is N! n1! n2! . . . , (1) where the ni must be consistent with the basic constraints (1.1.1) and (1.1.2). 19 If our parti- cles were distinguishable, then all these permutations would lead to “distinct” microstates. However, in view of the indistinguishability of the particles, these permutations must be regarded as leading to one and the same thing; consequently, for any distribution set {ni}, we have one, and only one, distinct microstate. As a result, the total number of distinct microstates accessible to the system, consistent with a given macrostate (N, V , E), would be severely cut down. However, since factor (1) itself depends on the numbers ni consti- tuting a particular distribution set and for a given macrostate there will be many such sets, there is no straightforward way to “correct down” the number of microstates computed on the basis of the classical concept of “distinguishability” of the particles. The recipe of Gibbs clearly amounts to disregarding the details of the numbers ni and slashing the whole sequence of microstates by a common factor N!; this is correct for situa- tions in which all N particles happen to be in different energy states but is certainly wrong for other situations. We must keep in mind that by adopting this recipe we are still using a spurious weight factor, w{ni} = 1 n1! n2! . . . , (2) for the distribution set {ni} whereas in principle we should use a factor of unity, irre- spective of the values of the numbers ni. 20 Nonetheless, the recipe of Gibbs does correct the situation in a gross manner, though in matters of detail it is still inadequate. In fact, it is only by taking w{ni} to be equal to unity (or zero) that we obtain true quantum statistics! We thus see that the recipe of Gibbs corrects the enumeration of the microstates, as necessitated by the indistinguishability of the particles, only in a gross manner. Numeri- cally, this would approach closer and closer to reality as the probability of the ni being greater than 1 becomes less and less. This in turn happens when the given system is at a sufﬁciently high temperature (so that many more energy states become accessible) and has a sufﬁciently low density (so that there are not as many particles to accommo- date). It follows that the “corrected” classical statistics represents truth more closely if the expectation values of the occupation numbers ni are much less than unity: ⟨ni⟩ ≪ 1, (3) 19The presence of the factors (ni! ) in the denominator is related to the comment made in the preceding note. 20Or a factor of zero if the distribution set {ni} is disallowed on certain physical grounds, such as the Pauli exclusion principle. 22 Chapter 1. The Statistical Basis of Thermodynamics that is, if the numbers ni are generally 0, occasionally 1, and rarely greater than 1. Condition (3) in a way deﬁnes the classical limit. We must, however, remember that it is because of the application of the correction factor 1/N!, which replaces (1) by (2), that our results agree with reality at least in the classical limit. In Section 5.5 we shall demonstrate, in an independent manner, that the factor by which the number of microstates, as computed for the “labeled” molecules, be reduced so that the formalism of classical statistical mechanics becomes a true limit of the formalism of quantum statistical mechanics is indeed N!. Problems 1.1. (a) Show that, for two large systems in thermal contact, the number \u0000(0)(E(0), E1) of Section 1.2 can be expressed as a Gaussian in the variable E1. Determine the root-mean-square deviation of E1 from the mean value E1 in terms of other quantities pertaining to the problem. (b) Make an explicit evaluation of the root-mean-square deviation of E1 in the special case when the systems A1 and A2 are ideal classical gases. 1.2. Assuming that the entropy S and the statistical number \u0000 of a physical system are related through an arbitrary functional form S = f (\u0000), show that the additive character of S and the multiplicative character of \u0000 necessarily require that the function f (\u0000) be of the form (1.2.6). 1.3. Two systems A and B, of identical composition, are brought together and allowed to exchange both energy and particles, keeping volumes VA and VB constant. Show that the minimum value of the quantity (dEA/dNA) is given by µATB − µBTA TB − TA , where the µ’s and the T ’s are the respective chemical potentials and temperatures. 1.4. In a classical gas of hard spheres (of diameter D), the spatial distribution of the particles is no longer uncorrelated. Roughly speaking, the presence of n particles in the system leaves only a volume (V − nv0) available for the (n + 1)th particle; clearly, v0 would be proportional to D3. Assuming that Nv0 ≪ V , determine the dependence of \u0000(N, V , E) on V (compare to equation (1.4.1)) and show that, as a result of this, V in the ideal-gas law (1.4.3) gets replaced by (V − b), where b is four times the actual volume occupied by the particles. 1.5. Read Appendix A and establish formulae (1.4.15) and (1.4.16). Estimate the importance of the linear term in these formulae, relative to the main term (π/6)ε∗3/2, for an oxygen molecule conﬁned to a cube of side 10 cm; take ε = 0.05 eV. 1.6. A cylindrical vessel 1 m long and 0.1 m in diameter is ﬁlled with a monatomic gas at P = 1 atm and T = 300 K. The gas is heated by an electrical discharge, along the axis of the vessel, which releases an energy of 104 joules. What will the temperature of the gas be immediately after the discharge? 1.7. Study the statistical mechanics of an extreme relativisitic gas characterized by the single-particle energy states ε(nx, ny, nz) = hc 2L ( n2 x + n2 y + n 2 z )1/2 , instead of (1.4.5), along the lines followed in Section 1.4. Show that the ratio CP/CV in this case is 4/3, instead of 5/3. 1.8. Consider a system of quasiparticles whose energy eigenvalues are given by ε(n) = nhν; n = 0, 1, 2, . . . . Problems 23 Obtain an asymptotic expression for the number \u0000 of this system for a given number N of the quasiparticles and a given total energy E. Determine the temperature T of the system as a function of E/N and hν, and examine the situation for which E/(Nhν) ≫ 1. 1.9. Making use of the fact that the entropy S(N, V , E) of a thermodynamic system is an extensive quantity, show that N( ∂S ∂N ) V ,E + V ( ∂S ∂V ) N,E + E( ∂S ∂E ) N,V = S. Note that this result implies that (−Nµ + PV + E)/T = S, that is, Nµ = E + PV − TS. 1.10. A mole of argon and a mole of helium are contained in vessels of equal volume. If argon is at 300 K, what should the temperature of helium be so that the two have the same entropy? 1.11. Four moles of nitrogen and one mole of oxygen at P = 1 atm and T = 300 K are mixed together to form air at the same pressure and temperature. Calculate the entropy of mixing per mole of the air formed. 1.12. Show that the various expressions for the entropy of mixing, derived in Section 1.5, satisfy the following relations: (a) For all N1, V1, N2, and V2, (1S)1≡2 = {(1S) − (1S) ∗} ≥ 0, the equality holding when and only when N1/V1 = N2/V2. (b) For a given value of (N1 + N2), (1S)∗ ≤ (N1 + N2)k ln 2, the equality holding when and only when N1 = N2. 1.13. If the two gases considered in the mixing process of Section 1.5 were initially at different temperatures, say T1 and T2, what would the entropy of mixing be in that case? Would the contribution arising from this cause depend on whether the two gases were different or identical? 1.14. Show that for an ideal gas composed of monatomic molecules the entropy change, between any two temperatures, when the pressure is kept constant is 5/3 times the corresponding entropy change when the volume is kept constant. Verify this result numerically by calculating the actual values of (1S)P and (1S)V per mole of an ideal gas whose temperature is raised from 300 K to 400 K. 1.15. We have seen that the (P, V )-relationship during a reversible adiabatic process in an ideal gas is governed by the exponent γ , such that PV γ = const. Consider a mixture of two ideal gases, with mole fractions f1 and f2 and respective exponents γ1 and γ2. Show that the effective exponent γ for the mixture is given by 1 γ − 1 = f1 γ1 − 1 + f2 γ2 − 1 . 1.16. Establish thermodynamically the formulae V ( ∂P ∂T ) µ = S and V ( ∂P ∂µ ) T = N. Express the pressure P of an ideal classical gas in terms of the variables µ and T , and verify the above formulae. 2 Elements of Ensemble Theory In the preceding chapter we noted that, for a given macrostate (N, V , E), a statistical system, at any time t, is equally likely to be in any one of an extremely large number of distinct microstates. As time passes, the system continually switches from one microstate to another, with the result that, over a reasonable span of time, all one observes is a behav- ior “averaged” over the variety of microstates through which the system passes. It may, therefore, make sense if we consider, at a single instant of time, a rather large number of systems — all being some sort of “mental copies” of the given system — which are charac- terized by the same macrostate as the original system but are, naturally enough, in all sorts of possible microstates. Then, under ordinary circumstances, we may expect that the aver- age behavior of any system in this collection, which we call an ensemble, would be identical to the time-averaged behavior of the given system. It is on the basis of this expectation that we proceed to develop the so-called ensemble theory. For classical systems, the most appropriate framework for developing the desired for- malism is provided by the phase space. Accordingly, we begin our study of the various ensembles with an analysis of the basic features of this space. 2.1 Phase space of a classical system The microstate of a given classical system, at any time t, may be deﬁned by specifying the instantaneous positions and momenta of all the particles constituting the system. Thus, if N is the number of particles in the system, the deﬁnition of a microstate requires the speciﬁcation of 3N position coordinates q1, q2, . . . , q3N and 3N momentum coordinates p1, p2, . . . , p3N . Geometrically, the set of coordinates (qi, pi), where i = 1, 2, . . . , 3N, may be regarded as a point in a space of 6N dimensions. We refer to this space as the phase space, and the phase point (qi, pi) as a representative point, of the given system. Of course, the coordinates qi and pi are functions of the time t; the precise manner in which they vary with t is determined by the canonical equations of motion, ˙qi = ∂H(qi, pi) ∂pi ˙pi = − ∂H(qi, pi) ∂qi    i = 1, 2, . . . , 3N, (1) where H(qi, pi) is the Hamiltonian of the system. Now, as time passes, the set of coordinates (qi, pi), which also deﬁnes the microstate of the system, undergoes a continual change. Correspondingly, our representative point in the phase space carves out a Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00002-5 © 2011 Elsevier Ltd. All rights reserved. 25 26 Chapter 2. Elements of Ensemble Theory trajectory whose direction, at any time t, is determined by the velocity vector v ≡ ( ˙qi, ˙pi), which in turn is given by the equations of motion (1). It is not difﬁcult to see that the trajectory of the representative point must remain within a limited region of the phase space; this is so because a ﬁnite volume V directly limits the values of the coordinates qi, while a ﬁnite energy E limits the values of both the qi and the pi [through the Hamiltonian H(qi, pi)]. In particular, if the total energy of the system is known to have a precise value, say E, the corresponding trajectory will be restricted to the “hypersurface” H(qi, pi) = E (2) of the phase space; on the other hand, if the total energy may lie anywhere in the range(E − 1 2 1, E + 1 2 1) , the corresponding trajectory will be restricted to the “hypershell” deﬁned by these limits. Now, if we consider an ensemble of systems (i.e., the given system, along with a large number of mental copies of it) then, at any time t, the various members of the ensem- ble will be in all sorts of possible microstates; indeed, each one of these microstates must be consistent with the given macrostate that is supposed to be common to all members of the ensemble. In the phase space, the corresponding picture will consist of a swarm of representative points, one for each member of the ensemble, all lying within the “allowed” region of this space. As time passes, every member of the ensemble undergoes a continual change of microstates; correspondingly, the representative points constituting the swarm continually move along their respective trajectories. The overall picture of this movement possesses some important features that are best illustrated in terms of what we call a density function ρ(q, p; t). 1 This function is such that, at any time t, the number of repre- sentative points in the “volume element” (d3N q d3N p) around the point (q, p) of the phase space is given by the product ρ(q, p; t)d3N q d3N p. Clearly, the density function ρ(q, p; t) symbolizes the manner in which the members of the ensemble are distributed over all possible microstates at different instants of time. Accordingly, the ensemble average ⟨ f ⟩ of a given physical quantity f (q, p), which may be different for systems in different microstates, would be given by ⟨ f ⟩ = ∫ f (q, p)ρ(q, p; t)d3N q d3N p ∫ ρ(q, p; t)d3N q d3N p . (3) The integrations in (3) extend over the whole of the phase space; however, it is only the populated regions of the phase space (ρ ̸= 0) that really contribute. We note that, in general, the ensemble average ⟨ f ⟩ may itself be a function of time. An ensemble is said to be stationary if ρ does not depend explicitly on time, that is, at all times ∂ρ ∂t = 0. (4) 1Note that (q, p) is an abbreviation of (qi, pi) ≡ (q1, . . . , q3N , p1, . . . , p3N ). 2.2 Liouville’s theorem and its consequences 27 Clearly, for such an ensemble the average value ⟨ f ⟩ of any physical quantity f (q, p) will be independent of time. Naturally, a stationary ensemble qualiﬁes to represent a system in equilibrium. To determine the circumstances under which equation (4) may hold, we have to make a rather detailed study of the movement of the representative points in the phase space. 2.2 Liouville’s theorem and its consequences Consider an arbitrary “volume” ω in the relevant region of the phase space and let the “surface” enclosing this volume be denoted by σ ; see Figure 2.1. Then, the rate at which the number of representative points in this volume increases with time is written as ∂ ∂t ∫ ω ρ dω, (1) where dω ≡ (d3N q d3N p). On the other hand, the net rate at which the representative points “ﬂow” out of ω (across the bounding surface σ ) is given by ∫ σ ρ v · ˆn dσ ; (2) here, v is the velocity vector of the representative points in the region of the surface element dσ while ˆn is the (outward) unit vector normal to this element. By the divergence theorem, (2) can be written as ∫ ω div(ρv)dω; (3) of course, the operation of divergence here means div(ρv) ≡ 3N∑ i=1 { ∂ ∂qi (ρ ˙qi) + ∂ ∂pi (ρ ˙pi) } . (4) \u0002 vdt d\u0002 n^ v \u0003 FIGURE 2.1 The “hydrodynamics” of the representative points in the phase space. 28 Chapter 2. Elements of Ensemble Theory In view of the fact that there are no “sources” or “sinks” in the phase space and hence the total number of representative points remains conserved,2 we have, by (1) and (3), ∂ ∂t ∫ ω ρ dω = − ∫ ω div(ρv)dω, (5) that is, ∫ ω { ∂ρ ∂t + div(ρv) } dω = 0. (6) Now, the necessary and sufﬁcient condition that integral (6) vanish for all arbitrary volumes ω is that the integrand itself vanish everywhere in the relevant region of the phase space. Thus, we must have ∂ρ ∂t + div(ρv) = 0, (7) which is the equation of continuity for the swarm of the representative points. Combining (4) and (7), we obtain ∂ρ ∂t + 3N∑ i=1 ( ∂ρ ∂qi ˙qi + ∂ρ ∂pi ˙pi ) + ρ 3N∑ i=1 ( ∂ ˙qi ∂qi + ∂ ˙pi ∂pi ) = 0. (8) The last group of terms vanishes identically because, by the equations of motion, we have, for all i, ∂ ˙qi ∂qi = ∂ 2H(qi, pi) ∂qi∂pi ≡ ∂ 2H(qi, pi) ∂pi∂qi = − ∂ ˙pi ∂pi . (9) Further, since ρ ≡ ρ (q, p; t), the remaining terms in (8) may be combined to form the “total” time derivative of ρ, with the result that dρ dt = ∂ρ ∂t + [ρ, H] = 0. (10)3 Equation (10) embodies Liouville’s theorem (1838). According to this theorem, the “local” density of the representative points, as viewed by an observer moving with a representa- tive point, stays constant in time. Thus, the swarm of the representative points moves in 2This means that in the ensemble under consideration neither are any new members being added nor are any old ones being removed. 3We recall that the Poisson bracket [ρ, H] stands for the sum 3N∑ i=1 ( ∂ρ ∂qi ∂H ∂pi − ∂ρ ∂pi ∂H ∂qi ) , which is identical to the group of terms in the middle of (8). 2.2 Liouville’s theorem and its consequences 29 the phase space in essentially the same manner as an incompressible ﬂuid moves in the physical space! A distinction must be made, however, between equation (10) on one hand and equation (2.1.4) on the other. While the former derives from the basic mechanics of the particles and is therefore quite generally true, the latter is only a requirement for equi- librium which, in a given case, may or may not be satisﬁed. The condition that ensures simultaneous validity of the two equations is clearly [ρ, H] = 3N∑ i=1 ( ∂ρ ∂qi ˙qi + ∂ρ ∂pi ˙pi ) = 0. (11) Now, one possible way of satisfying (11) is to assume that ρ, which is already assumed to have no explicit dependence on time, is independent of the coordinates (q, p) as well, that is, ρ(q, p) = const. (12) over the relevant region of the phase space (and, of course, is zero everywhere else). Physi- cally, this choice corresponds to an ensemble of systems that at all times are uniformly distributed over all possible microstates. The ensemble average (2.1.3) then reduces to ⟨ f ⟩ = 1 ω ∫ ω f (q, p)dω; (13) here, ω denotes the total “volume” of the relevant region of the phase space. Clearly, in this case, any member of the ensemble is equally likely to be in any one of the various possible microstates, inasmuch as any representative point in the swarm is equally likely to be in the neighborhood of any phase point in the allowed region of the phase space. This statement is usually referred to as the postulate of “equal a priori probabilities” for the various possible microstates (or for the various volume elements in the allowed region of the phase space); the resulting ensemble is referred to as the microcanonical ensemble. A more general way of satisfying (11) is to assume that the dependence of ρ on (q, p) comes only through an explicit dependence on the Hamiltonian H(q, p), that is, ρ(q, p) = ρ[H(q, p)]; (14) condition (11) is then identically satisﬁed. Equation (14) provides a class of density func- tions for which the corresponding ensemble is stationary. In Chapter 3 we shall see that the most natural choice in this class of ensembles is the one for which ρ(q, p) ∝ exp[−H(q, p)/kT ]. (15) The ensemble so deﬁned is referred to as the canonical ensemble. 30 Chapter 2. Elements of Ensemble Theory 2.3 The microcanonical ensemble In this ensemble the macrostate of a system is deﬁned by the number of molecules N, the volume V , and the energy E. However, in view of the considerations expressed in Section 1.4, we may prefer to specify a range of energy values, say from ( E − 1 2 1 ) to( E + 1 2 1 ), rather than a sharply deﬁned value E. With the macrostate speciﬁed, a choice still remains for the systems of the ensemble to be in any one of a large number of pos- sible microstates. In the phase space, correspondingly, the representative points of the ensemble have a choice to lie anywhere within a “hypershell” deﬁned by the condition ( E − 1 2 1) ≤ H(q, p) ≤ ( E + 1 2 1) . (1) The volume of the phase space enclosed within this shell is given by ω = ′∫ dω ≡ ′∫ (d3N q d3N p ) , (2) where the primed integration extends only over that part of the phase space which con- forms to condition (1). It is clear that ω will be a function of the parameters N, V , E, and 1. Now, the microcanonical ensemble is a collection of systems for which the density function ρ is, at all times, given by ρ(q, p) = const. if ( E − 1 2 1) ≤ H(q, p) ≤ (E + 1 2 1) 0 otherwise    . (3) Accordingly, the expectation value of the number of representative points lying in a vol- ume element dω of the relevant hypershell is simply proportional to dω. In other words, the a priori probability of ﬁnding a representative point in a given volume element dω is the same as that of ﬁnding a representative point in an equivalent volume element dω located anywhere in the hypershell. In our original parlance, this means an equal a priori probabil- ity for a given member of the ensemble to be in any one of the various possible microstates. In view of these considerations, the ensemble average ⟨ f ⟩, as given by equation (2.2.13), acquires a simple physical meaning. To see this, we proceed as follows. Since the ensemble under study is a stationary one, the ensemble average of any phy- sical quantity f will be independent of time; accordingly, taking a time average thereof will not produce any new result. Thus ⟨ f ⟩ ≡ the ensemble average of f = the time average of (the ensemble average of f ). 2.3 The microcanonical ensemble 31 Now, the processes of time averaging and ensemble averaging are completely indepen- dent, so the order in which they are performed may be reversed without causing any change in the value of ⟨ f ⟩. Thus ⟨ f ⟩ = the ensemble average of (the time average of f ). Now, the time average of any physical quantity, taken over a sufﬁciently long interval of time, must be the same for every member of the ensemble, for after all we are dealing with only mental copies of a given system. 4 Therefore, taking an ensemble average thereof should be inconsequential, and we may write ⟨ f ⟩ = the long-time average of f , where the latter may be taken over any member of the ensemble. Furthermore, the long- time average of a physical quantity is all one obtains by making a measurement of that quantity on the given system; therefore, it may be identiﬁed with the value one expects to obtain through experiment. Thus, we ﬁnally have ⟨ f ⟩ = fexp. (4) This brings us to the most important result: the ensemble average of any physical quantity f is identical to the value one expects to obtain on making an appropriate measurement on the given system. The next thing we look for is the establishment of a connection between the mechanics of the microcanonical ensemble and the thermodynamics of the member systems. To do this, we observe that there exists a direct correspondence between the various microstates of the given system and the various locations in the phase space. The volume ω (of the allowed region of the phase space) is, therefore, a direct measure of the multiplicity 0 of the microstates accessible to the system. To establish a numerical correspondence between ω 4To provide a rigorous justiﬁcation for this assertion is not trivial. One can readily see that if, for any particular mem- ber of the ensemble, the quantity f is averaged only over a short span of time, the result is bound to depend on the relevant “subset of microstates” through which the system passes during that time. In the phase space, this will mean an averaging over only a “part of the allowed region.” However, if we employ instead a sufﬁciently long interval of time, the system may be expected to pass through almost all possible microstates “without fear or favor”; consequently, the result of the averaging process would depend only on the macrostate of the system, and not on a subset of microstates. Correspondingly, the averaging in the phase space would go over practically all parts of the allowed region, again “with- out fear or favor.” In other words, the representative point of our system will have traversed each and every part of the allowed region almost uniformly. This statement embodies the so-called ergodic theorem or ergodic hypothesis, which was ﬁrst introduced by Boltzmann (1871). According to this hypothesis, the trajectory of a representative point passes, in the course of time, through each and every point of the relevant region of the phase space. A little reﬂection, however, shows that the statement as such requires a qualiﬁcation; we better replace it by the so-called quasiergodic hypothesis, according to which the trajectory of a representative point traverses, in the course of time, any neighborhood of any point of the relevant region. For further details, see ter Haar (1954, 1955), Farquhar (1964). Now, when we consider an ensemble of systems, the foregoing statement should hold for every member of the ensemble; thus, irrespective of the initial (and ﬁnal ) states of the various systems, the long-time average of any physical quantity f should be the same for every member system. 32 Chapter 2. Elements of Ensemble Theory and 0, we need to discover a fundamental volume ω0 that could be regarded as “equivalent to one microstate.” Once this is done, we may say that, asymptotically, 0 = ω/ω0. (5) The thermodynamics of the system would then follow in the same way as in Sections 1.2– 1.4, namely through the relationship S = k ln 0 = k ln(ω/ω0), etc. (6) The basic problem then consists in determining ω0. From dimensional considerations, see (2), ω0 must be in the nature of an “angular momentum raised to the power 3N.” To determine it exactly, we consider certain simpliﬁed systems, both from the point of view of the phase space and from the point of view of the distribution of quantum states. 2.4 Examples We consider, ﬁrst of all, the problem of a classical ideal gas composed of monatomic par- ticles; see Section 1.4. In the microcanonical ensemble, the volume ω of the phase space accessible to the representative points of the (member) systems is given by ω = ′∫ . . . ′∫ (d3N q d3N p) , (1) where the integrations are restricted by the conditions that (i) the particles of the system are conﬁned in physical space to volume V , and (ii) the total energy of the system lies between the limits (E − 1 2 1) and (E + 1 2 1). Since the Hamiltonian in this case is a function of the pi alone, integrations over the qi can be carried out straightforwardly; these give a factor of V N . The remaining integral is ∫ . . . ∫ ( E− 1 2 1)≤ 3N∑ i=1 (p2 i /2m )≤ (E+ 1 2 1) d3N p = ∫ . . . ∫ 2m( E− 1 2 1) ≤ 3N∑ i=1 y2 i ≤2m (E+ 1 2 1) d3N y, which is equal to the volume of a 3N-dimensional hypershell, bounded by hyperspheres of radii √[ 2m ( E + 1 2 1)] and √[ 2m ( E − 1 2 1)] . For 1 ≪ E, this is given by the thickness of the shell, which is almost equal to 1(m/2E)1/2, multiplied by the surface area of a 3N-dimensional hypersphere of radius √ (2mE). By 2.4 Examples 33 equation (7) of Appendix C, we obtain for this integral 1 ( m 2E )1/2 { 2π 3N/2 [(3N/2) − 1]! (2mE)(3N−1)/2} , which gives ω ≃ 1 E V N (2πmE)3N/2 [(3N/2) − 1]! . (2) Comparing (2) with (1.4.17 and 1.4.17a), we obtain the desired correspondence, namely (ω/ 0)asymp ≡ ω0 = h3N ; see also Problem 2.9. Quite generally, if the system under study has N degrees of freedom, the desired conversion factor is ω0 = h N . (3) In the case of a single particle, N = 3; accordingly, the number of microstates available would asymptotically be equal to the volume of the allowed region of the phase space divided by h3. Let 6(P) denote the number of microstates available to a free particle con- ﬁned to volume V of the physical space, its momentum p being less than or equal to a speciﬁed value P. Then 6(P) ≈ 1 h3 ∫ . . . ∫ p ≤ P (d3q d3p ) = V h3 4π 3 P3, (4) from which we obtain for the number of microstates with momentum lying between p and p + dp g(p)dp = d6(p) dp dp ≈ V h3 4π p 2dp. (5) Expressed in terms of the particle energy, these expressions assume the form 6(E) ≈ V h3 4π 3 (2mE)3/2 (6) and a(ε)dε = d6(ε) dε dε ≈ V h3 2π(2m) 3/2ε1/2dε. (7) The next case we consider here is that of a one-dimensional simple harmonic oscillator. The classical expression for the Hamiltonian of this system is H(q, p) = 1 2 kq2 + 1 2m p 2, (8) 34 Chapter 2. Elements of Ensemble Theory where k is the spring constant and m the mass of the oscillating particle. The space coordinate q and the momentum coordinate p of the system are given by q = A cos(ωt + φ), p = m ˙q = −mωA sin(ωt + φ), (9) A being the amplitude and ω the (angular) frequency of vibration: ω = √(k/m). (10) The energy of the oscillator is a constant of the motion, and is given by E = 1 2 mω2A 2. (11) The phase-space trajectory of the representative point (q, p) of this system is determined by eliminating t between expressions (9) for q(t) and p(t); we obtain q2 (2E/mω2) + p2 (2mE) = 1, (12) which is an ellipse, with axes proportional to √E and hence area proportional to E; to be precise, the area of this ellipse is 2π E/ω. Now, if we restrict the oscillator energy to the interval (E − 1 2 1, E + 1 2 1), its representative point in the phase space will be conﬁned to the region bounded by elliptical trajectories corresponding to the energy values (E + 1 2 1) and (E − 1 2 1). The “volume” (in this case, the area) of this region will be ∫ . . . ∫ (E− 1 2 1) ≤H(q,p)≤( E+ 1 2 1)(dq dp) = 2π(E + 1 2 1) ω − 2π(E − 1 2 1) ω = 2π1 ω . (13) According to quantum mechanics, the energy eigenvalues of the harmonic oscillator are given by En = (n + 1 2 )ℏω; n = 0, 1, 2, . . . (14) In terms of phase space, one could say that the representative point of the system must move along one of the “chosen” trajectories, as shown in Figure 2.2; the area of the phase space between two consecutive trajectories, for which 1 = ℏω, is simply 2π ℏ. 5 For arbitrary values of E and 1, such that E ≫ 1 ≫ ℏω, the number of eigenstates within the allowed 5Strictly speaking, the very concept of phase space is invalid in quantum mechanics because there, in principle, it is wrong to assign to a particle the coordinates q and p simultaneously. Nevertheless, the ideas discussed here are tenable in the correspondence limit. 2.5 Quantum states and the phase space 35 n \u0002 32p0 p0 \u0003p0 \u00032p0 q p n \u0002 2 n \u0002 1 n \u0002 0 \u00032q0 \u0003q0 q0 2q0 FIGURE 2.2 Eigenstates of a linear harmonic oscillator, in relation to its phase space. energy interval is very nearly equal to 1/ℏω. Hence, the area of the phase space equivalent to one eigenstate is, asymptotically, given by ω0 = (2π1/ω)/(1/ℏω) = 2π ℏ = h. (15) If, on the other hand, we consider a system of N harmonic oscillators along the same lines as above, we arrive at the result: ω0 = hN (see Problem 2.7). Thus, our ﬁndings in these cases are consistent with our earlier result (3). 2.5 Quantum states and the phase space At this stage we would like to say a few words on the central role played here by the Planck constant h. The best way to appreciate this role is to recall the implications of the Heisen- berg uncertainty principle, according to which we cannot specify simultaneously both the position and the momentum of a particle exactly. An element of uncertainty is inherently present and can be expressed as follows: assuming that all conceivable uncertainties of measurement are eliminated, even then, by the very nature of things, the product of the uncertainties 1q and 1p in the simultaneous measurement of the canonically conjugate coordinates q and p would be of order ℏ: (1q1p)min ∼ ℏ. (1) Thus, it is impossible to deﬁne the position of a representative point in the phase space of the given system more accurately than is allowed by condition (1). In other words, around any point (q, p) in the (two-dimensional) phase space, there exists an area of order ℏ within 36 Chapter 2. Elements of Ensemble Theory which the position of the representative point cannot be pinpointed. In a phase space of 2N dimensions, the corresponding “volume of uncertainty” around any point would be of order ℏN . Therefore, it seems reasonable to regard the phase space as made up of ele- mentary cells, of volume ∼ ℏN , and to consider the various positions within such a cell as nondistinct. These cells could then be put into one-to-one correspondence with the quantum-mechanical states of the system. It is, however, obvious that considerations of uncertainty alone cannot give us the exact value of the conversion factor ω0. This could only be done by an actual counting of microstates on one hand and a computation of volume of the relevant region of the phase space on the other, as was done in the examples of the previous section. Clearly, a procedure along these lines could not be possible until after the work of Schr¨odinger and others. Historically, however, the ﬁrst to establish the result (2.4.3) was Tetrode (1912) who, in his well-known work on the chemical constant and the entropy of a monatomic gas, assumed that ω0 = (zh)N , (2) where z was supposed to be an unknown numerical factor. Comparing theoretical results with the experimental data on mercury, Tetrode found that z was very nearly equal to unity; from this he concluded that “it seems rather plausible that z is exactly equal to unity, as has already been taken by O. Sackur (1911).”6 In the extreme relativistic limit, the same result was established by Bose (1924). In his famous treatment of the photon gas, Bose made use of Einstein’s relationship between the momentum of a photon and the frequency of the associated radiation, namely p = hν c , (3) and observed that, for a photon conﬁned to a three-dimensional cavity of volume V , the relevant “volume” of the phase space, ′∫ (d3q d3p) = V 4πp2dp = V (4π h 3ν2/c3)dν, (4) would correspond exactly to the Rayleigh expression, V (4πν2/c3)dν, (5) for the number of normal modes of a radiation oscillator, provided that we divide phase space into elementary cells of volume h3 and put these cells into one-to-one corre- spondence with the vibrational modes of Rayleigh. It may, however, be added that a two-fold multiplicity of these states (g = 2) arises from the spin orientations of the photon 6For a more satisfactory proof of this result, see Section 5.5, especially equation (5.5.22). Problems 37 (or from the states of polarization of the vibrational modes); this requires a multiplica- tion of both expressions (4) and (5) by a factor of 2, leaving the conversion factor h3 unchanged. Problems 2.1. Show that the volume element dω = 3N∏ i=1(dqi dpi) of the phase space remains invariant under a canonical transformation of the (generalized) coordinates (q, p) to any other set of (generalized) coordinates (Q, P). [Hint: Before considering the most general transformation of this kind, which is referred to as a contact transformation, it may be helpful to consider a point transformation — one in which the new coordinates Qi and the old coordinates qi transform only among themselves.] 2.2. (a) Verify explicitly the invariance of the volume element dω of the phase space of a single particle under transformation from the Cartesian coordinates (x, y, z, px, py, pz) to the spherical polar coordinates (r, θ, φ, pr, pθ , pφ). (b) The foregoing result seems to contradict the intuitive notion of “equal weights for equal solid angles,” because the factor sin θ is invisible in the expression for dω. Show that if we average out any physical quantity, whose dependence on pθ and pφ comes only through the kinetic energy of the particle, then as a result of integration over these variables we do indeed recover the factor sin θ to appear with the subelement (dθ dφ). 2.3. Starting with the line of zero energy and working in the (two-dimensional) phase space of a classical rotator, draw lines of constant energy that divide phase space into cells of “volume” h. Calculate the energies of these states and compare them with the energy eigenvalues of the corresponding quantum-mechanical rotator. 2.4. By evaluating the “volume” of the relevant region of its phase space, show that the number of microstates available to a rigid rotator with angular momentum ≤ M is (M/ℏ)2. Hence determine the number of microstates that may be associated with the quantized angular momentum Mj = √{ j( j + 1)}ℏ, where j = 0, 1, 2, . . . or 1 2 , 3 2 , 5 2 , . . .. Interpret the result physically. [Hint: It simpliﬁes to consider motion in the variables θ and ϕ, with M 2 = p2 θ + (pφ/ sin θ)2.] 2.5. Consider a particle of energy E moving in a one-dimensional potential well V (q), such that mℏ ∣ ∣ ∣ ∣ dV dq ∣ ∣ ∣ ∣ ≪ {m(E − V )} 3/2. Show that the allowed values of the momentum p of the particle are such that ∮ p dq = ( n + 1 2 ) h, where n is an integer. 2.6. The generalized coordinates of a simple pendulum are the angular displacement θ and the angular momentum ml2 ˙θ . Study, both mathematically and graphically, the nature of the corresponding trajectories in the phase space of the system, and show that the area A enclosed by a trajectory is equal to the product of the total energy E and the time period τ of the pendulum. 2.7. Derive (i) an asymptotic expression for the number of ways in which a given energy E can be distributed among a set of N one-dimensional harmonic oscillators, the energy eigenvalues of the oscillators being ( n + 1 2 ) ℏω; n = 0, 1, 2, . . ., and (ii) the corresponding expression for the “volume” of the relevant region of the phase space of this system. Establish the correspondence between the two results, showing that the conversion factor ω0 is precisely hN . 38 Chapter 2. Elements of Ensemble Theory 2.8. Following the method of Appendix C, replacing equation (C.4) by the integral ∞∫ 0 e−rr2dr = 2, show that V3N = ∫ . . . ∫ 0≤ N∑ i=1 ri≤R N∏ i=1 ( 4π r2 i dri) = (8π R3) N /(3N)! . Using this result, compute the “volume” of the relevant region of the phase space of an extreme relativistic gas (ε = pc) of N particles moving in three dimensions. Hence, derive expressions for the various thermodynamic properties of this system and compare your results with those of Problem 1.7. 2.9. (a) Solve the integral ∫ . . . ∫ 0≤ 3N∑ i=1 |xi|≤R (dx1 . . . dx3N ) and use it to determine the “volume” of the relevant region of the phase space of an extreme relativistic gas (ε = pc) of 3N particles moving in one dimension. Determine, as well, the number of ways of distributing a given energy E among this system of particles and show that, asymptotically, ω0 = h3N . (b) Compare the thermodynamics of this system with that of the system considered in Problem 2.8. 3 The Canonical Ensemble In the preceding chapter we established the basis of ensemble theory and made a somewhat detailed study of the microcanonical ensemble. In that ensemble the macrostate of the systems was deﬁned through a ﬁxed number of particles N, a ﬁxed vol- ume V , and a ﬁxed energy E [or, preferably, a ﬁxed energy range (E − 1 2 1, E + 1 2 1)]. The basic problem then consisted in determining the number \u0000(N, V , E), or 0(N, V , E; 1), of distinct microstates accessible to the system. From the asymptotic expressions of these numbers, complete thermodynamics of the system could be derived in a straightforward manner. However, for most physical systems, the mathematical problem of determin- ing these numbers is quite formidable. For this reason alone, a search for an alternative approach within the framework of the ensemble theory seems necessary. Practically, too, the concept of a ﬁxed energy (or even an energy range) for a system belonging to the real world does not appear satisfactory. For one thing, the total energy E of a system is hardly ever measured; for another, it is hardly possible to keep its value under strict physical control. A far better alternative appears to be to speak of a ﬁxed tem- perature T of the system — a parameter that is not only directly observable (by placing a “thermometer” in contact with the system) but also controllable (by keeping the system in contact with an appropriate “heat reservoir”). For most purposes, the precise nature of the reservoir is not very relevant; all one needs is that it should have an inﬁnitely large heat capacity, so that, irrespective of energy exchange between the system and the reser- voir, an overall constant temperature can be maintained. Now, if the reservoir consists of an inﬁnitely large number of mental copies of the given system we have once again an ensemble of systems — this time, however, it is an ensemble in which the macrostate of the systems is deﬁned through the parameters N, V , and T . Such an ensemble is referred to as a canonical ensemble. In the canonical ensemble, the energy E of a system is variable; in principle, it can take values anywhere between zero and inﬁnity. The question then arises: what is the probability that, at any time t, a system in the ensemble is found to be in one of the states characterized by the energy value Er? 1 We denote this probability by the symbol Pr. Clearly, there are two ways in which the dependence of Pr on Er can be determined. One consists of regarding the system as in equilibrium with a heat reservoir at a common temperature T and studying the statistics of the energy exchange between the two. The other consists of regarding the system as a member of a canonical ensemble (N, V , T ), in which an energy E is being shared by N identical systems constituting the ensemble, and studying the 1In what follows, the energy levels Er appear as purely mechanical quantities — independent of the temperature of the system. For a treatment involving “temperature-dependent energy levels,” see Elcock and Landsberg (1957). Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00003-7 © 2011 Elsevier Ltd. All rights reserved. 39 40 Chapter 3. The Canonical Ensemble statistics of this sharing process. We expect that in the thermodynamic limit the ﬁnal result in either case would be the same. Once Pr is determined, the rest follows without difﬁculty. 3.1 Equilibrium between a system and a heat reservoir We consider the given system A, immersed in a very large heat reservoir A′; see Figure 3.1. On attaining a state of mutual equilibrium, the system and the reservoir would have a common temperature, say T. Their energies, however, would be variable and, in principle, could have, at any time t, values lying anywhere between 0 and E(0), where E(0) denotes the energy of the composite system A(0)(≡ A + A′). If, at any particular instant of time, the system A happens to be in a state characterized by the energy value Er, then the reservoir would have an energy E′ r, such that Er + E′ r = E(0) = const. (1) Of course, since the reservoir is supposed to be much larger than the given system, any practical value of Er would be a very small fraction of E(0); therefore, for all practical purposes, Er E(0) = ( 1 − E′ r E(0) ) ≪ 1. (2) With the state of the system A having been speciﬁed, the reservoir A′ can still be in any one of a large number of states compatible with the energy value E′ r. Let the number of these states be denoted by \u0000′(E′ r). The prime on the symbol \u0000 emphasizes the fact that its functional form will depend on the nature of the reservoir; of course, the details of this dependence are not going to be of any particular relevance to our ﬁnal results. Now, the larger the number of states available to the reservoir, the larger the probability of the reservoir assuming that particular energy value E′ r (and, hence, of the system A assum- ing the corresponding energy value Er). Moreover, since the various possible states (with a given energy value) are equally likely to occur, the relevant probability would be directly proportional to this number; thus, Pr ∝ \u0000′(E′ r) ≡ \u0000′(E(0) − Er). (3) A9 (Er9;T ) A (Er ;T ) FIGURE 3.1 A given system A immersed in a heat reservoir A′; in equilibrium, the two have a common temperature T . 3.2 A system in the canonical ensemble 41 In view of (2), we may carry out an expansion of (3) around the value E′ r = E(0), that is, around Er = 0. However, for reasons of convergence, it is essential to effect the expansion of its logarithm instead: ln \u0000′(E′ r) = ln \u0000′(E(0)) + ( ∂ ln \u0000′ ∂E′ ) E′=E(0) (E′ r − E(0)) + · · · ≃ const − β′Er, (4) where use has been made of formula (1.2.3), whereby ( ∂ ln \u0000 ∂E ) N,V ≡ β; (5) note that, in equilibrium, β′ = β = 1/kT . From (3) and (4), we obtain the desired result: Pr ∝ exp(−βEr). (6) Normalizing (6), we get Pr = exp(−βEr) ∑ r exp(−βEr) , (7) where the summation in the denominator goes over all states accessible to the system A. We note that our ﬁnal result (7) bears no relation whatsoever to the physical nature of the reservoir A′. We now examine the same problem from the ensemble point of view. 3.2 A system in the canonical ensemble We consider an ensemble of N identical systems (which may be labelled as 1, 2, . . . , N ), sharing a total energy E ; let Er(r = 0, 1, 2, . . .) denote the energy eigenvalues of the systems. If nr denotes the number of systems which, at any time t, have the energy value Er, then the set of numbers {nr} must satisfy the obvious conditions ∑ r nr = N ∑ r nrEr = E = N U,    (1) where U(= E /N ) denotes the average energy per system in the ensemble. Any set {nr} that satisﬁes the restrictive conditions (1) represents a possible mode of distribution of the total energy E among the N members of the ensemble. Furthermore, any such mode can be realized in a number of ways, for we may effect a reshufﬂe among those members of the ensemble for which the energy values are different and thereby obtain a state of the 42 Chapter 3. The Canonical Ensemble ensemble that is distinct from the original one. Denoting the number of different ways of doing so by the symbol W {nr}, we have W {nr} = N ! n0! n1! n2! . . . . (2) In view of the fact that all possible states of the ensemble, which are compatible with con- ditions (1), are equally likely to occur, the frequency with which the distribution set {nr} may appear will be directly proportional to the number W {nr}. Accordingly, the “most probable” mode of distribution will be the one for which the number W is a maximum. We denote the corresponding distribution set by {n∗ r }; clearly, the set {n∗ r } must also satisfy conditions (1). As will be seen in the sequel, the probability of appearance of other modes of distribution, however little they may differ from the most probable mode, is extremely low! Therefore, for all practical purposes, the most probable distribution set {n∗ r } is the only one we have to contend with. However, unless this has been mathematically demonstrated, one must take into account all possible modes of distribution, as characterized by the various distribution sets {nr}, along with their respective weight factors W {nr}. Accordingly, the expectation values, or mean values, ⟨nr⟩ of the numbers nr would be given by ⟨nr⟩ = ∑ {nr } ′ nrW {nr} ∑ {nr } ′ W {nr} , (3) where the primed summations go over all distribution sets that conform to conditions (1). In principle, the mean value ⟨nr⟩, as a fraction of the total number N , should be a natural analog of the probability Pr evaluated in the preceding section. In practice, however, the fraction n∗ r /N also turns out to be the same. We now proceed to derive expressions for the numbers n∗ r and ⟨nr⟩, and to show that, in the limit N → ∞, they are identical. The method of most probable values Our aim here is to determine that distribution set which, while satisfying conditions (1), maximizes the weight factor (2). For simplicity, we work with ln W instead: ln W = ln(N ! ) − ∑ r ln(nr! ). (4) Since, in the end, we propose to resort to the limit N → ∞, the values of nr (which are going to be of any practical signiﬁcance) would also, in that limit, tend to inﬁnity. It is, therefore, justiﬁed to apply the Stirling formula, ln(n! ) ≈ n ln n − n, to (4) and write ln W = N ln N − ∑ r nr ln nr. (5) 3.2 A system in the canonical ensemble 43 If we shift from the set {nr} to a slightly different set {nr + δnr}, then expression (5) would change by an amount δ(ln W ) = − ∑ r (ln nr + 1)δnr. (6) Now, if the set {nr} is maximal, the variation δ(ln W ) should vanish. At the same time, in view of the restrictive conditions (1), the variations δnr themselves must satisfy the conditions ∑ r δnr = 0 ∑ r Erδnr = 0.    (7) The desired set {n∗ r } is then determined by the method of Lagrange multipliers, 2 by which the condition determining this set becomes ∑ r {−(ln n ∗ r + 1) − α − βEr}δnr = 0, (8) where α and β are the Lagrangian undetermined multipliers that take care of the restrictive conditions (7). In (8), the variations δnr become completely arbitrary; accordingly, the only way to satisfy this condition is that all its coefﬁcients must vanish identically, that is, for all r, ln n ∗ r = −(α + 1) − βEr, which gives n ∗ r = C exp(−βEr), (9) where C is again an undetermined parameter. To determine C and β, we subject (9) to conditions (1), with the result that n∗ r N = exp(−βEr) ∑ r exp(−βEr) , (10) the parameter β being a solution of the equation E N = U = ∑ r Er exp(−βEr) ∑ r exp(−βEr) . (11) 2For the method of Lagrange multipliers, see ter Haar and Wergeland (1966, Appendix C.1). 44 Chapter 3. The Canonical Ensemble Combining statistical considerations with thermodynamic ones, see Section 3.3, we can show that the parameter β here is exactly the same as the one appearing in Section 3.1, that is, β = 1/kT . The method of mean values Here we attempt to evaluate expression (3) for ⟨nr⟩, taking into account the weight factors (2) and the restrictive conditions (1). To do this, we replace (2) by ˜W {nr} = N ! ωn0 0 ωn1 1 ωn2 2 . . . n0! n1! n2! . . . , (12) with the understanding that in the end all ωr will be set equal to unity, and introduce a function 0(N , U) = ∑ {nr } ′ ˜W {nr}, (13) where the primed summation, as before, goes over all distribution sets that conform to conditions (1). Expression (3) can then be written as ⟨nr⟩ = ωr ∂ ∂ωr (ln 0) ∣ ∣ ∣ ∣ all ωr =1. (14) Thus, all we need to know here is the dependence of the quantity ln 0 on the parameters ωr. Now, 0(N , U) = N ! ∑ {nr } ′ ( ωn0 0 n0! · ωn1 1 n1! · ωn2 2 n2! · · · ) (15) but the summation appearing here cannot be evaluated explicitly because it is restricted to those sets only that conform to the pair of conditions (1). If our distribution sets were restricted by the condition ∑r nr = N alone, then the evaluation of (15) would have been trivial; by the multinomial theorem, 0(N ) would have been simply (ω0 + ω1 + · · · )N . The added restriction ∑r nrEr = N U, however, permits the inclusion of only a “limited” number of terms in the sum — and that constitutes the real difﬁculty of the problem. Nevertheless, we can still hope to make some progress because, from a physical point of view, we do not require anything more than an asymptotic result — one that holds in the limit N → ∞. The method commonly used for this purpose is the one developed by Darwin and Fowler (1922a,b, 1923), which itself makes use of the saddle-point method of integration or the so-called method of steepest descent. We construct a generating function G(N , z) for the quantity 0(N , U): G(N , z) = ∞∑ U=0 0(N , U)zN U (16) 3.2 A system in the canonical ensemble 45 which, in view of equation (15) and the second of the restrictive conditions (1), may be written as G(N , z) = ∞∑ U=0  ∑ {nr } ′ N ! n0! n1! . . . (ω0zE0 )n0 (ω1zE1 )n1 . . .   . (17) It is easy to see that the summation over doubly restricted sets {nr}, followed by a summa- tion over all possible values of U, is equivalent to a summation over singly restricted sets {nr}, namely the ones that satisfy only one condition: ∑r nr = N . Expression (17) can be evaluated with the help of the multinomial theorem, with the result G(N , z) = (ω0zE0 + ω1zE1 + · · · )N = [ f (z)]N , say. (18) Now, if we suppose that the Er (and hence the total energy value E = N U) are all integers, then, by (16), the quantity 0(N , U) is simply the coefﬁcient of zN U in the expansion of the function G(N , z) as a power series in z. It can, therefore, be evaluated by the method of residues in the complex z-plane. To make this plan work, we assume to have chosen, right at the outset, a unit of energy so small that, to any desired degree of accuracy, we can regard the energies Er (and the pre- scribed total energy N U) as integral multiples of this unit. In terms of this unit, any energy value we come across will be an integer. We further assume, without loss of generality, that the sequence E0, E1, . . . is a nondecreasing sequence, with no common divisor; 3 also, for the sake of simplicity, we assume that E0 = 0. 4 The solution now is 0(N , U) = 1 2πi ∮ [ f (z)]N zN U+1 dz, (19) where the integration is carried along any closed contour around the origin; of course, we must stay within the circle of convergence of the function f (z), so that a need for analytic continuation does not arise. First of all, we examine the behavior of the integrand as we proceed from the origin along the real positive axis, remembering that all our ωr are virtually equal to unity and that 0 = E0 ≤ E1 ≤ E2 · · · . We ﬁnd that the factor [ f (z)]N starts from the value 1 at z = 0, increases monotonically and tends to inﬁnity as z approaches the circle of convergence of f (z), wherever that may be. The factor z−(N U+1), on the other hand, starts from a positive, inﬁnite value at z = 0 and decreases monotonically as z increases. Moreover, the relative rate of increase of the factor [ f (z)]N itself increases monotonically while the relative rate 3Actually, this is not a serious restriction at all, for a common divisor, if any, can be removed by selecting the unit of energy correspondingly larger. 4This too is not serious, for by doing so we are merely shifting the zero of the energy scale; the mean energy U then becomes U − E0, but we can agree to call it U again. 46 Chapter 3. The Canonical Ensemble of decrease of the factor z−(N U+1) decreases monotonically. Under these circumstances, the integrand must exhibit a minimum (and no other extremum) at some value of z, say x0, within the circle of convergence. And, in view of the largeness of the numbers N and N U, this minimum may indeed be very steep! Thus, at z = x0 the ﬁrst derivative of the integrand must vanish, while the second derivative must be positive and, hopefully, very large. Accordingly, if we proceed through the point z = x0 in a direction orthogonal to the real axis, the integrand must exhibit an equally steep maximum.5 Thus, in the complex z-plane, as we move along the real axis our integrand shows a minimum at z = x0, whereas if we move along a path parallel to the imaginary axis but passing through the point z = x0, the integrand shows a maximum there. It is natural to call the point x0 a saddle point; see Figure 3.2. For the contour of integration we choose a circle, with center at z = 0 and radius equal to x0, hoping that on integration along this contour only the immediate neighborhood of the sharp maximum at the point x0 will make the most dominant contribution to the value of the integral.6 To carry out the integration we ﬁrst locate the point x0. For this we write our integrand as [ f (z)]N zN U+1 = exp[N g(z)], (20) where g(z) = ln f (z) − (U + 1 N ) ln z, (21) Saddle point Re z 0Im z Contour of integration x0 exp{ g(z)} FIGURE 3.2 The saddle point. 5This can be seen by noting that (i) an analytic function must possess a unique derivative everywhere (so, in our case, it must be zero, irrespective of the direction in which we pass through the point x0), and (ii) by the Cauchy–Riemann conditions of analyticity, the second derivative of the function with respect to y must be equal and opposite to the second derivative with respect to x. 6It is indeed true that, for large N , the contribution from the rest of the circle is negligible. The intuitive reason for this is that the terms (ωr zEr ), which constitute the function f (z), “reinforce” one another only at the point z = x0; elsewhere, there is bound to be disagreement among their phases, so that at all other points along the circle, |f (z)| < f (x0). Now, the factor that actually governs the relative contributions is [|f (z)|/f (x0)]N ; for N ≫ 1, this will clearly be negligible. For a rigorous demonstration of this point, see Schr¨odinger (1960, pp. 31–33). 3.2 A system in the canonical ensemble 47 while f (z) = ∑ r ωrzEr . (22) The number x0 is then determined by the equation g′(x0) = f ′(x0) f (x0) − N U + 1 N x0 = 0, (23) which, in view of the fact that N U ≫ 1, can be written as U ≈ x0 f ′(x0) f (x0) = ∑ r ωrErxEr 0 ∑ r ωrxEr 0 . (24) We further have g′′(x0) = ( f ′′(x0) f (x0) − [ f ′(x0)]2 [ f (x0)]2 ) + N U + 1 N x2 0 ≈ f ′′(x0) f (x0) − U 2 − U x2 0 . (25) It will be noted here that, in the limit N → ∞ and E (≡ N U) → ∞, with U staying constant, the number x0 and the quantity g′′(x0) become independent of N . Expanding g(z) about the point z = x0, along the direction of integration, that is, along the line z = x0 + iy, we have g(z) = g(x0) − 1 2 g′′(x0)y2 + · · · ; accordingly, the integrand (20) might be approximated as [ f (x0)]N xN U+1 0 exp [− N 2 g′′(x0)y2] . (26) Equation (19) then gives 0(N , U) ≃ 1 2πi [ f (x0)]N xN U+1 0 ∞∫ −∞ exp [− N 2 g′′(x0)y2] i dy = [ f (x0)]N xN U+1 0 · 1 {2πN g′′(x0)}1/2 , (27) which gives 1 N ln 0(N , U) = {ln f (x0) − U ln x0} − 1 N ln x0 − 1 2N ln{2πN g′′(x0)}. (28) 48 Chapter 3. The Canonical Ensemble In the limit N → ∞ (with U staying constant), the last two terms in this expression tend to zero, with the result 1 N ln 0(N , U) = ln f (x0) − U ln x0. (29) Substituting for f (x0) and introducing a new variable β, deﬁned by the relationship x0 ≡ exp(−β), (30) we get 1 N ln 0(N , U) = ln {∑ r ωr exp(−βEr) } + βU. (31) The expectation value of the number nr then follows from (14) and (31): ⟨nr⟩ N =   ωr exp(−βEr) ∑ r ωr exp(−βEr) +   − ∑ r ωrEr exp(−βEr) ∑ r ωr exp(−βEr) + U    ωr ∂β ∂ωr   all ωr =1 . (32) The term inside the curly brackets vanishes identically because of (24) and (30). It has been included here to emphasize the fact that, for a ﬁxed value of U, the number β(≡ − ln x0) in fact depends on the choice of the ωr; see (24). We will appreciate the importance of this fact when we evaluate the mean square ﬂuctuation in the number nr; in the calculation of the expectation value of nr, this does not really matter. We thus obtain ⟨nr⟩ N = exp(−βEr) ∑ r exp(−βEr) , (33) which is identical to expression (10) for n∗ r /N . The physical signiﬁcance of the parameter β is also the same as in that expression, for it is determined by equation (24), with all ωr = 1, that is, by equation (11) which ﬁts naturally with equation (33) because U is nothing but the ensemble average of the variable Er: U = ∑ r ErPr = 1 N ∑ r Er⟨nr⟩. (34) Finally, we compute ﬂuctuations in the values of the numbers nr. We have, ﬁrst of all, ⟨n2 r ⟩ ≡ ∑ {nr } ′n2 r W {nr} ∑ {nr } ′W {nr} = 1 0 ( ωr ∂ ∂ωr ) (ωr ∂ ∂ωr ) 0∣ ∣ ∣ ∣ all ωr =1 ; (35) see equations (12) to (14). It follows that ⟨(1nr)2⟩ ≡ ⟨{nr − ⟨nr⟩} 2⟩ = ⟨n 2 r ⟩ − ⟨nr⟩ 2 = ( ωr ∂ ∂ωr ) (ωr ∂ ∂ωr ) ln 0∣ ∣ ∣ ∣ all ωr =1 . (36) 3.2 A system in the canonical ensemble 49 Substituting from (31) and making use of (32), we get ⟨(1nr)2⟩ N = ωr ∂ ∂ωr   ωr exp(−βEr) ∑ r ωr exp(−βEr) +    − ∑ r ωrEr exp(−βEr) ∑ r ωr exp(−βEr) + U    ωr ∂β ∂ωr   all ωr =1 . (37) We note that the term in the curly brackets would not make any contribution because it is identically zero, whatever the choice of the ωr. However, in the differentiation of the ﬁrst term, we must not forget to take into account the implicit dependence of β on the ωr, which arises from the fact that unless the ωr are set equal to unity the relation determining β does contain ωr; see equations (24) and (30), whereby U = ∑ r ωrEr exp(−βEr) ∑ r ωr exp(−βEr) ∣ ∣ ∣ ∣ ∣ ∣ all ωr =1 . (38) A straightforward calculation gives ( ∂β ∂ωr ) U ∣ ∣ ∣ ∣ all ωr =1 = Er − U ⟨E2 r ⟩ − U 2 ⟨nr⟩ N . (39) We can now evaluate (37), with the result ⟨(1nr)2⟩ N = ⟨nr⟩ N − ( ⟨nr⟩ N )2 + ⟨nr⟩ N (U − Er) ( ∂β ∂ωr ) U ∣ ∣ ∣ ∣ all ωr =1 = ⟨nr⟩ N [ 1 − ⟨nr⟩ N − ⟨nr⟩ N (Er − U)2 ⟨(Er − U)2⟩ ] . (40) For the relative ﬂuctuation in nr, we get 〈( 1nr ⟨nr⟩ )2〉 = 1 ⟨nr⟩ − 1 N { 1 + (Er − U)2 ⟨(Er − U)2⟩ } . (41) As N → ∞, ⟨nr⟩ also → ∞, with the result that the relative ﬂuctuations in nr tend to zero; accordingly, the canonical distribution becomes inﬁnitely sharp and with it the mean value, the most probable value — in fact, any values of nr that appear with nonvanish- ing probability — become essentially the same. And that is the reason why two wildly different methods of obtaining the canonical distribution followed in this section have led to identical results. 50 Chapter 3. The Canonical Ensemble 3.3 Physical signiﬁcance of the various statistical quantities in the canonical ensemble We start with the canonical distribution Pr ≡ ⟨nr⟩ N = exp(−βEr) ∑ r exp(−βEr) , (1) where β is determined by the equation U = ∑ r Er exp(−βEr) ∑ r exp(−βEr) = − ∂ ∂β ln {∑ r exp(−βEr) } . (2) We now look for a general recipe to extract information about the various macroscopic properties of the given system on the basis of the foregoing statistical results. For this, we recall certain thermodynamic relationships involving the Helmholtz free energy A(= U − TS), namely dA = dU − TdS − SdT = −SdT − PdV + µ dN, (3) S = − ( ∂A ∂T ) N,V , P = − ( ∂A ∂V ) N,T , µ = ( ∂A ∂N ) V ,T , (4) and U = A + TS = A − T ( ∂A ∂T ) N,V = −T 2 [ ∂ ∂T ( A T )] N,V = [ ∂(A/T ) ∂(1/T ) ] N,V , (5) where the various symbols have their usual meanings. Comparing (5) with (2), we infer that there exists a close correspondence between the quantities entering through the statistical treatment and the ones coming from thermodynamics, namely β = 1 kT , ln {∑ r exp(−βEr) } = − A kT , (6) where k is a universal constant yet to be determined; soon we shall see that k is indeed the Boltzmann constant. The equations in (6) constitute the most fundamental result of the canonical ensemble theory. Customarily, we write it in the form A(N, V , T ) = −kT ln QN (V , T ), (7) where QN (V , T ) = ∑ r exp(−Er/kT ). (8) 3.3 Physical signiﬁcance of the various statistical quantities 51 The quantity QN (V , T ) is referred to as the partition function of the system; sometimes it is also called the “sum-over-states” (German: Zustandssumme). The dependence of Q on T is quite obvious. The dependence on N and V comes through the energy eigenvalues Er; in fact, any other parameters that might govern the values Er should also appear in the argument of Q. Moreover, for the quantity A(N, V , T ) to be an extensive property of the system, ln Q must also be an extensive quantity. Once the Helmholtz free energy is known, the rest of the thermodynamic quantities follow straightforwardly. While the entropy, the pressure and the chemical potential are obtained from formulae (4), the speciﬁc heat at constant volume follows from CV = ( ∂U ∂T ) N,V = −T ( ∂ 2A ∂T 2 ) N,V (9) and the Gibbs free energy from G = A + PV = A − V ( ∂A ∂V ) N,T = N ( ∂A ∂N ) V ,T = Nµ; (10) see Problem 3.5. At this stage it appears worthwhile to make a few remarks on the foregoing results. First of all, we note from equations (4) and (6) that the pressure P is given by P = − ∑ r ∂Er ∂V exp(−βEr) ∑ r exp(−βEr) , (11) so that PdV = − ∑ r PrdEr = −dU. (12) The quantity on the right side of this equation is clearly the change in the average energy of a system (in the ensemble) during a process that alters the energy levels Er, leaving the probabilities Pr unchanged. The left side then tells us that the volume change dV provides an example of such a process, and the pressure P is the “force” accompanying that process. The quantity P, which was introduced here through the thermodynamic relationship (3), thus acquires a mechanical meaning as well. The entropy of the system is determined as follows. Since Pr = Q−1 exp(−βEr), ⟨ln Pr⟩ = − ln Q − β⟨Er⟩ = β(A − U) = −S/k, with the result that S = −k⟨ln Pr⟩ = −k ∑ r Pr ln Pr. (13) 52 Chapter 3. The Canonical Ensemble This is an extremely interesting relationship, for it shows that the entropy of a physical sys- tem is solely and completely determined by the probability values Pr (of the system being in different dynamical states accessible to it)! From the very look of it, equation (13) appears to be of fundamental importance; indeed, it reveals a number of interesting conclusions. One of these relates to a system in its ground state (T = 0 K). If the ground state is unique, then the system is sure to be found in this particular state and in no other; consequently, Pr is equal to 1 for this state and 0 for all others. Equation (13) then tells us that the entropy of the system is precisely zero, which is essentially the content of the Nernst heat theorem or the third law of ther- modynamics. 7 We also infer that vanishing entropy and perfect statistical order (which implies complete predictability about the system) go together. As the number of acces- sible states increases, more and more of the Pr become nonzero; the entropy of the system thereby increases. As the number of states becomes exceedingly large, most of the P- values become exceedingly small (and their logarithms assume large, negative values); the net result is that the entropy becomes exceedingly large. Thus, the largeness of entropy and the high degree of statistical disorder (or unpredictability) in the system also go hand in hand. It is because of this fundamental connection between entropy on one hand and lack of information on the other that equation (13) became the starting point of the pioneering work of Shannon (1948, 1949) in the development of the theory of communication. It may be pointed out that formula (13) applies in the microcanonical ensemble as well. There, for each member system of the ensemble, we have a group of \u0000 states, all equally likely to occur. The value of Pr is, then, 1/\u0000 for each of these states and 0 for all others. Consequently, S = −k \u0000∑ r=1 { 1 \u0000 ln ( 1 \u0000 )} = k ln \u0000, (14) which is precisely the central result in the microcanonical ensemble theory; see equa- tion (1.2.6) or (2.3.6). 3.4 Alternative expressions for the partition function In most physical cases the energy levels accessible to a system are degenerate, that is, one has a group of states, gi in number, all belonging to the same energy value Ei. In such cases it is more useful to write the partition function (3.3.8) as QN (V , T ) = ∑ i gi exp(−βEi); (1) 7Of course, if the ground state of the system is degenerate (with a multiplicity \u00000), then the ground-state entropy is nonzero and is given by the expression k ln \u00000; see equation (14). 3.4 Alternative expressions for the partition function 53 the corresponding expression for Pi, the probability that the system be in a state with energy Ei, would be Pi = gi exp(−βEi) ∑ i gi exp(−βEi) . (2) Clearly, the gi states with a common energy Ei are all equally likely to occur. As a result, the probability of a system having energy Ei becomes proportional to the multiplicity gi of this level; gi thus plays the role of a “weight factor” for the level Ei. The actual probability is then determined by the weight factor gi as well as by the Boltzmann factor exp(−βEi) of the level, as we have in (2). The basic relations established in the preceding section, however, remain unaffected. Now, in view of the largeness of the number of particles constituting a given system and the largeness of the volume to which these particles are conﬁned, the consecutive energy values Ei of the system are, in general, very close to one another. Accordingly, there lie, within any reasonable interval of energy (E, E + dE), a very large number of energy levels. One may then regard E as a continuous variable and write P(E)dE for the probability that the given system, as a member of the canonical ensemble, may have its energy in the range (E, E + dE). Clearly, this probability will be given by the product of the relevant single-state probability and the number of energy states lying in the speciﬁed range. Denoting the latter by g(E)dE, where g(E) denotes the density of states around the energy value E, we have P(E)dE ∝ exp(−βE)g(E)dE (3) which, on normalization, becomes P(E)dE = exp(−βE)g(E)dE ∞∫ 0 exp(−βE)g(E)dE . (4) The denominator here is yet another expression for the partition function of the system: QN (V , T ) = ∞∫ 0 e−βE g(E)dE. (5) The expression for ⟨ f ⟩, the expectation value of a physical quantity f , may now be written as ⟨ f ⟩ ≡ ∑ i fiPi = ∑ i f (Ei)gie−βEi ∑ i gie−βEi → ∞∫ 0 f (E)e−βE g(E)dE ∞∫ 0 e−βE g(E)dE . (6) 54 Chapter 3. The Canonical Ensemble Before proceeding further, we take a closer look at equation (5) and note that, with β > 0, the partition function Q(β) is just the Laplace transform of the density of states g(E). We may, therefore, write g(E) as the inverse Laplace transform of Q(β): g(E) = 1 2πi β′+i∞∫ β′−i∞ eβE Q(β)dβ (β′ > 0) (7) = 1 2π ∞∫ −∞ e(β′+iβ′′)E Q(β′ + iβ′′)dβ′′, (8) where β is now treated as a complex variable, β′ + iβ′′, while the path of integration runs parallel to, and to the right of, the imaginary axis, that is, along the straight line Re β = β′ > 0. Of course, the path may be continuously deformed so long as the integral converges. 3.5 The classical systems The theory developed in the preceding sections is of very general applicability. It applies to systems in which quantum-mechanical effects are important as well as to those that can be treated classically. In the latter case, our formalism may be written in the language of the phase space; as a result, the summations over quantum states get replaced by integrations over phase space. We recall the concepts developed in Sections 2.1 and 2.2, especially formula (2.1.3) for the ensemble average ⟨ f ⟩ of a physical quantity f (q, p), namely ⟨ f ⟩ = ∫ f (q, p)ρ(q, p)d3N q d3N p ∫ ρ(q, p)d3N q d3N p , (1) where ρ(q, p) denotes the density of the representative points (of the systems) in the phase space; we have omitted here the explicit dependence of the function ρ on time t because we are interested in the study of equilibrium situations only. Evidently, the function ρ(q, p) is a measure of the probability of ﬁnding a representative point in the vicinity of the phase point (q, p), which in turn depends on the corresponding value H(q, p) of the Hamiltonian of the system. In the canonical ensemble, ρ(q, p) ∝ exp{−βH(q, p)}; (2) compare to equation (3.1.6). The expression for ⟨ f ⟩ then takes the form ⟨ f ⟩ = ∫ f (q, p) exp(−βH)dω ∫ exp(−βH)dω , (3) 3.5 The classical systems 55 where dω(≡ d3N q d3N p) denotes a volume element of the phase space. The denomina- tor of this expression is directly related to the partition function of the system. However, to write the precise expression for the latter, we must take into account the relationship between a volume element in the phase space and the corresponding number of distinct quantum states of the system. This relationship was established in Sections 2.4 and 2.5, whereby an element of volume dω in the phase space corresponds to dω N! h3N (4) distinct quantum states of the system.8 The appropriate expression for the partition function would, therefore, be QN (V , T ) = 1 N! h3N ∫ e−βH(q,p)dω; (5) it is understood that the integration in (5) goes over the whole of the phase space. As our ﬁrst application of this formulation, we consider the example of an ideal gas. Here, we have a system of N identical molecules, assumed to be monatomic (so there are no internal degrees of motion to be considered), conﬁned to a space of volume V and in equilibrium at temperature T . Since there are no intermolecular interactions to be taken into account, the energy of the system is wholly kinetic: H(q, p) = N∑ i=1(p2 i /2m). (6) The partition function of the system would then be QN (V , T ) = 1 N! h3N ∫ e−(β/2m)6ip2 i N∏ i=1 (d3qid3pi). (7) Integrations over the space coordinates are rather trivial; they yield a factor of V N . Integra- tions over the momentum coordinates are also quite easy, once we note that integral (7) is simply a product of N identical integrals. Thus, we get QN (V , T ) = V N N! h3N   ∞∫ 0 e−p2/2mkT ( 4π p 2dp)   N (8) = 1 N! [ V h3 (2π mkT ) 3/2]N ; (9) 8Ample justiﬁcation has already been given for the factor h3N . The factor N! comes from the considerations of Sections 1.5 and 1.6; it arises essentially from the fact that the particles constituting the given system are not only identical but, in fact, indistinguishable. For a complete proof of this result, see Section 5.5. 56 Chapter 3. The Canonical Ensemble here, use has been made of equation (B.13a). The Helmholtz free energy is then given by, using Stirling’s formula (B.29), A(N, V , T ) ≡ −kT ln QN (V , T ) = NkT  ln    N V ( h2 2π mkT )3/2   − 1  . (10) The foregoing result is identical to equation (1.5.8), which was obtained by following a very different procedure. The simplicity of the present approach is, however, striking. Needless to say, the complete thermodynamics of the ideal gas can be derived from equation (10) in a straightforward manner. For instance, µ ≡ ( ∂A ∂N ) V ,T = kT ln    N V ( h2 2π mkT )3/2   , (11) P ≡ −( ∂A ∂V ) N,T = NkT V (12) and S ≡ −( ∂A ∂T ) N,V = Nk [ ln { V N ( 2π mkT h2 )3/2} + 5 2 ] . (13) These results are identical to the ones derived previously, namely (1.5.7), (1.4.2), and (1.5.1a), respectively. In fact, the identiﬁcation of formula (12) with the ideal-gas law, PV = nRT , establishes the identity of the (hitherto undetermined) constant k as the Boltzmann constant; see equation (3.3.6). We further obtain U ≡ −[ ∂ ∂β (ln Q) ] Er ≡ −T 2 [ ∂ ∂T ( A T )] N,V ≡ A + TS = 3 2 NkT , (14) and so on. At this stage we have an important remark to make. Looking at the form of equation (8) and the manner in which it came about, we may write QN (V , T ) = 1 N! [Q1(V , T )]N , (15) where Q1(V , T ) may be regarded as the partition function of a single molecule in the sys- tem. A little reﬂection will show that this result obtains essentially from the fact that the basic constituents of our system are noninteracting (and hence the total energy of the system is simply the sum of their individual energies). Clearly, the situation will not be altered even if the molecules in the system had internal degrees of motion as well. What is essentially required for equation (15) to be valid is the absence of interactions among the basic constituents of the system (and, of course, the absence of quantum-mechanical correlations). 3.5 The classical systems 57 Going back to the ideal gas, we could as well have started with the density of states g(E). From equation (1.4.17), and in view of the Gibbs correction factor, we have g(E) = ∂6 ∂E ≈ 1 N! ( V h3 )N (2π m)3N/2 {(3N/2) − 1}! E(3N/2)−1. (16) Substituting this into equation (3.4.5), and noting that the integral involved is equal to {(3N/2) − 1}! /β3N/2, we obtain QN (β) = 1 N! ( V h3 )N ( 2π m β )3N/2, (17) which is identical to (9). It may also be noted that if one starts with the single-particle density of states (2.4.7), namely a(ε) ≈ 2π V h3 (2m) 3/2ε1/2, (18) computes the single-particle partition function, Q1(β) = ∞∫ 0 e−βεa(ε)dε = V h3 ( 2πm β )3/2 , (19) and then makes use of formula (15), one would arrive at the same result for QN (V , T ). Lastly, we consider the question of determining the density of states, g(E), from the expression for the partition function, Q(β) — assuming that the latter is already known; indeed, expression (9) for Q(β) was derived without making use of any knowledge regarding the function g(E). According to equation (3.4.7) and (9), we have g(E) = V N N! ( 2πm h2 )3N/2 1 2π i β′+i∞∫ β′−i∞ eβE β3N/2 dβ (β′ > 0). (20) Noting that, for all positive n, 1 2π i s′+i∞∫ s′−i∞ esx sn+1 ds =    xn n! for x ≥ 0 0 for x ≤ 0, (21)9 equation (20) becomes g(E) =    V N N! ( 2π m h2 )3N/2 E(3N/2)−1 {(3N/2) − 1}! for E ≥ 0 0 for E ≤ 0, (22) 9For the details of this evaluation, see Kubo (1965, pp. 165–168). 58 Chapter 3. The Canonical Ensemble which is indeed the correct result for the density of states of an ideal gas; compare to equation (16). The foregoing derivation may not appear particularly valuable because in the present case we already knew the expression for g(E). However, cases do arise where the evaluation of the partition function of a given system and the consequent evaluation of its density of states turn out to be quite simple, whereas a direct evaluation of the density of states from ﬁrst principles is rather involved. In such cases, the method given here can indeed be useful; see, for example, Problem 3.15 in comparison with Problems 1.7 and 2.8. 3.6 Energy ﬂuctuations in the canonical ensemble: correspondence with the microcanonical ensemble In the canonical ensemble, a system can have energy anywhere between zero and inﬁnity. On the other hand, the energy of a system in the microcanonical ensemble is restricted to a very narrow range. How, then, can we assert that the thermodynamic properties of a system derived through the formalism of the canonical ensemble would be the same as the ones derived through the formalism of the microcanonical ensemble? Of course, we do expect that the two formalisms yield identical results, for otherwise our whole scheme would be marred by internal inconsistency. And, indeed, in the case of an ideal classical gas the results obtained by following one approach were precisely the same as the ones obtained by following the other approach. What, then, is the underlying reason for this equivalence? The answer to this question is obtained by examining the extent of the range over which the energies of the systems in the canonical ensemble have a signiﬁcant probability to spread; that will tell us the extent to which the canonical ensemble really differs from the microcanonical one. To explore this point, we write down the expression for the mean energy U ≡ ⟨E⟩ = ∑ r Er exp(−βEr) ∑ r exp(−βEr) (1) and differentiate it with respect to the parameter β, holding the energy values Er constant. We obtain ∂U ∂β = − ∑ r E2 r exp(−βEr) ∑ r exp(−βEr) + [∑ r Er exp(−βEr) ]2 [∑ r exp(−βEr) ]2 = −⟨E2⟩ + ⟨E⟩ 2, (2) from which it follows that ⟨(1E) 2⟩ ≡ ⟨E2⟩ − ⟨E⟩2 = −( ∂U ∂β ) = kT 2 ( ∂U ∂T ) = kT 2CV . (3) 3.6 Energy ﬂuctuations in the canonical ensemble 59 Note that we have here the speciﬁc heat at constant volume, because the partial differen- tiation in (2) was carried out with the Er kept constant! For the relative root-mean-square ﬂuctuation in E, equation (3) gives √ [⟨(1E)2⟩] ⟨E⟩ = √(kT 2CV ) U , (4) which is O(N −1/2), N being the number of particles in the system. Consequently, for large N (which is true for every statistical system) the relative r.m.s. ﬂuctuation in the values of E is quite negligible! Thus, for all practical purposes, a system in the canonical ensemble has an energy equal to, or almost equal to, the mean energy U; the situation in this ensemble is, therefore, practically the same as in the microcanonical ensemble. That explains why the two ensembles lead to practically identical results. For further understanding of the situation, we consider the manner in which energy is distributed among the various members of the (canonical) ensemble. To do this, we treat E as a continuous variable and start with expression (3.4.3), namely P(E)dE ∝ exp(−βE)g(E)dE. (3.4.3) The probability density P(E) is given by the product of two factors: (i) the Boltzmann factor, which monotonically decreases with E, and (ii) the density of states, which monotonically increases with E. The product, therefore, has an extremum at some value of E, say E∗. 10 The value E∗ is determined by the condition ∂ ∂E {e−βE g(E)} ∣ ∣ ∣ ∣ E=E∗ = 0, that is, by ∂ ln g(E) ∂E ∣ ∣ ∣ ∣ E=E∗ = β. (5) Recalling that S = k ln g and ( ∂S(E) ∂E ) E=U = 1 T = kβ, the foregoing condition implies that E∗ = U. (6) This is a very interesting result, for it shows that, irrespective of the physical nature of the given system, the most probable value of its energy is identical to its mean value. Accordingly, if it is advantageous, we may use one instead of the other. 10Subsequently we shall see that this extremum is actually a maximum — and an extremely sharp one at that. 60 Chapter 3. The Canonical Ensemble We now expand the logarithm of the probability density P(E) around the value E∗ ≈ U; we get ln [ e−βE g(E)] = ( −βU + S k ) + 1 2 ∂ 2 ∂E2 ln {e−βE g(E) }∣ ∣ ∣ ∣ ∣ E=U (E − U)2 + · · · = −β(U − TS) − 1 2kT 2CV (E − U) 2 + · · · , (7) from which we obtain P(E) ∝ e−βE g(E) ≃ e−β(U−TS) exp { − (E − U)2 2kT 2CV } . (8) This is a Gaussian distribution in E, with mean value U and dispersion √ (kT 2CV ); compare with equation (3). In terms of the reduced variable E/U, the distribution is again Gaussian, with mean value unity and dispersion √ (kT 2CV )/U {which is O(N −1/2)}; thus, for N ≫ 1, we have an extremely sharp distribution which, as N → ∞, approaches a delta-function! It would be instructive here to consider once again the case of a classical ideal gas. Here, g(E) is proportional to E(3N/2−1) and hence increases very fast with E; the factor e−βE, of course, decreases with E. The product g(E) exp(−βE) exhibits a maximum at E∗ = (3N/2 − 1)β−1, which is practically the same as the mean value U = (3N/2)β−1. For values of E signiﬁcantly different from E∗, the product essentially vanishes (for smaller val- ues of E, due to the relative paucity of the available energy states; for larger values of E, due to the relative depletion caused by the Boltzmann factor). The overall picture is shown in Figure 3.3 where we have displayed the actual behavior of these functions in the special case N = 10. The most probable value of E is now 14 15 of the mean value; so, the distribution is somewhat asymmetrical. The effective width 1 can be readily calculated from (3) and turns out to be (2/3N)1/2U, which, for N = 10, is about a quarter of U. We can see that, as N becomes large, both E∗ and U increase (essentially linearly with N), the ratio E∗/U approaches unity and the distribution tends to become symmetrical about E∗. At the same time, the width 1 increases (but only as N 1/2); considered in the relative sense, it tends to vanish (as N −1/2). We ﬁnally look at the partition function QN (V , T ), as given by equation (3.4.5), with its integrand replaced by (8). We have QN (V , T ) ≃ e−β(U−TS) ∞∫ 0 e−(E−U)2/2kT 2CV dE ≃ e−β(U−TS)√ (2kT 2CV ) ∞∫ −∞ e−x2 dx = e−β(U−TS)√ (2πkT 2CV ), 3.7 Two theorems — the “equipartition” and the “virial” 61 g (E ) 0.5 0 E *U E 1.0g(E)e–\u0002E \u0002 \u0002 e–\u0002E FIGURE 3.3 The actual behavior of the functions g(E), e−βE , and g(E)e−βE for an ideal gas, with N = 10. The numerical values of the functions have been expressed as fractions of their respective values at E = U. so that −kT ln QN (V , T ) ≡ A ≃ (U − TS) − 1 2 kT ln(2π kT 2CV ). (9) The last term, being O(ln N), is negligible in comparison with the other terms, which are all O(N). Hence, A ≈ U − TS. (10) Note that the quantity A in this formula has come through the formalism of the canonical ensemble, while the quantity S has come through a deﬁnition belonging to the microcanonical ensemble. The fact that we ﬁnally end up with a consistent thermo- dynamic relationship establishes beyond doubt that these two approaches are, for all practical purposes, identical. 3.7 Two theorems — the “equipartition” and the “virial” To derive these theorems, we determine the expectation value of the quantity xi(∂H/∂xj), where H(q, p) is the Hamiltonian of the system (assumed classical) while xi 62 Chapter 3. The Canonical Ensemble and xj are any two of the 6N generalized coordinates (q, p). In the canonical ensemble, 〈 xi ∂H ∂xj 〉 = ∫ (xi ∂H ∂xj ) e−βH dω ∫ e−βH dω ( dω = d3N q d3N p) . (1) Let us consider the integral in the numerator. Integrating over xj by parts, it becomes ∫ [− 1 β xie−βH ∣ ∣ ∣ ∣ (xj)2 (xj)1 + 1 β ∫ ( ∂xi ∂xj ) e−βH dxj ] dω( j); here, (xj)1 and (xj)2 are the “extreme” values of the coordinate xj, while dω( j) denotes “dω devoid of dxj.” The integrated part here vanishes because whenever any of the coordinates takes an “extreme” value the Hamiltonian of the system becomes inﬁnite. 11 In the integral that remains, the factor ∂xi/∂xj, being equal to δij, comes out of the integral sign and we are left with 1 β δij ∫ e−βH dω. Substituting this into (1), we arrive at the remarkable result: 〈 xi ∂H ∂xj 〉 = δijkT , (2) which is independent of the precise form of the function H. In the special case xi = xj = pi, equation (2) takes the form 〈 pi ∂H ∂pi 〉 ≡ ⟨pi ˙qi⟩ = kT , (3) while for xi = xj = qi, it becomes 〈qi ∂H ∂qi 〉 ≡ −⟨qi ˙pi⟩ = kT . (4) Adding over all i, from i = 1 to 3N, we obtain 〈 ∑ i pi ∂H ∂pi 〉 ≡ 〈 ∑ i pi ˙qi 〉 = 3NkT (5) 11For instance, if xj is a space coordinate, then its extreme values will correspond to “locations at the walls of the con- tainer”; accordingly, the potential energy of the system would become inﬁnite. If, on the other hand, xj is a momentum coordinate, then its extreme values will themselves be ±∞, in which case the kinetic energy of the system would become inﬁnite. 3.7 Two theorems — the “equipartition” and the “virial” 63 and 〈∑ i qi ∂H ∂qi 〉 ≡ − 〈 ∑ i qi ˙pi 〉 = 3NkT . (6) Now, in many physical situations the Hamiltonian of the system happens to be a quadratic function of its coordinates; so, through a canonical transformation, it can be brought into the form H = ∑ j AjP2 j + ∑ j BjQ2 j , (7) where Pj and Qj are the transformed, canonically conjugate, coordinates while Aj and Bj are certain constants of the problem. For such a system, we clearly have ∑ j ( Pj ∂H ∂Pj + Qj ∂H ∂Qj ) = 2H; (8) accordingly, by equations (3) and (4), ⟨H⟩ = 1 2 fkT , (9) where f is the number of nonvanishing coefﬁcients in expression (7). We, therefore, con- clude that each harmonic term in the (transformed) Hamiltonian makes a contribution of 1 2 kT toward the internal energy of the system and, hence, a contribution of 1 2 k toward the speciﬁc heat CV . This result embodies the classical theorem of equipartition of energy (among the various degrees of freedom of the system). It may be mentioned here that, for the distribution of kinetic energy alone, the equipartition theorem was ﬁrst stated by Boltzmann (1871). In our subsequent study we shall ﬁnd that the equipartition theorem as stated here is not always valid; it applies only when the relevant degrees of freedom can be freely excited. At a given temperature T , there may be certain degrees of freedom which, due to the insuf- ﬁciency of the energy available, are more or less “frozen” due to quantum mechanical effects. Such degrees of freedom do not make a signiﬁcant contribution toward the inter- nal energy of the system or toward its speciﬁc heat; see, for example, Sections 6.5, 7.4, and 8.3. Of course, the higher the temperature of the system the better the validity of this theorem. We now consider the implications of formula (6). First of all, we note that this formula embodies the so-called virial theorem of Clausius (1870) for the quantity ⟨ ∑i qi ˙pi⟩, which is the expectation value of the sum of the products of the coordinates of the various particles in the system and the respective forces acting on them; this quantity is generally referred to as the virial of the system and is denoted by the symbol V. The virial theorem then states 64 Chapter 3. The Canonical Ensemble that V = −3NkT . (10) The relationship between the virial and other physical quantities of the system is best understood by ﬁrst looking at a classical gas of noninteracting particles. In this case, the only forces that come into play are the ones arising from the walls of the container; these forces can be designated by an external pressure P that acts on the system by virtue of the fact that it is bounded by the walls of the container. Consequently, we have here a force −P dS associated with an element of area dS of the walls; the negative sign appears because the force is directed inward while the vector dS is directed outward. The virial of the gas is then given by V 0 = (∑ i qiFi ) 0 = −P ∮ S r · dS, (11)12 where r is the position vector of a particle that happens to be in the (close) vicinity of the surface element dS; accordingly, r may be considered to be the position vector of the surface element itself. By the divergence theorem, equation (11) becomes V 0 = −P ∫ V (div r)dV = −3PV . (12) Comparing (12) with (10), we obtain the well-known result: PV = NkT . (13) The internal energy of the gas, which in this case is wholly kinetic, follows from the equipartition theorem (9) and is equal to 3 2 NkT , 3N being the number of degrees of freedom. Comparing this result with (10), we obtain the classical relationship V = −2K , (14) where K denotes the average kinetic energy of the system. It is straightforward to apply this theorem to a system of particles interacting through a two-body potential u(r). In the thermodynamic limit, the pressure of a d-dimensional system depends only on the virial terms arising from the forces between pairs of particles: P nkT = 1 + 1 NdkT 〈 ∑ i<j F(rij) · rij 〉 = 1 − 1 NdkT 〈 ∑ i<j ∂u(rij) ∂rij rij 〉 . (15) 12It will be noted that the summation over the various particles of the system, which appears in the deﬁnition of the virial, has been replaced by an integration over the surface of the container, for the simple reason that no contribution to the virial arises from the interior of the container. 3.8 A system of harmonic oscillators 65 Equation (15) is called the virial equation of state. This equation can also be written in terms of the pair correlation function, equation (10.7.11), and is also used in computer simulations to determine the pressure of the system; see Problem 3.14, Section 10.7, and Section 16.4. 3.8 A system of harmonic oscillators We shall now examine a system of N, practically independent, harmonic oscillators. This study will not only provide an interesting illustration of the canonical ensemble formu- lation but will also serve as a basis for some of our subsequent studies in this text. Two important problems in this line are (i) the theory of the black-body radiation (or the “sta- tistical mechanics of photons”) and (ii) the theory of lattice vibrations (or the “statistical mechanics of phonons”); see Sections 7.3 and 7.4 for details. We start with the specialized situation when the oscillators can be treated classically. The Hamiltonian of any one of them (assumed to be one-dimensional) is then given by H(qi, pi) = 1 2 mω2q2 i + 1 2m p 2 i (i = 1, . . . , N). (1) For the single-oscillator partition function, we readily obtain Q1(β) = ∞∫ −∞ ∞∫ −∞ exp { −β ( 1 2 mω2q2 + 1 2m p 2)} dqdp h = 1 h ( 2π βmω2 )1/2 ( 2πm β )1/2 = 1 βℏω = kT ℏω , (2) where ℏ = h/2π . This represents a classical counting of the average number of accessible microstates — that is, kT divided by the quantum harmonic oscillator energy spacing. The partition function of the N-oscillator system would then be QN (β) = [Q1(β)]N = (βℏω) −N = ( kT ℏω )N ; (3) note that in writing (3) we have assumed the oscillators to be distinguishable. This is so because, as we shall see later, these oscillators are merely a representation of the energy levels available in the system; they are not particles (or even “quasiparticles”). It is actu- ally photons in one case and phonons in the other, which distribute themselves over the various oscillator levels, that are indistinguishable! The Helmholtz free energy of the system is now given by A ≡ −kT ln QN = NkT ln ( ℏω kT ) , (4) 66 Chapter 3. The Canonical Ensemble whereby µ = kT ln ( ℏω kT ) , (5) P = 0, (6) S = Nk [ln ( kT ℏω ) + 1] , (7) U = NkT , (8) and CP = CV = Nk. (9) We note that the mean energy per oscillator is in complete agreement with the equiparti- tion theorem, namely 2 × 1 2 kT , for we have here two independent quadratic terms in the single-oscillator Hamiltonian. We may determine the density of states, g(E), of this system from expression (3) for its partition function. We have, in view of (3.4.7), g(E) = 1 (ℏω)N 1 2πi β′+i∞∫ β′−i∞ eβE βN dβ (β′ > 0), that is, g(E) =    1 (ℏω)N EN−1 (N − 1)! for E ≥ 0 0 for E ≤ 0. (10) To test the correctness of (10), we may calculate the entropy of the system with the help of this formula. Taking N ≫ 1 and making use of the Stirling approximation, we get S(N, E) = k ln g(E) ≈ Nk [ln ( E Nℏω ) + 1 ] , (11) which gives for the temperature of the system T = ( ∂S ∂E )−1 N = E Nk . (12) Eliminating E between these two relations, we obtain precisely our earlier result (7) for the function S(N, T ). 3.8 A system of harmonic oscillators 67 We now take up the quantum-mechanical situation, according to which the energy eigenvalues of a one-dimensional harmonic oscillator are given by εn = ( n + 1 2 ) ℏω; n = 0, 1, 2, . . . (13) Accordingly, we have for the single-oscillator partition function Q1(β) = ∞∑ n=0 e−β(n+1/2)ℏω = exp ( − 1 2 βℏω) 1 − exp(−βℏω) = {2 sinh ( 1 2 βℏω)}−1 . (14) The N-oscillator partition function is then given by QN (β) = [Q1(β)]N = [ 2 sinh ( 1 2 βℏω)]−N = e−(N/2)βℏω{1 − e−βℏω}−N . (15) For the Helmholtz free energy of the system, we get A = NkT ln [2 sinh ( 1 2 βℏω)] = N [ 1 2 ℏω + kT ln{1 − e−βℏω}] , (16) whereby µ = A/N, (17) P = 0, (18) S = Nk [ 1 2 βℏ ω coth ( 1 2 βℏ ω) − ln { 2 sinh ( 1 2 βℏ ω)}] = Nk [ βℏ ω eβℏ ω − 1 − ln{1 − e−βℏ ω}] , (19) U = 1 2 Nℏ ω coth ( 1 2 βℏ ω) = N [ 1 2 ℏ ω + ℏ ω eβℏ ω − 1 ] , (20) and CP = CV = Nk ( 1 2 βℏ ω)2 cosech2 ( 1 2 βℏ ω) = Nk(βℏ ω)2 eβℏ ω (eβℏ ω − 1)2 . (21) Formula (20) is especially signiﬁcant, for it shows that the quantum-mechanical oscil- lators do not obey the equipartition theorem. The mean energy per oscillator is different 68 Chapter 3. The Canonical Ensemble 2 1 0 0 3 1 2 12 \u0002 kT/ \u0002 ε FIGURE 3.4 The mean energy ⟨ε⟩ of a simple harmonic oscillator as a function of temperature. 1, the Planck oscillator; 2, the Schr ¨odinger oscillator; and 3, the classical oscillator. from the equipartition value kT ; actually, it is always greater than kT ; see curve 2 in Figure 3.4. Only in the limit of high temperatures, where the thermal energy kT is much larger than the energy quantum ℏ ω, does the mean energy per oscillator tend to the equipartition value. It should be noted here that if the zero-point energy 1 2 ℏ ω were not present, the limiting value of the mean energy would be (kT − 1 2 ℏ ω), and not kT — we may call such an oscillator the Planck oscillator; see curve 1 in Figure 3.4. In passing, we observe that the speciﬁc heat (21), which is the same for the Planck oscillator as for the Schr¨odinger oscillator, is temperature-dependent; moreover, it is always less than, and at high temperatures tends to, the classical value (9). Indeed, for kT ≫ ℏ ω, formulae (14) through (21) go over to their classical counterparts, namely (2) through (9), respectively. We shall now determine the density of states g(E) of the N-oscillator system from its partition function (15). Carrying out the binomial expansion of this expression, we have QN (β) = ∞∑ R=0 ( N + R − 1 R ) e−β( 1 2 Nℏ ω+Rℏ ω). (22) Comparing this with the formula QN (β) = ∞∫ 0 g(E)e−βE dE, we conclude that g(E) = ∞∑ R=0 ( N + R − 1 R ) δ ( E − { R + 1 2 N} ℏ ω) , (23) 3.8 A system of harmonic oscillators 69 where δ(x) denotes the Dirac delta function. Equation (23) implies that there are (N + R − 1)! /R! (N − 1)! microstates available to the system when its energy E has the dis- crete value (R + 1 2 N)ℏ ω, where R = 0, 1, 2, . . . , and that no microstate is available for other values of E. This is hardly surprising, but it is instructive to look at this result from a slightly different point of view. We consider the following problem that arises naturally in the microcanonical ensem- ble theory. Given an energy E for distribution among a set of N harmonic oscillators, each of which can be in any one of the eigenstates (13), what is the total number of distinct ways in which the process of distribution can be carried out? Now, in view of the form of the eigenvalues εn, it makes sense to give away, right in the beginning, the zero-point energy 1 2 ℏ ω to each of the N oscillators and convert the rest of it into quanta (of energy ℏ ω). Let R be the number of these quanta; then R = ( E − 1 2 Nℏ ω) ∕ℏ ω. (24) Clearly, R must be an integer; by implication, E must be of the form (R + 1 2 N)ℏ ω. The prob- lem then reduces to determining the number of distinct ways of allotting R quanta to N oscillators, such that an oscillator may have 0 or 1 or 2 . . . quanta; in other words, we have to determine the number of distinct ways of putting R indistinguishable balls into N dis- tinguishable boxes, such that a box may receive 0 or 1 or 2. . . balls. A little reﬂection will show that this is precisely the number of permutations that can be realized by shufﬂing R balls, placed along a row, with (N − 1) partitioning lines (that divide the given space into N boxes); see Figure 3.5. The answer clearly is (R + N − 1)! R! (N − 1)! , (25) which agrees with (23). We can now determine the entropy of the system from the number (25). Since N ≫ 1, we have S ≈ k{ln(R + N)! − ln R! − ln N! } ≈ k{(R + N) ln(R + N) − R ln R − N ln N}; (26) FIGURE 3.5 Distributing 17 indistinguishable balls among 7 distinguishable boxes. The arrangement shown here represents one of the 23! /17! 6! distinct ways of carrying out the distribution. 70 Chapter 3. The Canonical Ensemble the number R is, of course, a measure of the energy E of the system; see (24). For the temperature of the system, we obtain 1 T = ( ∂S ∂E ) N = ( ∂S ∂R ) N 1 ℏ ω = k ℏ ω ln ( R + N R ) = k ℏ ω ln ( E + 1 2 Nℏ ω E − 1 2 Nℏ ω ) , (27) so that E N = 1 2 ℏ ω exp(ℏ ω/kT ) + 1 exp(ℏ ω/kT ) − 1 , (28) which is identical to (20). It can be further checked that, by eliminating R between (26) and (27), we obtain precisely the formula (19) for S(N, T ). Thus, once again, we ﬁnd that the results obtained by following the microcanonical approach and the canonical approach are the same in the thermodynamic limit. Finally, we may consider the classical limit when E/N, the mean energy per oscillator, is much larger than the energy quantum ℏ ω, that is, when R ≫ N. The expression (25) may, in that case, be replaced by (R + N − 1)(R + N − 2) . . . (R + 1) (N − 1)! ≈ RN−1 (N − 1)! , (25a) with R ≈ E/ℏ ω. The corresponding expression for the entropy turns out to be S ≈ k{N ln(R/N) + N} ≈ Nk { ln ( E Nℏ ω ) + 1 } , (26a) which gives 1 T = ( ∂S ∂E ) N ≈ Nk E , (27a) so that E N ≈ kT . (28a) These results are identical to the ones derived in the classical limit earlier in this section. 3.9 The statistics of paramagnetism Next, we study a system of N magnetic dipoles, each having a magnetic moment µ. In the presence of an external magnetic ﬁeld H, the dipoles will experience a torque tending to 3.9 The statistics of paramagnetism 71 align them in the direction of the ﬁeld. If there were nothing else to check this tendency, the dipoles would align themselves precisely in this direction and we would achieve a complete magnetization of the system. In reality, however, thermal agitation in the system offers resistance to this tendency and, in equilibrium, we obtain only a partial magnetization. Clearly, as T → 0 K, the thermal agitation becomes ineffective and the system exhibits a complete orientation of the dipole moments, whatever the strength of the applied ﬁeld; at the other extreme, as T → ∞, we approach a state of complete randomization of the dipole moments, which implies a vanishing magnetization. At intermediate temperatures, the situation is governed by the parameter (µH/kT ). The model adopted for this study consists of N identical, localized (and, hence, dis- tinguishable), practically static, mutually noninteracting and freely orientable dipoles. We consider ﬁrst the case of classical dipoles that can be oriented in any direction relative to the applied magnetic ﬁeld. It is obvious that the only energy we need to consider here is the potential energy of the dipoles that arises from the presence of the external ﬁeld H and is determined by the orientations of the dipoles with respect to the direction of the ﬁeld: E = N∑ i=1 Ei = − N∑ i=1 µi · H = −µH N∑ i=1 cos θi. (1) The partition function of the system is then given by QN (β) = [Q1(β)] N , (2) where Q1(β) = ∑ θ exp(βµH cos θ). (3) The mean magnetic moment M of the system will obviously be in the direction of the ﬁeld H; for its magnitude we shall have Mz = N⟨µ cos θ ⟩ = N ∑ θ µ cos θ exp(βµH cos θ) ∑ θ exp(βµH cos θ) = N β ∂ ∂H ln Q1(β) = − ( ∂A ∂H ) T . (4) Thus, to determine the degree of magnetization in the system all we have to do is to evaluate the single-dipole partition function (3). First, we proceed classically (after Langevin, 1905a,b). Using (sin θ dθ dφ) as the elemen- tal solid angle representing a small range of orientations of the dipole, we get Q1(β) = 2π∫ 0 π∫ 0 eβµH cos θ sin θ dθ dφ = 4π sinh(βµH) βµH , (5) 72 Chapter 3. The Canonical Ensemble so that µz ≡ Mz N = µ { coth(βµH) − 1 βµH } = µL(βµH), (6) where L(x) is the so-called Langevin function L(x) = coth x − 1 x ; (7) a plot of the Langevin function is shown in Figure 3.6. We note that the parameter βµH denotes the strength of the (magnetic) potential energy µH compared to the (thermal) kinetic energy kT . If we have N0 dipoles per unit volume in the system, then the magnetization of the system, namely the mean magnetic moment per unit volume, is given by Mz0 = N0µz = N0µL(x) (x = βµH). (8) For magnetic ﬁelds so strong (or temperatures so low) that the parameter x ≫ 1, the function L(x) is almost equal to 1; the system then acquires a state of magnetic saturation: µz ≃ µ and Mz0 ≃ N0µ. (9) For temperatures so high (or magnetic ﬁelds so weak) that the parameter x ≪ 1, the function L(x) may be written as x 3 − x3 45 + · · · (10) which, in the lowest approximation, gives Mz0 ≃ N0µ2 3kT H. (11) 1.0 0.5 0048 12 xL(x)FIGURE 3.6 The Langevin function L(x). 3.9 The statistics of paramagnetism 73 The high-temperature isothermal susceptibility of the system is, therefore, given by χ T = Lim H→0 ( ∂Mz0 ∂H ) T ≃ N0µ2 3kT = C T , say. (12) Equation (12) is the Curie law of paramagnetism, the parameter C being the Curie constant of the system. Figure 3.7 shows a plot of the susceptibility of a powdered sample of copper– potassium sulphate hexahydrate as a function of T −1; the fact that the plot is linear and passes almost through the origin vindicates the Curie law for this particular salt. We shall now treat the problem of paramagnetism quantum-mechanically. The major modiﬁcation here arises from the fact that the magnetic dipole moment µ and its compo- nent µz in the direction of the applied ﬁeld cannot have arbitrary values. Quite generally, we have a direct relationship between the magnetic moment µ of a given dipole and its angular momentum l: µ = (g e 2mc ) l, (13) with l2 = J( J + 1)ℏ2; J = 1 2 , 3 2 , 5 2 , . . . or 0, 1, 2, . . . (14) The quantity g(e/2mc) is the gyromagnetic ratio of the dipole while the number g is Lande’s g-factor. If the net angular momentum of the dipole is due solely to electron spins, then 80 70 60 50 40 30 20 10 0 20406080(\u0002·106) (103/T in K 21) FIGURE 3.7 χ versus 1/T plot for a powdered sample of copper–potassium sulphate hexahydrate (after Hupse, 1942). 74 Chapter 3. The Canonical Ensemble g = 2; on the other hand, if it is due solely to orbital motions, then g = 1. In general, however, its origin is mixed; g is then given by the formula g = 3 2 + S(S + 1) − L(L + 1) 2J( J + 1) , (15) S and L being, respectively, the spin and the orbital quantum numbers of the dipole. Note that there is no upper or lower bound on the values that g can have! Combining (13) and (14), we can write µ2 = g2µ2 B J( J + 1), (16) where µB(= eℏ/2mc) is the Bohr magneton. The component µz of the magnetic moment in the direction of the applied ﬁeld is, on the other hand, given by µz = gµBm, m = −J, −J + 1, . . . , J − 1, J. (17) Thus, a dipole whose magnetic moment µ conforms to expression (16) can have no other orientations with respect to the applied ﬁeld except the ones conforming to the values (17) of the component µz; obviously, the number of allowed orientations, for a given value of J, is (2J + 1). In view of this, the single-dipole partition function Q1(β) is now given by, see (3), Q1(β) = J∑ m=−J exp(βgµBmH). (18) Introducing a parameter x, deﬁned by x = β(gµB J)H, (19) equation (18) becomes Q1(β) = J∑ m=−J emx/J = e−x{e(2J+1)x/J − 1} ex/J − 1 = e(2J+1)x/2J − e−(2J+1)x/2J ex/2J − e−x/2J = sinh {(1 + 1 2J ) x} ∕ sinh { 1 2J x} . (20) The mean magnetic moment of the system is then given by, see equation (4), Mz = Nµz = N β ∂ ∂H ln Q1(β) = N(gµB J) [( 1 + 1 2J ) coth {( 1 + 1 2J ) x} − 1 2J coth { 1 2J x}] . (21) 3.9 The statistics of paramagnetism 75 Thus µz = (gµBJ )BJ (x), (22) where BJ (x) is the Brillouin function of order J: BJ (x) = ( 1 + 1 2J ) coth {(1 + 1 2J ) x} − 1 2J coth { 1 2J x} . (23) In Figure 3.8 we have plotted the function BJ (x) for some typical values of the quantum number J. We shall now consider a few special cases. First of all, we note that for strong ﬁelds and low temperatures (x ≫ 1), the function BJ (x) ≃ 1 for all J, which corresponds to a state of magnetic saturation. On the other hand, for high temperatures and weak ﬁelds (x ≪ 1), the function BJ (x) may be written as 1 3 (1 + 1/J)x + . . . , (24) so that µz ≃ (gµBJ)2 3kT ( 1 + 1 J ) H = g2µ2 BJ( J + 1) 3kT H. (25) The Curie law, χ ∝ 1/T , is again obeyed; however, the Curie constant is now given by CJ = N0g2µ2 BJ( J + 1) 3k = N0µ2 3k ; (26) see equation (16). It is indeed interesting that the high-temperature results, (25) and (26), directly involve the eigenvalues of the operator µ2. 1.0 0.5 J 5`, , 1, 0024 3 2 6 1 2BJ(x) x FIGURE 3.8 The Brillouin function BJ (x) for various values of J. 76 Chapter 3. The Canonical Ensemble We now look a little more closely at the dependence of the foregoing results on the quantum number J. First of all, we consider the extreme case J → ∞, with the understand- ing that simultaneously g → 0, such that the value of µ stays constant. From equation (23), we readily observe that, in this limit, the Brillouin function BJ (x) tends to become (i) inde- pendent of J and (ii) identical to the Langevin function L(x). This is not surprising because, in this limit, the number of allowed orientations for a magnetic dipole becomes inﬁnitely large, with the result that the problem essentially reduces to its classical counterpart (where one must allow all possible orientations). At the other extreme, we have the case J = 1 2 , which allows only two orientations. The results in this case are very different from the ones for J ≫ 1. We now have, with g = 2, µz = µBB1/2(x) = µB tanh x. (27) For x ≫ 1, µz is very nearly equal to µB. For x ≪ 1, however, µz ≃ µBx, which corresponds to the Curie constant C1/2 = N0µ2 B k . (28) In Figure 3.9 we reproduce the experimental values of µz (in terms of µB) as a function of the quantity H/T , for three paramagnetic salts; the corresponding theoretical plots, namely the curves g JBJ (x), are also included in the ﬁgure. The agreement between theory and experiment is indeed good. In passing, we note that, at a temperature of 1.3 K, a ﬁeld of about 50,000 gauss is sufﬁcient to produce over 99 percent of saturation in these salts. 7.00 6.00 III II I 5.00 4.00 3.00 2.00 1.00 0 10203040 1.30 K 2.00 K 3.00 K 4.21 K(\u0002z/\u0002B) 10 \u00023H /T gauss/K FIGURE 3.9 Plots of µz/µB as a function of H/T . The solid curves represent the theoretical results, while the points mark the experimental ﬁndings of Henry (1952). Curve I is for potassium chromium alum (J = 3 2 , g = 2 ) , curve II for iron ammonia alum ( J = 5 2 , g = 2) , and curve III for gadolinium sulphate octahydrate (J = 7 2 , g = 2 ) . 3.10 Thermodynamics of magnetic systems: negative temperatures 77 3.10 Thermodynamics of magnetic systems: negative temperatures For the purpose of this section, it will sufﬁce to consider a system of dipoles with J = 1 2 . Each dipole then has a choice of two orientations, the corresponding energies being −µBH and +µBH; let us call these energies −ε and +ε, respectively. The partition function of the system is then given by QN (β) = (eβε + e−βε)N = {2 cosh(βε)}N ; (1) compare to the general expression (3.9.20). Accordingly, the Helmholtz free energy of the system is given by A = −NkT ln{2 cosh(ε/kT )}, (2) from which S = − ( ∂A ∂T ) H = Nk [ ln {2 cosh ( ε kT )} − ε kT tanh ( ε kT )] , (3) U = A + TS = −Nε tanh ( ε kT ) , (4) M = − ( ∂A ∂H ) T = NµB tanh ( ε kT ) (5) and, ﬁnally, C = ( ∂U ∂T ) H = Nk ( ε kT )2 sech 2 ( ε kT ) . (6) Equation (5) is essentially the same as (3.9.27); moreover, as expected, U = −MH. The temperature dependence of the quantities S, U, M, and C is shown in Figures 3.10 through 3.13. We note that the entropy of the system is vanishingly small for kT ≪ ε; it rises 1.0 In 2 0.5 00246 S Nk kT/´ FIGURE 3.10 The entropy of a system of magnetic dipoles (with J = 1 2 ) as a function of temperature. 78 Chapter 3. The Canonical Ensemble 0 20.5 21.0 0246 kT ´ U N´ FIGURE 3.11 The energy of a system of magnetic dipoles (with J = 1 2 ) as a function of temperature. 0.5 1.0 0 0 246 kT ´ M N\u0002 FIGURE 3.12 The magnetization of a system of magnetic dipoles (with J = 1 2 ) as a function of temperature. rapidly when kT is of the order of ε and approaches the limiting value Nk ln 2 for kT ≫ ε. This limiting value of S corresponds to the fact that at high temperatures the orientation of the dipoles assumes a completely random character, with the result that the system now has 2N equally likely microstates available to it. The energy of the system attains its lowest value, −Nε, as T → 0 K; this clearly corresponds to a state of magnetic satura- tion and, hence, to a state of perfect order in the system. Toward high temperatures, the energy tends to vanish,13 implying a purely random orientation of the dipoles and hence 13Note that in the present study we are completely disregarding the kinetic energy of the dipoles. 3.10 Thermodynamics of magnetic systems: negative temperatures 79 0.5 1.0 0 0 246 C Nk kT ´ FIGURE 3.13 The speciﬁc heat of a system of magnetic dipoles (with J = 1 2 ) as a function of temperature. a complete loss of magnetic order. These features are re-emphasized in Figure 3.12, which depicts the temperature dependence of the magnetization M. The speciﬁc heat of the sys- tem is vanishingly small at low temperatures but, in view of the fact that the energy of the system tends to a constant value as T → ∞, the speciﬁc heat vanishes at high tempera- tures as well. Somewhere around T = ε/k, it displays a maximum. Writing 1 for the energy difference between the two allowed states of the dipole, the formula for the speciﬁc heat can be written as C = Nk ( 1 kT )2 e1/kT (1 + e1/kT ) −2. (7) A speciﬁc heat peak of this form is generally known as the Schottky anomaly; it is observed in systems that have an excitation gap 1 above the ground state. Now, throughout our study so far we have considered only those cases for which T > 0. For normal systems, this is indeed essential, for otherwise we have to contend with canon- ical distributions that blow up as the energy of the system is indeﬁnitely increased. If, however, the energy of a system is bounded from above, then there is no compelling reason to exclude the possibility of negative temperatures. Such specialized situations do indeed exist, and the system of magnetic dipoles provides a good example thereof. From equa- tion (4), we note that, so long as U < 0, T > 0 — and that is the only range we covered in Figures 3.10 through 3.13. However, the same equation tells us that if U > 0 then T < 0, which prompts us to examine the matter a little more closely. For this, we consider the variation of the temperature T and the entropy S with energy U, namely 1 T = − k ε tanh −1( U Nε ) = k 2ε ln( Nε − U Nε + U ) (8) 80 Chapter 3. The Canonical EnsemblekT´ S Nk U N´ 0.5 In 2 1.0 21 10.5 11 12 15 1` 2` 25 22 21 20.5 0 01 FIGURE 3.14 The entropy of a system of magnetic dipoles (with J = 1 2 ) as a function of energy. Some values of the parameter kT /ε are also shown in the ﬁgure. The slope at the two endpoints diverges since both ends represent zero temperature but it is difﬁcult to see due to the logarithmic nature of the divergence. and S Nk = − Nε + U 2Nε ln( Nε + U 2Nε ) − Nε − U 2Nε ln( Nε − U 2Nε ) ; (9) these expressions follow straightforwardly from equations (3) and (4), and are shown graphically in Figures 3.14 and 3.15. We note that for U = −Nε, both S and T vanish. As U increases, they too increase until we reach the special situation where U = 0. The entropy is then seen to have attained its maximum value Nk ln 2, while the temperature has reached inﬁnity. Throughout this range, the entropy had been a monotonically increasing function of energy, so T was positive. Now, as U becomes 0+, (dS/dU) becomes 0− and T becomes −∞. With a further increase in U, the entropy monotonically decreases; as a result, the temperature continues to be negative, though its magnitude steadily decreases. Finally, we reach the largest value of U, namely +Nε, where the entropy is once again zero and T = 0−. The region where U > 0 (and hence T < 0) is indeed abnormal because it corresponds to a magnetization opposite in direction to that of the applied ﬁeld. Nevertheless, it can be realized experimentally in the system of nuclear moments of a crystal in which the relax- ation time t1 for mutual interaction among nuclear spins is very small in comparison with the relaxation time t2 for interaction between the spins and the lattice. Let such a crystal be magnetized in a strong magnetic ﬁeld and then the ﬁeld reversed so quickly that the spins are unable to follow the switch-over. This will leave the system in a nonequilibrium state, with energy higher than the new equilibrium value U. During a period of order t1, 3.10 Thermodynamics of magnetic systems: negative temperatures 81 kT / ´kT/´ \u0002 ´ \u0002 ´ 4 2 021 11 22 24 U N´ FIGURE 3.15 The temperature parameter kT /ε, and its reciprocal βε, for a system of magnetic dipoles (with J = 1 2 ) as a function of energy. the subsystem of the nuclear spins should be able to attain a state of internal equilibrium; this state will have a negative magnetization and will, therefore, correspond to a negative temperature. The subsystem of the lattice, which involves energy parameters that are in principle unbounded, will still be at a positive temperature. During a period of order t2, the two subsystems would attain a state of mutual equilibrium, which again will have a positive temperature. 14 An experiment of this kind was successfully performed by Purcell and Pound (1951) with a crystal of LiF; in this case, t1 was of order 10−5 sec while t2 was of order 5 min. A state of negative temperature for the subsystem of spins was indeed attained and was found to persist for a period of several minutes; see Figure 3.16. Before we close this discussion, a few general remarks seem in order. First of all, we should note that the onset of negative temperatures is possible only if there exists an upper limit on the energy of the given system. In most physical systems this is not the case, simply because most physical systems possess kinetic energy of motion which is obvi- ously unbounded. By the same token, the onset of positive temperatures is related to the 14Note that in the latter process, during which the spins realign themselves (now more favorably in the new direction of the ﬁeld), the energy will ﬂow from the subsystem of the spins to that of the lattice, and not vice versa. This is in perfect agreement with the fact that negative temperatures are hotter than positive ones; see the subsequent discussion in the text. 82 Chapter 3. The Canonical Ensemble Time 0.5 0.4 0.3 0.2 0.1 0 20.1 20.2 20.3 20.4 20.5Deflection 1min. FIGURE 3.16 A typical record of the reversed nuclear magnetization (after Purcell and Pound, 1951). On the left we have a deﬂection corresponding to normal, equilibrium magnetization (T ∼ 300 K); it is followed by the reversed deﬂection (corresponding to T ∼ −350 K), which decays through zero deﬂection (corresponding to a passage from T = −∞ to T = +∞) toward the new equilibrium state that again has a positive T . existence of a lower limit on the energy of a system; this, however, does not present any problem because, if nothing else, the uncertainty principle alone is sufﬁcient to set such a limit for every physical system. Thus, it is quite normal for a system to be at a positive temperature whereas it is very unusual for one to be at a negative temperature. Now, suppose that we have a system whose energy cannot assume unlimited high values. Then, we can surely visualize a temperature T such that the quantity NkT is much larger than any admissible value, Er, of the energy. At such a high temperature, the mutual interactions of the microscopic entities constituting the system may be regarded as negligible; accordingly, one may write for the partition function of the system QN (β) ≃ [ ∑ n e−βεn ]N . (10) Since, by assumption, all βεn ≪ 1, we have QN (β) ≃ [ ∑ n {1 − βεn + 1 2 β2ε2 n }]N . (11) Let g denote the number of possible orientations of a microscopic constituent of the sys- tem with respect to the direction of the external ﬁeld; then, the quantities ∑n εα n(α = 0, 1, 2) may be replaced by gεα. We thus get ln QN (β) ≃ N[ln g + ln( 1 − β ¯ε + 1 2 β2ε2)] ≃ N[ln g − β ¯ε + 1 2 β2(ε2 − ε2)]. (12) Problems 83 The Helmholtz free energy of the system is then given by A(N, β) ≃ − N β ln g + N ¯ε − N 2 β(ε − ¯ε)2, (13) from which S(N, β) ≃ Nk ln g − Nk 2 β2(ε − ¯ε)2, (14) U(N, β) ≃ Nε − Nβ(ε − ¯ε)2, (15) and C(N, β) ≃ Nkβ2(ε − ¯ε)2. (16)15 The formulae in equations (12) through (16) determine the thermodynamic properties of the system for β ≃ 0. The important thing to note here is that they do so not only for β ≳ 0 but also for β ≲ 0. In fact, these formulae hold in the vicinity of, and on both sides of, the maximum in the S − U curve; see Figure 3.14. Quite expectedly, the maximum value of S is given by Nk ln g, and it occurs at β = ±0; S here decreases both ways, whether U decreases (β > 0) or increases (β < 0). It will be noted that the speciﬁc heat of the system in either case is positive. It is not difﬁcult to show that if two systems, characterized by the temperature parame- ters β1 and β2, are brought into thermal contact, then energy will ﬂow from the system with the smaller value of β to the system with the larger value of β; this will continue until the two systems acquire a common value of this parameter. What is more important to note is that this result remains literally true even if one or both of the β are negative. Thus, if β1 is −ve while β2 is +ve, then energy will ﬂow from system 1 to system 2, that is, from the sys- tem at negative temperature to the one at positive temperature. In this sense, systems at negative temperatures are hotter than the ones at positive temperatures; indeed, negative temperatures are above +∞, not below zero! For further discussion of this topic, reference may be made to a paper by Ramsey (1956). Problems 3.1. (a) Derive formula (3.2.36) from equations (3.2.14) and (3.2.35). (b) Derive formulae (3.2.39) and (3.2.40) from equations (3.2.37) and (3.2.38). 3.2. Prove that the quantity g′′(x0), see equations (3.2.25), is equal to ⟨(E − U)2⟩ exp(2β). Thus show that equation (3.2.28) is physically equivalent to equation (3.6.9). 3.3. Using the fact that (1/n! ) is the coefﬁcient of xn in the power expansion of the function exp(x), derive an asymptotic formula for this coefﬁcient by the method of saddle-point integration. Compare your result with the Stirling formula for n!. 15Compare this result with equation (3.6.3). 84 Chapter 3. The Canonical Ensemble 3.4. Verify that the quantity (k/N ) ln 0, where 0(N , U) = ∑ {nr } ′W {nr}, is equal to the (mean) entropy of the given system. Show that this leads to essentially the same result for ln 0 if we take, in the foregoing summation, only the largest term of the sum, namely the term W {n∗ r } that corresponds to the most probable distribution set. [Surprised? Well, note the following example: For all N, the summation over the binomial coefﬁcients N Cr = N! /[r! (N − r! )] gives N∑ r=0 N Cr = 2 N ; therefore, ln { N∑ r=0 N Cr } = N ln 2. (a) Now, the largest term in this sum corresponds to r ≃ N/2; so, for large N, the logarithm of the largest term is very nearly equal to ln{N! } − 2 ln{(N/2)! } ≈N ln N − 2 N 2 ln N 2 = N ln 2, (b) which agrees with (a).] 3.5. Making use of the fact that the Helmholtz free energy A(N, V , T ) of a thermodynamic system is an extensive property of the system, show that N( ∂A ∂N ) V ,T + V ( ∂A ∂V ) N,T = A. [Note that this result implies the well-known relationship: Nµ = A + PV (≡ G).] 3.6. (a) Assuming that the total number of microstates accessible to a given statistical system is \u0000, show that the entropy of the system, as given by equation (3.3.13), is maximum when all \u0000 states are equally likely to occur. (b) If, on the other hand, we have an ensemble of systems sharing energy (with mean value E), then show that the entropy, as given by the same formal expression, is maximum when Pr ∝ exp(−βEr), β being a constant to be determined by the given value of E. (c) Further, if we have an ensemble of systems sharing energy (with mean value E) and also sharing particles (with mean value N), then show that the entropy, given by a similar expression, is maximum when Pr,s ∝ exp(−αNr − βEs), α and β being constants to be determined by the given values of N and E. 3.7. Prove that, quite generally, CP − CV = −k [ ∂ ∂T { T ( ∂ ln Q ∂V ) T }]2 V( ∂ 2 ln Q ∂V 2 ) T > 0. Verify that the value of this quantity for a classical ideal classical gas is Nk. Problems 85 3.8. Show that, for a classical ideal gas, S Nk = ln ( Q1 N ) + T ( ∂ ln Q1 ∂T ) P . 3.9. If an ideal monatomic gas is expanded adiabatically to twice its initial volume, what will the ratio of the ﬁnal pressure to the initial pressure be? If during the process some heat is added to the system, will the ﬁnal pressure be higher or lower than in the preceding case? Support your answer by deriving the relevant formula for the ratio Pf /Pi. 3.10. (a) The volume of a sample of helium gas is increased by withdrawing the piston of the containing cylinder. The ﬁnal pressure Pf is found to be equal to the initial pressure Pi times (Vi/Vf )1.2, Vi and Vf being the initial and ﬁnal volumes. Assuming that the product PV is always equal to 2 3 U, will (i) the energy and (ii) the entropy of the gas increase, remain constant, or decrease during the process? (b) If the process were reversible, how much work would be done and how much heat would be added in doubling the volume of the gas? Take Pi = 1 atm and Vi = 1 m3. 3.11. Determine the work done on a gas and the amount of heat absorbed by it during a compression from volume V1 to volume V2, following the law PV n = const. 3.12. If the “free volume” V of a classical system is deﬁned by the equation V N = ∫ e{U−U(qi)}/kT N∏ i=1 d3qi, where U is the average potential energy of the system and U(qi) the actual potential energy as a function of the molecular conﬁguration, then show that S = Nk [ ln { V N ( 2π mkT h2 )3/2} + 5 2 ] . In what sense is it justiﬁed to refer to the quantity V as the “free volume” of the system? Substantiate your answer by considering a particular case — for example, the case of a hard sphere gas. 3.13. (a) Evaluate the partition function and the major thermodynamic properties of an ideal gas consisting of N1 molecules of mass m1 and N2 molecules of mass m2, conﬁned to a space of volume V at temperature T . Assume that the molecules of a given kind are mutually indistinguishable, while those of one kind are distinguishable from those of the other kind. (b) Compare your results with the ones pertaining to an ideal gas consisting of (N1 + N2) molecules, all of one kind, of mass m, such that m(N1 + N2) = m1N1 + m2N2. 3.14. Consider a system of N classical particles with mass m moving in a cubic box with volume V = L3. The particles interact via a short-ranged pair potential u(rij) and each particle interacts with each wall with a short-ranged interaction uwall(z), where z is the perpendicular distance of a particle from the wall. Write down the Lagrangian for this model and use a Legendre transformation to determine the Hamiltonian H. (a) Show that the quantity P = − ( ∂H ∂V ) = −1 3L2 ( ∂H ∂L ) can clearly be identiﬁed as the instantaneous pressure — that is, the force per unit area on the walls. (b) Reconstruct the Lagrangian in terms of the relative locations of the particles inside the box ri = Lsi, where the variables si all lie inside a unit cube. Use a Legendre transformation to determine the Hamiltonian with this set of variables. (c) Recalculate the pressure using the second version of the Hamiltonian. Show that the pressure now includes three contributions: (1) a contribution proportional to the kinetic energy, (2) a contribution related to the forces between pairs of particles, and (3) a contribution related to the force on the wall. 86 Chapter 3. The Canonical Ensemble Show that in the thermodynamic limit the third contribution is negligible compared to the other two. Interpret contributions 1 and 2 and compare to the virial equation of state (3.7.15). 3.15. Show that the partition function QN (V , T ) of an extreme relativistic gas consisting of N monatomic molecules with energy–momentum relationship ε = pc, c being the speed of light, is given by QN (V , T ) = 1 N! { 8πV ( kT hc )3}N . Study the thermodynamics of this system, checking in particular that PV = 1 3 U, U/N = 3kT , and γ = 4 3 . Next, using the inversion formula (3.4.7), derive an expression for the density of states g(E) of this system. 3.16. Consider a system similar to the one in the preceding problem but consisting of 3N particles moving in one dimension. Show that the partition function in this case is given by Q3N (L, T ) = 1 (3N)! [2L ( kT hc )]3N , L being the “length” of the space available. Compare the thermodynamics and the density of states of this system with the corresponding quantities obtained in the preceding problem. 3.17. If we take the function f (q, p) in equation (3.5.3) to be U − H(q, p), then clearly ⟨ f ⟩ = 0; formally, this would mean ∫ [U − H(q, p)]e−βH(q,p)dω = 0. Derive, from this equation, expression (3.6.3) for the mean-square ﬂuctuation in the energy of a system embedded in the canonical ensemble. 3.18. Show that for a system in the canonical ensemble ⟨(1E)3⟩ = k2 {T 4 ( ∂CV ∂T ) V + 2T 3CV } . Verify that for an ideal gas 〈( 1E U )2〉 = 2 3N and 〈( 1E U )3〉 = 8 9N 2 . 3.19. Consider the long-time averaged behavior of the quantity dG/dt, where G = ∑ i qipi, and show that the validity of equation (3.7.5) implies the validity of equation (3.7.6), and vice versa. 3.20. Show that, for a statistical system in which the interparticle potential energy u(r) is a homogeneous function (of degree n) of the particle coordinates, the virial V is given by V = −3PV − nU Problems 87 and, hence, the mean kinetic energy K by K = − 1 2 V = 1 2 (3PV + nU) = 1 (n + 2) (3PV + nE); here, U denotes the mean potential energy of the system while E = K + U. Note that this result holds not only for a classical system but for a quantum-mechanical one as well. 3.21. (a) Calculate the time-averaged kinetic energy and potential energy of a one-dimensional harmonic oscillator, both classically and quantum-mechanically, and show that the results obtained are consistent with the result established in the preceding problem (with n = 2). (b) Consider, similarly, the case of the hydrogen atom (n = −1) on the basis of (i) the Bohr– Sommerfeld model and (ii) the Schr¨odinger model. (c) Finally, consider the case of a planet moving in (i) a circular orbit or (ii) an elliptic orbit around the sun. 3.22. The restoring force of an anharmonic oscillator is proportional to the cube of the displacement. Show that the mean kinetic energy of the oscillator is twice its mean potential energy. 3.23. Derive the virial equation of state equation (3.7.15) from the classical canonical partition function (3.5.5). Show that in the thermodynamic limit the interparticle terms dominate the ones that come from interactions of the particles with the walls of the container. 3.24. Show that in the relativistic case the equipartition theorem takes the form ⟨m0u2(1 − u 2/c2)−1/2⟩ = 3kT , where m0 is the rest mass of the particle and u its speed. Check that in the extreme relativistic case the mean thermal energy per particle is twice its value in the nonrelativistic case. 3.25. Develop a kinetic argument to show that in a noninteracting system the average value of the quantity ∑ i pi ˙qi is precisely equal to 3PV . Hence show that, regardless of relativistic considerations, PV = NkT . 3.26. The energy eigenvalues of an s-dimensional harmonic oscillator can be written as εj = ( j + s/2)ℏ ω; j = 0, 1, 2, . . . Show that the jth energy level has a multiplicity ( j + s − 1)! /j! (s − 1)!. Evaluate the partition function, and the major thermodynamic properties, of a system of N such oscillators, and compare your results with a corresponding system of sN one-dimensional oscillators. Show, in particular, that the chemical potential µs = sµ1. 3.27. Obtain an asymptotic expression for the quantity ln g(E) for a system of N quantum-mechanical harmonic oscillators by using the inversion formula (3.4.7) and the partition function (3.8.15). Hence show that S Nk = ( E Nℏ ω + 1 2 ) ln ( E Nℏ ω + 1 2 ) − ( E Nℏ ω − 1 2 ) ln ( E Nℏ ω − 1 2 ) . [Hint: Employ the Darwin–Fowler method.] 3.28. (a) When a system of N oscillators with total energy E is in thermal equilibrium, what is the probability pn that a particular oscillator among them is in the quantum state n? [Hint: Use expression (3.8.25).] Show that, for N ≫ 1 and R ≫ n, pn ≈ (n)n/(n + 1)n+1, where n = R/N. (b) When an ideal gas of N monatomic molecules with total energy E is in thermal equilibrium, show that the probability of a particular molecule having an energy in the neighborhood of ε is proportional to exp(−βε), where β = 3N/2E. [Hint: Use expression (3.5.16) and assume that N ≫ 1 and E ≫ ε.] 3.29. The potential energy of a one-dimensional, anharmonic oscillator may be written as V (q) = cq2 − gq3 − fq4, where c, g, and f are positive constants; quite generally, g and f may be assumed to be very small in value. Show that the leading contribution of anharmonic terms to the heat capacity of the 88 Chapter 3. The Canonical Ensemble oscillator, assumed classical, is given by 3 2 k2 ( f c2 + 5 4 g2 c3 ) T and, to the same order, the mean value of the position coordinate q is given by 3 4 gkT c2 . 3.30. The energy levels of a quantum-mechanical, one-dimensional, anharmonic oscillator may be approximated as εn = ( n + 1 2 ) ℏ ω − x ( n + 1 2 )2 ℏ ω; n = 0, 1, 2, . . . The parameter x, usually ≪ 1, represents the degree of anharmonicity. Show that, to the ﬁrst order in x and the fourth order in u(≡ ℏ ω/kT ), the speciﬁc heat of a system of N such oscillators is given by C = Nk [( 1 − 1 12 u 2 + 1 240 u4) + 4x ( 1 u + 1 80 u3)] . Note that the correction term here increases with temperature. 3.31. Study, along the lines of Section 3.8, the statistical mechanics of a system of N “Fermi oscillators,” which are characterized by only two eigenvalues, namely 0 and ε. 3.32. The quantum states available to a given physical system are (i) a group of g1 equally likely states, with a common energy ε1 and (ii) a group of g2 equally likely states, with a common energy ε2 > ε1. Show that this entropy of the system is given by S = −k[p1 ln(p1/g1) + p2 ln(p2/g2)], where p1 and p2 are, respectively, the probabilities of the system being in a state belonging to group 1 or to group 2: p1 + p2 = 1. (a) Assuming that the pi are given by a canonical distribution, show that S = k [ ln g1 + ln{1 + (g2/g1)e−x} + x 1 + (g1/g2)ex ] , where x = (ε2 − ε1)/kT , assumed positive. Compare the special case g1 = g2 = 1 with that of the Fermi oscillator of the preceding problem. (b) Verify the foregoing expression for S by deriving it from the partition function of the system. (c) Check that at T → 0, S → k ln g1. Interpret this result physically. 3.33. Gadolinium sulphate obeys Langevin’s theory of paramagnetism down to a few degrees Kelvin. Its molecular magnetic moment is 7.2 × 10−23amp-m2. Determine the degree of magnetic saturation in this salt at a temperature of 2 K in a ﬁeld of ﬂux density 2 weber/m 2. 3.34. Oxygen is a paramagnetic gas obeying Langevin’s theory of paramagnetism. Its susceptibility per unit volume, at 293 K and at atmospheric pressure, is 1.80 × 10−6 mks units. Determine its molecular magnetic moment and compare it with the Bohr magneton (which is very nearly equal to 9.27 × 10−24amp-m2). 3.35. (a) Consider a gaseous system of N noninteracting, diatomic molecules, each having an electric dipole moment µ, placed in an external electric ﬁeld of strength E. The energy of such a molecule will be given by the kinetic energy of rotation as well as translation plus the potential energy of orientation in the applied ﬁeld: ε = p2 2m + { p2 θ 2I + p2 φ 2I sin 2 θ } − µE cos θ, Problems 89 where I is the moment of inertia of the molecule. Study the thermodynamics of this system, including the electric polarization and the dielectric constant. Assume that (i) the system is a classical one and (ii) |µE| ≪ kT .16 (b) The molecule H2O has an electric dipole moment of 1.85 × 10−18 e.s.u. Calculate, on the basis of the preceding theory, the dielectric constant of steam at 100◦C and at atmospheric pressure. 3.36. Consider a pair of electric dipoles µµµ and µµµ′, oriented in the directions (θ, φ) and (θ ′, φ′), respectively; the distance R between their centers is assumed to be ﬁxed. The potential energy in this orientation is given by − µµ′ R3 {2 cos θ cos θ ′ − sin θ sin θ ′ cos(φ − φ′)}. Now, consider this pair of dipoles to be in thermal equilibrium, their orientations being governed by a canonical distribution. Show that the mean force between these dipoles, at high temperatures, is given by −2 (µµ′)2 kT ˆR R7 , ˆR being the unit vector in the direction of the line of centers. 3.37. Evaluate the high-temperature approximation of the partition function of a system of magnetic dipoles to show that the Curie constant CJ is given by CJ = N0g2µ2 B k m2. Hence derive the formula (3.9.26). 3.38. Replacing the sum in (3.9.18) by an integral, evaluate Q1(β) of the given magnetic dipole and study the thermodynamics following from it. Compare these results with the ones following from the Langevin theory. 3.39. Atoms of silver vapor, each having a magnetic moment µB(g = 2, J = 1 2 ), align themselves either parallel or antiparallel to the direction of an applied magnetic ﬁeld. Determine the respective fractions of atoms aligned parallel and antiparallel to a ﬁeld of ﬂux density 0.1 weber/m 2 at a temperature of 1,000 K. 3.40. (a) Show that, for any magnetizable material, the heat capacities at constant ﬁeld H and at constant magnetization M are connected by the relation CH − CM = −T ( ∂H ∂T ) M ( ∂M ∂T ) H . (b) Show that for a paramagnetic material obeying Curie’s law CH − CM = CH 2/T 2, where C on the right side of this equation denotes the Curie constant of the given sample. 3.41. A system of N spins at a negative temperature (E > 0) is brought into contact with an ideal-gas thermometer consisting of N ′ molecules. What will the nature of their state of mutual equilibrium be? Will their common temperature be negative or positive, and in what manner will it be affected by the ratio N ′/N? 3.42. Consider the system of N magnetic dipoles, studied in Section 3.10, in the microcanonical ensemble. Enumerate the number of microstates, \u0000(N, E), accessible to the system at energy E and evaluate the quantities S(N, E) and T (N, E). Compare your results with equations (3.10.8) and (3.10.9). 16The electric dipole moments of molecules are generally of order 10−18 e.s.u. (or a Debye unit). In a ﬁeld of 1 e.s.u. (= 300 volts/cm) and at a temperature of 300 K, the parameter βµE = O(10−4). 90 Chapter 3. The Canonical Ensemble 3.43. Consider a system of charged particles (not dipoles), obeying classical mechanics and classical statistics. Show that the magnetic susceptibility of this system is identically zero (Bohr–van Leeuwen theorem). [Note that the Hamiltonian of this system in the presence of a magnetic ﬁeld H(= ∇ × A) will be a function of the quantities pj + (ej/c)A(rj), and not of the pj as such. One has now to show that the partition function of the system is independent of the applied ﬁeld.] 3.44. The expression (3.3.13) for the entropy S is equivalent to Shannon’s (1949) deﬁnition of the information contained in a message I = − ∑ r Pr ln(Pr), where Pr represents the probability of message r. (a) Show that information is maximized if the probabilities of all messages are the same. Any other distribution of probabilities reduces the information. In English, “e” is more common than “z”, so Pe > Pz, so the information per character in an English message is less than the optimal amount possible based on the number of different characters used in an English text. (b) The information in a text is also affected by correlations between characters in the text. For example, in English, “q” is always followed by “u”, so this pair of characters contains the same information as “q” alone. The probability of a character indexed by r followed immediately by character indexed by r′ is Pr,r′ = PrPr′ Gr,r′ , where Gr,r′ is the character-pair correlation function. If pairs of characters are uncorrelated, then Gr,r′ = 1. Show that if characters are uncorrelated then the information in a two-character message is twice the information of a single-character message and that correlations (Gr,r′ ̸= 1) reduce the information content. [Hint: Use the inequality ln x ≤ x − 1.] (c) Write a computer program to determine the information per character in a text ﬁle by determining the single-character probabilities Pr and character-pair correlations Gr,r′ . Computers usually use one full byte per character to store information. Since one byte can store 256 different messages, the potential information per byte is ln 256 = 8 ln 2 ≡ 8 bits. Show that the information per character in your text ﬁle is considerably less than 8 bits and explain why it is possible for ﬁle-compression algorithms to reduce the size of a computer ﬁle without sacriﬁcing any of the information contained in the ﬁle. 4 The Grand Canonical Ensemble In the preceding chapter we developed the formalism of the canonical ensemble and established a scheme of operations for deriving the various thermodynamic properties of a given physical system. The effectiveness of that approach became clear from the examples discussed there; it will become even more vivid in the subsequent studies carried out in this text. However, for a number of problems, both physical and chemical, the usefulness of the canonical ensemble formalism turns out to be rather limited and it appears that a further generalization of this formalism is called for. The motivation that brings about this generalization is physically of the same nature as the one that led us from the microcanoni- cal to the canonical ensemble — it is just the next natural step from there. It comes from the realization that not only the energy of a system but the number of particles as well is hardly ever measured in a “direct” manner; we only estimate it through an indirect probing into the system. Conceptually, therefore, we may regard both N and E as variables and identify their expectation values, ⟨N⟩ and ⟨E⟩, with the corresponding thermodynamic quantities. The procedure for studying the statistics of the variables N and E is self-evident. We may either (i) consider the given system A as immersed in a large reservoir A′ with which it can exchange both energy and particles or (ii) regard it as a member of what we may call a grand canonical ensemble, which consists of the given system A and a large number of (mental) copies thereof, the members of the ensemble carrying out a mutual exchange of both energy and particles. The end results, in either case, are asymptotically the same. 4.1 Equilibrium between a system and a particle-energy reservoir We consider the given system A as immersed in a large reservoir A′, with which it can exchange both energy and particles; see Figure 4.1. After some time has elapsed, the system and the reservoir are supposed to attain a state of mutual equilibrium. Then, according to Section 1.3, the system and the reservoir will have a common temperature T and a common chemical potential µ. The fraction of the total number of particles N (0) and the fraction of the total energy E(0) that the system A can have at any time t are, however, variables (whose values, in principle, can lie anywhere between zero and unity). If, at a particular instant of time, the system A happens to be in one of its states characterized by the number Nr of particles and the amount Es of energy, then the number of particles in the reservoir would be N ′ r and its energy E′ s, such that Nr + N ′ r = N (0) = const. (1) Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00004-9 © 2011 Elsevier Ltd. All rights reserved. 91 92 Chapter 4. The Grand Canonical Ensemble A9 (N9r , E9s) A (Nr , Es) FIGURE 4.1 A statistical system immersed in a particle–energy reservoir. and Es + E′ s = E(0) = const. (2) Again, since the reservoir is supposed to be much larger than the given system, the values of Nr and Es that are going to be of practical importance will be very small fractions of the total magnitudes N (0) and E(0), respectively; therefore, for all practical purposes,1 Nr N (0) = ( 1 − N ′ r N (0) ) ≪ 1 (3) and Es E(0) = ( 1 − E′ s E(0) ) ≪ 1. (4) Now, in the manner of Section 3.1, the probability Pr,s that, at any time t, the sys- tem A is found to be in an (Nr, Es)-state would be directly proportional to the number of microstates \u0000′(N ′ r, E′ s) that the reservoir can have for the corresponding macrostate (N ′ r, E′ s). Thus, Pr,s ∝ \u0000′(N (0) − Nr, E(0) − Es). (5) Again, in view of (3) and (4), we can write ln \u0000′(N (0) − Nr, E(0) − Es) = ln \u0000′(N (0), E(0)) + ( ∂ ln \u0000′ ∂N ′ ) N ′=N (0) (−Nr) + ( ∂ ln \u0000′ ∂E′ ) E′=E(0) (−Es) + · · · ≃ ln \u0000′(N (0), E(0)) + µ′ kT ′ Nr − 1 kT ′ Es; (6) see equations (1.2.3), (1.2.7), (1.3.3), and (1.3.5). Here, µ′ and T ′ are, respectively, the chemical potential and the temperature of the reservoir (and hence of the given system 1Note that A here could well be a relatively small “part” of a given system A(0), while A′ represents the “rest” of A(0). That would give a truly practical perspective to the grand canonical formalism. 4.2 A system in the grand canonical ensemble 93 as well). From (5) and (6), we obtain the desired result: Pr,s ∝ exp (−αNr − βEs), (7) where α = −µ/kT , β = 1/kT . (8) On normalization, it becomes Pr,s = exp (−αNr − βEs) ∑ r,s exp (−αNr − βEs) ; (9) the summation in the denominator goes over all the (Nr, Es)-states accessible to the system A. Note that our ﬁnal expression for Pr,s is independent of the choice of the reservoir. We shall now examine the same problem from the ensemble point of view. 4.2 A system in the grand canonical ensemble We now visualize an ensemble of N identical systems (which, of course, can be labeled as 1, 2, . . . , N ) mutually sharing a total number of particles 2 N N and a total energy N E. Let nr,s denote the number of systems that have, at any time t, the number Nr of particles and the amount Es of energy (r, s = 0, 1, 2, . . .); then, obviously, ∑ r,s nr,s = N, (1a) ∑ r,s nr,sNr = N N, (1b) and ∑ r,s nr,sEs = N E. (1c) Any set {nr,s}, of the numbers nr,s, which satisﬁes the restrictive conditions (1), represents one of the possible modes of distribution of particles and energy among the members of our ensemble. Furthermore, any such mode of distribution can be realized in W {nr,s} different ways, where W {nr,s} = N ! ∏ r,s(nr,s! ) . (2) 2For simplicity, we shall henceforth use the symbols N and E instead of ⟨N⟩ and ⟨E⟩. 94 Chapter 4. The Grand Canonical Ensemble We may now deﬁne the most probable mode of distribution, {n∗ r,s}, as the one that maximizes expression (2), satisfying at the same time the restrictive conditions (1). Going through the conventional derivation, see Section 3.2, we obtain for a large ensemble n∗ r,s N = exp (−αNr − βEs) ∑ r,s exp (−αNr − βEs) ; (3) compare to the corresponding equation (3.2.10) for the canonical ensemble. Alternatively, we may deﬁne the expectation (or mean) values of the numbers nr,s, namely ⟨nr,s⟩ = ∑ {nr,s} ′ nr,sW {nr,s} ∑ {nr,s} ′ W {nr,s} , (4) where the primed summations go over all distribution sets that conform to conditions (1). An asymptotic expression for ⟨nr,s⟩ can be derived by using the method of Darwin and Fowler — the only difference from the corresponding derivation in Section 3.2 being that, in the present case, we will have to work with functions of more than one (complex) variable. The derivation, however, runs along similar lines, with the result Lim N →∞ ⟨nr,s⟩ N ≃ n∗ r,s N = exp (−αNr − βEs) ∑ r,s exp (−αNr − βEs) , (5) in agreement with equation (4.1.9). The parameters α and β, so far undetermined, are eventually determined by the equations N = ∑ r,s Nr exp (−αNr − βEs) ∑ r,s exp (−αNr − βEs) ≡ − ∂ ∂α { ln ∑ r,s exp (−αNr − βEs) } (6) and E = ∑ r,s Es exp (−αNr − βEs) ∑ r,s exp (−αNr − βEs) ≡ − ∂ ∂β { ln ∑ r,s exp (−αNr − βEs) } , (7) where the quantities N and E here are supposed to be preassigned. 4.3 Physical signiﬁcance of the various statistical quantities 95 4.3 Physical signiﬁcance of the various statistical quantities To establish a connection between the statistics of the grand canonical ensemble and the thermodynamics of the system under study, we introduce a quantity q, deﬁned by q ≡ ln {∑ r,s exp (−αNr − βEs) } ; (1) the quantity q is a function of the parameters α and β, and also of all the Es. 3 Taking the differential of q and making use of equations (4.2.5), (4.2.6), and (4.2.7), we get dq = −Ndα − Edβ − β N ∑ r,s ⟨nr,s⟩ dEs, (2) so that d(q + αN + βE) = β ( α β dN + dE − 1 N ∑ r,s ⟨nr,s⟩ dEs ) . (3) To interpret the terms appearing on the right side of this equation, we compare the expression enclosed within the parentheses with the statement of the ﬁrst law of thermo- dynamics, that is, δQ = dE + δW − µdN, (4) where the various symbols have their usual meanings. The following correspondence now seems inevitable: δW = − 1 N ∑ r,s ⟨nr,s⟩ dEs, µ = −α/β, (5) with the result that d(q + αN + βE) = βδQ. (6) The parameter β, being the integrating factor for the heat δQ, must be equivalent to the reciprocal of the absolute temperature T , so we may write β = 1/kT (7) and, hence, α = −µ/kT . (8) 3This quantity was ﬁrst introduced by Kramers, who called it the q-potential. 96 Chapter 4. The Grand Canonical Ensemble The quantity (q + αN + βE) would then be identiﬁed with the thermodynamic variable S/k; accordingly, q = S k − αN − βE = TS + µN − E kT . (9) However, µN is identically equal to G, the Gibbs free energy of the system, and hence to (E − TS + PV ). So, ﬁnally, q ≡ ln {∑ r,s exp (−αNr − βEs) } = PV kT . (10) Equation (10) provides the essential link between the thermodynamics of the given sys- tem and the statistics of the corresponding grand canonical ensemble. It is, therefore, a relationship of central importance in the formalism developed in this chapter. To derive further results, we prefer to introduce a parameter z, deﬁned by the relation z ≡ e−α = eµ/kT ; (11) the parameter z is generally referred to as the fugacity of the system. In terms of z, the q-potential takes the form q ≡ ln {∑ r,s zNr e−βEs } (12) = ln    ∞∑ Nr =0 zNr QNr (V , T )    (with Q0 ≡ 1), (13) so we may write q(z, V , T ) ≡ ln Q(z, V , T ), (14) where Q(z, V , T ) ≡ ∞∑ Nr =0 zNr QNr (V , T ) (with Q0 ≡ 1). (15) Note that, in going from expression (12) to (13), we have (mentally) carried out a sum- mation over the energy values Es, with Nr ﬁxed, thus giving rise to the partition function QNr (V , T ); of course, the dependence of QNr on V comes from the dependence of the Es on V . In going from (13) to (14), we have (again mentally) carried out a summation over all the numbers Nr = 0, 1, 2, · · · , ∞, thus giving rise to the grand partition function Q(z, V , T ) of the system. The q-potential, which we have already identiﬁed with PV /kT , is, therefore, the logarithm of the grand partition function. 4.3 Physical signiﬁcance of the various statistical quantities 97 It appears that in order to evaluate the grand partition function Q(z, V , T ) we have to go through the routine of evaluating the partition function Q(N, V , T ). In principle, this is indeed true. In practice, however, we ﬁnd that on many occasions an explicit evaluation of the partition function is extremely hard while considerable progress can be made in the evaluation of the grand partition function. This is particularly true when we deal with systems in which the inﬂuence of quantum statistics and/or interparticle interactions is important; see Sections 6.2 and 10.1. The formalism of the grand canonical ensemble then proves to be of considerable value. We are now in a position to write down the full recipe for deriving the leading ther- modynamic quantities of a given system from its q-potential. We have, ﬁrst of all, for the pressure of the system P(z, V , T ) = kT V q(z, V , T ) ≡ kT V ln Q(z, V , T ). (16) Next, writing N for N and U for E, we obtain with the help of equations (4.2.6), (4.2.7), and (11) N(z, V , T ) = z [ ∂ ∂z q(z, V , T )] V ,T = kT [ ∂ ∂µ q(µ, V , T ) ] V ,T (17) and U(z, V , T ) = − [ ∂ ∂β q(z, V , T )] z,V = kT 2 [ ∂ ∂T q(z, V , T ) ] z,V . (18) Eliminating z between equations (16) and (17), one obtains the equation of state, that is, the (P, V , T )-relationship, of the system. On the other hand, eliminating z between equa- tions (17) and (18), one obtains U as a function of N, V , and T , which readily leads to the speciﬁc heat at constant volume as (∂U/∂T )N,V . The Helmholtz free energy is given by the formula A = Nµ − PV = NkT ln z − kT ln Q(z, V , T ) = −kT ln Q(z, V , T ) zN , (19) which may be compared with the canonical ensemble formula A = −kT ln Q(N, V , T ); see also Problem 4.2. Finally, we have for the entropy of the system S = U − A T = kT ( ∂q ∂T ) z,V − Nk ln z + kq. (20) 98 Chapter 4. The Grand Canonical Ensemble 4.4 Examples We shall now study a couple of simple problems, with the explicit purpose of demonstrat- ing how the method of the q-potential works. This is not intended to be a demonstration of the power of this method, for we shall consider here only those problems that can be solved equally well by the methods of the preceding chapters. The real power of the new method will become apparent only when we study problems involving quantum-statistical effects and effects arising from interparticle interactions; many such problems will appear in the remainder of the text. The ﬁrst problem we propose to consider here is that of the classical ideal gas. In Section 3.5 we showed that the partition function QN (V , T ) of this system could be written as QN (V , T ) = [Q1(V , T )]N N! , (1) where Q1(V , T ) may be regarded as the partition function of a single particle in the sys- tem. First of all, we should note that equation (1) does not imply any restrictions on the particles having internal degrees of motion; those degrees of motion, if present, would affect the results only through Q1. Second, we should recall that the factor N! in the denominator arises from the fact that the particles constituting the gas are, in fact, indistinguishable. Closely related to the indistinguishability of the particles is the fact that they are nonlocalized, for otherwise we could distinguish them through their very sites; compare, for instance, the system of harmonic oscillators, which was studied in Section 3.8. Now, since our particles are nonlocalized they can be anywhere in the space available to them; consequently, the function Q1 will be directly proportional to V : Q1(V , T ) = Vf (T ), (2) where f (T ) is a function of temperature alone. We thus obtain for the grand partition function of the gas Q(z, V , T ) = ∞∑ Nr =0 zNr QNr (V , T ) = ∞∑ Nr =0 {zVf (T )}Nr Nr! = exp {zVf (T )}, (3) which gives q (z, V , T ) = zVf (T ). (4) 4.4 Examples 99 Formula (4.3.16) through (4.3.20) then lead to the following results: P = zkTf (T ), (5) N = zVf (T ), (6) U = zVkT 2f ′(T ), (7) A = NkT ln z − zVkTf (T ), (8) and S = −Nk ln z + zVk{Tf ′(T ) + f (T )}. (9) Eliminating z between (5) and (6), we obtain the equation of state of the system: PV = NkT . (10) We note that equation (10) holds irrespective of the form of the function f (T ). Next, eliminating z between (6) and (7), we obtain U = NkT 2f ′(T )/f (T ), (11) which gives CV = Nk 2Tf (T )f ′(T ) + T 2{f (T )f ′′(T ) − [f ′(T )]2} [f (T )]2 . (12) In simple cases, the function f (T ) turns out to be directly proportional to a certain power of T . Supposing that f (T ) ∝ T n, equations (11) and (12) become U = n(NkT ) (11a) and CV = n(Nk). (12a) Accordingly, the pressure in such cases is directly proportional to the energy density of the gas, the constant of proportionality being 1/n. The reader will recall that the case n = 3/2 corresponds to a nonrelativistic gas while n = 3 corresponds to an extreme relativistic one. Finally, eliminating z between equation (6) and equations (8) and (9), we obtain A and S as functions of N, V , and T . This essentially completes our study of the classical ideal gas. The next problem to be considered here is that of a system of independent, localized particles — a model which, in some respects, approximates a solid. Mathematically, the 100 Chapter 4. The Grand Canonical Ensemble problem is similar to that of a system of harmonic oscillators. In either case, the micro- scopic entities constituting the system are mutually distinguishable. The partition function QN (V , T ) of such a system can be written as QN (V , T ) = [Q1(V , T )] N . (13) At the same time, in view of the localized nature of the particles, the single-particle par- tition function Q1(V , T ) is essentially independent of the volume occupied by the system. Consequently, we may write Q1(V , T ) = φ(T ), (14) where φ(T ) is a function of temperature alone. We then obtain for the grand partition function of the system Q(z, V , T ) = ∞∑ Nr =0 [zφ(T )] Nr = [1 − zφ(T )] −1; (15) clearly, the quantity zφ(T ) must stay below unity, so that the summation over Nr is convergent. The thermodynamics of the system follows straightforwardly from equation (15). We have, to begin with, P ≡ kT V q(z, T ) = − kT V ln{1 − zφ(T )}. (16) Since both z and T are intensive variables, the right side of (16) vanishes as V → ∞. Hence, in the thermodynamic limit, P = 0. 4 For other quantities of interest, we obtain, with the help of equations (4.3.17) through (4.3.20), N = zφ(T ) 1 − zφ(T ) , (17) U = zkT 2φ′(T ) 1 − zφ(T ) , (18) A = NkT ln z + kT ln{1 − zφ(T )}, (19) and S = −Nk ln z − k ln{1 − zφ(T )} + zkT φ′(T ) 1 − zφ(T ) . (20) From (17), we get zφ(T ) = N N + 1 ≃ 1 − 1 N (N ≫ 1). (21) 4It will be seen in the sequel that P actually vanishes like (ln N)/N. 4.4 Examples 101 It follows that 1 − zφ(T ) = 1 N + 1 ≃ 1 N . (22) Equations (17) through (20) now give U/N = kT 2φ′(T )/φ(T ), (18a) A/N = −kT ln φ(T ) + O( ln N N ) , (19a) and S/Nk = ln φ(T ) + T φ′(T )/φ(T ) + O( ln N N ) . (20a) Substituting φ(T ) = [2 sinh(ℏω/2kT )]−1 (23) into these formulae, we obtain results pertaining to a system of quantum-mechanical, one-dimensional harmonic oscillators. The substitution φ(T ) = kT /ℏω, (24) on the other hand, leads to results pertaining to a system of classical, one-dimensional harmonic oscillators. As a corollary, we examine here the problem of solid–vapor equilibrium. Consider a single-component system, having two phases — solid and vapor — in equilibrium, con- tained in a closed vessel of volume V at temperature T . Since the phases are free to exchange particles, a state of mutual equilibrium would imply that their chemical poten- tials are equal; this, in turn, means that they have a common fugacity as well. Now, the fugacity zg of the gaseous phase is given by, see equation (6), zg = Ng Vg f (T ) , (25) where Ng is the number of particles in the gaseous phase and Vg the volume occupied by them; in a typical case, Vg ≃ V . The fugacity zs of the solid phase, on the other hand, is given by equation (21): zs ≃ 1 φ(T ) . (26) Equating (25) and (26), we obtain for the equilibrium particle density in the vapor phase Ng /Vg = f (T )/φ(T ). (27) 102 Chapter 4. The Grand Canonical Ensemble Now, if the density in the vapor phase is sufﬁciently low and the temperature of the system sufﬁciently high, the vapor pressure P would be given by Pvapor = Ng Vg kT = kT f (T ) φ(T ) . (28) To be speciﬁc, we may assume the vapor to be monatomic; the function f (T ) is then of the form f (T ) = (2πmkT ) 3/2/h3. (29) On the other hand, if the solid phase can be approximated by a set of three-dimensional harmonic oscillators characterized by a single frequency ω (the Einstein model), the function φ(T ) would be φ(T ) = [2 sinh(hω/2kT )]−3. (30) However, there is one important difference here. An atom in a solid is energetically more stabilized than an atom that is free — that is why a certain threshold energy is required to transform a solid into separate atoms. Let ε denote the value of this energy per atom, which in a way implies that the zeros of the energy spectra εg and εs, which led to the functions (29) and (30), respectively, are displaced with respect to one another by an amount ε. A true comparison between the functions f (T ) and φ(T ) must take this into account. As a result, we obtain for the vapor pressure Pvapor = kT ( 2π mkT h2 )3/2 [2 sinh(ℏω/2kT )]3e−ε/kT . (31) In passing, we note that equation (27) also gives us the necessary condition for the formation of the solid phase. The condition clearly is: N > V f (T ) φ(T ) , (32) where N is the total number of particles in the system. Alternatively, this means that T < Tc, (33) where Tc is a characteristic temperature determined by the implicit relationship f (Tc) φ(Tc) = N V . (34) Once the two phases appear, the number Ng (T ) will have a value determined by equa- tion (27) while the remainder, N − Ng , will constitute the solid phase. 4.5 Density and energy ﬂuctuations in the grand canonical ensemble 103 4.5 Density and energy ﬂuctuations in the grand canonical ensemble: correspondence with other ensembles In a grand canonical ensemble, the variables N and E, for any member of the ensemble, can lie anywhere between zero and inﬁnity. Therefore, on the face of it, the grand canoni- cal ensemble appears to be very different from its predecessors — the canonical and the microcanonical ensembles. However, as far as thermodynamics is concerned, the results obtained from this ensemble turn out to be identical to the ones obtained from the other two. Thus, in spite of strong facial differences, the overall behavior of a given physical sys- tem is practically the same whether it belongs to one kind of ensemble or another. The basic reason for this is that the “relative ﬂuctuations” in the values of the quantities that vary from member to member in an ensemble are practically negligible. Therefore, in spite of the different surroundings that different ensembles provide to a given physical system, the overall behavior of the system is not signiﬁcantly affected. To appreciate this point, we shall evaluate the relative ﬂuctuations in the particle den- sity n and the energy E of a given physical system in the grand canonical ensemble. Recalling that N = ∑ r,s Nre−αNr −βEs ∑ r,s e−αNr −βEs , (1) it readily follows that ( ∂N ∂α ) β,Es = −N 2 + N 2. (2) Thus (1N)2 ≡ N 2 − N 2 = − ( ∂N ∂α ) T ,V = kT ( ∂N ∂µ ) T ,V . (3) From (3), we obtain for the relative mean-square ﬂuctuation in the particle density n (= N/V ) (1n)2 n2 = (1N)2 N 2 = kT N 2 ( ∂N ∂µ ) T ,V . (4) In terms of the variable v (= V /N), we may write (1n)2 n 2 = kTv2 V 2 ( ∂(V /v) ∂µ ) T ,V = − kT V ( ∂v ∂µ ) T . (5) 104 Chapter 4. The Grand Canonical Ensemble To put this result into a more practical form, we recall the thermodynamic relation dµ = v dP − s dT , (6) according to which dµ (at constant T ) = v dP. Equation (5) then takes the form (1n)2 n 2 = − kT V 1 v ( ∂v ∂P ) T = kT V κT , (7) where κT is the isothermal compressibility of the system. Thus, the relative root-mean-square ﬂuctuation in the particle density of the given sys- tem is ordinarily O(N −1/2) and, hence, negligible. However, there are exceptions, like the ones met with in situations accompanying phase transitions. In those situations, the com- pressibility of a given system can become excessively large, as is evidenced by an almost “ﬂattening” of the isotherms. For instance, at a critical point the compressibility diverges, so it is no longer intensive. Finite-size scaling theory described in Chapters 12 and 14 indi- cates that at the critical point the isothermal compressibility scales with system size as κT (Tc) ∼ N γ /dν where γ and ν are certain critical exponents and d is the dimension. For the case of experimental liquid–vapor critical points, κT (Tc) ∼ N 0.63. Accordingly, the root- mean-square density ﬂuctuations grow faster than N 1/2 — in this case, like N 0.82. Thus, in the region of phase transitions, especially at the critical points, we encounter unusu- ally large ﬂuctuations in the particle density of the system. Such ﬂuctuations indeed exist and account for phenomena like critical opalescence. It is clear that under these circum- stances the formalism of the grand canonical ensemble could, in principle, lead to results that are not necessarily identical to the ones following from the corresponding canonical ensemble. In such cases, it is the formalism of the grand canonical ensemble that will have to be preferred because only this one will provide a correct picture of the actual physical situation. We shall now examine ﬂuctuations in the energy of the system. Following the usual procedure, we obtain (1E)2 ≡ E2 − E2 = − ( ∂E ∂β ) z,V = kT 2 ( ∂U ∂T ) z,V . (8) To put expression (8) into a more comprehensible form, we write ( ∂U ∂T ) z,V = ( ∂U ∂T ) N,V + ( ∂U ∂N ) T ,V ( ∂N ∂T ) z,V , (9) where the symbol N is being used interchangeably for N. Now, in view of the fact that N = −( ∂ ∂α ln Q ) β,V , U = −( ∂ ∂β ln Q ) α,V , (10) 4.6 Thermodynamic phase diagrams 105 we have ( ∂N ∂β ) α,V = ( ∂U ∂α ) β,V (11) and, hence, ( ∂N ∂T ) z,V = 1 T ( ∂U ∂µ ) T ,V . (12) Substituting expressions (9) and (12) into equation (8) and remembering that the quantity (∂U/∂T )N,V is the familiar CV , we get (1E)2 = kT 2CV + kT ( ∂U ∂N ) T ,V ( ∂U ∂µ ) T ,V . (13) Invoking equations (3.6.3) and (3), we ﬁnally obtain (1E)2 = ⟨(1E) 2⟩can + {( ∂U ∂N ) T ,V }2 (1N)2. (14) Formula (14) is highly instructive; it tells us that the mean-square ﬂuctuation in the energy E of a system in the grand canonical ensemble is equal to the value it would have in the canonical ensemble plus a contribution arising from the fact that now the particle number N is also ﬂuctuating. Again, under ordinary circumstances, the relative root-mean-square ﬂuctuation in the energy density of the system would be practically negligible. However, in the region of phase transitions, unusually large ﬂuctuations in the value of this variable can arise by virtue of the second term in the formula. 4.6 Thermodynamic phase diagrams One of the great successes of thermodynamics and statistical mechanics over the last 150 years has been in the study of phase transitions. Statistical mechanics provides the basis for accurate models for a wide variety of thermodynamic phases of materials and has led to a detailed understanding of phase transitions and critical phenomena. Condensed materials exist in a variety of phases that depend on thermodynamic parameters such as temperature, pressure, magnetic ﬁeld, and so on. Thermodynamics and statistical mechanics can be used to determine the properties of individual phases, and the locations and characteristics of the phase transitions that occur between those phases. Thermodynamic phases are regions in the phase diagram where the thermody- namics properties are analytic functions of the thermodynamic parameters, while phase transitions are points, lines, or surfaces in the phase diagram where the thermodynamic properties are nonanalytic. Much of the remainder of this text is devoted to using statistical mechanics to explain the properties of material phases and phase transitions. 106 Chapter 4. The Grand Canonical Ensemble P Pc Pt P S S L V Tt Tc T (a) (b) LV Vc V Pc Pt FIGURE 4.2 Sketches (not-to-scale) of the P–T (a) and P–V (b) phase diagrams for argon. This geometry is generic for a wide range of materials. The letters S, L, and V denote solid, liquid, and vapor phases. It is instructive to examine the structure of phase diagrams. Argon provides a good example because the structure of its phase diagram is similar to that of many other mate- rials (see Figure 4.2). At moderate temperatures and pressures, the stable thermodynamic phases of argon are solid, liquid, and vapor. At high temperatures there is a supercritical ﬂuid phase that smoothly connects the liquid and vapor phases. Most materials, includ- ing argon, exhibit multiple solid phases especially at high pressures and low temperatures. Figure 4.2(a) is the phase diagram in the P–T plane and shows the solid–liquid coexis- tence line, the liquid–vapor coexistence line, and the solid–vapor coexistence line. The three lines meet at the triple point (Tt, Pt) and the liquid–vapor coexistence line ends at the critical point (Tc, Pc). The triple point values and critical point values for argon are Tt = 83.8 K, Pt = 68.9 kPa, Tc = 150.7 K, and Pc = 4.86 MPa, respectively. Figure 4.2(b) is the phase diagram in the P–V plane and shows the pressure versus the speciﬁc volume v (= V /N) on the coexistence lines. The dashed lines indicate the triple point pressure and critical pressure in both ﬁgures. The horizontal tie lines are the por- tions of isotherms as they cross coexistence lines and show the discontinuities of v. The tie lines in order from bottom to top are: sublimation tie lines connecting the solid and vapor phases, the triple point tie line that connects all three phases, and a series of solid–liquid and liquid–vapor tie lines. Notice that the liquid and vapor speciﬁc volumes continuously approach each other and are both equal to the critical speciﬁc volume vc at the critical point. The properties of the vapor, liquid, and solid phases are: . The vapor phase is a low-density gas that is accurately described by the ideal-gas equation of state P = nkT with corrections that are described by the virial expansion; see Chapters 6 and 10. 4.6 Thermodynamic phase diagrams 107 . The liquid phase is a dense ﬂuid with strong interactions between the atoms. The ﬂuid exhibits characteristic short-range pair correlations and scattering structure, as discussed in Section 10.7. The structure factor and the pair correlation function for argon, as determined from neutron scattering, are shown in Figure 10.8. For temperatures above the critical temperature Tc, one cannot distinguish between liquid and vapor. The density in this supercritical phase is a smooth function of temperature and pressure from the low-density vapor to the high-density liquid. Virial expansions developed in Sections 10.1 through 10.3 aptly describe the supercritical region. Strictly speaking, one can only distinguish between the liquid and vapor phases on the liquid–vapor coexistence line since it is possible to evolve smoothly from one phase to the other without crossing a phase boundary.. The solid phase is a face-centered cubic crystal structure with long-range order, so the scattering structure factor displays Bragg peaks as described in Section 10.7.B. The thermodynamic properties of solid phases are described in Section 7.3. All equilibrium thermodynamic properties within a single phase are analytic func- tions of the thermodynamic parameters while phase transitions are deﬁned as places in the phase diagram where equilibrium thermodynamic properties are not analytic. Coexis- tence lines, or ﬁrst-order phase transition lines, separate different phases in the P–T phase diagram as shown in Figure 4.2(a). Thermodynamic densities are discontinuous across coexistence lines. This is displayed on the P–V phase diagram in Figure 4.2(b) by hori- zontal tie lines that connect different values the speciﬁc volume takes in the two phases. Generally, all densities such as the speciﬁc volume v = V /N, entropy per particle s = S/N, internal energy density u = U/V , and so on, are discontinuous across ﬁrst-order phase transition lines. The slopes of the coexistence lines in the P–V phase diagram depend on the latent heat of the transition and the speciﬁc volumes of the coexisting phases; see Section 4.7. All three phases coexist at the triple point. The liquid–vapor coexistence line extends from the triple point to the critical point at the end of the ﬁrst-order phase transition line. The speciﬁc volume is discontinuous on the liquid–vapor coexistence line but the size of the discontinuty vanishes at the critical point where the speciﬁc volume is vc; see Figure 4.2(b). All densities are continuous functions of T and P through the critical point. For this reason, critical points are called continuous transitions or, sometimes, second-order phase transitions. Even though thermodynamic densities are continuous, the thermodynamic behavior at the critical point is nonanalytic since, for example, the speciﬁc heat and isothermal compressibility both diverge at the critical point. Another characteristic property of critical points is the divergence of the cor- relation length, which results in a universal behavior of critical points for broad classes of materials. The theory of critical points is developed in Chapters 12, 13, and 14. Classical statistical mechanics provides a framework for understanding the phase dia- grams and thermodynamic properties of a wide variety of materials. However, quantum mechanics and quantum statistics play an important role at low temperatures when the size of the thermal deBroglie wavelength λ = h/√ 2π mkT is of the same order as the 108 Chapter 4. The Grand Canonical Ensemble P S superfluid L V Ps Pc Tc T T\u0002 FIGURE 4.3 Sketch of the P–T phase diagram for helium-4. The letters S, L, and V denote solid, liquid, and vapor phases. The critical point is Tc = 5.19 K and Pc = 227 kPa = 2.24 atm. The solid–liquid coexistence curve starts at Ps = 2.5 MPa = 25 atm at T = 0 K and does not intersect the liquid–vapor coexistence curve. The λ-line is the continuous phase transition between the normal liquid and the superﬂuid phase. The superﬂuid phase transition temperature at the liquid–vapor coexistence line is Tλ = 2.18 K. average distance between molecules. This is the case with liquid helium at temperatures below a few degrees kelvin. The phase diagram of helium-4 is shown in Figure 4.3. Some aspects of the phase diagram are similar to the phase diagram of argon. Both helium and argon have liquid–vapor coexistence lines that end in critical points and both have crystalline solid phases at low temperatures. Three differences between the two phase diagrams are most notable: the solid phase for helium only exists for pressures greater than Ps = 2.5 GPa = 25 atm, the liquid phase of helium extends all the way to zero temperature, and helium-4 exhibits a superﬂuid phase below Tλ = 2.18 K. The superﬂuid phase exhibits remarkable properties: zero viscosity, quantized ﬂow, propagating heat modes, and macroscopic quantum coherence. This extraordinary behavior is due to the Bose-Einstein statistics of 4He atoms and a Bose– Einstein condensation into a macroscopic quantum state as discussed in Sections 7.1 and 11.2 through 11.6. Even the solid phase of helium-4 shows evidence of a macroscopic quantum state with the observation of a “supersolid” phase by Kim and Chan (2004). By contrast, 3He atoms obey Fermi–Dirac statistics and display very different behav- iors from 4He atoms at low temperatures. The geometry of the phase diagram of helium-3 is similar to that of helium-4 except that the critical temperature is lower (Tc = 3.35 K compared to 5.19 K) and the solid phase forms at 30 atm of pressure rather than 25 atm. The dramatic difference is the lack of a superﬂuid phase near 1 K in helium-3. Helium- 3 remains a normal liquid all the way down to about 10 millikelvin. The properties of the normal liquid phase of helium-3 are described by the theory of degenerate Fermi gases and the Fermi liquid theory developed in Chapter 8 and Sections 11.7 and 11.8. The superﬂuid state that forms at millikelvin temperatures is the result of Bardeen, Cooper, and Schrieffer (BCS) p-wave pairing between atoms near the Fermi surface; this pairing is discussed in Section 11.9. 4.7 Phase equilibrium and the Clausius–Clapeyron equation 109 4.7 Phase equilibrium and the Clausius–Clapeyron equation The thermodynamic properties of the phases of a material determine the geometry of the phase diagram. In particular, the Gibbs free energy G(N, P, T ) = U − TS + PV = A + PV = µ(P, T )N (1) determines the locations of the phase boundaries. Note that the chemical potential is the Gibbs free energy per molecule; see Problem 4.6 and Appendix H. Consider a cylinder con- taining N molecules held at constant pressure P and constant temperature T , that is, in an isothermal, isobaric assembly. Suppose the cylinder initially contains two phases: vapor (A) and liquid (B) so that the total number of molecules is N = NA + NB and the Gibbs free energy is G = GA(NA, P, T ) + GB(NB, P, T ). If the two phases do not coexist at this pres- sure and temperature, the numbers of molecules in each phase will change as the system approaches equilibrium. As the number of molecules in each phase changes, the Gibbs free energy changes by an amount dG = ( ∂GA ∂NA ) T ,P dNA + ( ∂GB ∂NB ) T ,P dNB = (µA − µB)dNA, (2) where dNA is the change in the number of molecules in phase A. The Gibbs free energy is minimized at equilibrium, so dG ≤ 0. If µA > µB, the number of molecules in phase B will increase and the number in phase A will decrease as the sys- tem approaches equilibrium. If µA < µB, the number of molecules in phase A will increase and the number in phase B will decrease. If the chemical potentials are equal, the Gibbs free energy is independent of the number of molecules in the two phases. Therefore, the chemical potentials are equal at coexistence: µA = µB. (3) Let’s consider the familiar example of water. At normal pressures and temperatures, water has three phases: liquid water, solid ice, and water vapor, and its P–T phase diagram is similar to that shown for argon in Figure 4.2(a) — the P–V phase diagram for water is somewhat different because the density of the liquid phase is larger than the density of the solid ice phase; see Problems 4.15 and 4.20. At P = 1 atm, water and water vapor coex- ist at T = 100 ◦C, the “boiling point” — while boiling is a nonequilibrium process, boiling begins at the temperature at which the equilibrium vapor pressure is equal to the local atmospheric pressure. Consider a two-phase sample of water and water vapor at T = 99 ◦C. A two-phase sample containing both liquid water and water vapor is easy to create in a constant volume assembly. If there is sufﬁcient volume available, liquid water will evapo- rate until the water vapor pressure reaches the coexistence pressure at that temperature Pσ (99 ◦C) = 0.965 atm. If the applied pressure is then increased to, and held constant at, P = 1 atm while maintaining a constant temperature of T = 99 ◦C, the system will be out of equilibrium. At constant pressure, the system will return to equilibrium by decreasing 110 Chapter 4. The Grand Canonical Ensemble its volume as water vapor condenses into the liquid phase until the the system is com- pletely liquid water. This lowers the Gibbs free energy until it has the equilibrium value determined by the chemical potential of liquid water at this pressure and temperature. On the other hand, if T = 100 ◦C and P = 1 atm, the chemical potentials of the liquid and vapor phases are equal, so any combination of water vapor and liquid water has the same Gibbs free energy. The proportion of water and vapor will change as heat is added or removed. The latent heat of vaporization of water Lv = 540 cal/g = 2260 kJ/kg is the heat needed to convert liquid into vapor. The coexistence pressure Pσ (T ) deﬁnes the phase boundary between any two phases in the P–T plane, as shown in Figure 4.2(a). From equation (3), the coexistence pressure obeys µA(Pσ (T ), T ) = µB(Pσ (T ), T ). (4) The derivatives of the chemical potentials are related by ( ∂µA ∂T ) P + ( ∂µA ∂P ) T dPσ dT = ( ∂µB ∂T ) P + ( ∂µB ∂P ) T dPσ dT , (5) while the entropy per particle s = S/N and speciﬁc volume v = V /N are given by s = − ( ∂µ ∂T ) P , (6a) v = ( ∂µ ∂P ) T ; (6b) see equation (4.5.6). Equations (5) and (6) give the Clausius–Clapeyron equation dPσ dT = sB − sA vB − vA = 1s 1v = L T 1v , (7) where L = T 1s is the latent heat per particle. The slope of the coexistence curve depends on the discontinuities of the entropy per particle and the volume per particle. Equation (7) applies very generally to all ﬁrst-order phase transitions and can be used to determine the coexistence curve as a function of temperature; see Section 4.4, Problems 4.11, and 4.14 through 4.16. At a triple point, the chemical potentials of three phases are equal: µA = µB = µC. (8) The slopes of the three coexistence lines that deﬁne the triple point are related since 1sAB + 1sBC + 1sCA = 0 and 1vAB + 1vBC + 1vCA = 0. This guarantees that each coexis- tence line between two phases at the triple point “points into” the third phase; see Problem 4.17. Problems 111 Problems 4.1. Show that the entropy of a system in the grand canonical ensemble can be written as S = −k ∑ r,s Pr,s ln Pr,s, where Pr,s is given by equation (4.1.9). 4.2. In the thermodynamic limit (when the extensive properties of the system become inﬁnitely large, while the intensive ones remain constant), the q-potential of the system may be calculated by taking only the largest term in the sum ∞∑ Nr =0 zNr QNr (V , T ). Verify this statement and interpret the result physically. 4.3. A vessel of volume V (0) contains N (0) molecules. Assuming that there is no correlation whatsoever between the locations of the various molecules, calculate the probability, P(N, V ), that a region of volume V (located anywhere in the vessel) contains exactly N molecules. (a) Show that N = N (0)p and (1N)r.m.s. = {N (0)p(1 − p)}1/2, where p = V /V (0). (b) Show that if both N (0)p and N (0)(1 − p) are large numbers, the function P(N, V ) assumes a Gaussian form. (c) Further, if p ≪ 1 and N ≪ N (0), show that the function P(N, V ) assumes the form of a Poisson distribution: P(N) = e−N (N)N N! . 4.4. The probability that a system in the grand canonical ensemble has exactly N particles is given by p(N) = zN QN (V , T ) Q(z, V , T ) . Verify this statement and show that in the case of a classical, ideal gas the distribution of particles among the members of a grand canonical ensemble is identically a Poisson distribution. Calculate the root-mean-square value of (1N) for this system both from the general formula (4.5.3) and from the Poisson distribution, and show that the two results are the same. 4.5. Show that expression (4.3.20) for the entropy of a system in the grand canonical ensemble can also be written as S = k [ ∂ ∂T (Tq)] µ,V . 4.6. Deﬁne the isobaric partition function YN (P, T ) = 1 λ3 ∫ ∞ 0 QN (V , T )e−βPV dV . Show that in the thermodynamic limit the Gibbs free energy (4.7.1) is proportional to ln YN (P, T ). Evaluate the isobaric partition function for a classical ideal gas and show that PV = NkT . [The factor of the cube of the thermal deBroglie wavelength, λ3, serves to make the partition function dimensionless and does not contribute to the Gibbs free energy in the thermodynamic limit.] 4.7. Consider a classical system of noninteracting, diatomic molecules enclosed in a box of volume V at temperature T . The Hamiltonian of a single molecule is given by H(r1, r2, p1, p2) = 1 2m (p 2 1 + p 2 2) + 1 2 K |r1 − r2|2. Study the thermodynamics of this system, including the dependence of the quantity ⟨r2 12⟩ on T . 112 Chapter 4. The Grand Canonical Ensemble 4.8. Determine the grand partition function of a gaseous system of “magnetic” atoms (with J = 1 2 and g = 2) that can have, in addition to the kinetic energy, a magnetic potential energy equal to µBH or −µBH, depending on their orientation with respect to an applied magnetic ﬁeld H. Derive an expression for the magnetization of the system, and calculate how much heat will be given off by the system when the magnetic ﬁeld is reduced from H to zero at constant volume and constant temperature. 4.9. Study the problem of solid–vapor equilibrium (Section 4.4) by setting up the grand partition function of the system. 4.10. A surface with N0 adsorption centers has N(≤ N0) gas molecules adsorbed on it. Show that the chemical potential of the adsorbed molecules is given by µ = kT ln N (N0 − N)a(T ) , where a(T ) is the partition function of a single adsorbed molecule. Solve the problem by constructing the grand partition function as well as the partition function of the system. [Neglect the intermolecular interaction among the adsorbed molecules.] 4.11. Study the state of equilibrium between a gaseous phase and an adsorbed phase in a single- component system. Show that the pressure in the gaseous phase is given by the Langmuir equation Pg = θ 1 − θ × (a certain function of temperature), where θ is the equilibrium fraction of the adsorption sites that are occupied by the adsorbed molecules. 4.12. Show that for a system in the grand canonical ensemble {(NE) − N E} = ( ∂U ∂N ) T ,V (1N)2. 4.13. Deﬁne a quantity J as J = E − Nµ = TS − PV . Show that for a system in the grand canonical ensemble (1J)2 = kT 2CV + {( ∂U ∂N ) T ,V − µ }2 (1N)2. 4.14. Assuming that the latent heat of vaporization of water Lv = 2260 kJ/kg is independent of temperature and the speciﬁc volume of the liquid phase is negligible compared to the speciﬁc volume of the vapor phase, vvapor = kT /Pσ (T ), integrate the Clausius–Clapeyron equation (4.7.7) to obtain the coexistence pressure as a function of temperature. Compare your result to the experimental vapor pressure of water from the triple point to 200 ◦C. The equilibrium vapor pressure at 373 K is 101 kPa = 1 atm. 4.15. Assuming that the latent heat of sublimation of ice Ls = 2500 kJ/kg is independent of temperature and the speciﬁc volume of the solid phase is negligible compared to the speciﬁc volume of the vapor phase, vvapor = kT /Pσ (T ), integrate the Clausius–Clapeyron equation (4.7.7) to obtain the coexistence pressure as a function of temperature. Compare your result to the experimental vapor pressure of ice from T = 0 to the triple point. The equilibrium vapor pressure at the triple point is 612 Pa. 4.16. Calculate the slope of the solid-liquid transition line for water near the triple point T = 273.16 K, given that the latent heat of melting is 80 cal/g, the density of the liquid phase is 1.00 g/cm3, and the density of the ice phase is 0.92 g/cm3. Estimate the melting temperature at P = 100 atm. Problems 113 4.17. Show that the Clausius–Clapeyron equation (4.7.7) guarantees that each of the coexistence curves at the triple point of a material “points into” the third phase; for example, the slope of the solid–vapor coexistence line has a value in-between the slopes of the the the solid–liquid and liquid–vapor coexistence lines. 4.18. Sketch the P–V phase diagram for helium-4 using the sketch of the P–T phase diagram in Figure 4.3. 4.19. Derive the equivalent of the Clausius–Clapeyron equation (4.7.7) for the slope of the coexistence chemical potential as a function of temperature. Use the fact that the pressures P(µ, T ) in two different phases are equal on the coexistence curve. 4.20. Sketch the P–T and P–V phase diagrams of water, taking into account the fact that the mass density of the liquid phase is larger than the mass density of the solid phase. 5 Formulation of Quantum Statistics The scope of the ensemble theory developed in Chapters 2 through 4 is extremely general, though the applications considered so far were conﬁned either to classical systems or to quantum-mechanical systems composed of distinguishable entities. When it comes to quantum-mechanical systems composed of indistinguishable entities, as most physical systems are, considerations of the preceding chapters have to be applied with care. One ﬁnds that in this case it is advisable to rewrite ensemble theory in a language that is more natural to a quantum-mechanical treatment, namely the language of the operators and the wavefunctions. Insofar as statistics are concerned, this rewriting of the theory may not seem to introduce any new physical ideas as such; nonetheless, it provides us with a tool that is highly suited for studying typical quantum systems. And once we set out to study these systems in detail, we encounter a stream of new, and altogether different, physical concepts. In particular, we ﬁnd that the behavior of even a noninteracting system, such as the ideal gas, departs considerably from the pattern set by the classical treatment. In the presence of interactions, the pattern becomes even more complicated. Of course, in the limit of high temperatures and low densities, the behavior of all physical systems tends asymptotically to what we expect on classical grounds. In the process of demonstrating this point, we automatically obtain a criterion that tells us whether a given physical sys- tem may or may not be treated classically. At the same time, we obtain rigorous evidence in support of the procedure, employed in the previous chapters, for computing the number, 0, of microstates (corresponding to a given macrostate) of a given system from the vol- ume, ω, of the relevant region of its phase space, namely 0 ≈ ω/h f , where f is the number of “degrees of freedom” in the problem. 5.1 Quantum-mechanical ensemble theory: the density matrix We consider an ensemble of N identical systems, where N ≫ 1. These systems are char- acterized by a (common) Hamiltonian, which may be denoted by the operator ˆH. At time t, the physical states of the various systems in the ensemble will be characterized by the wavefunctions ψ(ri, t), where ri denote the position coordinates relevant to the sys- tem under study. Let ψ k(ri, t) denote the (normalized) wavefunction characterizing the physical state in which the kth system of the ensemble happens to be at time t; natu- rally, k = 1, 2, . . . , N . The time variation of the function ψ k(t) will be determined by the Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00005-0 © 2011 Elsevier Ltd. All rights reserved. 115 116 Chapter 5. Formulation of Quantum Statistics Schr¨odinger equation 1 ˆHψ k(t) = iℏ ˙ψ k(t). (1) Introducing a complete set of orthonormal functions φn, the wavefunctions ψ k(t) may be written as ψ k(t) = ∑ n ak n(t)φn, (2) where ak n(t) = ∫ φ∗ nψ k(t)dτ ; (3) here, φ∗ n denotes the complex conjugate of φn while dτ denotes the volume element of the coordinate space of the given system. Clearly, the physical state of the kth system can be described equally well in terms of the coefﬁcients ak n(t). The time variation of these coefﬁcients will be given by iℏ ˙ak n(t) = iℏ ∫ φ∗ n ˙ψ k(t)dτ = ∫ φ∗ n ˆHψ k(t)dτ = ∫ φ∗ n ˆH{ ∑ m ak m(t)φm } dτ = ∑ m Hnmak m(t), (4) where Hnm = ∫ φ∗ n ˆHφmdτ . (5) The physical signiﬁcance of the coefﬁcients ak n(t) is evident from equation (2). They are the probability amplitudes for the various systems of the ensemble to be in the various states φn; to be practical, the number |ak n(t)|2 represents the probability that a measure- ment at time t ﬁnds the kth system of the ensemble to be in the particular state φn. Clearly, we must have ∑ n |ak n(t)| 2 = 1 (for all k). (6) We now introduce the density operator ˆρ(t), as deﬁned by the matrix elements ρmn(t) = 1 N N∑ k=1 { ak m(t)ak∗ n (t)} ; (7) clearly, the matrix element ρmn(t) is the ensemble average of the quantity am(t)a∗ n(t), which, as a rule, varies from member to member in the ensemble. In particular, the diagonal element ρnn(t) is the ensemble average of the probability |an(t)|2, the latter 1For simplicity of notation, we suppress the coordinates ri in the argument of the wavefunction ψ k. 5.1 Quantum-mechanical ensemble theory: the density matrix 117 itself being a (quantum-mechanical) average. Thus, we encounter here a double-averaging process — once due to the probabilistic aspect of the wavefunctions and again due to the statistical aspect of the ensemble. The quantity ρnn(t) now represents the probability that a system, chosen at random from the ensemble, at time t, is found to be in the state φn. In view of equations (6) and (7), ∑ n ρnn = 1. (8) We shall now determine the equation of motion for the density matrix ρmn(t). We obtain, with the help of the foregoing equations, iℏ ˙ρmn(t) = 1 N N∑ k=1 [ iℏ { ˙ak m(t)ak∗ n (t) + ak m(t) ˙ak∗ n (t)}] = 1 N N∑ k=1 [{ ∑ l Hmlak l (t)} ak∗ n (t) − ak m(t) { ∑ l H ∗ nlak∗ l (t) }] = ∑ l {Hmlρln(t) − ρml(t)Hln} = ( ˆH ˆρ − ˆρ ˆH)mn; (9) here, use has been made of the fact that, in view of the Hermitian character of the operator ˆH, H ∗ nl = Hln. Using the commutator notation, equation (9) may be written as iℏ ˙ˆρ = [ ˆH, ˆρ]−. (10) Equation (10) is the quantum-mechanical analog of the classical equation (2.2.10) of Liouville. As expected in going from a classical equation of motion to its quantum- mechanical counterpart, the Poisson bracket [ρ, H] has given place to the commutator ( ˆρ ˆH − ˆH ˆρ)/iℏ. If the given system is known to be in a state of equilibrium, the corresponding ensemble must be stationary, that is, ˙ρmn = 0. Equations (9) and (10) then tell us that, for this to be the case, (i) the density operator ˆρ must be an explicit function of the Hamiltonian operator ˆH (for then the two operators will necessarily commute) and (ii) the Hamiltonian must not depend explicitly on time, that is, we must have (i) ˆρ = ˆρ( ˆH) and (ii) ˙ˆH = 0. Now, if the basis functions φn were the eigenfunctions of the Hamiltonian itself, then the matrices H and ρ would be diagonal: Hmn = Enδmn, ρmn = ρnδmn. (11)2 2It may be noted that in this (so-called energy) representation the density operator ˆρ may be written as ˆρ = ∑ n |φn⟩ρn⟨φn|, (12) for then ρkl = ∑ n ⟨φk|φn⟩ρn⟨φn|φl⟩ = ∑ n δknρnδnl = ρkδkl. 118 Chapter 5. Formulation of Quantum Statistics The diagonal element ρn, being a measure of the probability that a system, chosen at ran- dom (and at any time) from the ensemble, is found to be in the eigenstate φn, will naturally depend on the corresponding eigenvalue En of the Hamiltonian; the precise nature of this dependence is, however, determined by the “kind” of ensemble we wish to construct. In any representation other than the energy representation, the density matrix may or may not be diagonal. However, quite generally, it will be symmetric: ρmn = ρnm. (13) The physical reason for this symmetry is that, in statistical equilibrium, the tendency of a physical system to switch from one state (in the new representation) to another must be counterbalanced by an equally strong tendency to switch between the same states in the reverse direction. This condition of detailed balancing is essential for the maintenance of an equilibrium distribution within the ensemble. Finally, we consider the expectation value of a physical quantity G, which is dynami- cally represented by an operator ˆG. This will be given by ⟨G⟩ = 1 N N∑ k=1 ∫ ψ k∗ ˆGψ kdτ . (14) In terms of the coefﬁcients ak n, ⟨G⟩ = 1 N N∑ k=1 [ ∑ m,n ak∗ n ak mGnm ] , (15) where Gnm = ∫ φ∗ n ˆGφmdτ . (16) Introducing the density matrix ρ, equation (15) becomes ⟨G⟩ = ∑ m,n ρmnGnm = ∑ m ( ˆρ ˆG)mm = Tr( ˆρ ˆG). (17) Taking ˆG = ˆ1, where ˆ1 is the unit operator, we have Tr( ˆρ) = 1, (18) which is identical to (8). It should be noted here that if the original wavefunctions ψ k were not normalized then the expectation value ⟨G⟩ would be given by the formula ⟨G⟩ = Tr( ˆρ ˆG) Tr( ˆρ) (19) 5.2 Statistics of the various ensembles 119 instead. In view of the mathematical structure of formulae (17) and (19), the expectation value of any physical quantity G is manifestly independent of the choice of the basis {φn}, as it indeed should be. 5.2 Statistics of the various ensembles 5.2.A The microcanonical ensemble The construction of the microcanonical ensemble is based on the premise that the sys- tems constituting the ensemble are characterized by a ﬁxed number of particles N, a ﬁxed volume V , and an energy lying within the interval (E − 1 2 1, E + 1 2 1), where 1 ≪ E. The total number of distinct microstates accessible to a system is then denoted by the sym- bol 0(N, V , E; 1) and, by assumption, any one of these microstates is as likely to occur as any other. This assumption enters into our theory in the nature of a postulate and is often referred to as the postulate of equal a priori probabilities for the various accessible states. Accordingly, the density matrix ρmn (which, in the energy representation, must be a diagonal matrix) will be of the form ρmn = ρnδmn, (1) with ρn =    1/ 0 for each of the accessible states, 0 for all other states; (2) the normalization condition (5.1.18) is clearly satisﬁed. As we already know, the thermody- namics of the system is completely determined from the expression for its entropy which, in turn, is given by S = k ln 0. (3) Since 0, the total number of distinct, accessible states, is supposed to be computed quantum-mechanically, taking due account of the indistinguishability of the particles right from the beginning, no paradox, such as Gibbs’, is now expected to arise. Moreover, if the quantum state of the system turns out to be unique (0 = 1), the entropy of the sys- tem will identically vanish. This provides us with a sound theoretical basis for the hitherto empirical theorem of Nernst (also known as the third law of thermodynamics). The situation corresponding to the case 0 = 1 is usually referred to as a pure case. In such a case, the construction of an ensemble is essentially superﬂuous, because every sys- tem in the ensemble has got to be in one and the same state. Accordingly, there is only one diagonal element ρnn that is nonzero (actually equal to unity), while all others are zero. The 120 Chapter 5. Formulation of Quantum Statistics density matrix, therefore, satisﬁes the relation ρ2 = ρ. (4) In a different representation, the pure case will correspond to ρmn = 1 N N∑ k=1 ak mak∗ n = ama∗ n (5) because all values of k are now literally equivalent. We then have ρ2 mn = ∑ l ρmlρln = ∑ l ama∗ l ala∗ n = ama∗ n (because ∑ l a∗ l al = 1 ) = ρmn. (6) Relation (4) thus holds in all representations. A situation in which 0 > 1 is usually referred to as a mixed case. The density matrix, in the energy representation, is then given by equations (1) and (2). If we now change over to any other representation, the general form of the density matrix should remain the same, namely (i) the off-diagonal elements should continue to be zero, while (ii) the diagonal elements (over the allowed range) should continue to be equal to one another. Now, had we constructed our ensemble on a representation other than the energy representation right from the beginning, how could we have possibly anticipated ab initio property (i) of the density matrix, though property (ii) could have been easily invoked through a pos- tulate of equal a priori probabilities? To ensure that property (i), as well as property (ii), holds in every representation, we must invoke yet another postulate, namely the postulate of random a priori phases for the probability amplitudes ak n, which in turn implies that the wavefunction ψ k, for all k, is an incoherent superposition of the basis {φn}. As a con- sequence of this postulate, coupled with the postulate of equal a priori probabilities, we would have in any representation ρmn ≡ 1 N N∑ k=1 ak mak∗ n = 1 N N∑ k=1 |a| 2ei(θ k m−θ k n) = c 〈ei( θ k m−θ k n)〉 = cδmn, (7) as it should be for a microcanonical ensemble. Thus, contrary to what might have been expected on customary grounds, to secure the physical situation corresponding to a microcanonical ensemble, we require in general two 5.2 Statistics of the various ensembles 121 postulates instead of one! The second postulate arises solely from quantum-mechanics and is intended to ensure noninterference (and hence a complete absence of correlations) among the member systems; this, in turn, enables us to form a mental picture of each system of the ensemble, one at a time, completely disentangled from other systems. 5.2.B The canonical ensemble In this ensemble the macrostate of a member system is deﬁned through the parameters N, V , and T ; the energy E is now a variable quantity. The probability that a system, chosen at random from the ensemble, possesses an energy Er is determined by the Boltzmann factor exp (−βEr), where β = 1/kT ; see Sections 3.1 and 3.2. The density matrix in the energy representation is, therefore, taken as ρmn = ρnδmn, (8) with ρn = C exp (−βEn); n = 0, 1, 2, . . . (9) The constant C is determined by the normalization condition (5.1.18), whereby C = 1 ∑ n exp (−βEn) = 1 QN (β) , (10) where QN (β) is the partition function of the system. In view of equations (5.1.12), see footnote 2, the density operator in this ensemble may be written as ˆρ = ∑ n |φn⟩ 1 QN (β) e−βEn ⟨φn| = 1 QN (β) e−β ˆH ∑ n |φn⟩⟨φn| = 1 QN (β) e−β ˆH = e−β ˆH Tr (e−β ˆH ) , (11) for the operator ∑n |φn⟩⟨φn| is identically the unit operator. It is understood that the operator exp (−β ˆH) in equation (11) stands for the sum ∞∑ j=0(−1) j (β ˆH) j j! . (12) 122 Chapter 5. Formulation of Quantum Statistics The expectation value ⟨G⟩N of a physical quantity G, which is represented by an operator ˆG, is now given by ⟨G⟩N = Tr( ˆρ ˆG) = 1 QN (β) Tr( ˆGe−β ˆH ) = Tr( ˆGe−β ˆH ) Tr( e−β ˆH ) ; (13) the sufﬁx N here emphasizes the fact that the averaging is being done over an ensemble with N ﬁxed. 5.2.C The grand canonical ensemble In this ensemble the density operator ˆρ operates on a Hilbert space with an indeﬁ- nite number of particles. The density operator must therefore commute not only with the Hamiltonian operator ˆH but also with a number operator ˆn whose eigenvalues are 0, 1, 2, . . .. The precise form of the density operator can now be obtained by a straightfor- ward generalization of the preceding case, with the result ˆρ = 1 Q(µ, V , T ) e−β( ˆH−µ ˆn), (14) where Q(µ, V , T ) = ∑ r,s e−β(Er −µNs) = Tr{e−β( ˆH−µ ˆn)}. (15) The ensemble average ⟨G⟩ is now given by ⟨G⟩ = 1 Q(µ, V , T ) Tr ( ˆGe−β ˆH eβµ ˆn) = ∞∑ N=0 zN ⟨G⟩N QN (β) ∞∑ N=0 zN QN (β) , (16) where z(≡ eβµ) is the fugacity of the system while ⟨G⟩N is the canonical-ensemble average, as given by equation (13). The quantity Q(µ, V , T ) appearing in these formulae is, clearly, the grand partition function of the system. 5.3 Examples 5.3.A An electron in a magnetic ﬁeld We consider, for illustration, the case of a single electron that possesses an intrinsic spin 1 2 ℏ ˆσ and a magnetic moment µB, where ˆσ is the Pauli spin operator and µB = eℏ/2mc. 5.3 Examples 123 The spin of the electron can have two possible orientations, ↑ or ↓, with respect to an applied magnetic ﬁeld B. If the applied ﬁeld is taken to be in the direction of the z-axis, the conﬁgurational Hamiltonian of the spin takes the form ˆH = −µB ( ˆσ · B) = −µB B ˆσz. (1) In the representation that makes ˆσz diagonal, namely ˆσx = ( 0 1 1 0 ) , ˆσy = (0 −i i 0 ) , ˆσz = (1 0 0 −1 ) , (2) the density matrix in the canonical ensemble would be ( ˆρ) = ( e−β ˆH ) Tr (e−β ˆH ) (3) = 1 eβµ B B + e−βµ B B ( eβµB B 0 0 e−βµ B B ) . We thus obtain for the expectation value σz ⟨σz⟩ = Tr( ˆρ ˆσz) = eβµB B − e−βµ B B eβµB B + e−βµ B B = tanh(βµB B), (4) in perfect agreement with the ﬁndings of Sections 3.9 and 3.10. 5.3.B A free particle in a box We now consider the case of a free particle, of mass m, in a cubical box of side L. The Hamiltonian of the particle is given by ˆH = − ℏ2 2m ∇2 = − ℏ2 2m ( ∂ 2 ∂x2 + ∂ 2 ∂y2 + ∂ 2 ∂z2 ) , (5) while the eigenfunctions of the Hamiltonian that satisfy periodic boundary conditions, φ(x + L, y, z) = φ(x, y + L, z) = φ(x, y, z + L) = φ(x, y, z), (6) are given by φE (r) = 1 L3/2 exp (ik · r), (7) the corresponding eigenvalues E being E = ℏ2k2 2m , (8) 124 Chapter 5. Formulation of Quantum Statistics and the corresponding wave vector k being k ≡ (kx, ky, kz) = 2π L (nx, ny, nz); (9) the quantum numbers nx, ny, and nz must be integers (positive, negative, or zero). Symbolically, we may write k = 2π L n, (10) where n is a vector with integral components 0, ±1, ±2, . . .. We now proceed to evaluate the density matrix ( ˆρ) of this system in the canonical ensemble; we shall do so in the coordinate representation. In view of equation (5.2.11), we have ⟨r|e−β ˆH |r′⟩ = ∑ E ⟨r|E⟩e−βE ⟨E|r′⟩ (11) = ∑ E e−βE φE (r)φ∗ E (r′). Substituting from equation (7) and making use of relations (8) and (10), we obtain ⟨r|e−β ˆH |r′⟩ = 1 L3 ∑ k exp [ − βℏ2 2m k2 + ik · (r − r′) ] ≈ 1 (2π)3 ∫ exp [ − βℏ2 2m k2 + ik · (r − r′) ] d3k = ( m 2πβℏ2 )3/2 exp [ − m 2βℏ2 |r − r′| 2] ; (12) see equations (B.41) and (B.42) in Appendix B. It follows that Tr(e−β ˆH ) = ∫ ⟨r|e−β ˆH |r⟩d3r = V ( m 2πβℏ2 )3/2 . (13) The expression in equation (13) is indeed the partition function, Q1(β), of a single particle conﬁned to a box of volume V ; see equation (3.5.19). Dividing (12) by (13), we obtain for the density matrix in the coordinate representation ⟨r| ˆρ|r′⟩ = 1 V exp [ − m 2βℏ2 |r − r′| 2] . (14) As expected, the matrix ρr,r′ is symmetric between the states r and r′. Moreover, the diagonal element ⟨r|ρ|r⟩, which represents the probability density for the particle to be in 5.3 Examples 125 the neighborhood of the point r, is independent of r; this means that, in the case of a sin- gle free particle, all positions within the box are equally likely to obtain. A nondiagonal element ⟨r|ρ|r′⟩, on the other hand, is a measure of the probability of “spontaneous tran- sition” between the position coordinates r and r′ and is therefore a measure of the relative “intensity” of the wave packet (associated with the particle) at a distance |r − r′| from the center of the packet. The spatial extent of the wave packet, which is a measure of the uncer- tainty involved in locating the position of the particle, is clearly of order ℏ/(mkT )1/2; the latter is also a measure of the mean thermal wavelength of the particle. The spatial spread found here is a purely quantum-mechanical effect; quite expectedly, it tends to vanish at high temperatures. In fact, as β → 0, the behavior of the matrix element (14) approaches that of a delta function, which implies a return to the classical picture of a point particle. Finally, we determine the expectation value of the Hamiltonian itself. From equa- tions (5) and (14), we obtain ⟨H⟩ = Tr( ˆH ˆρ) = − ℏ2 2mV ∫ { ∇2 exp [ − m 2βℏ2 |r − r′| 2]} r=r′ d3r = 1 2βV ∫ {[3 − m βℏ2 |r − r′|2] exp [− m 2βℏ2 |r − r′|2]} r=r′ d3r = 3 2β = 3 2 kT , (15) which was indeed expected. Otherwise, too, ⟨H⟩ = Tr( ˆHe−β ˆH ) Tr( e−β ˆH ) = − ∂ ∂β ln Tr( e−β ˆH ) (16) which, on combination with (13), leads to the same result. 5.3.C A linear harmonic oscillator Next, we consider the case of a linear harmonic oscillator whose Hamiltonian is given by ˆH = − ℏ2 2m ∂ 2 ∂q2 + 1 2 mω2q2, (17) with eigenvalues En = ( n + 1 2 ) ℏω; n = 0, 1, 2, . . . (18) and eigenfunctions φn(q) = ( mω πℏ )1/4 Hn(ξ ) (2nn! )1/2 e−(1/2)ξ 2 , (19) 126 Chapter 5. Formulation of Quantum Statistics where ξ = ( mω ℏ )1/2 q (20) and Hn(ξ ) = (−1) ne ξ 2 ( d dξ )n e−ξ 2 . (21) The matrix elements of the operator exp (−β ˆH) in the q-representation are given by ⟨q|e−β ˆH |q′⟩ = ∞∑ n=0 e−βEn φn(q)φn(q′) = ( mω πℏ )1/2 e−(1/2)(ξ 2+ξ ′2) ∞∑ n=0 { e−(n+1/2)βℏω Hn(ξ )Hn(ξ ′) 2nn! } . (22) The summation over n is somewhat difﬁcult to evaluate; nevertheless, the ﬁnal result is3 ⟨q|e−β ˆH |q′⟩ = [ mω 2πℏ sinh(βℏω) ]1/2 × exp [− mω 4ℏ { (q + q′)2 tanh ( βℏω 2 ) + (q − q′)2 coth ( βℏω 2 )}] , (23) which gives Tr(e−β ˆH ) = ∞∫ −∞ ⟨q|e−β ˆH |q⟩dq = [ mω 2π ℏ sinh(βℏω) ]1/2 ∞∫ −∞ exp [ − mωq2 ℏ tanh ( βℏω 2 )] dq = 1 2 sinh ( 1 2 βℏω) = e−(1/2)βℏω 1 − e−βℏω . (24) Expression (24) is indeed the partition function of a linear harmonic oscillator; see equation (3.8.14). At the same time, we ﬁnd that the probability density for the oscillator coordinate to be in the vicinity of the value q is given by ⟨q| ˆρ|q⟩ =   mω tanh ( 1 2 βℏω) πℏ   1/2 exp [ − mωq2 ℏ tanh ( βℏω 2 )] ; (25) 3The mathematical details of this derivation can be found in Kubo (1965, pp. 175–177). 5.3 Examples 127 we note that this is a Gaussian distribution in q, with mean value zero and root-mean- square deviation qr.m.s. =   ℏ 2mω tanh ( 1 2 βℏω)   1/2 . (26) The probability distribution (25) was ﬁrst derived by Bloch in 1932. In the classical limit (βℏω ≪ 1), the distribution becomes purely thermal — free from quantum effects: ⟨q| ˆρ|q⟩ ≈ ( mω2 2πkT )1/2 exp [ − mω2q2 2kT ] , (27) with dispersion (kT /mω2)1/2. At the other extreme (βℏω ≫ 1), the distribution becomes purely quantum-mechanical — free from thermal effects: ⟨q| ˆρ|q⟩ ≈ ( mω πℏ )1/2 exp [ − mωq2 ℏ ] , (28) with dispersion (ℏ/2mω)1/2. Note that the limiting distribution (28) is precisely the one expected for an oscillator in its ground state (n = 0), that is one with probability density φ2 0(q); see equations (19) through (21). In view of the fact that the mean energy of the oscillator is given by ⟨H⟩ = − ∂ ∂β ln Tr (e−β ˆH ) = 1 2 ℏω coth ( 1 2 βℏω) , (29) we observe that the temperature dependence of the distribution (25) is solely determined by the expectation value ⟨H⟩. Actually, we can write ⟨q| ˆρ|q⟩ = ( mω2 2π ⟨H⟩ )1/2 exp [ − mω2q2 2⟨H⟩ ] , (30) with qr.m.s. = ( ⟨H⟩ mω2 )1/2 . (31) It is now straightforward to see that the mean value of the potential energy ( 1 2 mω2q2) of the oscillator is 1 2 ⟨H⟩; accordingly, the mean value of the kinetic energy (p2/2m) will also be the same. 128 Chapter 5. Formulation of Quantum Statistics 5.4 Systems composed of indistinguishable particles We shall now formulate the quantum-mechanical description of a system of N identical particles. To ﬁx ideas, we consider a gas of noninteracting particles; the ﬁndings of this study will be of considerable relevance to other systems as well. Now, the Hamiltonian of a system of N noninteracting particles is simply a sum of the individual single-particle Hamiltonians: ˆH(q, p) = N∑ i=1 ˆH i(qi, pi); (1) here, (qi, pi) are the coordinates and momenta of the ith particle while ˆH i is its Hamilto- nian. 4 Since the particles are identical, the Hamiltonians ˆH i(i = 1, 2, . . . , N) are formally the same; they only differ in the values of their arguments. The time-independent Schr¨odinger equation for the system is ˆHψE (q) = EψE (q), (2) where E is an eigenvalue of the Hamiltonian and ψE(q) the corresponding eigenfunction. In view of (1), we can write a straightforward solution of the Schr¨odinger equation, namely ψE (q) = N∏ i=1 uεi (qi), (3) with E = N∑ i=1 εi; (4) the factor uεi (qi) in (3) is an eigenfunction of the single-particle Hamiltonian ˆH i(qi, pi), with eigenvalue εi: ˆH iuεi (qi) = εiuεi (qi). (5) Thus, a stationary state of the given system may be described in terms of the single-particle states of the constituent particles. In general, we may do so by specifying the set of num- bers {ni} to represent a particular state of the system; this would imply that there are ni particles in the eigenstate characterized by the energy value εi. Clearly, the distribution set 4We are studying here a single-component system composed of “spinless” particles. Generalization to a system composed of particles with spin and to a system composed of two or more components is quite straightforward. 5.4 Systems composed of indistinguishable particles 129 {ni} must conform to the conditions ∑ i ni = N (6) and ∑ i niεi = E. (7) Accordingly, the wavefunction of this state may be written as ψE (q) = n1∏ m=1 u1(m) n1+n2∏ m=n1+1 u2(m) . . . , (8) where the symbol ui(m) stands for the single-particle wavefunction uεi (qm). Now, suppose we effect a permutation among the coordinates appearing on the right side of (8); as a result, the coordinates (1, 2, . . . , N) get replaced by (P1, P2, . . . , PN), say. The resulting wavefunction, which we may call PψE(q), will be PψE (q) = n1∏ m=1 u1(Pm) n1+n2∏ m=n1+1 u2(Pm) . . . . (9) In classical physics, where the particles of a given system, even though identical, are regarded as mutually distinguishable, any permutation that brings about an interchange of particles in two different single-particle states is recognized to have led to a new, physi- cally distinct, microstate of the system. For example, classical physics regards a microstate in which the so-called 5th particle is in the state ui and the so-called 7th particle in the state uj( j ̸= i) as distinct from a microstate in which the 7th particle is in the state ui and the 5th particle in the state uj. This leads to N! n1! n2! . . . (10) (supposedly distinct) microstates of the system, corresponding to a given mode of distri- bution {ni}. The number (10) would then be ascribed as a “statistical weight factor” to the distribution set {ni}. Of course, the “correction” applied by Gibbs, which has been discussed in Sections 1.5 and 1.6, reduces this weight factor to Wc{ni} = 1 n1! n2! . . . . (11) And the only way one could understand the physical basis of that “correction” was in terms of the inherent indistinguishability of the particles. According to quantum physics, however, the situation remains unsatisfactory even after the Gibbs correction has been incorporated, for, strictly speaking, an interchange 130 Chapter 5. Formulation of Quantum Statistics among identical particles, even if they are in different single-particle states, should not lead to a new microstate of the system! Thus, if we want to take into account the indistin- guishability of the particles properly, we must not regard a microstate in which the “5th” particle is in the state ui and the “7th” in the state uj as distinct from a microstate in which the “7th” particle is in the state ui and the “5th” in the state uj (even if i ̸= j), for the labeling of the particles as No. 1, No. 2, and so on (which one often resorts to) is at most a matter of convenience — it is not a matter of reality. In other words, all that matters in the descrip- tion of a particular state of the given system is the set of numbers ni that tell us how many particles there are in the various single-particle states ui; the question, “which particle is in which single-particle state?” has no relevance at all. Accordingly, the microstates resulting from any permutation P among the N parti- cles (so long as the numbers ni remain the same) must be regarded as one and the same microstate. For the same reason, the weight factor associated with a distribution set {ni}, provided that the set is not disallowed on some other physical grounds, should be identically equal to unity, whatever the values of the numbers ni may be: Wq{ni} ≡ 1. (12)5 Indeed, if for some physical reason the set {ni} is disallowed, the weight factor Wq for that set should be identically equal to zero; see, for instance, equation (19). At the same time, a wavefunction of the type (8), which we may call Boltzmannian and denote by the symbol ψBoltz(q), is inappropriate for describing the state of a system composed of indistinguishable particles because an interchange of arguments among the factors ui and uj, where i ̸= j, would lead to a wavefunction that is both mathematically and physically different from the one we started with. Now, since a mere interchange of the particle coordinates must not lead to a new microstate of the system, the wavefunction ψE(q) must be constructed in such a way that, for all practical purposes, it is insensitive to any interchange among its arguments. The simplest way to do this is to set up a lin- ear combination of all the N! functions of the type (9) that obtain from (8) by all possible permutations among its arguments; of course, the combination must be such that if a per- mutation of coordinates is carried out in it, then the wavefunctions ψ and Pψ must satisfy the property |Pψ| 2 = |ψ| 2. (13) This leads to the following possibilities: Pψ = ψ for all P, (14) 5It may be mentioned here that as early as in 1905 Ehrenfest pointed out that to obtain Planck’s formula for the black-body radiation one must assign equal a priori probabilities to the various distribution sets {ni}. 5.4 Systems composed of indistinguishable particles 131 which means that the wavefunction is symmetric in all its arguments, or Pψ =    +ψ if P is an even permutation, −ψ if P is an odd permutation, (15)6 which means that the wavefunction is antisymmetric in its arguments. We call these wavefunctions ψS and ψA, respectively; their mathematical structure is given by ψS(q) = const. ∑ P PψBoltz(q) (16) and ψA(q) = const. ∑ P δPPψBoltz(q), (17) where δP in the expression for ψA is +1 or −1 according to whether the permutation P is even or odd. We note that the function ψA(q) can be written in the form of a Slater determinant: ψA(q) = const. ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ui(1) ui(2) · · · ui(N) uj(1) uj(2) · · · uj(N) · · · · · · · · · · · · · · · · · · ul(1) ul(2) · · · ul(N) ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ , (18) where the leading diagonal is precisely the Boltzmannian wavefunction while the other terms of the expansion are the various permutations thereof; positive and negative signs in the combination (17) appear automatically as we expand the determinant. On interchang- ing a pair of arguments (which amounts to interchanging the corresponding columns of the determinant), the wavefunction ψA merely changes its sign, as it indeed should. How- ever, if two or more particles happen to be in the same single-particle state, then the corresponding rows of the determinant become identical and the wavefunction vanishes.7 Such a state is physically impossible to realize. We therefore conclude that if a system com- posed of indistinguishable particles is characterized by an antisymmetric wavefunction, 6An even (odd) permutation is one that can be arrived at from the original order by an even (odd) number of “pair interchanges” among the arguments. For example, of the six permutations (1, 2, 3), (2, 3, 1), (3, 1, 2), (1, 3, 2), (3, 2, 1), and (2, 1, 3), of the arguments 1, 2, and 3, the ﬁrst three are even permutations while the last three are odd. A single interchange, among any two arguments, is clearly an odd permutation. 7This is directly related to the fact that if we effect an interchange among two particles in the same single-particle state, then PψA will obviously be identical to ψA. At the same time, if we also have PψA = −ψA, then ψA must be identically zero. 132 Chapter 5. Formulation of Quantum Statistics then the particles of the system must all be in different single-particle states — a result equivalent to Pauli’s exclusion principle for electrons. Conversely, a statistical system composed of particles obeying an exclusion principle must be described by a wavefunction that is antisymmetric in its arguments. The statistics governing the behavior of such particles is called Fermi–Dirac, or simply Fermi; statistics and the constituent particles themselves are referred to as fermions. The statistical weight factor WF.D.{ni} for such a system is unity so long as the ni in the distribution set are either 0 or 1; otherwise, it is zero: WF.D.{ni} =    1 if ∑ i n2 i = N, 0 if ∑ i n2 i > N. (19)8 No such problems arise for systems characterized by symmetric wavefunctions: in partic- ular, we have no restriction whatsoever on the values of the numbers ni. The statistics governing the behavior of such systems is called Bose–Einstein, or simply Bose, statis- tics and the constituent particles themselves are referred to as bosons. 9 The weight factor WB.E.{ni} for such a system is identically equal to 1, whatever the values of the numbers ni: WB.E.{ni} = 1; ni = 0, 1, 2, . . . . (20) It should be pointed out here that there exists an intimate connection between the statistics governing a particular species of particles and the intrinsic spin of the particles. For instance, particles with an integral spin (in units of ℏ, of course) obey Bose–Einstein statistics, while particles with a half-odd integral spin obey Fermi–Dirac statistics. Exam- ples in the ﬁrst category are photons, phonons, π -mesons, gravitons, He 4-atoms, and so on, while those in the second category are electrons, nucleons (protons and neutrons), µ-mesons, neutrinos, He3-atoms, and so on. Finally, it must be emphasized that, although we have derived our conclusions here on the basis of a study of noninteracting systems, the basic results hold for interacting systems as well. In general, the desired wavefunction ψ(q) will not be expressible in terms of the single-particle wavefunctions ui(qm); nonetheless, it will have to be either of the kind ψS(q), satisfying equation (14), or of the kind ψA(q), satisfying equation (15). 8Note that the condition ∑ i n2 i = N would be implies that all ni are either 0 or 1. On the other hand, if any of the ni are greater than 1, the sum ∑ i n2 i would be greater than N. 9Possibilities other than Bose–Einstein and Fermi–Dirac statistics can arise in which the wavefunction changes by a complex phase factor eiθ when particles are interchanged. For topological reasons, this can only happen in two dimen- sions. Quasiparticle excitations with this property are called anyons and, if θ is a rational fraction (other than 1 or 1/2) of 2π, are said to have fractional statistics and they play an important role in the theory of the fractional quantum Hall effect; see Wilczek (1990) and Ezawa (2000). 5.5 The density matrix of a system of free particles 133 5.5 The density matrix and the partition function of a system of free particles Suppose that the given system, which is composed of N indistinguishable, noninteracting particles conﬁned to a cubical box of volume V , is a member of a canonical ensemble characterized by the temperature parameter β. The density matrix of the system in the coordinate representation will be10 ⟨r1, . . . , rN | ˆρ|r′ 1, . . . , r′ N ⟩ = 1 QN (β) ⟨r1, . . . , rN |e−β ˆH |r′ 1, . . . , r′ N ⟩, (1) where QN (β) is the partition function of the system: QN (β) = Tr(e−β ˆH ) = ∫ ⟨r1, . . . , rN |e−β ˆH |r1, . . . , rN ⟩d3N r. (2) For brevity, we denote the vector ri by the letter i and the primed vector r′ i by i′. Further, let ψE(1, . . . , N) denote the eigenfunctions of the Hamiltonian, the sufﬁx E representing the corresponding eigenvalues. We then have ⟨1, . . . , N|e−β ˆH |1 ′, . . . , N ′⟩ = ∑ E e−βE [ψE (1, . . . , N)ψ ∗ E (1 ′, . . . , N ′)] , (3) where the summation goes over all possible values of E; compare to equation (5.3.11). Since the particles constituting the given system are noninteracting, we may express the eigenfunctions ψE(1, . . . , N) and the eigenvalues E in terms of the single-particle wavefunctions ui(m) and the single-particle energies εi. Moreover, we ﬁnd it advisable to work with the wave vectors ki rather than the energies εi; so we write E = ℏ2K 2 2m = ℏ2 2m ( k2 1 + k2 2 + · · · + k2 N ), (4) where the ki on the right side are the wave vectors of the individual particles. Imposing periodic boundary conditions, the normalized single-particle wavefunctions are uk(r) = V −1/2 exp {i(k · r)}, (5) with k = 2πV −1/3n; (6) here, n stands for a three-dimensional vector whose components have values 0, ±1, ±2, . . .. The wavefunction ψ of the total system would then be, see equations (5.4.16) 10For a general survey of the density matrix and its applications, see ter Haar (1961). 134 Chapter 5. Formulation of Quantum Statistics and (5.4.17), ψK (1, . . . , N) = (N! ) −1/2 ∑ P δPP{uk1 (1) . . . ukN (N)}, (7) where the magnitudes of the individual ki are such that (k2 1 + · · · + k2 N ) = K 2. (8) The number δP in the expression for ψK is identically equal to +1 if the particles are bosons; for fermions, it is +1 or −1 according to whether the permutation P is even or odd. Thus, quite generally, we may write δP = (±1)[P], (9) where [P] denotes the order of the permutation; note that the upper sign in this expression holds for bosons while the lower sign holds for fermions. The factor (N! )−1/2 has been introduced here to ensure the normalization of the total wavefunction. Now, it makes no difference to the wavefunction (7) whether the permutations P are carried out on the coordinates 1, . . . , N or on the wave vectors k1, . . . , kN , because after all we are going to sum over all the N! permutations. Denoting the permuted coordinates by P1, . . . , PN and the permuted wave vectors by Pk1, . . . , PkN , equation (7) may be written as ψK (1, . . . , N) = (N! ) −1/2 ∑ P δP {uk1 (P1) . . . ukN (PN)} (10a) = (N! ) −1/2 ∑ P δP {uPk1 (1) . . . uPkN (N)}. (10b) Equations (10a and 10b) may now be substituted into (3), with the result ⟨1, . . . , N|e−β ˆH |1 ′, . . . , N ′⟩ = (N! )−1 ∑ K e−βℏ2K 2/2m ×  ∑ ˜P δ ˜P{uk1 (P1) . . . ukN (PN)} ∑ ˜P δ ˜P{u ∗ ˜Pk1 (1′) . . . u∗ ˜PkN (N ′)}  , (11) where P and ˜P are any of the N! possible permutations. Now, since a permutation among the ki changes the wavefunction ψ at most by a sign, the quantity [ψψ ∗] in (11) is insen- sitive to such a permutation; the same holds for the exponential factor as well. The summation over K is, therefore, equivalent to (1/N! ) times a summation over all the vectors k1, . . . , kN independently of one another. Next, in view of the N-fold summation over the ki, all the permutations ˜P will make equal contributions toward the sum (because they differ from one another only in the 5.5 The density matrix of a system of free particles 135 ordering of the ki). Therefore, we may consider only one of these permutations, say the one for which ˜Pk1 = k1, . . . , ˜PkN = kN (and hence δ ˜P = 1 for both kinds of statistics), and include a factor of (N! ). The net result is: ⟨1, . . . , N|e−β ˆH |1 ′, . . . , N ′⟩ = (N! ) −1 ∑ k1,...,kN e−βℏ2(k2 1+···+k2 N )/2m [ ∑ P δP { uk1 (P1)u∗ k1 (1 ′) } . . . {ukN (PN)u ∗ kN (N ′) }] . (12) Substituting from (5) and noting that, in view of the largeness of V , the summations over the ki may be replaced by integrations, equation (12) becomes ⟨1, . . . , N|e−β ˆH |1′, . . . , N ′⟩ = 1 N! (2π)3N ∑ P δP [∫ e−βℏ2k2 1/2m+ik1·(P1−1′)d3k1 . . . ∫ e−βℏ2k2 N /2m+ikN ·(PN−N ′)d3kN ] (13) = 1 N! ( m 2πβℏ2 )3N/2 ∑ P δP[ f (P1 − 1′) . . . f (PN–N ′)], (14) where f (ξ ) = exp ( − m 2βℏ2 ξ 2). (15) Here, use has been made of the mathematical result (5.3.12), which is clearly a special case of the present formula. Introducing the mean thermal wavelength, often referred to as the thermal deBroglie wavelength, λ = h (2πmkT )1/2 = ℏ ( 2πβ m )1/2 , (16) and rewriting our coordinates as r1, . . . , rN , the diagonal elements among (14) take the form ⟨r1, . . . , rN |e−β ˆH |r1, . . . , rN ⟩ = 1 N! λ3N ∑ P δP[ f (Pr1 − r1) . . . f (PrN − rN )], (17) where f (r) = exp ( − πr2/λ2). (18) 136 Chapter 5. Formulation of Quantum Statistics To obtain the partition function of the system, we have to integrate (17) over all the coordinates involved. However, before we do that, we would like to make some observa- tions on the summation ∑P. First of all, we note that the leading term in this summation, namely the one for which Pri = ri, is identically equal to unity (because f (0) = 1). This is followed by a group of terms in which only one pair interchange (among the coordi- nates) has taken place; a typical term in this group will be f (rj − ri)f (ri − rj) where i ̸= j. This group of terms is followed by other groups of terms in which more than one pair interchange has taken place. Thus, we may write ∑ P = 1 ± ∑ i<j fijfji + ∑ i<j<k fijfjkfki ± · · · , (19) where fij ≡ f (ri − rj); again, note that the upper (lower) signs in this expansion pertain to a system of bosons (fermions). Now, the function fij vanishes rapidly as the distance rij becomes much larger than the mean thermal wavelength λ. It then follows that if the mean interparticle distance, (V /N)1/3, in the system is much larger than the mean thermal wavelength, that is, if nλ 3 = nh3 (2π mkT )3/2 ≪ 1, (20) where n is the particle density in the system, then the sum ∑P in (19) may be approx- imated by unity. Accordingly, the partition function of the system would become, see equation (17), QN (V , T ) ≡ Tr ( e−β ˆH ) ≈ 1 N! λ3N ∫ 1 (d3N r) = 1 N! ( V λ3 )N . (21) This is precisely the result obtained earlier for the classical ideal gas; see equation (3.5.9). Thus, we have obtained from our quantum-mechanical treatment the precise classical limit for the partition function QN (V , T ). Incidentally, we have achieved something more. First, we have automatically recovered here the Gibbs correction factor (1/N! ), which was introduced into the classical treatment on an ad hoc, semi-empirical basis. We, of course, tried to understand its origin in terms of the inherent indistinguishability of the parti- cles. Here, we see it coming in a very natural manner and its source indeed lies in the symmetrization of the wavefunctions of the system (which is ultimately related to the indistinguishability of the particles); compare to Problem 5.4. Second, we ﬁnd here a formal justiﬁcation for computing the number of microstates of a system corresponding to a given region of its phase space by dividing the volume of that region into cells of a “suitable” size and then counting instead the number of these cells. This correspondence becomes all the more transparent by noting that formula (21) 5.5 The density matrix of a system of free particles 137 is exactly equivalent to the classical expression QN (V , T ) = 1 N! ∫ e−β(p2 1+···+p2 N )/2m ( d3Nq d3N p ω0 ) , (22) with ω0 = h3N . Thirdly, in deriving the classical limit we have also evolved a criterion that enables us to determine whether a given physical system can be treated classically; math- ematically, this criterion is given by condition (20). Now, in statistical mechanical studies, a system that cannot be treated classically is said to be degenerate; the quantity nλ3 may, therefore, be regarded as a degeneracy discriminant. Accordingly, the condition that clas- sical considerations may be applicable to a given physical system is that “the value of the degeneracy discriminant of the system be much less than unity.” Next, we note that, in the classical limit, the diagonal elements of the density matrix are given by ⟨r1, . . . , rN | ˆρ|r1, . . . , rN ⟩ ≈ ( 1 V )N , (23) which is simply a product of N factors, each equal to (1/V ). Recalling that, for a single particle in a box of volume V , ⟨r| ˆρ|r⟩ = (1/V ), see equation (5.3.14), we infer that in the classical limit there is no spatial correlation among the various particles of the system. In general, however, spatial correlations exist even if the particles are supposedly noninter- acting; these correlations arise from the symmetrization of the wavefunctions and their magnitude is quite signiﬁcant if the interparticle distances in the system are comparable with the mean thermal wavelength of the particles. To see this more clearly, we consider the simplest relevant case, namely the one with N = 2. The sum ∑ P is now exactly equal to 1 ± [ f (r12)]2. Accordingly, ⟨r1, r2|e−β ˆH |r1, r2⟩ = 1 2λ6 [ 1 ± exp ( − 2πr2 12/λ2)] (24) and hence Q2(V , T ) = 1 2λ6 ∫∫ [1 ± exp (−2πr2 12/λ2] d3r1d3r2 = 1 2 ( V λ3 )2  1 ± 1 V ∞∫ 0 exp (−2π r2/λ2) 4πr2dr   (25) = 1 2 ( V λ3 )2 [ 1 ± 1 23/2 ( λ3 V )] ≈ 1 2 ( V λ3 )2 . (26) 138 Chapter 5. Formulation of Quantum Statistics Combining (24) and (26), we obtain ⟨r1, r2| ˆρ|r1, r2} ≈ 1 V 2 [1 ± exp ( − 2π r2 12/λ2)]. (27) Thus, if r12 is comparable to λ, the probability density (27) may differ considerably from the classical value (1/V )2. In particular, the probability density for a pair of bosons to be a distance r apart is larger than the classical, r-independent value by a factor of [1 + exp (−2π r2/λ2)], which becomes as high as 2 as r → 0. The corresponding result for a pair of fermions is smaller than the classical value by a factor of [1 − exp (−2π r2/λ2)], which becomes as low as 0 as r → 0. Thus, we obtain a positive spatial correlation among particles obeying Bose statistics and a negative spatial correlation among particles obeying Fermi statistics; see also Section 6.3. Another way of expressing correlations (among otherwise noninteracting particles) is by introducing a statistical interparticle potential vs(r) and then treating the particles classically (see Uhlenbeck and Gropper, 1932). The potential vs(r) must be such that the Boltzmann factor exp (−βvs) is precisely equal to the pair correlation function [. . .] in (27), that is, vs(r) = −kT ln [ 1 ± exp (− 2π r2/λ2)] . (28) Figure 5.1 shows a plot of the statistical potential vs(r) for a pair of bosons or fermions. In the Bose case, the potential is throughout attractive, thus giving rise to a “statistical attraction” among bosons; in the Fermi case, it is throughout repulsive, giving rise to a “statistical repulsion” among fermions. In either case, the potential vanishes rapidly as r becomes larger than λ; accordingly, its inﬂuence becomes less and less important as the temperature of the system rises. \u00021 0 1.0 (r/\u0002)\u0003vs(r) \u00031 \u0003In 2 B.E. F.D. 0.5 FIGURE 5.1 The statistical potential vs(r) between a pair of particles obeying Bose–Einstein statistics or Fermi–Dirac statistics. Problems 139 Problems 5.1. Evaluate the density matrix ρmn of an electron spin in the representation that makes ˆσx diagonal. Next, show that the value of ⟨σz⟩, resulting from this representation, is precisely the same as the one obtained in Section 5.3. Hint: The representation needed here follows from the one used in Section 5.3 by carrying out a transformation with the help of the unitary operator ˆU = ( 1/√ 2 1/ √ 2 −1/√ 2 1/ √ 2 ) . 5.2. Prove that ⟨q|e−β ˆH |q′⟩ = exp [ −β ˆH ( −iℏ ∂ ∂q , q)] δ(q − q′), where ˆH(−iℏ ∂/∂q, q) is the Hamiltonian operator of the system in the q-representation, which formally operates on the Dirac delta function δ(q − q′). Writing the δ-function in a suitable form, apply this result to (i) a free particle and (ii) a linear harmonic oscillator. 5.3. Derive the density matrix ρ for (i) a free particle and (ii) a linear harmonic oscillator in the momentum representation and study its main properties along the lines of Section 5.3. 5.4. Study the density matrix and the partition function of a system of free particles, using the unsymmetrized wavefunction (5.4.3) instead of the symmetrized wavefunction (5.5.7). Show that, following this procedure, one encounters neither the Gibbs’ correction factor (1/N! ) nor a spatial correlation among the particles. 5.5. Show that in the ﬁrst approximation the partition function of a system of N noninteracting, indistinguishable particles is given by QN (V , T ) = 1 N! λ3N ZN (V , T ), where ZN (V , T ) = ∫ exp    −β ∑ i<j vs(rij)    d3N r, vs(r) being the statistical potential (5.5.28). Hence evaluate tht ﬁrst-order correction to the equation of state of this system. 5.6. Determine the values of the degeneracy discriminant (nλ3) for hydrogen, helium, and oxygen at NTP. Make an estimate of the respective temperature ranges where the magnitude of this quantity becomes comparable to unity and hence quantum effects become important. 5.7. Show that the quantum-mechanical partition function of a system of N interacting particles approaches the classical form QN (V , T ) = 1 N! h3N ∫ e−βE(q,p)d3Nq d3N p as the mean thermal wavelength λ becomes much smaller than (i) the mean interparticle distance (V /N)1/3 and (ii) a characteristic length r0 of the interparticle potential.11 5.8. Prove the following theorem due to Peierls.12 “If ˆH is the hermitian Hamiltonian operator of a given physical system and {φn} an arbitrary orthonormal set of wavefunctions satisfying the symmetry requirements and the boundary 11See Huang (1963, Section 10.2). 12See Peierls (1938) and Huang (1963, Section 10.3). 140 Chapter 5. Formulation of Quantum Statistics conditions of the problem, then the partition function of the system satisﬁes the following inequality: Q(β) ≥ ∑ n exp {−β⟨φn| ˆH|φn⟩}; the equality holds when {φn} constitute a complete orthonormal set of eigenfunctions of the Hamiltonian itself.” 6 The Theory of Simple Gases We are now fully equipped with the formalism required for determining the macroscopic properties of a large variety of physical systems. In most cases, however, derivations run into serious mathematical difﬁculties, with the result that one is forced to restrict one’s analysis either to simpler kinds of systems or to simpliﬁed models of actual systems. In practice, even these restricted studies are carried out in a series of stages, the ﬁrst stage of the process being highly “idealized.” The best example of such an idealization is the familiar ideal gas, a study of which is not only helpful in acquiring facility with the math- ematical procedures but also throws considerable light on the physical behavior of gases actually met with in nature. In fact, it also serves as a base on which the theory of real gases can be founded; see Chapter 10. In this chapter we propose to derive, and at some length discuss, the most basic pro- perties of simple gaseous systems obeying quantum statistics; the discussion will include some of the essential features of diatomic and polyatomic gases and chemical equilibrium. 6.1 An ideal gas in a quantum-mechanical microcanonical ensemble We consider a gaseous system of N noninteracting, indistinguishable particles conﬁned to a space of volume V and sharing a given energy E. The statistical quantity of interest in this case is \u0000(N, V , E) which, by deﬁnition, denotes the number of distinct microstates accessible to the system under the macrostate (N, V , E). While determining this number, we must remember that a failure to take into account the indistinguishability of the parti- cles in a proper manner could lead to results which, except in the classical limit, may not be acceptable. With this in mind, we proceed as follows. Since, for large V , the single-particle energy levels in the system are very close to one another, we may divide the energy spectrum into a large number of “groups of levels,” which may be referred to as energy cells; see Figure 6.1. Let εi denote the average energy of a level, and gi the (arbitrary) number of levels, in the ith cell; we assume that all gi ≫ 1. In a particular situation, we may have n1 particles in the ﬁrst cell, n2 particles in the second cell, and so on. Clearly, the distribution set {ni} must conform to the conditions ∑ i ni = N (1) Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00006-2 © 2011 Elsevier Ltd. All rights reserved. 141 142 Chapter 6. The Theory of Simple Gases g4 ; n4 g3 ; n3 g2 ; n2 g1 ; n1´1 ´2 ´3 ´4 ´ FIGURE 6.1 The grouping of the single-particle energy levels into “cells.” and ∑ i niεi = E. (2) Then \u0000(N, V , E) = ∑′ {ni} W {ni}, (3) where W {ni} is the number of distinct microstates associated with the distribution set {ni} while the primed summation goes over all distribution sets that conform to conditions (1) and (2). Next, W {ni} = ∏ i w(i), (4) where w(i) is the number of distinct microstates associated with the ith cell of the spectrum (the cell that contains ni particles, to be accommodated among gi levels) while the product goes over all the cells in the spectrum. Clearly, w(i) is the number of distinct ways in which the ni identical, and indistinguishable, particles can be distributed among the gi levels of the ith cell. This number, in the Bose–Einstein case, is given by, see equation (3.8.25), wB.E.(i) = (ni + gi − 1)! ni! (gi − 1)! , (5) so that WB.E.{ni} = ∏ i (ni + gi − 1)! ni! (gi − 1)! . (6) 6.1 An ideal gas in a quantum-mechanical microcanonical ensemble 143 In the Fermi–Dirac case, no single level can accommodate more than one particle; accord- ingly, the number ni cannot exceed gi. The number w(i) is then given by the “number of ways in which the gi levels can be divided into two subgroups — one consisting of ni levels (which will have one particle each) and the other consisting of (gi − ni) levels (which will be unoccupied).” This number is given by wF.D.(i) = gi! ni! (gi − ni)! , (7) so that WF.D.{ni} = ∏ i gi! ni! (gi − ni)! . (8) For completeness, we may include the classical — or what is generally known as the Maxwell–Boltzmann — case as well. There, the particles are regarded as distinguishable, with the result that any of the ni particles may be put into any of the gi levels, inde- pendently of one another, and the resulting states may all be regarded as distinct; the number of these states is clearly (gi)ni . Moreover, the distribution set {ni} in this case is itself regarded as obtainable in N ! n1! n2! . . . (9) different ways which, on the introduction of the Gibbs correction factor, lead to a “weight factor” of 1 n1! n2! . . . = ∏ i 1 ni! ; (10) see also Section 1.6, especially equation (1.6.2). Combining these two results, we obtain WM.B.{ni} = ∏ i (gi)ni ni! . (11) Now, the entropy of the system would be given by S(N, V , E) = k ln \u0000(N, V , E) = k ln [∑′ {ni} W {ni} ]. (12) It can be shown that, under the conditions of our analysis, the logarithm of the sum on the right side of (12) can be approximated by the logarithm of the largest term in the sum; see Problem 3.4. We may, therefore, replace (12) by S(N, V , E) ≈ k ln W {n ∗ i }, (13) 144 Chapter 6. The Theory of Simple Gases where {n∗ i } is the distribution set that maximizes the number W {ni}; the numbers n∗ i are clearly the most probable values of the distribution numbers ni. The maximization, how- ever, is to be carried out under the restrictions that the quantities N and E remain constant. This can be done by the method of Lagrange’s undetermined multipliers; see Section 3.2. Our condition for determining the most probable distribution set {n∗ i } now turns out to be, see equations (1), (2), and (13), δ ln W {ni} − [ α ∑ i δni + β ∑ i εiδni ] = 0. (14) For ln W {ni}, we obtain from equations (6), (8), and (11), assuming that not only all gi but also all ni ≫ 1 (so that the Stirling approximation ln(x! ) ≈ x ln x − x can be applied to all the factorials that appear in these expressions), ln W {ni} = ∑ i ln w(i) ≈ ∑ i [ ni ln ( gi ni − a) − gi a ln ( 1 − a ni gi )] , (15) where a = −1 for the B.E. case, +1 for the F.D. case, and 0 for the M.B. case. Equation (14) then becomes ∑ i [ln ( gi ni − a) − α − βεi ] ni=n∗ i δni = 0. (16) In view of the arbitrariness of the increments δni in (16), we must have (for all i) ln ( gi n∗ i − a ) − α − βεi = 0, (17) so that 1 n ∗ i = gi eα+βεi + a . (18) The fact that n∗ i turns out to be directly proportional to gi prompts us to interpret the quantity n∗ i gi = 1 eα+βεi + a , (18a) which is actually the most probable number of particles per energy level in the ith cell, as the most probable number of particles in a single level of energy εi. Incidentally, our ﬁnal result (18a) is totally independent of the manner in which the energy levels of the particles 1For a critique of this derivation, see Landsberg (1954a, 1961). 6.1 An ideal gas in a quantum-mechanical microcanonical ensemble 145 are grouped into cells, so long as the number of levels in each cell is sufﬁciently large. As shown in Section 6.2, formula (18a) can also be derived without grouping energy levels into cells at all; in fact, it is only then that this result becomes truly acceptable! Substituting (18) into (15), we obtain for the entropy of the gas S k ≈ ln W {n ∗ i } = ∑ i [ n ∗ i ln ( gi n∗ i − a ) − gi a ln (1 − a n∗ i gi )] = ∑ i [ n ∗ i (α + βεi) + gi a ln { 1 + ae−α−βεi }] . (19) The ﬁrst sum on the right side of (19) is identically equal to αN while the second sum is identically equal to βE. For the third sum, therefore, we have 1 a ∑ i gi ln { 1 + ae−α−βεi } = S k − αN − βE. (20) Now, the physical interpretation of the parameters α and β here is going to be precisely the same as in Section 4.3, namely α = − µ kT , β = 1 kT ; (21) for conﬁrmation see Section 6.2. The right side of equation (20) is, therefore, equal to S k + µN kT − E kT = G − (E − TS) kT = PV kT . (22) The thermodynamic pressure of the system is, therefore, given by PV = kT a ∑ i [ gi ln {1 + ae−α−βεi }] . (23) In the Maxwell–Boltzmann case (a → 0), equation (23) takes the form PV = kT ∑ i gie−α−βεi = kT ∑ i n ∗ i = NkT , (24) which is the familiar equation of state of the classical ideal gas. Note that equation (24) for the Maxwell–Boltzmann case holds irrespective of the details of the energy spectrum εi. It will be recognized that the expression a−1 ∑i[ ] in equation (23), being equal to the thermodynamic quantity (PV /kT ), ought to be identical to the q-potential of the ideal gas. One may, therefore, expect to obtain from this expression all the macroscopic properties of this system. However, before demonstrating this, we would like to ﬁrst develop the formal theory of an ideal gas in the canonical and grand canonical ensembles. 146 Chapter 6. The Theory of Simple Gases 6.2 An ideal gas in other quantum-mechanical ensembles In the canonical ensemble the thermodynamics of a given system is derived from its partition function QN (V , T ) = ∑ E e−βE , (1) where E denotes the energy eigenvalues of the system while β = 1/kT . Now, an energy value E can be expressed in terms of the single-particle energies ε; for instance, E = ∑ ε nεε, (2) where nε is the number of particles in the single-particle energy state ε. The values of the numbers nε must satisfy the condition ∑ ε nε = N. (3) Equation (1) may then be written as QN (V , T ) = ∑′ {nε} g{nε}e−β ∑ ε nεε, (4) where g{nε} is the statistical weight factor appropriate to the distribution set {nε} and the summation ∑′ goes over all distribution sets that conform to the restrictive condition (3). The statistical weight factor in different cases is given by gB.E.{nε} = 1, (5) gF.D.{nε} = {1 if all nε = 0 or 1 0 otherwise, (6) and gM.B.{nε} = ∏ ε 1 nε! . (7) Note that in the present treatment we are dealing with single-particle states as individ- ual states, without requiring them to be grouped into cells; indeed, the weight factors (5), (6), and (7) follow straightforwardly from their respective predecessors (6.1.6), (6.1.8), and (6.1.11) by putting all gi = 1. 6.2 An ideal gas in other quantum-mechanical ensembles 147 First of all, we work out the Maxwell–Boltzmann case. Substituting (7) into (4), we get QN (V , T ) = ∑′ {nε} [(∏ ε 1 nε! ) ∏ ε (e−βε)nε ] = 1 N! ∑′ {nε}   N! ∏ ε nε! ∏ ε (e−βε)nε  . (8) Since the summation here is governed by condition (3), it can be evaluated with the help of the multinomial theorem, with the result QN (V , T ) = 1 N! [ ∑ ε e−βε]N = 1 N! [Q1(V , T )]N, (9) in agreement with equation (3.5.15). The evaluation of Q1 is, of course, straightforward. One obtains, using the asymptotic formula (2.4.7) for the number of single-particle states with energies lying between ε and ε + dε, Q1(V , T ) ≡ ∑ ε e−βε ≈ 2π V h3 (2m) 3/2 ∞∫ 0 e−βεε1/2dε = V /λ3, (10) where λ [= h/(2πmkT )1/2] is the mean thermal wavelength of the particles. Hence QN (V , T ) = V N N! λ3N , (11) from which complete thermodynamics of this system can be derived; see, for example, Section 3.5. Further, we obtain for the grand partition function of this system Q(z, V , T ) = ∞∑ N=0 zN QN (V , T ) = exp(zV /λ3); (12) compare to equation (4.4.3). We know that the thermodynamics of the system follows equally well from the expression for Q. In the Bose–Einstein and Fermi–Dirac cases, we obtain, by substituting (5) and (6) into (4), QN (V , T ) = ∑′ {nε} ( e−β ∑ ε nεε) ; (13) 148 Chapter 6. The Theory of Simple Gases the difference between the two cases, B.E. and F.D., arises from the values that the numbers nε can take. Now, in view of restriction (3) on the summation ∑′, an explicit evaluation of the partition function QN in these cases is rather cumbersome. The grand partition function Q, on the other hand, turns out to be more easily tractable; we have Q(z, V , T ) = ∞∑ N=0 [zN ∑′ {nε} e−β ∑ ε nεε ] (14a) = ∞∑ N=0 [∑′ {nε} ∏ ε ( ze−βε)nε ] . (14b) Now, the double summation in (14b) — ﬁrst over the numbers nε constrained by a ﬁxed value of the total number N, and then over all possible values of N — is equivalent to a summation over all possible values of the numbers nε, independently of one another. Hence, we may write Q(z, V , T ) = ∑ n0,n1,... [(ze−βε0 )n0 (ze−βε1 )n1 . . .] =   ∑ n0 (ze−βε0 )n0    ∑ n1 ( ze−βε1 )n1   . . . . (15) Now, in the Bose–Einstein case the nε can be either 0 or 1 or 2 or . . ., while in the Fermi– Dirac case they can be only 0 or 1. Therefore, Q(z, V , T ) =    ∏ ε 1 (1 − ze−βε) in the B.E. case, with ze−βε < 1 (16a) ∏ ε (1 + ze−βε) in the F.D. case. (16b) The q-potential of the system is thus given by q(z, V , T ) ≡ PV kT ≡ ln Q(z, V , T ) = ∓ ∑ ε ln(1 ∓ ze−βε); (17) compare to equation (6.1.23), with gi = 1. The identiﬁcation of the fugacity z with the quantity e−α of equation (6.1.23) is quite natural; accordingly, α = −µ/kT . As usual, the upper (lower) sign in equation (17) corresponds to the Bose (Fermi) case. In the end, we may write our results for q in a form applicable to all three cases: q(z, V , T ) ≡ PV kT = 1 a ∑ ε ln(1 + aze−βε), (18) 6.3 Statistics of the occupation numbers 149 where a = −1, +1, or 0, depending on the statistics governing the system. In particular, the classical case (a → 0) gives qM.B. = z ∑ ε e−βε = zQ1, (19) in agreement with equation (4.4.4). From (18), it follows that N ≡ z ( ∂q ∂z ) V ,T = ∑ ε 1 z−1eβε + a (20) and E ≡ − ( ∂q ∂β ) z,V = ∑ ε ε z−1eβε + a . (21) At the same time, the mean occupation number ⟨nε⟩ of level ε turns out to be, see equa- tions (14a) and (17), ⟨nε⟩ = 1 Q [ − 1 β ( ∂Q ∂ε ) z,T , all other ε ] ≡ − 1 β ( ∂q ∂ε ) z,T , all other ε = 1 z−1eβε + a , (22) in keeping with equations (20) and (21). Comparing our ﬁnal result (22) with its coun- terpart (6.1.18a), we ﬁnd that the mean value ⟨n⟩ and the most probable value n∗ of the occupation number n of a single-particle state are indeed identical. 6.3 Statistics of the occupation numbers Equation (6.2.22) gives the mean occupation number of a single-particle state with energy ε as an explicit function of the quantity (ε − µ)/kT : ⟨nε⟩ = 1 e(ε−µ)/kT + a . (1) The functional behavior of this number is shown in Figure 6.2. In the Fermi–Dirac case (a = +1), the mean occupation number never exceeds unity, for the variable nε itself cannot have a value other than 0 or 1. Moreover, for ε < µ and |ε − µ| ≫ kT , the mean occu- pation number tends to its maximum possible value 1. In the Bose–Einstein case (a = −1), we must have µ < all ε; see equation (6.2.16a). In fact, when µ becomes equal to the low- est value of ε, say ε0, the occupancy of that particular level becomes inﬁnitely high, which leads to the phenomenon of Bose–Einstein condensation; see Sections 7.1 and 7.2. For 150 Chapter 6. The Theory of Simple Gases 2 1 0 22 21 1 3 2 0123\u0002n´\u0003 ´ 2 \u0002 kT \u0004\u0005 FIGURE 6.2 The mean occupation number ⟨nε⟩ of a single-particle energy state ε in a system of noninteracting particles: curve 1 is for fermions, curve 2 for bosons, and curve 3 for the Maxwell–Boltzmann particles. µ < ε0, all values of (ε − µ) are positive and the behavior of all ⟨nε⟩ is nonsingular. Finally, in the Maxwell–Boltzmann case (a = 0), the mean occupation number takes the familiar form ⟨nε⟩M.B. = exp{(µ − ε)/kT } ∝ exp(−ε/kT ). (2) The important thing to note here is that the distinction between the quantum statistics (a = ±1) and the classical statistics (a = 0) becomes imperceptible when, for all values of ε that are of practical interest, exp{(ε − µ)/kT } ≫ 1. (3) In that event, equation (1) essentially reduces to (2) and we may write, instead of (3), ⟨nε⟩ ≪ 1. (4) Condition (4) is quite understandable, for it implies that the probability of any of the nε being greater than unity is quite negligible, with the result that the classical weight factors g{nε}, as given by equation (6.2.7), become essentially equal to 1. The distinction between the classical treatment and the quantum-mechanical treatment then becomes rather insigniﬁcant. Correspondingly, we ﬁnd, see Figure 6.2, that for large values of (ε − µ)/kT the quantum curves 1 and 2 essentially merge into the classical curve 3. Since we already know that the higher the temperature of the system the better the validity of the classical treatment, condition (3) also implies that µ, the chemical potential of the system, must be negative and large in magnitude. This means that the fugacity z[≡ exp(µ/kT )] of the system must be much smaller than unity; see also equation (6.2.22). One can see, from 6.3 Statistics of the occupation numbers 151 equations (4.4.6) and (4.4.29), that this is further equivalent to the requirement Nλ3 V ≪ 1, (5) which agrees with condition (5.5.20). We shall now examine statistical ﬂuctuations in the variable nε. Going a step further from the calculation that led to equation (6.2.22), we have ⟨n2 ε ⟩ = 1 Q [( − 1 β ∂ ∂ε )2 Q ] z,T , all other ε ; (6) it follows that ⟨n 2 ε ⟩ − ⟨nε⟩2 = [( − 1 β ∂ ∂ε )2 ln Q ] z,T , all other ε = [( − 1 β ∂ ∂ε ) ⟨nε⟩] z,T . (7) For the relative mean-square ﬂuctuation, we obtain (irrespective of the statistics obeyed by the particles) ⟨n2 ε ⟩ − ⟨nε⟩2 ⟨nε⟩2 = ( 1 β ∂ ∂ε ) { 1 ⟨nε⟩ } = z−1eβε; (8) of course, the actual value of this quantity will depend on the statistics of the particles because, for a given particle density (N/V ) and a given temperature T , the value of z will be different for different statistics. It seems more instructive to write (8) in the form ⟨n2 ε ⟩ − ⟨nε⟩2 ⟨nε⟩2 = 1 ⟨nε⟩ − a. (9) In the classical case (a = 0), the relative ﬂuctuation is normal. In the Fermi–Dirac case, it is given by 1/⟨nε⟩ − 1, which is below normal and tends to vanish as ⟨nε⟩ → 1. In the Bose– Einstein case, the ﬂuctuation is clearly above normal. 2 Obviously, this result would apply to a gas of photons and, hence, to the oscillator states in the black-body radiation. In the latter context, Einstein derived this result as early as 1909 following Planck’s approach and even pointed out that the term 1 in the expression for the ﬂuctuation may be attributed to the wave character of the radiation and the term 1/⟨nε⟩ to the particle character of the photons; for details, see Kittel (1958), ter Haar (1968). Closely related to the subject of ﬂuctuations is the problem of “statistical correlations in photon beams,” which have been observed experimentally (see Hanbury Brown and 2The special case of ﬂuctuations in the ground state occupation number, n0, of a Bose–Einstein system has been discussed by Wergeland (1969) and by Fujiwara, ter Haar, and Wergeland (1970). 152 Chapter 6. The Theory of Simple Gases Twiss, 1956, 1957, 1958) and have been explained theoretically in terms of the quantum- statistical nature of these ﬂuctuations (see Purcell, 1956; Kothari and Auluck, 1957). For further details, refer to Mandel, Sudarshan, and Wolf (1964); and Holliday and Sage (1964). For greater understanding of the statistics of the occupation numbers, we evaluate the quantity pε(n), which is the probability that there are exactly n particles in a state of energy ε. Referring to equation (6.2.14b), we infer that pε(n) ∝ (ze−βε)n. On normalization, it becomes in the Bose–Einstein case pε(n)|B.E. = ( ze−βε)n [1 − ze−βε] = ( ⟨nε⟩ ⟨nε⟩ + 1 )n 1 ⟨nε⟩ + 1 = (⟨nε⟩)n (⟨nε⟩ + 1) n+1 . (10) In the Fermi–Dirac case, we get pε(n)|F.D. = (ze−βε)n [ 1 + ze−βε]−1 = {1 − ⟨nε⟩ for n = 0 ⟨nε⟩ for n = 1. (11) In the Maxwell–Boltzmann case, we have pε(n) ∝ (ze−βε)n/n! instead; see equation (6.2.8). On normalization, we get pε(n)|M.B. = (ze−βε)n /n! exp ( ze−βε) = (⟨nε⟩)n n! e−⟨nε⟩. (12) Distribution (12) is clearly a Poisson distribution, for which the mean square deviation of the variable in question is equal to the mean value itself; compare to equation (9), with a = 0. It also resembles the distribution of the total particle number N in a grand canonical ensemble consisting of ideal, classical systems; see Problem 4.4. We also note that the ratio pε(n)/pε(n − 1) in this case varies inversely with n, which is a “normal” statistical behavior of uncorrelated events. On the other hand, the distribution in the Bose–Einstein case is geometric, with a con- stant common ratio ⟨nε⟩/(⟨nε⟩ + 1). This means that the probability of a state ε acquiring one more particle for itself is independent of the number of particles already occupying that state; thus, in comparison with the “normal” statistical behavior, bosons exhibit a spe- cial tendency of “bunching” together, which means a positive statistical correlation among them. In contrast, fermions exhibit a negative statistical correlation. 6.4 Kinetic considerations The thermodynamic pressure of an ideal gas is given by equation (6.1.23) or (6.2.18). In view of the largeness of volume V , the single-particle energy states ε would be so close 6.4 Kinetic considerations 153 to one another that a summation over them may be replaced by integration. One thereby gets P = kT a ∞∫ 0 ln [ 1 + aze−βε(p)] 4π p2dp h3 = 4π kT ah3   p3 3 ln [1 + aze−βε(p)] ∣ ∣ ∣ ∣ ∞ 0 + ∞∫ 0 p3 3 aze−βε(p) 1 + aze−βε(p) β dε dp dp  . The integrated part vanishes at both limits while the rest of the expression reduces to P = 4π 3h3 ∞∫ 0 1 z−1eβε(p) + a ( p dε dp ) p2dp. (1) Now, the total number of particles in the system is given by N = ∫ ⟨np⟩ Vd3p h3 = 4πV h3 ∞∫ 0 1 z−1eβε(p) + a p 2dp. (2) Comparing (1) and (2), we can write P = 1 3 N V 〈 p dε dp 〉 = 1 3 n⟨pu⟩, (3) where n is the particle density in the gas and u the speed of an individual particle. If the relationship between the energy ε and the momentum p is of the form ε ∝ ps, then P = s 3 n⟨ε⟩ = s 3 E V ; (4) the particular cases s = 1 and s = 2 are pretty easy to recognize. It should be noted here that results (3) and (4) hold independently of the statistics obeyed by the particles. The structure of formula (3) suggests that the pressure of the gas arises essentially from the physical motion of the particles; it should, therefore, be derivable from kinetic consid- erations alone. To do this, we consider the bombardment, by the particles of the gas, on the walls of the container. Let us take, for example, an element of area dA on one of the walls normal to the z-axis, see Figure 6.3, and focus our attention on those particles whose velocity lies between u and u + du; the number of such particles per unit volume may be denoted by nf (u)du, where ∫ all u f (u)du = 1. (5) 154 Chapter 6. The Theory of Simple Gases (udt ) dA z FIGURE 6.3 The molecular bombardment on one of the walls of the container. Now, the question is: how many of these particles will strike the area dA in time dt? The answer is: all those particles that happen to lie in a cylindrical region of base dA and height u dt, as shown in Figure 6.3. Since the volume of this region is (dA · u)dt, the number of such particles would be {(dA · u)dt × nf (u)du}. On reﬂection from the wall, the normal component of the momentum of a particle would undergo a change from pz to −pz; as a result, the normal momentum imparted by these particles per unit time to a unit area of the wall would be 2 pz{uznf (u)du}. Integrating this expression over all relevant u, we obtain the total normal momentum imparted per unit time to a unit area of the wall by all the particles of the gas which, by deﬁnition, is the kinetic pressure of the gas: P = 2n ∞∫ ux=−∞ ∞∫ uy =−∞ ∞∫ uz=0 pzuzf (u)duxduyduz. (6)3 Since (i) f (u) is a function of u alone and (ii) the product (pzuz) is an even function of uz, the foregoing result may be written as P = n ∫ all u (pzuz)f (u)du. (7) Comparing (7) with (5), we obtain P = n⟨pzuz⟩ = n⟨pu cos 2 θ⟩ (8) = 1 3 n⟨pu⟩, (9) which is identical to (3). 3Clearly, only those velocities for which uz > 0 are relevant here. 6.5 Gaseous systems composed of molecules with internal motion 155 In a similar manner, we can determine the rate of effusion of the gas particles through a hole (of unit area) in the wall. This is given by, compared to (6), R = n ∞∫ ux=−∞ ∞∫ uy =−∞ ∞∫ uz=0 uzf (u)duxduyduz (10) = n 2π∫ φ=0 π/2∫ θ =0 ∞∫ u=0 {u cos θf (u)}(u 2 sin θ du dθ dφ); (11) note that the condition uz > 0 restricts the range of the angle θ between the values 0 and π/2. Carrying out integrations over θ and φ, we obtain R = nπ ∞∫ 0 f (u)u 3 du. (12) In view of the fact that ∞∫ 0 f (u)(4πu2 du) = 1, (5a) equation (12) may be written as R = 1 4 n⟨u⟩. (13) Again, this result holds independently of the statistics obeyed by the particles. It is obvious that the velocity distribution among the effused particles is considerably different from the one among the particles inside the container. This is due to the fact that, ﬁrstly, the velocity component uz of the effused particles must be positive (which intro- duces an element of anisotropy into the distribution) and, secondly, the particles with larger values of uz appear with an extra weightage, the weightage being directly propor- tional to the value of uz; see equation (10). As a result of this, (i) the effused particles carry with them a net forward momentum, thus causing the container to experience a recoil force, and (ii) they carry away a relatively large amount of energy per particle, thus leaving the gas in the container at not only a progressively decreasing pressure and density but also a progressively decreasing temperature; see Problem 6.14. 6.5 Gaseous systems composed of molecules with internal motion In most of our studies so far we have considered only the translational part of the molecu- lar motion. Though this aspect of motion is invariably present in a gaseous system, other 156 Chapter 6. The Theory of Simple Gases aspects, which are essentially concerned with the internal motion of the molecules, also exist. It is only natural that in the calculation of the physical properties of such a sys- tem, contributions arising from these motions are also taken into account. In doing so, we shall assume that (i) the effects of the intermolecular interactions are negligible and (ii) the nondegeneracy criterion nλ 3 = nh3 (2πmkT )3/2 ≪ 1 (5.5.20) is fulﬁlled; this makes our system an ideal, Boltzmannian gas. Under these assumptions, which hold sufﬁciently well in a large number of applications, the partition function of the system is given by QN (V , T ) = 1 N! [Q1(V , T )]N , (1) where Q1(V , T ) = V λ3 j(T ); (2) the factor within the curly brackets is the familiar translational partition function of a molecule, while j(T ) is the partition function corresponding to internal motions. The latter may be written as j(T ) = ∑ i gie−εi/kT , (3) where εi is the energy associated with a state of internal motion (characterized by the quantum numbers i), while gi is the multiplicity of that state. The contributions made by the internal motions of the molecules, over and above the translational degrees of freedom, follow straightforwardly from the function j(T ). We obtain Aint = −NkT ln j, (4) µint = −kT ln j, (5) Sint = Nk ( ln j + T ∂ ∂T ln j) , (6) Uint = NkT 2 ∂ ∂T ln j, (7) and (CV )int = Nk ∂ ∂T { T 2 ∂ ∂T ln j} . (8) 6.5 Gaseous systems composed of molecules with internal motion 157 Thus, the central problem in this study is to derive an explicit expression for the function j(T ) from a knowledge of the internal states of the molecules. For this, we note that the internal state of a molecule is determined by (i) the electronic state, (ii) the state of the nuclei, (iii) the vibrational state, and (iv) the rotational state. Rigorously speaking, these four modes of excitation mutually interact; in many cases, however, they can be treated independently of one another. We can then write j(T ) = jelec(T )jnuc(T )jvib(T )jrot(T ), (3a) with the result that the net contribution made by the internal motions to the various thermodynamic properties of the system is given by a simple sum of the four respective contributions. There is one interaction, however, that plays a special role in the case of homonuclear molecules, such as AA, and which is between the states of the nuclei and the rotational states. In such a case, we better write j(T ) = jelec(T )jnuc−rot(T )jvib(T ). (3b) We now examine this problem for various systems in the order of increasing complexity. 6.5.A Monatomic molecules For simplicity, we consider a monatomic gas at temperatures such that the thermal energy kT is small in comparison with the ionization energy εion; for different atoms, this amounts to the condition T ≪ εion/k ∼ 104 − 105 K. At these temperatures, the number of ionized atoms in the gas would be insigniﬁcant. The same would be true of atoms in the excited states, for the separation of any of the excited states from the ground state of the atom is generally of the same order of magnitude as the ionization energy itself. Thus, we may regard all atoms in the gas to be in their (electronic) ground state. Now, there is a special class of atoms, namely He, Ne, A, . . ., which, in their ground state, possess neither orbital angular momentum nor spin (L = S = 0). Their (electronic) ground state is clearly a singlet, with ge = 1. The nucleus, however, possesses a degeneracy that arises from the possibility of different orientations of the nuclear spin. 4 If the value of this spin is Sn, the corresponding degeneracy factor gn = 2Sn + 1. Moreover, a monatomic molecule cannot have any vibrational or rotational states. The internal partition function (3a) of such a molecule is, therefore, given by j(T ) = (g)gr.st. = ge · gn = 2Sn + 1. (9) 4As is well known, the presence of the nuclear spin gives rise to the so-called hyperﬁne structure in the electronic states. However, the intervals of this structure are such that, for practically all temperatures of interest, they are small in comparison with kT ; for concreteness, these intervals correspond to T -values of the order of 10−1 to 100 K. Accordingly, in the evaluation of the partition function j(T ), the hyperﬁne splitting of the electronic state may be disregarded while the multiplicity introduced by the nuclear spin may be taken into account through a degeneracy factor. 158 Chapter 6. The Theory of Simple Gases Equations (4) through (8) then tell us that the internal motions in this case contribute only toward properties such as the chemical potential and the entropy of the gas; they do not contribute toward the internal energy and the speciﬁc heat. If, on the other hand, the ground state does not possess orbital angular momentum but possesses spin (L = 0, S ̸= 0 — as, for example, in the case of alkali atoms), then the ground state will still have no ﬁne structure; it will, however, have a degeneracy ge = 2S + 1. As a result, the internal partition function j(T ) will get multiplied by a factor of (2S + 1) and the properties such as the chemical potential and the entropy of the gas will get modiﬁed accordingly. In other cases, the ground state of the atom may possess both orbital angular momen- tum and spin (L ̸= 0, S ̸= 0); the ground state would then possess a deﬁnite ﬁne structure. The intervals of this structure are, in general, comparable to kT ; hence, in the evaluation of the partition function, the energies of the various components of the ﬁne structure will have to be taken into account. Since these components differ from one another in the value of the total angular momentum J, the relevant partition function may be written as jelec(T ) = ∑ J (2J + 1)e−εJ /kT . (10) The foregoing expression simpliﬁes considerably in the following limiting cases: (a) kT ≫ all εJ ; then jelec(T ) ≃ ∑ J (2J + 1) = (2L + 1)(2S + 1). (10a) (b) kT ≪ all εJ ; then jelec(T ) ≃ (2J0 + 1)e−ε0/kT , (10b) where J0 is the total angular momentum, and ε0 the energy, of the atom in the lowest state. In either case, the electronic motion makes no contribution toward the speciﬁc heat of the gas. Of course, at intermediate temperatures, we do obtain a contribution toward this property. And, in view of the fact that both at high and low temperatures the speciﬁc heat tends to be equal to the translational value 3 2 Nk, it must pass through a maximum at a temperature comparable to the separation of the ﬁne structure levels. 5 Needless to say, the multiplicity (2Sn + 1) introduced by the nuclear spin must be taken into account in each case. 6.5.B Diatomic molecules Now we consider a diatomic gas at temperatures such that kT is small compared to the energy of dissociation; for different molecules, this amounts once again to the condition 5It seems worthwhile to note here that the values of 1εJ /k for the components of the normal triplet term of oxygen are 230 K and 320 K, while those for the normal quintuplet term of iron range from 600 to 1,400 K. 6.5 Gaseous systems composed of molecules with internal motion 159 T ≪ εdiss/k ∼ 104 − 105 K. At these temperatures the number of dissociated molecules in the gas would be insigniﬁcant. At the same time, in most cases, there would be practi- cally no molecules in the excited states as well, for the separation of any of these states from the ground state of the molecule is in general comparable to the dissociation energy itself. 6 Accordingly, in the evaluation of j(T ), we have to take into account only the lowest electronic state of the molecule. The lowest electronic state, in most cases, is nondegenerate: ge = 1. We then need not consider any further the question of the electronic state making a contribution toward the thermodynamic properties of the gas. However, certain molecules (though not very many) have, in their lowest electronic state, either (i) a nonzero orbital angular momentum (3 ̸= 0) or (ii) a nonzero spin (S ̸= 0) or (iii) both. In case (i), the electronic state acquires a twofold degeneracy corresponding to the two possible orientations of the oribital angular momentum relative to the molecular axis;7 as a result, ge = 2. In case (ii), the state acquires a degeneracy 2S + 1 corresponding to the space quantization of the spin.8 In both these cases the chemical potential and the entropy of the gas are modiﬁed by the multiplicity of the electronic state, while the energy and the speciﬁc heat remain unaf- fected. In case (iii), we encounter a ﬁne structure that necessitates a rather detailed study because the intervals of this structure are generally of the same order of magnitude as kT . In particular, for a doublet ﬁne-structure term, such as the one that arises in the molecule NO (51/2,3/2 with a separation of 178 K, the components themselves being 3-doublets), we have for the electronic partition function jelec(T ) = g0 + g1e−1/kT , (11) where g0 and g1 are the degeneracy factors of the two components while 1 is their separa- tion energy. The contribution made by (11) toward the various thermodynamic properties of the gas can be calculated with the help of formulae (4) through (8). In particular, we obtain for the contribution toward the speciﬁc heat (CV )elec = Nk (1/kT )2 [1 + (g0/g1)e1/kT ] [1 + (g1/g0)e−1/kT ] . (12) We note that this contribution vanishes both for T ≪ 1/k and for T ≫ 1/k and is maxi- mum for a certain temperature ∼1/k; compare to the corresponding situation in the case of monatomic molecules. 6An odd case arises with oxygen. The separation between its normal term 36 and the ﬁrst excited term 11 is about 11,250 K, whereas the dissociation energy is about 55,000 K. The relevant factor e−ε1/kT , therefore, can be quite signiﬁcant even when the factor e−εdiss/kT is not, say for T ∼ 2000 to 6000 K. 7Strictly speaking, the term in question splits into two levels — the so-called 3-doublet. The separation of the levels, however, is such that we can safely neglect it. 8The separation of the resulting levels is again negligible from the thermodynamic point of view; as an example, one may cite the very narrow triplet term of O2. 160 Chapter 6. The Theory of Simple Gases We now consider the effect of the vibrational states of the molecules on the thermo- dynamic properties of the gas. To have an idea of the temperature range over which this effect would be signiﬁcant, we note that the magnitude of the corresponding quantum of energy, namely ℏω, for different diatomic gases is of order 103 K. Thus, we would obtain full contributions (consistent with the dictates of the equipartition theorem) at temperatures of the order of 104 K or more, and practically no contribution at temperatures of the order of 102 K or less. Let us assume that the temperature is not high enough to excite vibra- tional states of large energy; the oscillations of the nuclei then remain small in amplitude and hence harmonic. The energy levels for a mode of frequency ω are then given by the well-known expression (n + 1 2 )ℏω. 9 The evaluation of the vibrational partition function jvib(T ) is quite elementary; see Section 3.8. In view of the rapid convergence of the series involved, the summation may formally be extended to n = ∞. The corresponding contributions toward the various ther- modynamic properties of the system are then given by equations (3.8.16) through (3.8.21). In particular, (CV )vib = Nk ( 2v T )2 e2v/T (e2v/T − 1)2 ; 2v = ℏω k . (13) We note that for T ≫ 2v, the vibrational speciﬁc heat is very nearly equal to the equipar- tition value Nk; otherwise, it is always less than Nk. In particular, for T ≪ 2v, the speciﬁc heat tends to zero (see Figure 6.4); the vibrational degrees of freedom are then said to be “frozen.” At sufﬁciently high temperatures, when vibrations with large n are also excited, the effects of anharmonicity and of interaction between the vibrational and the rotational modes of the molecule can become important.10 However, since this happens only at large n, the relevant corrections to the various thermodynamic quantities can be determined even classically; see Problems 3.29 and 3.30. One ﬁnds that the ﬁrst-order correction to Cvib is directly proportional to the temperature of the gas. Finally, we consider the effect of (i) the states of the nuclei and (ii) the rotational states of the molecule; wherever necessary, we shall take into account the mutual interaction of these modes. This interaction is of no relevance in the case of heteronuclear molecules, such as AB; it is, however, important in the case of homonuclear molecules, such as AA. We may, therefore, consider the two cases separately. The states of the nuclei in the heteronuclear case may be treated separately from the rotational states of the molecule. Proceeding in the same manner as for monatomic molecules, we conclude that the effect of the nuclear states is adequately taken care of 9It may be pointed out that the vibrational motion of a molecule is inﬂuenced by the centrifugal force arising from the molecular rotation. This leads to an interaction between the rotational and the vibrational modes. However, unless the temperature is too high, this interaction can be neglected and the two modes treated independently of one another. 10In principle, these two effects are of the same order of magnitude. 6.5 Gaseous systems composed of molecules with internal motion 161 1.0 0.5 0 0.5 1.0 (T/\u0002v)(Cvib/Nk) 1.5 2.0 FIGURE 6.4 The vibrational speciﬁc heat of a gas of diatomic molecules. At T = 2v, the speciﬁc heat is already about 93 percent of the equipartition value. through a degeneracy factor gn. Denoting the spins of the two nuclei by SA and SB, gn = (2SA + 1)(2SB + 1). (14) As before, we obtain a ﬁnite contribution toward the chemical potential and the entropy of the gas but none toward the internal energy and the speciﬁc heat. Now, the rotational levels of a linear “rigid” rotator, with two degrees of freedom (for the axis of rotation) and the principal moments of inertia (I, I, 0), are given by εrot = l(l + 1)ℏ2/2I, l = 0, 1, 2, . . . ; (15) here, I = µr2 0 where µ[= m1m2/(m1 + m2)] is the reduced mass of the nuclei and r0 the equi- librium distance between them. The rotational partition function of the molecule is then given by jrot(T ) = ∞∑ l=0(2l + 1) exp { −l(l + 1) ℏ2 2IkT } = ∞∑ l=0(2l + 1) exp{ −l(l + 1) 2r T }; 2r = ℏ2 2Ik . (16) The values of 2r, for all gases except the ones involving the isotopes H and D, are much smaller than room temperature. For example, the value of 2r for HCl is about 15 K, for N2, O2, and NO it lies between 2 K and 3 K, while for Cl2 it is about one-third of a degree. On the other hand, the values of 2r for H2, D2, and HD are, respectively, 85 K, 43 K, and 64 K. 162 Chapter 6. The Theory of Simple Gases These numbers give us an idea of the respective temperature ranges in which the effects arising from the discreteness of the rotational states are expected to be important. For T ≫ 2r, the spectrum of the rotational states may be approximated by a contin- uum. The summation in (16) is then replaced by an integration: jrot(T ) ≈ ∞∫ 0 (2l + 1) exp { −l(l + 1) 2r T } dl = T 2r . (17) The rotational speciﬁc heat is then given by (CV )rot = Nk, (18) consistent with the equipartition theorem. A better evaluation of the sum in (16) can be made with the help of the Euler–Maclaurin formula, namely ∞∑ n=0 f (n) = ∞∫ 0 f (x)dx + 1 2 f (0) − 1 12 f ′(0) + 1 720 f ′′′(0) − 1 30, 240 f v(0) + · · · . (19) Writing f (x) = (2x + 1) exp{−x(x + 1)2r/T }, one obtains jrot(T ) = T 2r + 1 3 + 1 15 2r T + 4 315 ( 2r T )2 + · · · , (20) which is the so-called Mulholland’s formula; as expected, the main term of this formula is identical to the classical partition function (17). The corresponding result for the speciﬁc heat is (CV )rot = Nk { 1 + 1 45 ( 2r T )2 + 16 945 ( 2r T )3 + · · · } , (21) which shows that at high temperatures the rotational speciﬁc heat decreases with temper- ature and ultimately tends to the classical value Nk. Thus, at high (but ﬁnite) temperatures the rotational speciﬁc heat of a diatomic gas is greater than the classical value. On the other hand, it must go to zero as T → 0. We, therefore, conclude that it passes through at least one maximum. Numerical studies show that there is only one maximum that appears at a temperature of about 0.82r and has a value of about 1.1Nk; see Figure 6.5. 6.5 Gaseous systems composed of molecules with internal motion 163 1.2 1.0 0.8 0.6 0.4 0.2 0 0.5 1.0 1.5 2.0 (T/\u0002r )(Crot/Nk) FIGURE 6.5 The rotational speciﬁc heat of a gas of heteronuclear diatomic molecules. In the other limiting case, when T ≪ 2r, one may retain only the ﬁrst few terms of the sum in (16); then jrot(T ) = 1 + 3e−22r /T + 5e−62r /T + · · · , (22) from which one obtains, in the lowest approximation, (CV )rot ≃ 12Nk ( 2r T )2 e−22r /T . (23) Thus, as T → 0, the speciﬁc heat drops exponentially to zero; see again Figure 6.5. We, therefore, conclude that at low enough temperatures the rotational degrees of freedom of the molecules are also “frozen.” At this stage it appears worthwhile to remark that, since the internal motions of the molecules do not make any contribution toward the pressure of the gas (Aint being inde- pendent of V ), the quantity (CP − CV ) is the same for a diatomic gas as for a monatomic one. Moreover, under the assumptions made in the very beginning of this section, the value of this quantity at all temperatures of interest would be equal to the classical value Nk. Thus, at sufﬁciently low temperatures (when rotational as well as vibrational degrees of freedom of the molecules are “frozen”), we have, by virtue of the translational motion alone, CV = 3 2 Nk, CP = 5 2 NK ; γ = 5 3 . (24) As temperature rises, the rotational degrees of freedom begin to “loosen up” until we reach temperatures that are much larger than 2r but much smaller than 2v; the rotational degrees of freedom are then fully excited while the vibrational ones are still “frozen.” 164 Chapter 6. The Theory of Simple Gases 10 9 8 7 6 5 4 10 50 HD HT DT HD HT DT 9R /2 7R /2 5R /2 100 500 1000 5000 T (in K)Cp(in cal mole21 deg21) FIGURE 6.6 The rotational-vibrational speciﬁc heat, CP, of the diatomic gases HD, HT, and DT. Accordingly, for 2r ≪ T ≪ 2v, CV = 5 2 Nk, CP = 7 2 Nk; γ = 7 5 . (25) As temperature rises further, the vibrational degrees of freedom as well start loosening up, until we reach temperatures that are much larger than 2v. Then, the vibrational degrees of freedom are also fully excited and we have CV = 7 2 Nk, CP = 9 2 Nk; γ = 9 7 . (26) These features are displayed in Figure 6.6 where the experimental results for CP are plot- ted for three gases HD, HT, and DT. We note that, in view of the considerable difference between the values of 2r and 2v, the situation depicted by (25) prevails over a consider- ably large range of temperatures. In passing, it may be pointed out that, for most diatomic gases, the situation at room temperatures corresponds to the one depicted by (25). We now study the case of homonuclear molecules, such as AA. To start with, we consider the limiting case of high temperatures where classical approximation is admissible. The rotational motion of the molecule may then be visualized as a rotation of the molecular axis, that is, the line joining the two nuclei, about an “axis of rotation” that is perpendic- ular to the molecular axis and passes through the center of mass of the molecule. Then, the two opposing positions of the molecular axis, namely the ones corresponding to the azimuthal angles φ and φ + π, differ simply by an interchange of the two identical nuclei and, hence, correspond to only one distinct state of the molecule. Therefore, in the evalu- ation of the partition function, the range of the angle φ should be taken as (0, π) instead of the customary (0, 2π). Moreover, since the energy of rotational motion does not depend on angle φ, the only effect of this on the partition function of the molecule would be to reduce 6.5 Gaseous systems composed of molecules with internal motion 165 it by a factor of 2. We thus obtain, in the classical approximation, 11 jnuc−rot(T ) = (2SA + 1) 2 T 22r . (27) Obviously, the factor 2 here will not affect the speciﬁc heat of the gas; in the classical approximation, therefore, the speciﬁc heat of a gas of homonuclear molecules is the same as that of a corresponding gas of heteronuclear molecules. In contrast, signiﬁcant changes result at relatively lower temperatures where the states of rotational motion have to be treated as discrete. These changes arise from the cou- pling between the nuclear and the rotational states that in turn arises from the symmetry character of the nuclear-rotational wavefunction. As discussed in Section 5.4, the total wavefunction of a physical state must be either symmetric or antisymmetric (depend- ing on the statistics obeyed by the particles involved) with respect to an interchange of two identical particles. Now, the rotational wavefunction of a diatomic molecule is sym- metric or antisymmetric depending on whether the quantum number l is even or odd. The nuclear wavefunction, on the other hand, consists of a linear combination of the spin functions of the two nuclei and its symmetry character depends on the manner in which the combination is formed. It is not difﬁcult to see that, of the (2SA + 1)2 different com- binations that one constructs, exactly (SA + 1)(2SA + 1) are symmetric with respect to an interchange of the nuclei and the remaining SA(2SA + 1) antisymmetric. 12 In constructing the total wavefunction, as a product of the nuclear and the rotational wavefunctions, we then proceed as follows: (i) If the nuclei are fermions (SA = 1 2 , 3 2 , . . .), as in the molecule H2, the total wavefunction must be antisymmetric. To secure this, we may associate any one of the SA(2SA + 1) antisymmetric nuclear wavefunctions with any one of the even-l rotational wavefunctions or any one of the (SA + 1)(2SA + 1) symmetric nuclear wavefunctions with any one of the odd-l rotational wavefunctions. Accordingly, the nuclear- rotational partition function of such a molecule would be j(F.D.) nuc−rot(T ) = SA(2SA + 1)reven + (SA + 1)(2SA + 1)rodd, (28) 11It seems instructive to outline here the purely classical derivation of the rotational partition function. Specifying the rotation of the molecule by the angles (θ, φ) and the corresponding momenta (pθ , pφ ), the kinetic energy assumes the form εrot = 1 2I p2 θ + 1 2I sin2 θ p2 φ , from which jrot(T ) = 1 h2 ∫ e−εrot/kT (dpθ dpφ dθ dφ) = IkT πℏ2 φmax∫ 0 dφ. For heteronuclear molecules φmax = 2π , while for homonuclear ones φmax = π. 12See, for example, Schiff (1968, Section 41). 166 Chapter 6. The Theory of Simple Gases where reven = ∞∑ l=0,2,...(2l + 1) exp{−l(l + 1)2r/T } (29) and rodd = ∞∑ l=1,3,... (2l + 1) exp{−l(l + 1)2r/T }. (30) (ii) If the nuclei are bosons (SA = 0, 1, 2, . . .), as in the molecule D2, the total wavefunction must be symmetric. To secure this, we may associate any one of the (SA + 1)(2SA + 1) symmetric nuclear wavefunctions with any one of the even-l rotational wavefunc- tions or any one of the SA(2SA + 1) antisymmetric nuclear wavefunctions with any one of the odd-l rotational wavefunctions. We then have j(B.E.) nuc−rot(T ) = (SA + 1)(2SA + 1)reven + SA(2SA + 1)rodd. (31) At high temperatures, it is the larger values of l that contribute most to the sums (29) and (30). The difference between the two sums is then negligibly small, and we have reven ≃ rodd ≃ 1 2 jrot(T ) = T /22r; (32) see equations (16) and (17). Consequently, j(B.E.) nuc−rot ≃ j(F.D.) nuc−rot = (2SA + 1) 2T /22r, (33) in agreement with our previous result (27). Under these circumstances, the statistics gov- erning the nuclei does not make a signiﬁcant difference to the thermodynamic behaviour of the gas. Things change when the temperature of the gas is in a range comparable to the value of 2r. It seems most reasonable then to regard the gas as a mixture of two components, generally referred to as ortho- and para-, whose relative concentrations in equilibrium are determined by the relative magnitudes of the two parts of the partition function (28) or (31), as the case may be. Customarily, the name ortho- is given to that component that carries the larger statistical weight. Thus, in the case of fermions (as in H2), the ortho- to para-ratio is given by n (F.D.) = (SA + 1)rodd SAreven , (34) while in the case of bosons (as in D2), the corresponding ratio is given by n(B.E.) = (SA + 1)reven SArodd . (35) 6.5 Gaseous systems composed of molecules with internal motion 167 As temperature rises, the factor rodd/reven tends to unity and the ratio n, in each case, approaches the temperature-independent value (SA + 1)/SA. In the case of H2, this lim- iting value is 3 (since SA = 1 2 ) while in the case of D2 it is 2 (since SA = 1). At sufﬁciently low temperatures, one may retain only the main terms of the sums (29) and (30), with the result that rodd reven ≃ 3 exp( − 22r T ) (T ≪ 2r), (36) which tends to zero as T → 0. The ratio n then tends to zero in the case of fermions and to inﬁnity in the case of bosons. Hence, as T → 0, the hydrogen gas is wholly para-, while deuterium is wholly ortho-; of course, in each case, the molecules do settle down in the rotational state l = 0. At intermediate temperatures, one has to work with the equilibrium ratio (34), or (35), and with the composite partition function (28), or (31), in order to compute the thermody- namic properties of the gas. One ﬁnds, however, that the theoretical results so derived do not generally agree with the ones obtained experimentally. This discrepancy was resolved by Dennison (1927) who pointed out that the samples of hydrogen, or deuterium, ordi- narily subjected to experiment are not in thermal equilibrium as regards the relative magnitudes of the ortho- and para-components. These samples are ordinarily prepared and kept at room temperatures that are well above 2r, with the result that the ortho- to para-ratio in them is very nearly equal to the limiting value (SA + 1)SA. If now the temperature is lowered, one would expect this ratio to change in accordance with equation (34), or (35). However, it does not do so for the following reason. Since the transition of a molecule from one form of existence to another involves the ﬂipping of the spin of one of its nuclei, the transition probability of the process is quite small. Actu- ally, the periods involved are of the order of a year! Obviously, one cannot expect to attain the true equilibrium ratio n during the short times available. Consequently, even at lower temperatures, what one generally has is a nonequilibrium mixture of two independent substances, the relative concentration of which is preassigned. The partition functions (28) and (31) as such are, therefore, inapplicable; we rather have directly for the speciﬁc heat C(F.D.) = SA 2SA + 1 Ceven + SA + 1 2SA + 1 Codd (37) and C(B.E.) = SA + 1 2SA + 1 Ceven + SA 2SA + 1 Codd, (38) where Ceven/odd = Nk ∂ ∂T {T 2(∂/∂T ) ln reven/odd}. (39) We have, therefore, to compute Ceven and Codd separately and then derive the net value of the rotational speciﬁc heat with the help of formula (37) or (38), as the case may be. 168 Chapter 6. The Theory of Simple Gases 2.0 1.5 1.0 1 3 2 0.5 001 2 3 4 5 Cv Nk\u0002\u0003 (T/\u0002r ) FIGURE 6.7 The theoretical speciﬁc heat of a 1:3 mixture of para-hydrogen and ortho-hydrogen. The experimental points originate from various sources listed in Wannier (1966). Figure 6.7 shows the relevant results for hydrogen. Curves 1 and 2 correspond to the para- hydrogen (Ceven) and the ortho-hydrogen (Codd), respectively, while curve 3 represents the weighted mean, as given by equation (37). The experimental results are also shown in the ﬁgure; the agreement between theory and experiment is clearly good. Further evidence in favor of Dennison’s explanation is obtained by performing exper- iments with ortho–para mixtures of different relative concentration. This can be done by speeding up the ortho–para conversion by passing hydrogen over activated charcoal. By doing this at various temperatures, and afterwards removing the catalyst, one can ﬁx the ratio n at any desired value. The speciﬁc heat then follows a curve obtained by mixing Ceven and Codd with appropriate weight factors. Further, if one measures the speciﬁc heat of the gas in such a way that the ratio n, at every temperature T , has the value that is given by formula (34), it indeed follows the curve obtained from expression (28) for the partition function. 6.5.C Polyatomic molecules Once again, the translational degrees of freedom of the molecules contribute their usual share, 3 2 k per molecule, toward the speciﬁc heat of the gas. As regards the lowest electronic state, it is, in most cases, far below any of the excited states; nevertheless, it generally pos- sesses a multiplicity (depending on the orbital and spin angular momenta of the state) that can be taken care of by a degeneracy factor ge. As regards the rotational states, they can be treated classically because the large values of the moments of inertia characteris- tic of polyatomic molecules make the quantum of rotational energy, ℏ2/2Ii, much smaller than the thermal energy kT at practically all temperatures of interest. Consequently, the interaction between the rotational states and the states of the nuclei can also be treated classically. As a result, the nuclear-rotational partition function is given by the product of the respective partition functions, divided by a symmetry number γ that denotes the num- ber of physically indistinguishable conﬁgurations realized during one complete rotation of 6.5 Gaseous systems composed of molecules with internal motion 169 the molecule: 13 jnuc−rot(T ) = gnuc jC rot(T ) γ ; (40) compare to equation (27). Here, jC rot(T ) is the rotational partition function of the molecule evaluated in the classical approximation (without paying regard to the presence of identi- cal nuclei, if any); it is given by jC rot(T ) = π 1/2 ( 2I1kT ℏ2 )1/2 ( 2I2kT ℏ2 )1/2 ( 2I3kT ℏ2 )1/2 (41) where I1, I2, and I3 are the principal moments of inertia of the molecule; see Prob- lem 6.27. 14 The rotational speciﬁc heat is then given by Crot = Nk ∂ ∂T { T 2 ∂ ∂T ln jC rot(T )} = 3 2 Nk, (42) consistent with the equipartition theorem. As regards vibrational states, we ﬁrst note that, unlike a diatomic molecule, a poly- atomic molecule has not one but several vibrational degrees of freedom. In particular, a noncollinear molecule consisting of n atoms has 3n − 6 vibrational degrees of freedom, six degrees of freedom out of the total 3n having gone into the translational and rotational motions. On the other hand, a collinear molecule consisting of n atoms would have 3n − 5 vibrational degrees of freedom, for the rotational motion in this case has only two, not three, degrees of freedom. The vibrational degrees of freedom correspond to a set of nor- mal modes characterized by a set of frequencies ωi. It might happen that some of these frequencies have identical values; we then speak of degenerate frequencies. 15 In the harmonic approximation, these normal modes may be treated independently of one another. The vibrational partition function of the molecule is then given by the product of the partition functions corresponding to individual normal modes, that is, jvib(T ) = ∏ i e−2i/2T 1 − e−2i/T ; 2i = ℏωi k , (43) 13For example, the symmetry number γ for H2O (isosceles triangle) is 2, for NH3 (regular triangular pyramid) it is 3, while for CH4 (tetrahedron) and C6H6 (regular hexagon) it is 12. For heteronuclear molecules, the symmetry number is unity. 14In the case of a collinear molecule, such as N2O or CO2, there are only two degrees of freedom for rotation; con- sequently, jC rot(T ) is given by (2IkT /ℏ2), where I is the (common) value of the two moments of inertia of the molecule; see equation (17). Of course, we must also take into account the symmetry number γ . In the examples quoted here, the molecule N2O, being spatially asymmetric (NNO), has symmetry number 1, while the molecule CO2, being spatially symmetric (OCO), has symmetry number 2. 15For example, of the four frequencies characterizing the normal modes of vibration of the collinear molecule OCO, two that correspond to the (transverse) bending modes, namely ↑ O C O ↓ ↓, are equal while the others that correspond to (longitudinal) oscillations along the molecular axis, namely ←O C→ ←O and ←O C O→, are different; see Problem 6.28. 170 Chapter 6. The Theory of Simple Gases and the vibrational speciﬁc heat is given by the sum of the contributions arising from the individual modes: Cvib = Nk ∑ i {( 2i T )2 e2i/T (e2i/T − 1 )2 } . (44) In general, the various 2i are of order 103 K; for instance, in the case of CO2, which was cited in footnote 15, 21 = 22 = 960 K, 23 = 1,990 K, and 24 = 3,510 K. For temperatures large in comparison with all 2i, the speciﬁc heat would be given by the equipartition value, namely Nk for each of the normal modes. In practice, however, this limit can hardly be realized because the polyatomic molecules generally break up well before such high tem- peratures are reached. Secondly, the different frequencies ωi of a polyatomic molecule are generally spread over a rather wide range of values. Consequently, as temperature rises, different modes of vibration get gradually “included” into the process; in between these “inclusions,” the speciﬁc heat of the gas may stay constant over considerably large stretches of temperature. 6.6 Chemical equilibrium The equilibrium amounts of chemicals in a chemical reaction are determined by the chemical potentials of each of the species. Consider the following chemical reaction between chemical species A and B to form species X and Y with stoichiometric coefﬁcients νA, νB, νX , and νY : νAA + νBB ⇄ νX X + νY Y . (1) Each individual reaction that occurs changes the number of molecules of each species according to the stoichiometric coefﬁcients. If the initial numbers of molecules of the species are N 0 A, N 0 B, N 0 X , and N 0 Y , then the numbers of each species after 1N chemical reac- tions have occurred would be NA = N 0 A − νA1N, NB = N 0 B − νB1N, NX = N 0 X + νX 1N, and NY = N 0 Y + νY 1N. If 1N > 0, the reaction has proceeded in the positive direction increas- ing the numbers of X and Y . If 1N < 0, the reaction has proceeded in the direction of increasing the numbers of A and B. If the reaction takes place in a closed isothermal sys- tem with ﬁxed pressure, the Gibbs free energy G(NA, NB, NX , NY , P, T ) is changed by the amount 1G = (−νAµA − νBµB + νX µX + νY µY )1N, (2) where µA = ( ∂G ∂NA ) T ,P is the chemical potential of species A, and so on; see Sections 3.3, 4.7, and Appendix H. Since the Gibbs free energy decreases as a system approaches equi- librium, 1G ≤ 0. When the system reaches chemical equilibrium, the Gibbs free energy reaches its minimum value so 1G = 0. This gives us the general relationship for chemical 6.6 Chemical equilibrium 171 equilibrium of the reaction in equation (1), namely νAµA + νBµB = νX µX + νY µY . (3) Note that if a chemical species that acts as a catalyst is added in equal amounts to both sides of equation (1), the equilibrium relation (3) is unaffected. Therefore, a cata- lyst may serve to increase the rate of approach toward equilibrium, without affecting the equilibrium condition itself. If the free energy can be approximated as a sum of the free energies of the individual species such as in an ideal gas or a dilute solution, then we can derive a simple rela- tion between the equilibrium densities of the species. Following from equations (3.5.10) and (6.5.4), the Helmholtz free energy of a classical ideal gas consisting of molecules with internal degrees of freedom can be written as A(N, V , T ) = Nε + NkT ln ( Nλ3 V ) − NkT − NkT ln j(T ), (4) where ε is the ground state energy of the molecule, λ = h/ √ 2πmkT is the thermal deBroglie wavelength, and j(T ) is the partition function for the internal degrees of freedom of the molecule. This gives for the chemical potential of species A µA = ( ∂A ∂NA ) T ,V = εA + kT ln ( nAλ3 A) − kT ln jA(T ), (5) where nA is the number density of species A. The equilibrium condition then (3) gives [X ]νX [Y ]νY [A]νA [B]νB = K (T ) = exp (−β1µ (0)) , (6) where [A] = nA/n0, and so on, 1µ(0) = νX µ(0) X + νY µ(0) Y − νAµ(0) A − νBµ(0) B , (7a) µ(0) A = εA + kT ln (n0λ3 A) − kT ln jA(T ), etc. (7b) and K (T ) is the equilibrium constant. Equation (6) is called the law of mass action. The quantity n0 is a standard number density and µ (0) A , and so on, are the chemical potentials of the species at temperature T and standard number density n0. The quantity 1µ(0) represents the Gibbs free energy change per chemical reaction at standard density. Note that the reaction constant K (T ) is a function only of the temperature and determines the densities of the components in equilibrium at temperature T through equation (6). The standard number density for gases is usually chosen to be the number density of an ideal gas at temperature T and standard pressure, that is, n0 = (1 atm)/kT . The standard density for aqueous solutions is usually 172 Chapter 6. The Theory of Simple Gases chosen to be one mole per liter. The Gibbs free energy in chemical tables is expressed relative to the standard states of the elements. We now examine a speciﬁc example, the combustion of hydrocarbons with oxygen in an internal combustion engine. The reaction used to power clean buses and automobiles using natural gas is CH4 + 2O2 ⇄ CO2 + 2H2O . (8) The primary reaction products are carbon dioxide and water vapor but carbon monoxide is also produced by the reaction 2CH4 + 3O2 ⇄ 2CO + 4H2O . (9) A primary goal for a clean burning engine is to combust nearly all the hydrocarbon fuel while producing as little carbon monoxide as possible. By combining reactions (8) and (9), we get a direct reaction between carbon monoxide, oxygen, and carbon dioxide: 2CO + O2 ⇄ 2CO2 . (10) Equation (6) now gives the equilibrium ratio of CO to CO2 as [CO] [CO2] = √ 1 K (T )[O2] . (11) At T ≈ 1, 500 K, as combustion occurs inside the cylinder of the engine, the equilibrium constant K ≈ 1010 so carbon monoxide is present as a combustion product in the few parts per million range — combustion reactions that are not in equilibrium can have CO concentrations well above the equilibrium value. The exhaust gases cool quickly during the power stroke of the engine. As these gases exit the exhaust at T ≈ 600 K, the equilib- rium constant K ≈ 1040, which should result in almost no carbon monoxide in the exhaust stream. However, the reaction rate is typically too slow to keep the CO concentration in chemical equilibrium during the rapid cooling, so the amount of CO present in the exhaust stream remains close to the larger value determined at the higher temperature.16 Fortu- nately, the leftover carbon monoxide can be converted into carbon dioxide at the exhaust temperature in a catalytic converter that uses platinum and palladium as catalysts to increase the reaction rate. Equation (11) indicates that the carbon monoxide fraction is reduced by increasing the amount of oxygen present in the reaction. This is accomplished by running the engine with a hydrocarbon/air ratio that is a little bit short of the stoichio- metric point of equation (8). This reduces the amount of CO left from the combustion itself and also leaves excess O2 in the exhaust stream for use in the catalytic converter. 16Very similar effects happened during the early stages of the universe as the temperature cooled but the cooling rate was too rapid for some constituents to remain in thermal equilibrium; see Chapter 9. Problems 173 Problems 6.1. Show that the entropy of an ideal gas in thermal equilibrium is given by the formula S = k ∑ ε [⟨nε + 1⟩ ln⟨nε + 1⟩ − ⟨nε⟩ ln⟨nε⟩] in the case of bosons and by the formula S = k ∑ ε [−⟨1 − nε⟩ ln⟨1 − nε⟩ − ⟨nε⟩ ln⟨nε⟩] in the case of fermions. Verify that these results are consistent with the general formula S = −k ∑ ε {∑ n pε(n) ln pε(n) } , where pε(n) is the probability that there are exactly n particles in the energy state ε. 6.2. Derive, for all three statistics, the relevant expressions for the quantity ⟨n2 ε ⟩ − ⟨nε⟩2 from the respective probabilities pε(n). Show that, quite generally, ⟨n2 ε ⟩ − ⟨nε⟩2 = kT ( ∂⟨nε⟩ ∂µ ) T ; compare with the corresponding result, (4.5.3), for a system embedded in a grand canonical ensemble. 6.3. Refer to Section 6.2 and show that, if the occupation number nε of an energy level ε is restricted to the values 0, 1, . . . , l, then the mean occupation number of that level is given by ⟨nε⟩ = 1 z−1eβε − 1 − l + 1 (z−1eβε)l+1 − 1 . Check that while l = 1 leads to ⟨nε⟩F.D., l → ∞ leads to ⟨nε⟩B.E.. 6.4. The potential energy of a system of charged particles, characterized by particle charge e and number density n(r), is given by U = e2 2 ∫∫ n(r)n(r′) |r − r′| drdr′ + e ∫ n(r)φext(r)dr, where φext(r) is the potential of an external electric ﬁeld. Assume that the entropy of the system, apart from an additive constant, is given by the formula S = −k ∫ n(r) ln n(r)dr; compare to formula (3.3.13). Using these expressions, derive the equilibrium equations satisﬁed by the number density n(r) and the total potential φ(r), the latter being φext(r) + e ∫ n(r′) |r − r′| dr′. 6.5. Show that the root-mean-square deviation in the molecular energy ε, in a system obeying Maxwell–Boltzmann distribution, is √ (2/3) times the mean molecular energy ε. Compare this result with that of Problem 3.18. 6.6. Show that, for any law of distribution of molecular speeds, {⟨u⟩ 〈 1 u 〉} ≥ 1. Check that the value of this quantity for the Maxwellian distribution is 4/π . 174 Chapter 6. The Theory of Simple Gases 6.7. Through a small window in a furnace, which contains a gas at a high temperature T , the spectral lines emitted by the gas molecules are observed. Because of molecular motions, each spectral line exhibits Doppler broadening. Show that the variation of the relative intensity I(λ) with wavelength λ in a line is given by I(λ) ∝ exp { − mc2(λ − λ0)2 2λ2 0kT } , where m is the molecular mass, c the speed of light, and λ0 the mean wavelength of the line. 6.8. An ideal classical gas composed of N particles, each of mass m, is enclosed in a vertical cylinder of height L placed in a uniform gravitational ﬁeld (of acceleration g) and is in thermal equilibrium; ultimately, both N and L → ∞. Evaluate the partition function of the gas and derive expressions for its major thermodynamic properties. Explain why the speciﬁc heat of this system is larger than that of a corresponding system in free space. 6.9. Centrifuge-based uranium enrichment: Natural uranium is composed of two isotopes: 238U and 235U, with percentages of 99.27% and 0.72%, respectively. If uranium hexaﬂuoride gas UF6 is injected into a rapidly spinning hollow metal cylinder with inner radius R, the equilibrium pressure of the gas is largest at the inner radius and isotopic concentration differences between the axis and the inner radius allow enrichment of the concentration of 235U. (a) Write down the Lagrangian L({qk, ˙qk}) for particles of mass m moving in a cylindrical coordinate system rotating at angular velocity ω and use a Legendre transformation H ({qk, pk}) = ∑ k pk ˙qk − L, to show that the one-particle Hamiltonian H in that cylindrical coordinate system is H (r, θ , z, pr, pθ , pz) = p2 r 2m + (p2 θ − mr2ω)2 2mr2 + p2 z 2m . Ignore the internal degrees of freedom of the molecules since they will not affect the density as a function of position. Show that the one-particle partition function shown here can be written as Q1(V , T ) = 1 h3 ∞∫ −∞ dpr ∞∫ −∞ dpθ ∞∫ −∞ dpz R∫ 0 dr 2π∫ 0 dθ H∫ 0 dz exp (−βH ) , by constructing the Jacobian of transformation between the cartesian and the cylindrical coordinates for the phase space integral. Evaluate the partition function Q1 in a closed form and determine the Helmholtz free energy of this system. (b) Determine the number density n(r) as a function of the distance r from the axis for the N molecules of gas in the rotating cylinder. Show that, in the limit ω → 0, the density becomes uniform with the value n = N/πR2H. Find an expression for the ratio of the pressure at the inner radius of the cylinder R to the pressure at the axis of the cylinder as a function of ω and R. (c) Evaluate the pressure ratios for the two isotopically different UF6 gases at room temperature for the case ωR = 500 m/s. Show that the pressure ratio for 238U is approximately 20% larger than the pressure ratio for 235U so that extracting gas near the axis results in an enriched concentration of 235U. A series of centrifuges can be used to raise the concentration of 235U to create a ﬁssionable grade of uranium for use in power-generating reactors or in nuclear weapons. Not surprisingly, this technology is a major concern for possible nuclear proliferation. Problems 175 6.10. (a) Show that, if the temperature is uniform, the pressure of a classical gas in a uniform gravitational ﬁeld decreases with height according to the barometric formula P(z) = P(0) exp {−mgz/kT } , where the various symbols have their usual meanings.17 (b) Derive the corresponding formula for an adiabatic atmosphere, that is, the one in which (PV γ ), rather than (PV ), stays constant. Also study the variation, with height, of the temperature T and the density n in such an atmosphere. 6.11. (a) Show that the momentum distribution of particles in a relativistic Boltzmannian gas, with ε = c(p2 + m2 0c2)1/2, is given by f (p)dp = Ce−βc(p2+m2 0c2)1/2 p 2dp, with the normalization constant C = β m2 0cK2(βm0c2) , Kν (z) being a modiﬁed Bessel function. (b) Check that in the nonrelativistic limit (kT ≪ m0c2) we recover the Maxwellian distribution, f (p)dp = ( β 2πm0 )3/2 e−βp2/2m0 (4π p 2 dp), while in the extreme relativistic limit (kT ≫ m0c2) we obtain f (p)dp = (βc)3 8π e−βpc(4π p 2 dp). (c) Verify that, quite generally, ⟨pu⟩ = 3 kT . 6.12. (a) Considering the loss of translational energy suffered by the molecules of a gas on reﬂection from a receding wall, derive, for a quasistatic adiabatic expansion of an ideal nonrelativistic gas, the well-known relation PV γ = const., where γ = (3a + 2)/3a, a being the ratio of the total energy to the translational energy of the gas. (b) Show that, in the case of an extreme relativistic gas, γ = (3a + 1)/3a. 6.13. (a) Determine the number of impacts made by gas molecules on a unit area of the wall in a unit time for which the angle of incidence lies between θ and θ + dθ . (b) Determine the number of impacts made by gas molecules on a unit area of the wall in a unit time for which the speed of the molecules lies between u and u + du. (c) A molecule AB dissociates if it hits the surface of a solid catalyst with a normal translational energy greater than 10−19 J. Show that the rate of the dissociative reaction AB → A + B is more than doubled by raising the temperature of the gas from 300 K to 310 K. 6.14. Consider the effusion of molecules of a Maxwellian gas through an opening of area a in the walls of a vessel of volume V . (a) Show that, while the molecules inside the vessel have a mean kinetic energy 3 2 kT , the effused ones have a mean kinetic energy 2 kT , T being the quasistatic equilibrium temperature of the gas. 17This formula was ﬁrst given by Boltzmann (1879). For a critical study of its derivation, see Walton (1969). 176 Chapter 6. The Theory of Simple Gases (b) Assuming that the effusion is so slow that the gas inside is always in a state of quasistatic equilibrium, determine the manner in which the density, the temperature, and the pressure of the gas vary with time. 6.15. A polyethylene balloon at an altitude of 30,000 m is ﬁlled with helium gas at a pressure of 10−2 atm and a temperature of 300 K. The balloon has a diameter of 10 m, and has numerous pinholes of diameter 10−5 m each. How many pinholes per square meter of the surface of the balloon must there be if 1 percent of the gas were to leak out in 1 hour? 6.16. Consider two Boltzmannian gases A and B, at pressures PA and PB and temperatures TA and TB, respectively, contained in two regions of space that communicate through a very narrow opening in the partitioning wall; see Figure 6.8. Show that the dynamic equilibrium resulting from the mutual effusion of the two kinds of molecules satisﬁes the condition PA/PB = (mATA/mBTB)1/2, rather than PA = PB (which would be the case if the equilibrium had resulted from a hydrodynamic ﬂow). A (PA, TA) B (PB, TB) FIGURE 6.8 The molecules of the gases A and B undergoing a two-way effusion. 6.17. A small sphere, with initial temperature T , is immersed in an ideal Boltzmannian gas at temperature T0. Assuming that the molecules incident on the sphere are ﬁrst absorbed and then reemitted with the temperature of the sphere, determine the variation of the temperature of the sphere with time. [Note: The radius of the sphere may be assumed to be much smaller than the mean free path of the molecules.] 6.18. Show that the mean value of the relative speed of two molecules in a Maxwellian gas is √ 2 times the mean speed of a molecule with respect to the walls of the container. [Note: A similar result for the root-mean-square speeds (instead of the mean speeds) holds under much more general conditions.] 6.19. What is the probability that two molecules picked at random from a Maxwellian gas will have a total energy between E and E + dE? Verify that ⟨E⟩ = 3kT . 6.20. The energy difference between the lowest electronic state 1S0 and the ﬁrst excited state 3S1 of the helium atom is 159,843 cm−1. Evaluate the relative fraction of the excited atoms in a sample of helium gas at a temperature of 6000 K. 6.21. Derive an expression for the equilibrium constant K (T ) for the reaction H2 + D2 ↔ 2HD at temperatures high enough to allow classical approximation for the rotational motion of the molecules. Show that K (∞) = 4. 6.22. With the help of the Euler–Maclaurin formula (6.5.19), derive high-temperature expansions for reven and rodd, as deﬁned by equations (6.5.29) and (6.5.30), and obtain corresponding expansions for Ceven and Codd, as deﬁned by equation (6.5.39). Compare the mathematical trend of these results with the nature of the corresponding curves in Figure 6.7. Also study the low-temperature behavior of the two speciﬁc heats and once again compare your results with the relevant parts of the aforementioned curves. 6.23. The potential energy between the atoms of a hydrogen molecule is given by the (semiempirical) Morse potential V (r) = V0{e−2(r−r0)/a − 2e−(r−r0)/a}, Problems 177 where V0 = 7 × 10−12 erg, r0 = 8 × 10−9 cm, and a = 5 × 10−9 cm. Evaluate the rotational and vibrational quanta of energy, and estimate the temperatures at which the rotational and vibrational modes of the molecules would begin to contribute toward the speciﬁc heat of the hydrogen gas. 6.24. Show that the fractional change in the equilibrium value of the internuclear distance of a diatomic molecule, as a result of rotation, is given by 1r0 r0 ≃ ( ℏ µr2 0 ω )2 J(J + 1) = 4 ( 2r 2v )2 J(J + 1); here, ω is the angular frequency of the vibrational state in which the molecule happens to be. Estimate the numerical value of this fraction in a typical case. 6.25. The ground state of an oxygen atom is a triplet, with the following ﬁne structure: εJ=2 = εJ=1 − 158.5 cm −1 = εJ=0 − 226.5 cm −1. Calculate the relative fractions of the atoms occupying different J-levels in a sample of atomic oxygen at 300 K. 6.26. Calculate the contribution of the ﬁrst excited electronic state, namely 11 with ge = 2, of the O2 molecule toward the Helmholtz free energy and the speciﬁc heat of oxygen gas at a temperature of 5000 K; the separation of this state from the ground state, namely 36 with ge = 3, is 7824 cm−1. How would these results be affected if the parameters 2r and 2v of the O2 molecule had different values in the two electronic states? 6.27. The rotational kinetic energy of a rotator with three degrees of freedom can be written as εrot = M 2 ξ 2I1 + M 2 η 2I2 + M 2 ζ 2I3 , where (ξ , η, ζ ) are coordinates in a rotating frame of reference whose axes coincide with the principal axes of the rotator, while (Mξ , Mη, Mζ ) are the corresponding angular momenta. Carrying out integrations in the phase space of the rotator, derive expression (6.5.41) for the partition function jrot(T ) in the classical approximation. 6.28. Determine the translational, rotational, and vibrational contributions toward the molar entropy and the molar speciﬁc heat of carbon dioxide at NTP. Assume the ideal-gas formulae and use the following data: molecular weight M = 44.01; moment of inertia I of a CO2 molecule = 71.67 × 10−40 g cm2; wave numbers of the various modes of vibration: ν1 = ν2 = 667.3 cm−1, ν3 = 1383.3 cm−1, and ν4 = 2439.3 cm−1. 6.29. Determine the molar speciﬁc heat of ammonia at a temperature of 300 K. Assume the ideal-gas formula and use the following data: the principal moments of inertia: I1 = 4.44 × 10−40g cm2, I2 = I3 = 2.816 × 10−40g cm2; wave numbers of the various modes of vibration: ν1 = ν2 = 3336 cm−1, ν3 = ν4 = 950 cm−1, ν5 = 3414 cm−1, and ν6 = 1627 cm−1. 6.30. Derive the equilibrium concentration equation (6.6.6) from the equilibrium condition (6.6.3). 6.31. Use the following values to determine the equilibrium constant for the reaction 2CO + O2 ⇄ 2CO2. At a combustion temperature of T = 1500 K: βµ (0) CO2 = −60.95, βµ (0) CO = −35.18, and βµ (0) O2 = −27.08. Use this data to compute the fraction [CO]/[CO2] for the case of [O2] = 0.01. Repeat for a catalytic converter temperature of T = 600 K, where βµ (0) CO2 = −103.45, βµ (0) CO = −45.38, and βµ (0) O2 = −23.49. 6.32. Derive an expression for the equilibrium constant K (T ) for the reaction N2 + O2 ⇄ 2NO in terms of the ground state energy change 1ε0 = 2εNO − εN2 − εO2 and the vibrational and rotational partition functions of the diatomic molecules, using results from Section 6.5. Give predictions for the ranges of temperatures where the rotational modes are classically excited but the vibration modes are suppressed and for higher temperatures where both the rotational and vibrational models are classically excited. 6.33. Analyze the combustion reaction CH4 + 2O2 ⇄ CO2 + 2H2O , (6.6.8) 178 Chapter 6. The Theory of Simple Gases assuming that at combustion temperatures the equilibrium constant K (T ) ≫ 1. Show that conducting combustion at the stoichiometric point or just a bit short of the stoichiometric point (so there is enough oxygen to oxidize all of the methane) will lead to low amounts of CH4 in the exhaust. Determine the equilibrium amount of CH4 in terms of the initial excess amount of O2. Determine the equilibrium constant at T = 1500 K from the data βµ (0) CO2 = −60.95, βµ (0) O2 = −27.08, βµ (0) CH4 = −31.95, and βµ (0) H2O = −44.62. 6.34. Determine the equilibrium ionization fraction for the reaction Na ⇄ Na + + e− in a sodium vapor. Treat all three species as ideal classical monatomic gases. The ionization energy of sodium is 5.139 eV, Na + ions are spin-zero, and neutral Na and free e− are both spin- 1 2 . Derive the Saha equation for the ionized fraction [Na+]/([Na] + [Na+]) for a neutral plasma as a function of temperature at a ﬁxed total density. Plot the ionized fraction as a function of temperature for some chosen total density. [Note that, this calculation is very similar to the one concerning ionized hydrogen fraction as a function of temperature during the recombination era in the early universe; see Section 9.8.] 7 Ideal Bose Systems In continuation of Sections 6.1 through 6.3, we shall now investigate in detail the physical behavior of a class of systems in which, while the intermolecular interactions are still neg- ligible, the effects of quantum statistics (which arise from the indistinguishability of the particles) assume an increasingly important role. This means that the temperature T and the particle density n of the system no longer conform to the criterion nλ 3 ≡ nh3 (2πmkT )3/2 ≪ 1, (5.5.20) where λ{≡ h/(2π mkT )1/2} is the mean thermal wavelength or thermal deBroglie wave- length of the particles. In fact, the quantity nλ3 turns out to be a very appropriate parameter, in terms of which the various physical properties of the system can be ade- quately expressed. In the limit nλ3 → 0, all physical properties go over smoothly to their classical counterparts. For small, but not negligible, values of nλ3, the various quantities pertaining to the system can be expanded as power series in this parameter; from these expansions one obtains the ﬁrst glimpse of the manner in which departure from classi- cal behavior sets in. When nλ3 becomes of the order of unity, the behavior of the system becomes signiﬁcantly different from the classical one and is characterized by quantum effects. A study of the system under these circumstances brings us face to face with a set of phenomena unknown in classical statistics. It is evident that a system is more likely to display quantum behavior when it is at a relatively low temperature and/or has a relatively high density of particles. 1 Moreover, the smaller the particle mass the larger the quantum effects. Now, when nλ3 is of the order of unity, then not only does the behavior of a system exhibit signiﬁcant departure from typical classical behavior but it is also inﬂuenced by whether the particles constituting the system obey Bose–Einstein statistics or Fermi–Dirac statistics. Under these circumstances, the properties of the two kinds of systems are them- selves very different. In the present chapter we consider systems belonging to the ﬁrst category while the succeeding chapter will deal with systems belonging to the second category. 1Actually it is the ratio n/T 3/2, rather than the quantities n and T separately, that determines the degree of degeneracy in a given system. For instance, white dwarf stars, even at temperatures of order 107 K, constitute statistically degenerate systems; see Section 8.5. Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00007-4 © 2011 Elsevier Ltd. All rights reserved. 179 180 Chapter 7 . Ideal Bose Systems 7.1 Thermodynamic behavior of an ideal Bose gas We obtained, in Sections 6.1 and 6.2, the following formulae for an ideal Bose gas: PV kT ≡ ln Q = − ∑ ε ln(1 − ze−βε) (1) and N ≡ ∑ ε ⟨nε⟩ = ∑ ε 1 z−1eβε − 1 , (2) where β = 1/kT , while z is the fugacity of the gas which is related to the chemical potential µ through the formula z ≡ exp(µ/kT ); (3) as noted earlier, ze−βε, for all ε, is less than unity. In view of the fact that, for large V , the spectrum of the single-particle states is almost a continuous one, the summations on the right sides of equations (1) and (2) may be replaced by integrations. In doing so, we make use of the asymptotic expression (2.4.7) for the nonrelativistic density of states a(ε) in the neighborhood of a given energy ε, namely2 a(ε)dε = (2πV /h 3)(2m)3/2ε1/2dε. (4) We, however, note that by substituting this expression into our integrals we are inadver- tently giving a weight zero to the energy level ε = 0. This is wrong because in a quantum- mechanical treatment we must give a statistical weight unity to each nondegenerate single-particle state in the system. It is, therefore, advisable to take this particular state out of the sum in question before carrying out the integration; for a rigorous justiﬁcation of this (unusual) step, see Appendix F. We thus obtain P kT = − 2π h3 (2m)3/2 ∞∫ 0 ε1/2 ln(1 − ze−βε)dε − 1 V ln(1 − z) (5) and N V = 2π h3 (2m)3/2 ∞∫ 0 ε1/2dε z−1eβε − 1 + 1 V z 1 − z ; (6) of course, the lower limit of these integrals can still be taken as 0, because the state ε = 0 is not going to contribute toward them anyway. Before proceeding further, a word about the relative importance of the last terms in equations (5) and (6). For z ≪ 1, which corresponds to situations not far removed from 2The theory of this section is restricted to a system of nonrelativistic particles. For the more general case, see Kothari and Singh (1941) and Landsberg and Dunning-Davies (1965). 7.1 Thermodynamic behavior of an ideal Bose gas 181 the classical limit, each of these terms is of order 1/N and, therefore, negligible. How- ever, as z increases and assumes values close to unity, the term z/(1 − z)V in (6), which is identically equal to N0/V (N0 being the number of particles in the ground state ε = 0), can well become a signiﬁcant fraction of the quantity N/V ; this accumulation of a macro- scopic fraction of the particles into a single state ε = 0 leads to the phenomenon of Bose–Einstein condensation. Nevertheless, since z/(1 − z) = N0 and hence z = N0/(N0 + 1), the term {−V −1 ln(1 − z)} in (5) is equal to {V −1 ln(N0 + 1)}, which is at most O(N −1 ln N); this term is, therefore, negligible for all values of z and hence may be dropped altogether. We now obtain from equations (5) and (6), on substituting βε = x, P kT = − 2π(2mkT )3/2 h3 ∞∫ 0 x1/2 ln(1 − ze−x)dx = 1 λ3 g5/2(z) (7) and N − N0 V = 2π(2mkT )3/2 h3 ∞∫ 0 x1/2dx z−1ex − 1 = 1 λ3 g3/2(z), (8) where λ = h/(2π mkT ) 1/2, (9) while gν(z) are Bose–Einstein functions deﬁned by, see Appendix D, gν (z) = 1 0(ν) ∞∫ 0 xν−1dx z−1ex − 1 = z + z2 2ν + z3 3ν + · · · ; (10) note that to write (7) in terms of the function g5/2(z) we ﬁrst carried out an integration by parts. Equations (7) and (8) are our basic results; on elimination of z, they would give us the equation of state of the system. The internal energy of this system is given by U ≡ −( ∂ ∂β ln Q ) z,V = kT 2{ ∂ ∂T ( PV kT )} z,V = kT 2V g5/2(z){ d dT ( 1 λ3 )} = 3 2 kT V λ3 g5/2(z); (11) here, use has been made of equation (7) and of the fact that λ ∝ T −1/2. Thus, quite generally, our system satisﬁes the relationship P = 2 3 (U/V ). (12) For small values of z, we can make use of expansion (10); at the same time, we can neglect N0 in comparison with N. An elimination of z between equations (7) and (8) can then be 182 Chapter 7 . Ideal Bose Systems carried out by ﬁrst inverting the series in (8) to obtain an expansion for z in powers of nλ3 and then substituting this expansion into the series appearing in (7). The equation of state thereby takes the form of the virial expansion, PV NkT = ∞∑ l=1 al ( λ3 v )l−1 , (13) where v (≡ 1/n) is the volume per particle; the coefﬁcients al, which are referred to as the virial coefﬁcients of the system, turn out to be a1 = 1, a2 = − 1 4 √ 2 = −0.17678, a3 = −( 2 9 √3 − 1 8 ) = −0.00330, a4 = −( 3 32 + 5 32 √2 − 1 2 √ 6 ) = −0.00011,    (14) and so on. For the speciﬁc heat of the gas, we obtain CV Nk ≡ 1 Nk ( ∂U ∂T ) N,V = 3 2 { ∂ ∂T ( PV Nk )} v = 3 2 ∞∑ l=1 5 − 3l 2 al ( λ3 v )l−1 = 3 2  1 + 0.0884 ( λ3 v ) + 0.0066 ( λ3 v )2 + 0.0004 ( λ3 v )3 + · · ·  . (15) As T → ∞ (and hence λ → 0), both the pressure and the speciﬁc heat of the gas approach their classical values, namely nkT and 3 2 Nk, respectively. We also note that at ﬁnite, but large, temperatures the speciﬁc heat of the gas is larger than its limiting value; in other words, the (CV , T )-curve has a negative slope at high temperatures. On the other hand, as T → 0, the speciﬁc heat must go to zero. Consequently, it must pass through a maximum somewhere. As seen later, this maximum is in the nature of a cusp that appears at a criti- cal temperature Tc; the derivative of the speciﬁc heat is found to be discontinuous at this temperature (see Figure 7.4 later in this section). As the temperature of the system falls (and the value of the parameter λ3/v grows), expansions such as (13) and (15) do not remain useful. We then have to work with formulae (7), (8), and (11) as such. The precise value of z is now obtained from equation (8), which may be rewritten as Ne = V (2π mkT )3/2 h3 g3/2(z), (16) 7.1 Thermodynamic behavior of an ideal Bose gas 183 where Ne is the number of particles in the excited states (ε ̸= 0); of course, unless z gets extremely close to unity, Ne ≃ N. 3 It is obvious that, for 0 ≤ z ≤ 1, the function g3/2(z) increases monotonically with z and is bounded, its largest value being g3/2(1) = 1 + 1 23/2 + 1 33/2 + · · · ≡ ζ ( 3 2 ) ≃ 2.612; (17) see equation (D.5) in Appendix D. Hence, for all z of interest, g3/2(z) ≤ ζ ( 3 2 ) . (18) Consequently, for given V and T , the total (equilibrium) number of particles in all the excited states taken together is also bounded, that is, Ne ≤ V (2πmkT )3/2 h3 ζ ( 3 2 ) . (19) Now, so long as the actual number of particles in the system is less than this limiting value, everything is well and good; practically all the particles in the system are distributed over the excited states and the precise value of z is determined by equation (16), with Ne ≃ N. However, if the actual number of particles exceeds this limiting value, then it is natural that the excited states will receive as many of them as they can hold, namely Ne = V (2πmkT )3/2 h3 ζ ( 3 2 ), (20) while the rest will be pushed en masse into the ground state ε = 0 (whose capacity, under all circumstances, is essentially unlimited): N0 = N − { V (2π mkT )3/2 h3 ζ ( 3 2 )} . (21) The precise value of z is now determined by the formula z = N0 N0 + 1 ≃ 1 − 1 N0 (22) which, for all practical purposes, is unity. This curious phenomenon of a macroscopi- cally large number of particles accumulating in a single quantum state (ε = 0) is generally referred to as the phenomenon of Bose–Einstein condensation. In a certain sense, this phenomenon is akin to the familiar process of a vapor condensing into the liquid state, which takes place in the ordinary physical space. Conceptually, however, the two pro- cesses are very different. Firstly, the phenomenon of Bose–Einstein condensation is purely 3Remember that the largest value z can have in principle is unity. In fact, as T → 0, z = N0/(N0 + 1) → N/(N + 1), which is very nearly unity (but certainly on the right side of it). 184 Chapter 7 . Ideal Bose Systems of quantum origin (occurring even in the absence of intermolecular forces); secondly, it takes place at best in the momentum space and not in the coordinate space.4 The condition for the onset of Bose–Einstein condensation is N > VT 3/2 (2π mk)3/2 h3 ζ ( 3 2 ) (23) or, if we hold N and V constant and vary T , T < Tc = h2 2π mk    N V ζ ( 3 2 )    2/3 ; (24)5 here, Tc denotes a characteristic temperature that depends on the particle mass m and the particle density N/V in the system. Accordingly, for T < Tc, the system may be looked on as a mixture of two “phases”: (i) a normal phase, consisting of Ne {= N(T /Tc)3/2} particles distributed over the excited states (ε ̸= 0), and (ii) a condensed phase, consisting of N0 {= (N − Ne)} particles accumulated in the ground state (ε = 0). Figure 7.1 shows the manner in which the complementary fractions (Ne/N) and (N0/N) vary with T . For T > Tc, we have the normal phase alone; the number of particles in the ground state, namely z/(1 − z), is O(1), which is completely negligible in comparison with the total number N. Clearly, the situation is singular at T = Tc. For later reference, we note that, at T → Tc from below, the condensate fraction vanishes as follows: N0 N = 1 −( T Tc )3/2 ≈ 3 2 Tc − T Tc . (25) A knowledge of the variation of z with T is also of interest here. It is, however, sim- pler to consider the variation of z with (v/λ3), the latter being proportional to T 3/2. For 0 ≤ (v/λ3) ≤ (2.612)−1, which corresponds to 0 ≤ T ≤ Tc, the parameter z ≃ 1; see equation (22). For (v/λ3) > (2.612)−1, z < 1 and is determined by the relationship g3/2(z) = (λ 3/v) < 2.612; (26)6 4Of course, the repercussions of this phenomenon in the coordinate space are no less curious. It prepares the stage for the onset of superﬂuidity, a quantum manifestation discussed in Section 7.6. 5For a rigorous discussion of the onset of Bose–Einstein condensation, see Landsberg (1954b), where an attempt has also been made to coordinate much of the previously published work on this topic. For a more recent study, see Greenspoon and Pathria (1974), Pathria (1983), and Appendix F. 6An equivalent relationship is g3/2(z)/g3/2(1) = (Tc/T )3/2 < 1. 7.1 Thermodynamic behavior of an ideal Bose gas 185 1.0 00 1.0 1 2NeNN0N, (T/Tc)21 FIGURE 7.1 Fractions of the normal phase and the condensed phase in an ideal Bose gas as a function of the temperature parameter (T /Tc). 1.0 0.5 00 1.0 2.01 2.612 (v/\u0002 3)z z \u0002(v /\u00023)\u00021 FIGURE 7.2 The fugacity of an ideal Bose gas as a function of (v/λ3). see equation (8). For (v/λ3) ≫ 1, we have g3/2(z) ≪ 1 and, hence, z ≪ 1. Under these circumstances, g3/2(z) ≃ z; see equation (10). Therefore, in this region, z ≃ (v/λ3)−1, in agreement with the classical case.7 Figure 7.2 shows the variation of z with (v/λ3). Next, we examine the (P, T )-diagram of this system, that is, the variation of P with T , keeping v ﬁxed. Now, for T < Tc, the pressure is given by equation (7), with z replaced by unity: P(T ) = kT λ3 ζ ( 5 2 ) , (27) which is proportional to T 5/2 and is independent of v — implying inﬁnite compressibility. At the transition point the value of the pressure is P(Tc) = ( 2π m h2 )3/2 (kTc) 5/2ζ ( 5 2 ) ; (28) 7Equation (6.2.12) gives, for an ideal classical gas, ln Q = zV /λ3. Accordingly, N ≡ z(∂ ln Q/∂z) = z(V /λ3), with the result that z = (λ3/v). 186 Chapter 7 . Ideal Bose Systems with the help of (24), this can be written as P(Tc) = ζ ( 5 2 ) ζ ( 3 2 ) ( N V kTc ) ≃ 0.5134 ( N V kTc ) . (29) Thus, the pressure exerted by the particles of an ideal Bose gas at the transition temper- ature Tc is about one-half of that exerted by the particles of an equivalent Boltzmannian gas. 8 For T > Tc, the pressure is given by P = N V kT g5/2(z) g3/2(z) , (30) where z(T ) is determined by the implicit relationship g3/2(z) = λ3 v = N V h3 (2π mkT )3/2 . (26a) Unless T is very high, the pressure P cannot be expressed in any simpler terms; of course, for T ≫ Tc, the virial expansion (13) can be used. As T → ∞, the pressure approaches the classical value NkT /V . All these features are shown in Figure 7.3. The transition line in the ﬁgure portrays equation (27). The actual (P, T )-curve follows this line from T = 0 up to T = Tc and thereafter departs, tending asymptotically to the classical limit. It may be pointed out that the region to the right of the transition line belongs to the normal phase alone, the line itself belongs to the mixed phase, while the region to the left is inaccessible to the system. In view of the direct relationship between the internal energy of the gas and its pres- sure, see equation (12), Figure 7.3 depicts equally well the variation of U with T (of course, with v ﬁxed). Its slope should, therefore, be a measure of the speciﬁc heat CV (T ) of the gas. We readily observe that the speciﬁc heat is vanishingly small at low temperatures and rises with T until it reaches a maximum at T = Tc; thereafter, it decreases, tending asymptoti- cally to the constant classical value. Analytically, for T ≤ Tc, we obtain [see equations (15) and (27)] CV Nk = 3 2 V N ζ ( 5 2 ) d dT ( T λ3 ) = 15 4 ζ ( 5 2 ) v λ3 , (31) 8Actually, for all T ≤ Tc, we can write P(T ) = P(Tc) · (T /Tc)5/2 ≃ 0.5134(NekT /V ). We infer that, while particles in the condensed phase do not exert any pressure at all, particles in the excited states are about half as effective as in the Boltzmannian case. 7.1 Thermodynamic behavior of an ideal Bose gas 187 2 Transition line Classical B.E. 1 0 01 2 3PVNkTc2U3NkTc (T /Tc)\u0002 FIGURE 7.3 The pressure and the internal energy of an ideal Bose gas as a function of the temperature parameter (T /Tc). which is proportional to T 3/2. At T = Tc, we have CV (Tc) Nk = 15 4 ζ ( 5 2 ) ζ ( 3 2 ) ≃ 1.925, (32) which is signiﬁcantly higher than the classical value 1.5. For T > Tc, we obtain an implicit formula. First of all, CV Nk = [ ∂ ∂T ( 3 2 T g5/2(z) g3/2(z) )] v ; (33) see equations (11) and (26). To carry out the differentiation, we need to know (∂z/∂T )v; this can be obtained from equation (26) with the help of the recurrence relation (D.10) in Appendix D. On one hand, since g3/2(z) ∝ T −3/2, [ ∂ ∂T g3/2(z)] v = − 3 2T g3/2(z); (34) on the other, z ∂ ∂z g3/2(z) = g1/2(z). (35) Combining these two results, we obtain 1 z ( ∂z ∂T ) v = − 3 2T g3/2(z) g1/2(z) . (36) 188 Chapter 7 . Ideal Bose Systems Equation (33) now gives CV Nk = 15 4 g5/2(z) g3/2(z) − 9 4 g3/2(z) g1/2(z) ; (37) the value of z, as a function of T , is again to be determined from equation (26). In the limit z → 1, the second term in (37) vanishes because of the divergence of g1/2(z), while the ﬁrst term gives exactly the result appearing in (32). The speciﬁc heat is, therefore, con- tinuous at the transition point. Its derivative is, however, discontinuous, the magnitude of the discontinuity being ( ∂CV ∂T ) T =Tc−0 − ( ∂CV ∂T ) T =Tc+0 = 27Nk 16πTc { ζ ( 3 2 )}2 ≃ 3.665 Nk Tc ; (38) see Problem 7.6. For T > Tc, the speciﬁc heat decreases steadily toward the limiting value ( CV Nk ) z→0 = 15 4 − 9 4 = 3 2 . (39) Figure 7.4 shows all these features of the (CV , T )-relationship. It may be noted that it was the similarity of this curve with the experimental one for liquid He4 (Figure 7.5) that prompted F. London to suggest, in 1938, that the curious phase transition that occurs in liquid He4 at a temperature of about 2.19 K might be a manifestation of the Bose–Einstein condensation taking place in the liquid. Indeed, if we substitute, in (24), data for liquid He 4, namely m = 6.65 × 10−24 g and V = 27.6 cm3/mole, we obtain for Tc a value of about 3.13 K, which is not drastically different from the observed transition temperature of the liquid. Moreover, the interpretation of the phase transition in liquid He4 as Bose–Einstein condensation provides a theoretical basis for the two-ﬂuid model of this liquid, which was empirically put forward by Tisza (1938a,b) to explain the physical behavior of the liquid below the transition temperature. According to London, the N0 particles that occupy a single, entropyless state (ε = 0) could be identiﬁed with the “superﬂuid component” of the liquid and the Ne particles that occupy the excited states (ε ̸= 0) with the “normal component.” As required in the 001 2 3 1.5Cv~T3/2 1.925 (T/Tc)(Cv/Nk)FIGURE 7.4 The speciﬁc heat of an ideal Bose gas as a function of the temperature parameter (T /Tc). 7.1 Thermodynamic behavior of an ideal Bose gas 189 1.5 2.0 2.5 3.0 0 0.5 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 3.0 T (K)C (cal g21 K21) FIGURE 7.5 The speciﬁc heat of liquid He 4 under its own vapor pressure (after Keesom and coworkers). model of Tisza, the superﬂuid fraction makes its appearance at the transition tempera- ture Tc, and builds up at the cost of the normal fraction until at T = 0 the whole ﬂuid becomes superﬂuid; compare to Figure 7.1. Of course, the actual temperature dependence of these fractions, and of other physical quantities pertaining to liquid He4, is consider- ably different from what the simple-minded ideal Bose gas suggests. London had expected that the inclusion of intermolecular interactions would improve the quantitative agree- ment. Although this expectation has been partially vindicated, there have been other advances in the ﬁeld that provide alternative ways of looking at the helium problem; see Section 7.6. Nevertheless, many of the features provided by London’s interpretation of this phenomenon continue to be of value. Historically, the experimental measurements of the speciﬁc heat of liquid He 4, which led to the discovery of this so-called He I–He II transition, were ﬁrst made by Keesom in 1927 and 1928. Struck by the shape of the (CV , T )-curve, Keesom gave this transition the name λ-transition; as a result, the term transition temperature (or transition point) also came to be known as λ-temperature (or λ-point). We shall now look at the isotherms of the ideal Bose gas; that is, the variation of the pressure of the gas with its volume, keeping T ﬁxed. The Bose–Einstein condensation now sets in at a characteristic volume vc, given by vc = λ 3/ζ ( 3 2 ) ; (40) see (23). We note that vc ∝ T −3/2. For v < vc, the pressure of the gas is independent of v and is given by P0 = kT λ3 ζ ( 5 2 ) ; (41) 190 Chapter 7 . Ideal Bose Systems P01 P02 Pv 5/3 \u0002 const. Vc 2 Vc 1 T 2 \u0003 T 1Transition line V FIGURE 7.6 The isotherms of an ideal Bose gas. see (27). The region of the mixed phase in the (P, v)-diagram is marked by a boundary line (called the transition line) given by the equation P0v5/3 c = h2 2πm ζ ( 5 2 ) { ζ ( 3 2 )}5/3 = const.; (42) see Figure 7.6. Clearly, the region to the left of this line belongs to the mixed phase, while the region to the right belongs to the normal phase alone. Finally, we examine the adiabats of the ideal Bose gas. For this, we need an expression for the entropy of the system. Making use of the thermodynamic formula U − TS + PV ≡ Nµ (43) and the expressions for U and P obtained above, we get S Nk ≡ U + PV NkT − µ kT =    5 2 g5/2(z) g3/2(z) − ln z for T > Tc, (44a) 5 2 v λ3 ζ ( 5 2 ) for T ≤ Tc; (44b) again, the value of z(T ), for T > Tc, is to be obtained from equation (26). Now, a reversible adiabatic process implies the constancy of S and N. For T > Tc, this implies the constancy of z as well and in turn, by (26), the constancy of (v/λ3). For T ≤ Tc, it again implies the same. We thus obtain, quite generally, the following relationship between the volume and the temperature of the system when it undergoes a reversible adiabatic process: vT 3/2 = const. (45) The corresponding relationship between the pressure and the temperature is P/T 5/2 = const.; (46) 7.2 Bose–Einstein condensation in ultracold atomic gases 191 see equations (7) and (27). Eliminating T , we obtain Pv5/3 = const. (47) as the equation for an adiabat of the ideal Bose gas. Incidentally, the foregoing results are exactly the same as for an ideal classical gas. There is, however, a signiﬁcant difference between the two cases; that is, while the exponent 5 3 in formula (47) is identically equal to the ratio of the speciﬁc heats CP and CV in the case of the ideal classical gas, it is not so in the case of the ideal Bose gas. For the latter, this ratio is given by γ ≡ CP CV = 1 + 4 9 CV Nk g1/2(z) g3/2(z) (48a) = 5 3 g5/2(z)g1/2(z) {g3/2(z)}2 ; (48b) see Problems 7.4 and 7.5. It is only for T ≫ Tc that γ ≃ 5 3 . At any ﬁnite temperature, γ > 5 3 and as T → Tc, γ → ∞. Equation (47), on the other hand, holds for all T . In the mixed-phase region (T < Tc), the entropy of the gas may be written as S = Ne · 5 2 k ζ ( 5 2 ) ζ ( 3 2 ) ∝ Ne; (49) see equations (20) and (44b). As expected, the N0 particles that constitute the “condensate” do not contribute toward the entropy of the system, while the Ne particles that constitute the normal part contribute an amount of 5 2 kζ ( 5 2 )/ζ ( 3 2 ) per particle. 7.2 Bose–Einstein condensation in ultracold atomic gases The ﬁrst demonstration of Bose–Einstein condensation in ultracold atomic gases came in 1995. Cornell and Wieman Bose-condensed 87Rb (Anderson, Ensher, Matthews, Wieman, and Cornell (1995)) and Ketterle Bose-condensed 23Na (Davis, Mewes, Andrews, van Druten, Durfee, Kurn, and Ketterle (1995)) using magneto-optical traps (MOTs) and magnetic traps to cool vapors of tens of thousands of atoms to temperatures of a few nanokelvin. 9 A survey of the theory and experiments can be found in Pitaevskii and Stringari (2003), Leggett (2006), and Pethick and Smith (2008). The ﬁrst step of the cooling of the atomic vapor uses three sets of counter-propagating laser beams oriented along cartesian axes that are tuned just below the resonant frequency 9Since 1995, many isotopes have been Bose-condensed including 7Li, 23Na, 41K, 52Cr, 84Sr, 85Rb, 87Rb, 133Cs, and 174Yb. The ﬁrst molecular Bose–Einstein condensates were created in 2003 by the research groups of Rudolf Grimm at the University of Innsbruck, Deborah S. Jin at the University of Colorado at Boulder, and Wolfgang Ketterle at Massachusetts Institute of Technology. 192 Chapter 7 . Ideal Bose Systems of the atoms in the trap. Atoms that are stationary are just off resonance and so rarely absorb a photon. Moving atoms are Doppler shifted on resonance to the laser beam that is propagating opposite to the velocity vector of the atom. Those atoms preferentially absorb photons from that direction and then reemit in random directions, resulting in a net momentum kick opposite to the direction of motion. This results in an “optical molasses” that slows the atoms. This cooling method is constrained by the “recoil limit” in which the atoms have a minimum momentum of the order of the momentum of the photons used to cool the gas. This gives a limiting temperature of (hf )2/2mc2k ≈ 1 µK, where f is the frequency of the spectral line used for cooling and m is the mass of an atom. In the next step of the cooling process, the lasers are turned off and a spatially vary- ing magnetic ﬁeld creates an attractive anisotropic harmonic oscillator potential near the center of the magnetic trap V (r) = 1 2 m (ω2 1x2 + ω2 2y2 + ω2 3z2). (1) The frequencies of the trap ωα are controlled by the applied magnetic ﬁeld. One can then lower the trap barrier using a resonant transition to remove the highest energy atoms in the trap. If the atoms in the vapor are sufﬁciently coupled to one other, then the remaining atoms in the trap are cooled by evaporation. If the interactions between the atoms in the gas can be neglected, the energy of each atom in the harmonic oscillator potential is εl1,l2,l3 = ℏω1l1 + ℏω2l2 + ℏω3l3 + 1 2 ℏ(ω1 + ω2 + ω3) , (2) where lα (= 0, 1, 2, . . . ∞) are the quantum numbers of the harmonic oscillator. If the three frequencies are all the same, then the quantum degeneracy of a level with energy ε = ℏω(l + 3/2) is (l + 1)(l + 2)/2; see Problem 3.26. For the general anisotropic case, the smoothed density of states as a function of energy (suppressing the zero point energy and assuming ε ≫ ℏωα) is given by a(ε) = ∞∫ 0 ∞∫ 0 ∞∫ 0 δ (ε − ℏω1l1 − ℏω2l2 − ℏω3l3) dl1dl2dl3 = ε2 2 (ℏω0)3 , (3) where ω0 = (ω1ω2ω3) 1/3; this assumes a single spin state per atom. The thermodynamic potential 5, see Appendix H, for bosons in the trap is then given by 5(µ, T ) = − ( kT )4 2 (ℏω0)3 ∞∫ 0 x2 ln ( 1 − e−xeβµ) dx = (kT )4 (ℏω0)3 g4(z), (4) 7.2 Bose–Einstein condensation in ultracold atomic gases 193 where z = exp(βµ) is the fugacity and gν(z) is deﬁned in Appendix D. Volume is not a parameter in the thermodynamic potential since the atoms are conﬁned by the har- monic trap. The average number of atoms in the excited states in the trap is N(µ, T ) = ( ∂5 ∂µ ) T = ( kT ℏω0 )3 g3(z) . (5) For ﬁxed N, the chemical potential monotonically increases as temperature is lowered until Bose–Einstein condensation occurs when µ = 0 (z = 1). The critical temperature for N trapped atoms is then given by kTc ℏω0 = ( N ζ (3) )1/3 , (6) where ζ (3) = g3(1) ≃ 1.202. While the spacing of the energy levels is of order ℏω0, the crit- ical temperature for condensation is much larger than the energy spacing of the lowest levels for N ≫ 1. A typical magnetic trap oscillation frequency f ≈ 100Hz. For N = 2 × 104, as in Cornell and Wieman’s original experiment, kTc/ℏω0 ≈ 25.5. The observed critical temperature was about 170nK (Anderson et al. (1995)). For T < Tc, the number of atoms in the excited states is Nexcited N = ζ (3) N ( kT ℏω0 )3 = ( T Tc )3 , (7) so the fraction of atoms that condense into the ground state of the harmonic oscillator is N0 N = 1 − ( T Tc )3 ; (8) see de Groot, Hooyman, and ten Seldam (1950), and Bagnato, Pritchard, and Kleppner (1987). In the thermodynamic limit, a nonzero fraction of the atoms occupy the ground state for T < Tc. By contrast, the occupancy of the ﬁrst excited state is only of order N 1/3, so in the thermodynamic limit the occupancy fraction in each excited state is zero. A compar- ison of the experimentally measured Bose-condensed fraction with equation (8) is shown in Figure 7.7. 7.2.A Detection of the Bose–Einstein condensate The linear size of the ground state wavefunction in cartesian direction α is aα = √ ℏ mωα , (9) 194 Chapter 7 . Ideal Bose Systems 0.8 0.6 0.4 0.2 0.0 0.0 0.0 0.5 1.0 1.5 0.5 1.0 T/Tc(N )N(104)N0/N 1.5 1.0 12 8 4 FIGURE 7.7 Experimental measurement of the Bose-condensed fraction vs. temperature, as compared to equation (8). The scaled temperature on the horizontal axis is the temperature divided by the N-dependent critical temperature given in equation (6). The inset shows the total number of atoms in the trap after the evaporative cooling. From Ensher et al. (1996). Reprinted with permission; copyright © 1996, American Physical Society. while the linear size of the thermal distribution of the noncondensed atoms in that direction is athermal = √ kT mω2 α = aα √ kT ℏωα . (10) At trap frequency f = 100 Hz and temperature T = 100 nK, these sizes are about 1 µm and 5 µm, respectively. Instead of measuring the atoms directly in the trapping potential, experimenters usually measure the momentum distribution of the ultracold gas by a time- of-ﬂight experiment. At time t = 0, the magnetic ﬁeld is turned off suddenly, eliminating the trapping potential. The atomic cloud then expands according to the momentum dis- tribution the atoms had in the harmonic trap. The cloud is allowed to expand for about 100 milliseconds. The speed of the atoms at this temperature is a few millimeters per second, so the cloud expands to a few hundred microns in this period of time. The cloud is then illuminated with a laser pulse on resonance with the atoms, leaving a shadow on a CCD in the image plane of the optics. The size and shape of the light intensity pattern directly measures the momentum distribution the atoms had in the trap at t = 0. The expanding cloud can be divided into two components, the N0 atoms that had been Bose-condensed into the ground state and the remaining N − N0 atoms that were in the excited states of the harmonic oscillator potential. The Bose-condensed atoms have smaller momenta than the atoms that were in the excited states. After time t, the quantum evolution of the ground 7.2 Bose–Einstein condensation in ultracold atomic gases 195 state has a spatial number density n0(r, t) = N0 |ψ0(r, t)| 2 = N0 π 3/2 3∏ α=1   1 aα√ 1 + ω2 αt2 exp ( −r2 α a2 α (1 + ω2 αt2) ) ; (11) see Pitaevskii and Stringari (2003), Pethick and Smith (2008), and Problem 7.15. The atoms that are not condensed into the ground state can be treated semiclassi- cally, that is, the position-momentum distribution function is treated classically while the density follows the Bose–Einstein distribution function: f (r, p, 0) = 1 exp ( βp2 2m + βm 2 ( ω2 1x2 + ω2 2y2 + ω2 3z2) − βµ) − 1 . (12) After the potential is turned off at t = 0, the distribution evolves ballistically: f (r, p, t) = f ( r + pt m , p, 0) . (13) The spatial number density of atoms in the excited states is nexcited(r, t) = 1 h3 ∫ f ( r + pt m , p, t) dp , (14) which can be integrated to give nexcited(r, t) = 1 λ3 ∞∑ j=1 eβµj j3/2    3∏ α=1   1 √ 1 + ω2 αt2 exp ( −βjmω2 αr2 α 2 ( 1 + ω2 αt2) )     , (15) where λ = h/√ 2π mkT is the thermal deBroglie wavelength; see Pethick and Smith (2008), and Problem 7.16. The integrals over the condensed state and the excited states correctly count all the atoms: N0 = ∫ n0(r, t)dr, (16a) N − N0 = ∫ nexcited(r, t)dr = Nexcited; (16b) see Problem 7.18. Note that at early times (ωαt ≪ 1) both the condensed and the excited distributions are anisotropic due to the anisotropic trapping potential. However, at late times (ωαt ≫ 1), the atoms from the excited states form a spherically symmetric cloud because of the isotropic momentum dependence of the t = 0 distribution function. By contrast, the atoms that were condensed into the ground state expand anisotropically due to the different spa- tial extents of the ground state wavefunction at t = 0. The direction that has the largest 196 Chapter 7 . Ideal Bose Systems FIGURE 7.8 The two-dimensional time-of-ﬂight number density equations (11) and (15) at late times (ω0t ≫ 1) for T /Tc = 0.98 using the experimental parameters in Anderson et al. (1995): N = 2 × 104 atoms in the trap and ω2 = √8ω1. The plot shows the full density and, underneath, the broader isotropic density just due to the excited states. The z-dimension has been integrated out. The Bose-condensed peak is anisotropic: the y-direction spread is 81/4 = 1.68 times larger than in the x-direction while the broad peak caused by the excited states is isotropic. The distance scale v0t = t√ ℏω1/m determines the width of the distribution that results from the Bose-condensed peak in the x-direction at late times; compare to Figure 7.9. ωα is quantum mechanically squeezed the most at t = 0; so, according to the uncertainty principle, it expands the fastest. This is an important feature of the experimental data that conﬁrms the onset of Bose–Einstein condensation;10 see Figures 7.8 and 7.9. 7.2.B Thermodynamic properties of the Bose–Einstein condensate The temperature, condensate fraction, and internal energy can all be observed using time- of-ﬂight measurements. The internal energy can also be written in terms of the function gν(z): U(µ, T ) = ∞∫ 0 ε3 2(ℏω0)3 1 eβ(ε−µ) − 1 dε = 3 (kT )4 (ℏω0)3 g4(z). (17) 10Repulsive interactions between atoms create additional forces that modify the time-of-ﬂight expansion. This is especially important in condensates with a very large numbers of atoms, as many as 107 or more in some experiments; see Section 11.2.A. 7.2 Bose–Einstein condensation in ultracold atomic gases 197 FIGURE 7.9 Time-of-ﬂight images from the ﬁrst observation of Bose–Einstein condensation in a dilute vapor of 87Rb by Anderson et al. (1995) at temperatures just above and below the phase transition temperature. The anisotropic pattern of the Bose-condensed fraction is evident; compare to Figure 7.8. Courtesy of NIST/JILA/University of Colorado. The heat capacity at constant number can be written as CN (T ) = ( ∂U ∂T ) N = ( ∂U ∂T ) µ + ( ∂U ∂µ ) T ( ∂µ ∂T ) N = ( ∂U ∂T ) µ − ( ∂U ∂T ) µ ( ∂N ∂T ) µ ( ∂N ∂µ ) T . (18) Equations (5) and (6) can be used to determine the fugacity z numerically, as shown in Figure 7.10(a). The fugacity can then be used in equation (17) to obtain the scaled internal energy U NkTc =    3 ( T Tc )4 ζ (4) ζ (3) for T ≤ Tc, 3 ( T Tc )4 g4(z) ζ (3) for T ≥ Tc; (19) 198 Chapter 7 . Ideal Bose Systems see Figures 7.10(b) and 7.12. The scaled speciﬁc heat is given by CN Nk =    12ζ (4) ζ (3) ( T Tc )3 for T < Tc, 1 ζ (3) ( T Tc )3 ( 12g4(z) − 9g2 3 (z) g2(z) ) for T > Tc, (20) and is shown in Figure 7.11. Unlike the case of Bose–Einstein condensation of free parti- cles in a box (Figure 7.4), the speciﬁc heat of a condensate in a harmonic trap displays a (a) (b) 1.5 1.0 0.5 0.0 0.0 0.5 1.0 T/Tc T/Tc 1.5 2.0 0.0 0 2 4 6 0.5 1.0 1.5 2.0z\u0002exp(\u0002\u0003)UNkTc FIGURE 7.10 Fugacity (a) and scaled internal energy (b) vs. scaled temperature (T /Tc) for a Bose–Einstein condensate in a harmonic trap. 12 10 8 6 4 2 0 0.0 0.5 1.0 T/Tc 1.5 2.0CNNk FIGURE 7.11 Scaled speciﬁc heat of a Bose–Einstein condensate in a harmonic trap as a function of the scaled temperature (T /Tc); compare with Figure 7.4 for a free-particle Bose gas. 7.2 Bose–Einstein condensation in ultracold atomic gases 199 discontinuity at the critical temperature: CN Nk →    12ζ (4) ζ (3) ≃ 10.805 as T → T − c , 12ζ (4) ζ (3) − 9ζ (3) ζ (2) ≃ 4.228 as T → T + c . (21) Figure 7.12 shows experimental data for the internal energy of a Bose–Einstein con- densate of 87Rb. The break in slope is an indication of the discontinuous speciﬁc heat. Naturally, in a system with a ﬁnite number of particles, all nonanalyticities associated with the phase transition are removed. When N is ﬁnite, the condensate fraction approaches zero smoothly and the discontinuity in the heat capacity is rounded off. Pathria (1998) has derived N-dependent temperature markers that indicate the onset of Bose–Einstein con- densation in terms of the condensate fraction and the speciﬁc heat; see also Kirsten and Toms (1996) and Haugerud, Haugest, and Ravndal (1997). 2 1.5 1 0.5 0.5 1 1.5 0 1.110.9 1.5 1.4 1.3 1.2 1.1 T/TcU/NkTc FIGURE 7.12 Comparison of the experimental measurements of Ensher et al. (1996) (diamonds) with the noninteracting internal energy result — see equation (19) and Figure 7.10(b) — (dotted curve), the zero-order solution including interactions (full curve), ﬁrst-order perturbative treatment (dashed curve), and numerical solution (circles). The straight line is the classical Maxwell–Boltzmann result. The inset is an enlargement of the region around the critical temperature. The break in slope is an indication of the discontinuity in the thermodynamic limit speciﬁc heat shown in Figure 7.11; from Minguzzi, Conti, and Tosi (1997). Reprinted with permission; copyright © 1997, American Institute of Physics. 200 Chapter 7 . Ideal Bose Systems 7.3 Thermodynamics of the blackbody radiation One of the most important applications of Bose–Einstein statistics is to investigate the equilibrium properties of the blackbody radiation. We consider a radiation cavity of vol- ume V at temperature T . Historically, this system has been looked on from two, practically identical but conceptually different, points of view: (i) as an assembly of harmonic oscillators with quantized energies (ns + 1 2 )ℏωs, where ns = 0, 1, 2, . . ., and ωs is the (angular) frequency of an oscillator, or (ii) as a gas of identical and indistinguishable quanta — the so-called photons — the energy of a photon (corresponding to the frequency ωs of the radiation mode) being ℏωs. The ﬁrst point of view is essentially the one adopted by Planck (1900), except that we have also included here the zero-point energy of the oscillator; for the thermodynamics of the radiation, this energy is of no great consequence and may be dropped altogether. The oscillators, being distinguishable from one another (by the very values of ωs), would obey Maxwell–Boltzmann statistics; however, the expression for the single-oscillator par- tition function Q1(V , T ) would be different from the classical expression because now the energies accessible to the oscillator are discrete, rather than continuous; compare to equa- tions (3.8.2) and (3.8.14). The expectation value of the energy of a Planck oscillator of frequency ωs is then given by equation (3.8.20), excluding the zero-point term 1 2 ℏωs: ⟨εs⟩ = ℏωs eℏωs/kT − 1 . (1) Now, the number of normal modes of vibration per unit volume of the cavity in the frequency range (ω, ω + dω) is given by the Rayleigh expression 2 · 4π( 1 λ )2 d( 1 λ ) = ω2dω π 2c3 , (2) where the factor 2 has been included to take into account the duplicity of the transverse modes; 11 the symbol c here denotes the speed of light. By equations (1) and (2), the energy density associated with the frequency range (ω, ω + dω) is given by u(ω)dω = ℏ π 2c3 ω3dω eℏω/kT − 1 , (3) which is Planck’s formula for the distribution of energy over the blackbody spectrum. Integrating (3) over all values of ω, we obtain the total energy density in the cavity. The second point of view originated with Bose (1924) and Einstein (1924, 1925). Bose investigated the problem of the “distribution of photons over the various energy levels” in the system; however, instead of worrying about the allocation of the various photons 11As is well-known, the longitudinal modes play no role in the case of radiation. 7.3 Thermodynamics of the blackbody radiation 201 to the various energy levels (as one would have ordinarily done), he concentrated on the statistics of the energy levels themselves! He examined questions such as the “probability of an energy level εs(= ℏωs) being occupied by ns photons at a time,” “the mean values of ns and εs,” and so on. The statistics of the energy levels is indeed Boltzmannian; the mean values of ns and εs, however, turn out to be ⟨ns⟩ = ∞∑ ns=0 nse−nsℏωs/kT ∕ ∞∑ ns=0 e−nsℏωs/kT = 1 eℏωs/kT − 1 (4) and hence ⟨εs⟩ = ℏωs⟨ns⟩ = ℏωs eℏωs/kT − 1 , (5) identical with our earlier result (1). To obtain the number of photon states with momenta lying between ℏω/c and ℏ (ω + dω)/c, Bose made use of the connection between this number and the “volume of the relevant region of the phase space,” with the result g(ω)dω ≈ 2 · V h3 { 4π( ℏω c )2 ( ℏ dω c )} = V ω2dω π 2c3 , (6)12 which is also identical to our earlier result (2). Thus, he ﬁnally obtained the distribution formula of Planck. It must be noted here that, although emphasis lay elsewhere, the math- ematical steps that led Bose to his ﬁnal result went literally parallel to the ones occurring in the oscillator approach! Einstein, on the other hand, went deeper into the problem and pondered over the statistics of both the photons and the energy levels, taken together. He inferred (from Bose’s treatment) that the basic fact to keep in mind during the process of distributing photons over the various energy levels is that the photons are indistinguishable — a fact that had been implicitly taken care of in Bose’s treatment. Einstein’s derivation of the desired distribution was essentially the same as given in Section 6.1, with one important difference, that is, since the total number of photons in any given volume was indeﬁnite, the constraint of a ﬁxed N was no longer present. As a result, the Lagrange multiplier α did not enter into the discussion and to that extent the ﬁnal formula for ⟨nε⟩ was simpler: ⟨nε⟩ = 1 eε/kT − 1 ; (7) compare to equation (6.1.18a) or (6.2.22). The foregoing result is identical to (4), with ε = hωs. The subsequent steps in Einstein’s treatment were the same as in Bose’s. 12The factor 2 in this expression arises essentially from the same cause as in the Rayleigh expression (2). However, in the present context, it would be more appropriate to regard it as representing the two states of polarization of the photon spin. 202 Chapter 7 . Ideal Bose Systems 002 4 6 8 10 12 14 [x \u0002 2.8214...] 1.0 1.5 0.5 2.0u\u0003(x) x Rayleigh-Jeans’ law Wien’s law Planck’s law FIGURE 7.13 The spectral distribution of energy in the blackbody radiation. The solid curve represents the quantum-theoretical formula of Planck. The long-wavelength approximation of Rayleigh–Jeans and the short-wavelength approximation of Wien are also shown. Looking back at the two approaches, we note that there is a complete correspondence between them — “an oscillator in the eigenstate ns, with energy (ns + 1 2 )ℏωs” in the ﬁrst approach corresponds to “the occupation of the energy level hωs by ns photons” in the second approach, “the average energy ⟨εs⟩ of an oscillator” corresponds to “the mean occupation number ⟨ns⟩ of the corresponding energy level,” and so on.13 Figure 7.13 shows a plot of the distribution function (3), which may be written in the dimensionless form u ′(x)dx = x3dx ex − 1 , (8) where u′(x) = π 2ℏ3c3 (kT )4 u(x) and x = ℏω kT . (9) For long wavelengths (x ≪ 1), formula (8) reduces to the classical approximation of Rayleigh (1900) and Jeans (1905), namely 14 u ′(x) ≈ x2, (10) while for short wavelengths (x ≫ 1), it reduces to the rival formula of Wien (1896), namely u ′(x) ≈ x3e−x. (11) 13Compared to the standard Bose–Einstein result (7.1.2), formula (7) suggests that we are dealing here with a case for which z is precisely equal to unity. It is not difﬁcult to see that this is due to the fact that the total number of particles in the present case is indeﬁnite. For then, their equilibrium number N has to be determined by the condition that the free energy of the system is at its minimum, that is, {(∂A/∂N)N=N }V ,T = 0, which, by deﬁnition, implies that µ = 0 and hence z = 1. 14The Rayleigh–Jeans formula follows directly if we use for ⟨εs⟩ the equipartition value kT rather than the quantum- theoretical value (1). 7.3 Thermodynamics of the blackbody radiation 203 For comparison, the limiting forms (10) and (11) are also included in the ﬁgure. We note that the areas under the Planck curve and the Wien curve are π 4/15(≃ 6.49) and 6, respec- tively. The Rayleigh–Jeans curve, however, suffers from a high-frequency catastrophe! For the total energy density in the cavity, we obtain from equations (8) and (9) U V = ∞∫ 0 u(x)dx = (kT )4 π 2ℏ3c3 ∞∫ 0 x3dx ex − 1 = π 2k4 15ℏ3c3 T 4. (12)15 If there is a small opening in the walls of the cavity, the photons will “effuse” through it. The net rate of ﬂow of the radiation, per unit area of the opening, will be given by, see equation (6.4.12), 1 4 U V c = π 2k4 60ℏ3c2 T 4 = σ T 4, (13) where σ = π 2k4 60ℏ3c2 = 5.670 × 10 −8 W m−2 K−4. (14) Equation (13) describes the Stefan–Boltzmann law of blackbody radiation, σ being the Ste- fan constant. This law was deduced from experimental observations by Stefan in 1879; ﬁve years later, Boltzmann derived it from thermodynamic considerations. For further study of thermodynamics, we evaluate the grand partition function of the photon gas. Using equation (6.2.17) with z = 1, we obtain ln Q(V , T ) ≡ PV kT = − ∑ ε ln(1 − e−ε/kT ). (15) Replacing summation by integration and making use of the extreme relativistic formula a(ε)dε = 2V 4π p2dp h3 = 8π V h3c3 ε2dε, (16) we obtain, after an integration by parts, ln Q(V , T ) ≡ PV kT = 8πV 3h3c3 1 kT ∞∫ 0 ε3dε eε/kT − 1 . 15Here, use has been made of the fact that the value of the deﬁnite integral is 6ζ (4) = π 4/15; see Appendix D. 204 Chapter 7 . Ideal Bose Systems By a change of variable, this becomes PV = 8πV 3h3c3 (kT ) 4 ∞∫ 0 x3dx ex − 1 = 8π 5V 45h3c3 (kT ) 4 = 1 3 U. (17) We thus obtain the well-known result of the radiation theory; that is, the pressure of the radiation is equal to one-third its energy density; see also equations (6.4.3) and (6.4.4). Next, since the chemical potential of the system is zero, the Helmholtz free energy is equal to −PV ; therefore A = −PV = − 1 3 U, (18) whereby S ≡ U − A T = 4 3 U T ∝ VT 3 (19) and CV = T ( ∂S ∂T ) V = 3S. (20) If the radiation undergoes a reversible adiabatic change, the law governing the variation of T with V would be, see (19), VT 3 = const. (21) Combining (21) with the fact that P ∝ T 4, we obtain an equation for the adiabats of the system, namely PV 4/3 = const. (22) It should be noted, however, that the ratio CP/CV of the photon gas is not 4/3; it is inﬁnite! Finally, we derive an expression for the equilibrium number N of photons in the radiation cavity. We obtain N = V π 2c3 ∞∫ 0 ω2dω eℏω/kT − 1 = V 2ζ (3)(kT )3 π 2h3c3 ∝ VT 3. (23) Instructive though it may be, formula (23) cannot be taken at its face value because in the present problem the magnitude of the ﬂuctuations in the variable N, which is determined by the quantity (∂P/∂V )−1, is inﬁnitely large; see equation (4.5.7). 7.4 The ﬁeld of sound waves 205 One of the most important examples of blackbody radiation is the 2.7 K cosmic microwave background, which is a remnant from the Big Bang. Equations (12) and (23) play an important role in our understanding of the thermodynamics of the early universe; see Problem 7.24 and Chapter 9. 7.4 The ﬁeld of sound waves A problem mathematically similar to the one discussed in Section 7.3 arises from the vibrational modes of a macroscopic body, speciﬁcally a solid. As in the case of black- body radiation, the problem of the vibrational modes of a solid can be studied equally well by regarding the system as a collection of harmonic oscillators or by regarding it as an enclosed region containing a gas of sound quanta — the so-called phonons. To illus- trate this point, we consider the Hamiltonian of a classical solid composed of N atoms whose positions in space are speciﬁed by the coordinates (x1, x2, . . . , x3N ). In the state of lowest energy, the values of these coordinates may be denoted by (x1, x2, . . . , x3N ). Denoting the displacements (xi − xi) of the atoms from their equilibrium positions by the variables ξi(i = 1, 2, . . . , 3N), the kinetic energy of the system in conﬁguration (xi) is given by K = 1 2 m 3N∑ i=1 ˙x2 i = 1 2 m 3N∑ i=1 ˙ξ 2 i , (1) and the potential energy by 8 ≡ 8(xi) = 8( xi) + ∑ i ( ∂8 ∂xi ) (xi)=(xi) (xi − xi) + ∑ i,j 1 2 ( ∂ 28 ∂xi∂xj ) (xi)=(xi) (xi − xi)(xj − xj) + · · · . (2) The main term in this expansion represents the (minimum) energy of the solid when all the atoms are at rest at their mean positions xi; this energy may be denoted by the symbol 80. The next set of terms is identically zero because the function 8(xi) has a minimum at (xi) = (xi) and hence all its ﬁrst derivatives vanish there. The second-order terms of the expansion represent the harmonic component of the vibrations of the atoms about their mean positions. If we assume that the overall amplitude of these vibrations is not large we may retain only the harmonic terms of the expansion and neglect all successive ones; we are then working in the so-called harmonic approximation. Thus, we may write H = 80 +    ∑ i 1 2 m ˙ξ 2 i + ∑ i,j αijξiξj   , (3) 206 Chapter 7 . Ideal Bose Systems where αij = 1 2 ( ∂ 28 ∂xi∂xj ) (xi)=(xi). (4) We now introduce a linear transformation, from the coordinates ξi to the so-called normal coordinates qi, and choose the transformation matrix such that the new expression for the Hamiltonian does not contain any cross terms, that is, H = 80 + ∑ i 1 2 m( ˙q2 i + ω2 i q2 i ) , (5) where ωi(i = 1, 2, . . . , 3N) are the characteristic frequencies of the normal modes of the sys- tem and are determined essentially by the quantities αij or, in turn, by the nature of the potential energy function 8(xi). Equation (5) suggests that the energy of the solid, over and above the (minimum) value 80, may be considered as arising from a set of 3N one- dimensional, noninteracting, harmonic oscillators whose characteristic frequencies ωi are determined by the interatomic interactions in the system. Classically, each of the 3N normal modes of vibration corresponds to a wave of distor- tion of the lattice, that is, a sound wave. Quantum-mechanically, these modes give rise to quanta, called phonons, in much the same way as the vibrational modes of the electromag- netic ﬁeld give rise to photons. There is one important difference, however, that is, while the number of normal modes in the case of an electromagnetic ﬁeld is inﬁnite, the num- ber of normal modes (or the number of phonon energy levels) in the case of a solid is ﬁxed by the number of lattice sites. 16 This introduces certain differences in the thermodynamic behavior of the sound ﬁeld in contrast to the thermodynamic behavior of the radiation ﬁeld; however, at low temperatures, where the high-frequency modes of the solid are not very likely to be excited, these differences become rather insigniﬁcant and we obtain a striking similarity between the two sets of results. The thermodynamics of the solid can now be studied along the lines of Section 3.8. First of all, we note that the eigenvalues of the Hamiltonian (5) are E{ni} = 80 + ∑ i ( ni + 1 2 )ℏωi, (6) where the numbers ni denote the “states of excitation” of the various oscillators (or, equally well, the occupation numbers of the various phonon levels in the system). The internal energy of the system is then given by U(T ) = { 80 + ∑ i 1 2 ℏωi } + ∑ i ℏωi eℏωi/kT − 1 . (7) 16Of course, the number of phonons themselves is indeﬁnite. As a result, the chemical potential of the phonon gas is also zero. 7.4 The ﬁeld of sound waves 207 The expression within the curly brackets gives the energy of the solid at absolute zero. The term 80 is negative and larger in magnitude than the total zero-point energy, ∑ i 1 2 ℏωi, of the oscillators: together, they determine the binding energy of the lattice. The last term in (7) represents the temperature-dependent part of the energy, 17 which determines the speciﬁc heat of the solid: CV (T ) ≡ ( ∂U ∂T ) V = k ∑ i (ℏωi/kT )2eℏωi/kT (eℏωi/kT − 1)2 . (8) To proceed further, we need to know the frequency spectrum of the solid. To obtain this from ﬁrst principles is not an easy task. Accordingly, one obtains this spectrum either through experiment or by making certain plausible assumptions about it. Einstein, who was the ﬁrst to apply the quantum concept to the theory of solids (1907), assumed, for simplicity, that the frequencies ωi are all equal. Denoting this (common) value by ωE, the speciﬁc heat of the solid is given by CV (T ) = 3NkE(x), (9) where E(x) is the so-called Einstein function: E(x) = x2ex (ex − 1)2 , (10) with x = ℏωE /kT = 2E /T . (11) The dashed curve in Figure 7.14 depicts the variation of the speciﬁc heat with tempera- ture, as given by the Einstein formula (9). At sufﬁciently high temperatures, where T ≫ 2E and hence x ≪ 1, the Einstein result tends toward the classical one, namely 3Nk. 18 At sufﬁciently low temperatures, where T ≪ 2E and hence x ≫ 1, the speciﬁc heat falls expo- nentially fast and tends to zero as T → 0. The theoretical rate of fall, however, turns out to be too fast in comparison with the observed one. Nevertheless, Einstein’s approach did at least provide a theoretical basis for understanding the observed departure of the speciﬁc heat of solids from the classical law of Dulong and Petit, whereby CV = 3R ≃ 5.96 calories per mole per degree. Debye (1912), on the other hand, allowed a continuous spectrum of frequencies, cut off at an upper limit ωD such that the total number of normal modes of vibration is 3N, 17The thermal energy of the solid may well be written as ∑ i⟨ni⟩ℏωi, where ⟨ni⟩{= (eℏωi/kT − 1)−1} is the mean occupation number of the phonon level εi. Clearly, the phonons, like photons, obey Bose–Einstein statistics, with µ = 0. 18Actually, when the temperature is high enough, so that all (ℏωi/kT ) ≪ 1, the general formula (8) itself reduces to the classical one. This corresponds to the situation when each of the 3N modes of vibration possesses a thermal energy kT . 208 Chapter 7 . Ideal Bose Systems 0.5 0 1.0 0 0.5 1.0(Cv/3Nk) (T /\u0002 ) T 3-law FIGURE 7.14 The speciﬁc heat of a solid, according to the Einstein model: – – – , and according to the Debye model: —–. The circles denote the experimental results for copper. that is ωD∫ 0 g(ω)dω = 3N, (12) where g(ω)dω denotes the number of normal modes of vibration whose frequency lies in the range (ω, ω + dω). For g(ω), Debye adopted the Rayleigh expression (7.3.2), modiﬁed so as to suit the problem under study. Writing cL for the velocity of propagation of the longi- tudinal modes and cT for that of the transverse modes (and noting that, for any frequency ω, the transverse mode is doubly degenerate), equation (12) becomes ωD∫ 0 V ( ω2dω 2π 2c3 L + ω2dω π 2c3 T ) = 3N, (13) from which one obtains for the cutoff frequency ω3 D = 18π 2 N V ( 1 c3 L + 2 c3 T )−1 . (14) Accordingly, the Debye spectrum may be written as g(ω) =    9N ω3 D ω2 for ω ≤ ωD, 0 for ω > ωD. (15) Before we proceed further to calculate the speciﬁc heat of solids on the basis of the Debye spectrum, two remarks seem to be in order. First, the Debye spectrum is only an idealization of the actual situation obtaining in a solid; it may, for instance, be compared with a typical spectrum such as the one shown in Figure 7.15. While for low-frequency modes (the so-called acoustic modes) the Debye approximation is reasonable, serious dis- crepancies are seen in the case of high-frequency modes (the so-called optical modes). At 7.4 The ﬁeld of sound waves 209 2 3 4 5 1 0 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0g(\u0002), in arbitrary units \u0002, in units of 2\u0003 3 10 13 sec 21 FIGURE 7.15 The normal-mode frequency distribution g(ω) for aluminum. The solid curve is derived from x-ray scattering measurements [Walker (1956)] while the dashed curve represents the corresponding Debye approximation. any rate, for “averaged” quantities, such as the speciﬁc heat, the ﬁner details of the spec- trum are not very important. Second, the longitudinal and the transverse modes of the solid should have their own cutoff frequencies, ωD,L and ωD,T say, rather than a common cutoff at ωD, for the simple reason that, of the 3N normal modes of the lattice, exactly N are longitudinal and 2N transverse. Accordingly, we should have, instead of (13), ωD,L∫ 0 V ω2dω 2π 2c3 L = N and ωD,T∫ 0 V ω2dω π 2c3 T = 2N. (16) We note that the two cutoffs correspond to a common wavelength λmin{= (4π V /3N)1/3}, which is comparable to the mean interatomic distance in the solid. This is quite reasonable because, for wavelengths shorter than λmin, it would be rather meaningless to speak of a wave of atomic displacements. In the Debye approximation, formula (8) gives CV (T ) = 3NkD(x0), (17) where D(x0) is the so-called Debye function: D(x0) = 3 x3 0 x0∫ 0 x4exdx (ex − 1)2 , (18) with x0 = ℏωD kT = 2D T , (19) 210 Chapter 7 . Ideal Bose Systems 2D being the so-called Debye temperature of the solid. Integrating by parts, the expression for the Debye function becomes D(x0) = − 3x0 ex0 − 1 + 12 x3 0 x0∫ 0 x3dx ex − 1 . (20) For T ≫ 2D, which means x0 ≪ 1, the function D(x0) may be expressed as a power series in x0: D(x0) = 1 − x2 0 20 + · · · . (21) Thus, as T → ∞, CV → 3Nk; moreover, according to this theory, the classical result should be applicable to within 1 2 percent so long as T > 32D. For T ≪ 2D, which means x0 ≫ 1, the function D(x0) may be written as D(x0) = 12 x3 0 ∞∫ 0 x3dx ex − 1 + O(e−x0 ), ≈ 4π 4 5x3 0 = 4π 4 5 ( T 2D )3 . (22) Thus, at low temperatures the speciﬁc heat of the solid obeys the Debye T 3-law : CV = 12π 4 5 Nk( T 2D )3 = 464.4( T 2D )3 cal mole−1K−1. (23) It is clear from equation (23) that a measurement of the low-temperature speciﬁc heat of a solid should enable us not only to check the validity of the T 3-law but also to obtain an empirical value of the Debye temperature 2D. 19 The value of 2D can also be obtained by computing the cutoff frequency ωD from a knowledge of the parameters N/V , cL and cT ; see equations (14) and (19). The closeness of these estimates is further evidence in favor of Debye’s theory. Once 2D is known, the whole temperature range can be covered theo- retically by making use of the tabulated values of the function D(x0). 20 A typical case was shown earlier in Figure 7.14. We saw that not only was the T 3-law obeyed at low temper- atures, but also the agreement between theory and experiment was good throughout the range of observations. 19It can be shown that, according to this theory, deviations from the T 3-law should not exceed 2 percent so long as T < 2D/10. However, in the case of metals, one cannot expect to reach a true T 3-region because, well before that, the speciﬁc heat of the electron gas might become a dominant contribution (see Section 8.3); unless the two contributions are separated out, one is likely to obtain a somewhat suppressed value of 2D from these observations. 20See, for example, Fowler and Guggenheim (1960, p. 144). 7.4 The ﬁeld of sound waves 211 As another illustration of agreement in the low-temperature regime, we include here another plot, Figure 7.16, which is based on data obtained with the KCl crystal at temper- atures below 5 K; see Keesom and Pearlman (1953). Here, the observed values of CV /T are plotted against T 2. It is evident that the data fall quite well on a straight line from whose slope the value of 2D can be determined. One thus obtains, for KCl, 2D = 233 ± 3 K, which is in reasonable agreement with the values of 230 to 246 K coming from various estimates of the relevant elastic constants. In Table 7.1 we list the values of 2D for several crystals, as derived from the speciﬁc heat measurements and from the values of the elastic constants. In general, if the speciﬁc heat measurements of a given system conform to a T 3-law, one may infer that the thermal excitations in the system are accounted for solely by phonons. We expect something similar to happen in liquids as well, with two important differences. First, since liquids cannot withstand shear stress they cannot sustain transverse modes of vibration; a liquid composed of N atoms will, therefore, have only N longitudinal modes of vibration. Second, the normal modes of a liquid cannot be expected to be strictly har- monic; consequently, in addition to phonons, we might have other types of excitation such as vortex ﬂow or turbulence (or even a modiﬁed kind of excitation, such as rotons in liquid He4). 2.0 4.0 0 5 10 15 20 6.0Cv/T(in milli joules mole\u00021 K\u00022) T 2(in K 2) FIGURE 7.16 A plot of (CV /T ) versus T 2 for KCl, showing the validity of the Debye T 3-law. The experimental points are from Keesom and Pearlman (1953). Table 7.1 The Values of the Debye Temperature 2D for Different Crystals Crystal Pb Ag Zn Cu Al C NaCl KCl MgO 2D from the speciﬁc 88 215 308 345 398 ∼1850 308 233 ∼850 heat measurements 2D from the elastic 73 214 305 332 402 – 320 240 ∼950 constants 212 Chapter 7 . Ideal Bose Systems Now, helium is the only substance that remains liquid at temperatures low enough to exhibit the T 3-behavior. In the case of the lighter isotope, He3, the results are strongly inﬂu- enced by the Fermi–Dirac statistics; as a result, a speciﬁc heat proportional to the ﬁrst power of T dominates the scene (see Section 8.1). In the case of the heavier isotope, He4, the low-temperature situation is completely governed by phonons; accordingly, we expect its speciﬁc heat to be given by, see equations (16) and (23), CV = 4π 4 5 Nk( kT ℏωD )3 , (24) where ωD = ( 6π 2N V )1/3 c, (25) c being the velocity of sound in the liquid. The speciﬁc heat per unit mass of the liquid is then given by cV = 2π 2k4 15ρℏ3c3 T 3, (26) where ρ is the mass density. Substituting ρ = 0.1455 g/cm3 and c = 238 m/s, the foregoing result becomes cV = 0.0209T 3 joule g−1K−1. (27) The experimental measurements of Wiebes et al. (1957), for 0 < T < 0.6 K, conformed to the expression cV = (0.0204 ± 0.0004)T 3 joule g−1K−1. (28) The agreement between the theoretical result and the experimental observations is clearly good. 7.5 Inertial density of the sound ﬁeld For further understanding of the low-temperature behavior of liquid He 4, we determine the “inertial mass” associated with a gas of sound quanta in thermal equilibrium. For this, we consider “a phonon gas in mass motion,” for then by determining the relation- ship between the momentum P of the gas and the velocity v of its mass motion we can readily evaluate the property in question. Now, since the total number of phonons in the system is indeﬁnite, the problem is free from the constraint of a ﬁxed N; consequently, the undetermined multiplier α may be taken to be identically zero. However, we now have a new constraint on the system, namely that of a ﬁxed total momentum P, additional to 7.5 Inertial density of the sound ﬁeld 213 the constraint of the ﬁxed total energy E. Under these constraints, the mean occupation number of the phonon level ε(p) would be ⟨n(p)⟩ = 1 exp(βε + γ · p) − 1 . (1) As usual, the parameter β is equal to 1/kT . To determine γ , it seems natural to evaluate the drift velocity of the gas. Choosing the z-axis in the direction of the mass motion, the magnitude v of the drift velocity will be given by “the mean value of the component uz of the individual phonon velocities”: v = ⟨u cos θ ⟩. (2) Now, for phonons ε = pc and u ≡ dε dp = c, (3) where c is the velocity of sound in the medium. Moreover, by reasons of symmetry, we expect the undetermined vector γ to be either parallel or antiparallel to the direction of mass motion; hence, we may write γ · p = γzpz = γzp cos θ . (4) In view of equations (1), (3), and (4), equation (2) becomes v = ∫ ∞ 0 ∫ π 0 [exp{βpc(1 + (γz/βc) cos θ)} − 1]−1(c cos θ)(p2dp 2π sin θdθ) ∫ ∞ 0 ∫ π 0 [exp{βpc(1 + (γz/βc) cos θ)} − 1]−1(p2dp 2π sin θ dθ) . (5) Making the substitutions cos θ = η, p(1 + (γz/βc)η) = p′ and cancelling away the integrations over p′, we obtain v = c ∫ 1 −1(1 + (γz/βc)η)−3ηdη ∫ 1 −1(1 + (γz/βc)η)−3dη = −γz/β. It follows that γ = −βv. (6) Accordingly, the expression for the mean occupation number becomes ⟨n(p)⟩ = 1 exp{β(ε − v · p)} − 1 . (7) 214 Chapter 7 . Ideal Bose Systems A comparison of (7) with the corresponding result in the rest frame of the gas, namely ⟨n0(p0)⟩ = 1 exp(βε0) − 1 , (8) shows that the change caused by the imposition of mass motion on the system is noth- ing but a straightforward manifestation of the Galilean transformation between the two frames of reference. Alternatively, equation (7) may be written as ⟨n(p)⟩ = 1 exp(βp′c) − 1 = 1 exp{βpc(1 − (v/c) cos θ)} − 1 . (9) As such, formula (9) lays down a serious restriction on the drift velocity v, that is, it must not exceed c, the velocity of the phonons, for otherwise some of the occupation num- bers would become negative! Actually, as our subsequent analysis will show, the formalism developed in this section breaks down as v approaches c. The velocity c may, therefore, be regarded as the critical velocity for the ﬂow of the phonon gas: (vc)ph = c. (10) The relevance of this result to the problem of superﬂuidity in liquid helium II will be seen in the following section. Next we now calculate the total momentum P of the phonon gas: P = ∑ p ⟨n(p)⟩p. (11) Indeed, the vector P will be parallel to the vector v, the latter being already in the direction of the z-axis. We have, therefore, to calculate only the z-component of the momentum: P = Pz = ∑ p ⟨n(p)⟩pz = ∞∫ 0 π∫ 0 p cos θ exp{βpc(1 − (v/c) cos θ)} − 1 ( Vp2dp 2π sin θ dθ h3 ) = 2πV h3 ∞∫ 0 p′3dp′ exp(βp′c) − 1 π∫ 0 {1 − (v/c) cos θ}−4 cos θ sin θdθ = V 16π 5 45h3c3β4 · v/c2 (1 − v2/c2)3 . (12) 7.6 Elementary excitations in liquid helium II 215 The total energy E of the gas is given by E = ∑ p ⟨n(p)⟩pc = 2π Vc h3 ∞∫ 0 p′3dp′ exp(βp′c) − 1 π∫ 0 {1 − (v/c) cos θ } −4 sin θ dθ = V 4π 5 15h3c3β4 1 + 1 3 v2/c2 (1 − v2/c2)3 . (13) It is now natural to regard the ratio P/v as the “inertial mass” of the phonon gas. The corresponding mass density ρ is, therefore, given by ρ = P vV = 16π 5k4T 4 45h3c5 1 (1 − v2/c2)3 . (14) For (v/c) ≪ 1, which is generally true, the mass density of the phonon gas is given by (ρ0)ph = 16π 5k4 45h3c5 T 4 = 4 3c2 (E0/V ). (15) Substituting the value of c for liquid He4 at low temperatures, the phonon mass density, as a fraction of the actual density of the liquid, is given by (ρ0)ph/ρHe = 1.22 × 10−4T 4; (16) thus, for example, at T = 0.3 K the value of this fraction turns out to be about 9.9 × 10−7. Now, at a temperature like 0.3 K, phonons are the only excitations in liquid He4 that need to be considered; the calculated result should, therefore, correspond to the “ratio of the den- sity ρn of the normal ﬂuid in the liquid to the total density ρ of the liquid.” It is practically impossible to make a direct determination of a fraction as small as that; however, indirect evaluations that make use of other experimentally viable properties of the liquid provide a striking conﬁrmation of the foregoing result; see Figure 7.17. 7.6 Elementary excitations in liquid helium II Landau (1941, 1947) developed a simple theoretical scheme that explains reasonably well the behavior of liquid helium II at low temperatures not too close to the λ-point. Accord- ing to this scheme, the liquid is treated as a weakly excited quantum-mechanical system, in which deviations from the ground state (T = 0 K ) are described in terms of “a gas of ele- mentary excitations” hovering over a quiescent background. The gas of excitations corre- sponds to the “normal ﬂuid,” while the quiescent background represents the “superﬂuid.” 216 Chapter 7 . Ideal Bose Systems 0.1 0.2 0.3 0.4 0.50.6 0.8 1.0 1.5 2.0 10 \u00028 10 \u00027 10 \u00026(\u0002n/\u0002) \u0002 phon / \u0002 \u0003 1.24 \u0004 10 \u0002 4 T 4 10 \u00025 10 \u00024 10 \u00023 10 \u00022 10 \u00021 1 T (in K) ( T / T \u0003 ) 5.6 T\u0003 FIGURE 7.17 The normal fraction (ρn/ρ), as obtained from experimental data on (i) the velocity of second sound and (ii) the entropy of liquid He II (after de Klerk, Hudson, and Pellam, 1953). At T = 0 K, there are no excitations at all (ρn = 0) and the whole of the ﬂuid constitutes the superﬂuid background (ρs = ρHe). At higher temperatures, we may write ρs(T ) = ρHe(T ) − ρn(T ), (1) so that at T = Tλ, ρn = ρHe and ρs = 0. At T > Tλ, the liquid behaves in all respects as a normal ﬂuid, commonly known as liquid helium I. Guided by purely empirical considerations, Landau also proposed an energy– momentum relationship ε(p) for the elementary excitations in liquid helium II. At low momenta, the relationship between ε and p was linear (which is characteristic of phonons), while at higher momenta it exhibited a nonmonotonic character. The excita- tions were assumed to be bosons and, at low temperatures (when their number is not very large), mutually noninteracting; the macroscopic properties of the liquid could then be calculated by following a straightforward statistical-mechanical approach. It was found that Landau’s theory could explain quite successfully the observed properties of liquid helium II over a temperature range of about 0 to 2 K; however, it still remained to be ver- iﬁed that the actual excitations in the liquid did, in fact, conform to the proposed energy spectrum. Following a suggestion by Cohen and Feynman (1957), a number of experimental work- ers set out to investigate the spectrum of excitations in liquid helium II by scattering long-wavelength neutrons (λ ≳ 4 ˚A) from the liquid. At temperatures below 2 K, the most important scattering process is the one in which a neutron creates a single excitation in the liquid. By measuring the modiﬁed wavelength λf of the neutrons scattered at an angle φ, the energy ε and the momentum p of the excitation created in the scattering process could 7.6 Elementary excitations in liquid helium II 217 be determined on the basis of the relevant conservation laws: ε = h2(λ −2 i − λ −2 f )/2m, (2) p 2 = h2(λ −2 i + λ −2 f − 2λ −1 i λ−1 f cos φ), (3) where λi is the initial wavelength of the neutrons and m the neutron mass. By varying φ, or λi, one could map the entire spectrum of the excitations. The ﬁrst exhaustive investigation along these lines was carried out by Yarnell et al. (1959); their results, shown in Figure 7.18, possess a striking resemblance to the empiri- cal spectrum proposed by Landau. The more important features of the spectrum, which was obtained at a temperature of 1.1 K, are the following: (i) If we ﬁt a linear, phonon-like spectrum (ε = pc) to points in the vicinity of p/ℏ = 0.55 ˚A −1, we obtain for c a value of (239 ± 5) m/s, which is in excellent agreement with the measured value of the velocity of sound in the liquid, namely about 238 m/s. (ii) The spectrum passes through a maximum value of ε/k = (13.92 ± 0.10) K at p/ℏ = (1.11 ± 0.02) ˚A −1. (iii) This is followed by a minimum at p/ℏ = (1.92 ± 0.01) ˚A −1, whose neighborhood may be represented by Landau’s roton spectrum: ε(p) = 1 + (p − p0)2 2µ , (4) T 5 1.1 K 5 0 0.5 1.0 1.5 2.0 2.5 p /ℏ, in A21 10 15´/k, in KFIGURE 7.18 The energy spectrum of the elementary excitations in liquid He II at 1.1 K [after Yarnell et al. (1959)]; the dashed line emanating from the origin has a slope corresponding to the velocity of sound in the liquid, namely (239 ± 5) m/s. 218 Chapter 7 . Ideal Bose Systems with 1/k = (8.65 ± 0.04)K, p0/ℏ = (1.92 ± 0.01) ˚A−1, (5)21 and µ = (0.16 ± 0.01)mHe. (iv) Above p/ℏ ≃ 2.18 ˚A −1, the spectrum rises linearly, again with a slope equal to c. Data were also obtained at temperatures 1.6 K and 1.8 K. The spectrum was found to be of the same general shape as at 1.1 K; only the value of 1 was slightly lower. In a later investigation, Henshaw and Woods (1961) extended the range of observation at both ends of the spectrum; their results are shown in Figure 7.19. On the lower side, they carried out measurements down to p/ℏ = 0.26 ˚A −1 and found that the experimental 8 0 0.6 1.2 1.8 2.4 3.0 16 24 32 Temperature Free particle Neutron wavelength 40 1.12 KEnergy change, in K Momentum change, in A21 4.04 A FIGURE 7.19 The energy spectrum of the elementary excitations in liquid He II at 1.12 K (after Henshaw and Woods, 1961); the dashed straight lines have a common slope corresponding to the velocity of sound in the liquid, namely 237 m/s. The parabolic curve rising from the origin represents the energy spectrum, ε(p) = p2/2m, of free helium atoms. 21The term “roton” for these excitations was coined by Landau who had originally thought that these excitations might, in some way, represent local disturbances of a rotational character in the liquid. However, subsequent theoretical work, especially that of Feynman (1953, 1954) and of Brueckner and Sawada (1957), did not support this contention. Nevertheless, the term “roton” has remained. 7.6 Elementary excitations in liquid helium II 219 points indeed lie on a straight line (of slope 237 m/s). On the upper side, they pushed their measurements up to p/ℏ = 2.68 ˚A−1 and found that, after passing through a minimum at 1.91 ˚A−1, the curve rises with an increasing slope up to about 2.4 ˚A−1 at which point the second derivative ∂ 2ε/∂p2 changes sign; the subsequent trend of the curve suggests the possible existence of a second maximum in the spectrum!22 To evaluate the thermodynamics of liquid helium II, we ﬁrst of all note that at suf- ﬁciently low temperatures we have only low-lying excitations, namely the phonons. The thermodynamic behavior of the liquid is then governed by formulae derived in Sections 7.4 and 7.5. At temperatures higher than about 0.5 K, the second group of exci- tations, namely the rotons (with momenta in the vicinity of p0), also shows up. Between 0.5 K and about 1 K, the behavior of the liquid is governed by phonons and rotons together. Above 1 K, however, the phonon contributions to the various thermodynamic properties of the liquid become rather unimportant; then, rotons are the only excitations that need to be considered. We shall now study the temperature dependence of the roton contributions to the various thermodynamic properties of the liquid. In view of the continuity of the energy spectrum, it is natural to expect that, like phonons, rotons also obey Bose–Einstein statis- tics. Moreover, their total number N in the system is quite indeﬁnite; consequently, their chemical potential µ is identically zero. We then have for the mean occupation numbers of the rotons ⟨n(p)⟩ = 1 exp{βε(p)} − 1 , (6) where ε(p) is given by equations (4) and (5). Now, at all temperatures of interest (namely T ≤ 2 K), the minimum value of the term exp{βε(p)}, namely exp(1/kT ), is considerably larger than unity. We may, therefore, write ⟨n(p)⟩ ≃ exp{−βε(p)}. (7) The q-potential of the system of rotons is, therefore, given by q(V , T ) ≡ PV kT = − ∑ p ln[1 − exp{−βε(p)}] ≃ ∑ p exp{−βε(p)} ≃ N, (8) where N is the “equilibrium” number of rotons in the system. The summation over p may be replaced by integration, with the result PV kT = N = V h3 ∞∫ 0 e−{ 1+ (p−p0)2 2µ }∕kT (4π p 2dp). (9) 22This seems to conﬁrm a remarkable prediction by Pitaevskii (1959) that an end point in the spectrum might occur at a “critical” value pc of the excitation momentum where εc is equal to 21 and (∂ε/∂p)c is zero. 220 Chapter 7 . Ideal Bose Systems Substituting p = p0 + (2µkT )1/2x, we get PV kT = N = 4πp2 0V h3 e−1/kT (2µkT ) 1/2 ∫ e−x2 { 1 + (2µkT )1/2 p0 x }2 dx. (10) The “relevant” range of the variable x that makes a signiﬁcant contribution toward this integral is fairly symmetric about the value x = 0; consequently, the net effect of the linear term in the integrand is vanishingly small. The quadratic term too is unimportant because its coefﬁcient (2µkT )/p2 0 ≪ 1. Thus, all we have to consider is the integral of exp(−x2). Now, one can readily verify that the limits of this integral are such that, without seriously affect- ing the value of the integral, they may be taken as −∞ and +∞; the value of the integral is then simply π 1/2. We thus obtain PV kT = N = 4πp2 0V h3 (2πµkT ) 1/2e−1/kT . (11)23 The free energy of the roton gas is given by (since µ = 0) A = −PV = −NkT ∝ T 3/2e−1/kT , (12) which gives S = −( ∂A ∂T ) V = −A { 3 2T + 1 kT 2 } = Nk { 3 2 + 1 kT } , (13) U = A + TS = N ( 1 + 1 2 kT ) (14)24 and CV = ( ∂U ∂T ) V = Nk { 3 4 + 1 kT + ( 1 kT )2} . (15) Clearly, as T → 0, all these results tend to zero (essentially exponentially). We now determine the inertial mass density of the roton gas. Proceeding as in Section 7.5, we obtain for a gas of excitations with energy spectrum ε(p) ρ0 = M0 V = lim v→0 1 v ∫ n(ε − v · p)p d3p h3 , (16) 23Looking back at integral (9), what we have done here amounts to replacing p2 in the integrand by its mean value p2 0 and then carrying out integration over the “complete” range of the variable (p − p0). 24This result is highly suggestive of the fact that for rotons there is only one true degree of freedom, namely the magnitude of the roton momentum, that is thermally effective! 7.6 Elementary excitations in liquid helium II 221 where n(ε − v · p) is the mean occupation number of the state ε(p), as observed in a frame of reference K with respect to which the gas is in mass motion with a drift velocity v. 25 For small v, the function n(ε − v · p) may be expanded as a Taylor series in v and only the terms n(ε) − (v · p)∂n(ε)/∂ε retained. The integral over the ﬁrst part denotes the momen- tum density of the system, as observed in the rest frame K0, and is identically zero. We are thus left with ρ0 = − 1 h3 ∫ p 2 cos 2 θ ∂n(ε) ∂ε (p2dp 2π sin θ dθ) = − 4π 3h3 ∞∫ 0 ∂n(ε) ∂ε p 4dp, (17) which holds for any energy spectrum and for any statistics. For phonons, we obtain (ρ0)ph = − 4π 3h3c ∞∫ 0 dn(p) dp p4dp = − 4π 3h3c  n(p) · p 4∣ ∣ ∣ ∣ ∞ 0 − ∞∫ 0 n(p) · 4p3dp   = 4 3c2 ∞∫ 0 n(p) · pc ( 4π p2dp h3 ) = 4 3c2 (E0)ph/V , (18) which is identical to our earlier result (7.5.15). For rotons, n(ε) ≃ exp(−βε); hence, ∂n(ε)/∂ε ≃ −βn(ε). Accordingly, by (17), (ρ0)rot = 4πβ 3h3 ∫ n(ε)p 4dp = β 3 ⟨p 2⟩ N V ≃ p2 0 3kT N V (19) = 4πp4 0 3h3 ( 2πµ kT )1/2 e−1/kT ; (20) At very low temperatures (T < 0.3 K), the roton contribution toward the inertia of the ﬂuid is negligible in comparison with the phonon contribution. At relatively higher tem- peratures (T ∼ 0.6 K), the two contributions become comparable. At temperatures above 1 K, the roton contribution is far more dominant than the phonon contribution; at such temperatures, the roton density alone accounts for the density ρn of the normal ﬂuid. 25The drift velocity v must satisfy the condition (v · p) ≤ ε, for otherwise some of the occupation numbers will become negative! This leads to the existence of a critical velocity vc for these excitations, such that for v exceeding vc the formalism developed here would break down. It is not difﬁcult to see that this (critical) velocity is given by the relation vc = (ε/p)min, as in equation (24). 222 Chapter 7 . Ideal Bose Systems It would be instructive to determine the critical temperature Tc at which the theoreti- cal value of the density ρn became equal to the actual density ρHe of the liquid; this would mean the disappearance of the superﬂuid component of the liquid (and hence a transition from liquid He II to liquid He I). In this manner, we ﬁnd that Tc ≃ 2.5K, as opposed to the experimental value of Tλ, which is ≃ 2.19 K. The comparison is not too bad, considering the fact that in the present calculation we have assumed the roton gas to be a noninteract- ing system right up to the transition point; in fact, due to the presence of an exceedingly large number of excitations at higher temperatures, this assumption would not remain plausible. Equation (19) suggests that a roton excitation possesses an effective mass p2 0/3kT . Numerically, this is about 10 to 15 times the mass of a helium atom (and, hence, orders of magnitude larger than the parameter µ of the roton spectrum). However, the more impor- tant aspect of the roton effective mass is that it is inversely proportional to the temperature of the roton gas! Historically, this aspect was ﬁrst discovered empirically by Landau (1947) on the basis of the experimental data on the velocity of second sound in liquid He II and its speciﬁc heat. Now, since the effective mass of an excitation is generally determined by the quantity ⟨p2⟩/3kT , Landau concluded that the quantity ⟨p2⟩ of the relevant excitations in this liquid must be temperature-independent. Thus, as the temperature of the liquid rises, the mean value of p2 of the excitations must stay constant; this value may be denoted by p2 0. The mean value of ε, on the other hand, must rise with temperature. The only way to reconcile the two was to invoke a nonmonotonic spectrum with a minimum at p = p0. Finally, we would like to touch on the question of the critical velocity of superﬂow. For this, we consider a mass M of excitation-free superﬂuid in mass motion; its kinetic energy E and momentum P are given by 1 2 Mv2 and Mv, respectively. Any changes in these quantities are related as follows: δE = (v · δP). (21) Supposing that these changes came about as a result of the creation of an excitation ε(p) in the ﬂuid, we must have, by the principles of conservation, δE = −ε and δP = −p. (22) Equations (21) and (22) lead to the result ε = (v · p) ≤ vp. (23) Thus, it is impossible to create an excitation ε(p) in the ﬂuid unless the drift velocity v of the ﬂuid is greater than, or at least equal to, the quantity (ε/p). Accordingly, if v is less than even the lowest value of ε/p, no excitation at all can be created in the ﬂuid, which will there- fore maintain its superﬂuid character. We thus obtain a condition for the maintenance of Problems 223 superﬂuidity, namely v < vc = (ε/p)min, (24) which is known as the Landau criterion for superﬂow. The velocity vc is called the criti- cal velocity of superﬂow; it marks an “upper limit” to the ﬂow velocities at which the ﬂuid exhibits superﬂuid behavior. The observed magnitude of the critical velocity varies signiﬁ- cantly with the geometry of the channel employed; as a rule, the narrower the channel the larger the critical velocity. The observed values of vc range from about 0.1 cm/s to about 70 cm/s. The theoretical estimates of vc are clearly of interest. On one hand, we ﬁnd that if the excitations obey the ideal-gas relationship, namely ε = p2/2m, then the critical velocity turns out to be exactly zero. Any velocity v is then greater than the critical velocity; accord- ingly, no superﬂow is possible at all. This is a very signiﬁcant result, for it brings out very clearly the fact that interatomic interactions in the liquid, which give rise to an excita- tion spectrum different from the one characteristic of the ideal gas, play a fundamental role in bringing about the phenomenon of superﬂuidity. Thus, while an ideal Bose gas does undergo the phenomenon of Bose–Einstein condensation, it cannot support the phe- nomenon of superﬂuidity as such! On the other hand, we ﬁnd that (i) for phonons, vc = c ≃ 2.4 × 104 cm/s and (ii) for rotons, vc = {(p2 0 + 2µ1)1/2 − p0}/µ ≃ 1/p0 ≃ 6.3 × 103 cm/s, which are too high in comparison with the observed values of vc. In fact, there is another type of collective excitations that can appear in liquid helium II, namely quantized vortex rings, with energy–momentum relationship of the form: ε ∝ p1/2. The critical velocity for the creation of these rings turns out to be numerically consistent with the experimental ﬁndings; not only that, the dependence of vc on the geometry of the channel can also be understood in terms of the size of the rings created. For a review of this topic, especially in regard to Feynman’s contributions, see Mehra and Pathria (1994); see also Sections 11.4 through 11.6 of this text. Quantized dissipationless bosonic ﬂow has also been observed in the solid phase of helium-4. This “supersolid” behavior was observed by Kim and Chan (2004a, 2004b) using a torsional oscillator containing solid helium infused silica with atomic-sized pores. At P = 60 atm, the torsional frequency increases abruptly for temperatures below 175 mK. These authors interpret this result as helium atoms in the solid phase in the pores being free to ﬂow without dissipation. Problems 7.1. By considering the order of magnitude of the occupation numbers ⟨nε⟩, show that it makes no difference to the ﬁnal results of Section 7.1 if we combine a ﬁnite number of (ε ̸= 0)-terms of the sum (7.1.2) with the (ε = 0)-part of equation (7.1.6) or include them in the integral over ε. 7.2. Deduce the virial expansion (7.1.13) from equations (7.1.7) and (7.1.8), and verify the quoted values of the virial coefﬁcients. 224 Chapter 7 . Ideal Bose Systems 7.3. Combining equations (7.1.24) and (7.1.26), and making use of the ﬁrst two terms of formula (D.9) in Appendix D, show that, as T approaches Tc from above, the parameter α(= −lnz) of the ideal Bose gas assumes the form α ≈ 1 π ( 3ζ (3/2) 4 )2 ( T − Tc Tc )2 . 7.4. Show that for an ideal Bose gas 1 z ( ∂z ∂T ) P = − 5 2T g5/2(z) g3/2(z) ; compare this result with equation (7.1.36). Hence show that γ ≡ CP CV = (∂z/∂T )P (∂z/∂T )v = 5 3 g5/2(z)g1/2(z) {g3/2(z)}2 , as in equation (7.1.48b). Check that, as T approaches Tc from above, both γ and CP diverge as (T − Tc)−1. 7.5. (a) Show that the isothermal compressibility κT and the adiabatic compressibility κS of an ideal Bose gas are given by κT = 1 nkT g1/2(z) g3/2(z) , κS = 3 5nkT g3/2(z) g5/2(z) , where n(= N/V ) is the particle density in the gas. Note that, as z → 0, κT and κS approach their respective classical values, namely 1/P and 1/γ P. How do they behave as z → 1? (b) Making use of the thermodynamic relations CP − CV = T ( ∂P ∂T ) V ( ∂V ∂T ) P = TV κT ( ∂P ∂T )2 V and CP/CV = κT /κS, derive equations (7.1.48a) and (7.1.48b). 7.6. Show that for an ideal Bose gas the temperature derivative of the speciﬁc heat CV is given by 1 Nk ( ∂CV ∂T ) V =    1 T [ 45 8 g5/2(z) g3/2(z) − 9 4 g3/2(z) g1/2(z) − 27 8 {g3/2(z)}2g−1/2(z) {g1/2(z)}3 ] for T > Tc, 45 8 v T λ3 ζ ( 5 2 ) for T < Tc. Using these results and the main term of formula (D.9), verify equation (7.1.38). 7.7. Evaluate the quantities (∂ 2P/∂T 2)v, (∂ 2µ/∂T 2)v, and (∂ 2µ/∂T 2)P for an ideal Bose gas and check that your results satisfy the thermodynamic relationships CV = VT ( ∂ 2P ∂T 2 ) v − NT ( ∂ 2µ ∂T 2 ) v , and CP = −NT ( ∂ 2µ ∂T 2 ) P . Examine the behavior of these quantities as T → Tc from above and from below. Problems 225 7.8. The velocity of sound in a ﬂuid is given by the formula w = √ (∂P/∂ρ)s, where ρ is the mass density of the ﬂuid. Show that for an ideal Bose gas w2 = 5kT 3m g5/2(z) g3/2(z) = 5 9 ⟨u2⟩, where ⟨u2⟩ is the mean square speed of the particles in the gas. 7.9. Show that for an ideal Bose gas ⟨u⟩ 〈 1 u 〉 = 4 π g1(z)g2(z) {g3/2(z)}2 , u being the speed of a particle. Examine and interpret the limiting cases z → 0 and z → 1; compare with Problem 6.6. 7.10. Consider an ideal Bose gas in a uniform gravitational ﬁeld of acceleration g. Show that the phenomenon of Bose–Einstein condensation in this gas sets in at a temperature Tc given by Tc ≃ T 0 c  1 + 8 9 1 ζ ( 3 2 ) ( π mgL kT 0 c )1/2  , where L is the height of the container and mgL ≪ kT 0 c . Also show that the condensation here is accompanied by a discontinuity in the speciﬁc heat CV of the gas: (1CV )T =Tc ≃ − 9 8π ζ ( 3 2 ) Nk ( πmgL kT 0 c )1/2 ; see Eisenschitz (1958). 7.11. Consider an ideal Bose gas consisting of molecules with internal degrees of freedom. Assuming that, besides the ground state ε0 = 0, only the ﬁrst excited state ε1 of the internal spectrum needs to be taken into account, determine the condensation temperature of the gas as a function of ε1. Show that, for (ε1/kT 0 c ) ≫ 1, Tc T 0 c ≃ 1 − 2 3 ζ ( 3 2 ) e−ε1/kT 0 c while, for (ε1/kT 0 c ) ≪ 1, Tc T 0 c ≃ ( 1 2 )2/3  1 + 24/3 3ζ ( 3 2 ) ( πε1 kT 0 c )1/2  . [Hint: To obtain the last result, use the ﬁrst two terms of formula (D.9) in Appendix D.] 7.12. Consider an ideal Bose gas in the grand canonical ensemble and study ﬂuctuations in the total number of particles N and the total energy E. Discuss, in particular, the situation when the gas becomes highly degenerate. 7.13. Consider an ideal Bose gas conﬁned to a region of area A in two dimensions. Express the number of particles in the excited states, Ne, and the number of particles in the ground state, N0, in terms of z, T , and A, and show that the system does not exhibit Bose–Einstein condensation unless T → 0 K. Reﬁne your argument to show that, if the area A and the total number of particles N are held ﬁxed and we require both Ne and N0 to be of order N, then we do achieve condensation when T ∼ h2 mkl2 1 ln N , 226 Chapter 7 . Ideal Bose Systems where l [∼ √ (A/N)] is the mean interparticle distance in the system. Of course, if both A and N → ∞, keeping l ﬁxed, then the desired T does go to zero. 7.14. Consider an n-dimensional Bose gas whose single-particle energy spectrum is given by ε ∝ ps, where s is some positive number. Discuss the onset of Bose–Einstein condensation in this system, especially its dependence on the numbers n and s. Study the thermodynamic behavior of this system and show that, P = s n U V , CV (T → ∞) = n s Nk, and CP(T → ∞) = ( n s + 1 ) Nk. 7.15. At time t = 0, the ground state wavefunction of a one-dimensional quantum harmonic oscillator with potential V (x) = 1 2 mω2 0x2 is given by ψ(x, 0) = 1 π 1/4√ a exp ( − x2 2a2 ) , where a = √ ℏ mω0 . At t = 0, the harmonic potential is abruptly removed. Use the momentum representation of the wavefunction at t = 0 and the time-dependent Schrodinger equation to determine the spatial wavefunction and density at time t > 0; compare to equation (7.2.11). 7.16. At time t = 0, a collection of classical particles is in equilibrium at temperature T in a three- dimensional harmonic oscillator potential V (r) = 1 2 mω2 0 |r|2. At t = 0, the harmonic potential is abruptly removed. Use the momentum distribution at t = 0 to determine the spatial density at time t > 0. Show that this is equivalent to the high temperature limit of equation (7.2.15). 7.17. As shown in Section 7.1, nλ3 is a measure of the quantum nature of the system. Use equations (7.2.11) and (7.2.15) to determine nλ3 at the center of the harmonic trap at T = Tc/2 for the condensed and noncondensed fractions. 7.18. Show that the integral of the semiclassical spatial density in equation (7.2.15) gives the correct counting of the atoms that are not condensed into the ground state. 7.19. Construct a theory for N bosons in an isotropic two-dimensional trap. This corresponds to a trap in which the energy level spacing due to excitations in the z direction is much larger than the spacing in the other directions. Determine the density of states a(ε) of this system. Can a Bose–Einstein condensate form in this trap? If so, ﬁnd the critical temperature as a function of the trapping frequencies and N. How much larger must the frequency in the third direction be for the system to display two-dimensional behavior? 7.20. The (canonical) partition function of the blackbody radiation may be written as Q(V , T ) = ∏ ω Q1(ω, T ), so that ln Q(V , T ) = ∑ ω ln Q1(ω, T ) ≈ ∞∫ 0 ln Q1(ω, T )g(ω)dω; here, Q1(ω, T ) is the single-oscillator partition function given by equation (3.8.14) and g(ω) is the density of states given by equation (7.3.2). Using this information, evaluate the Helmholtz free energy of the system and derive other thermodynamic properties such as the pressure P and the (thermal) energy density U/V . Compare your results with the ones derived in Section 7.3 from the q-potential of the system. 7.21. Show that the mean energy per photon in a blackbody radiation cavity is very nearly 2.7kT . 7.22. Considering the volume dependence of the frequencies ω of the vibrational modes of the radiation ﬁeld, establish relation (7.3.17) between the pressure P and the energy density U/V . 7.23. The sun may be regarded as a black body at a temperature of 5800 K. Its diameter is about 1.4 × 109 m while its distance from the earth is about 1.5 × 1011m. Problems 227 (a) Calculate the total radiant intensity (in W/m2) of sunlight at the surface of the earth. (b) What pressure would it exert on a perfectly absorbing surface placed normal to the rays of the sun? (c) If a ﬂat surface on a satellite, which faces the sun, were an ideal absorber and emitter, what equilibrium temperature would it ultimately attain? 7.24. Calculate the photon number density, entropy density, and energy density of the 2.725 K cosmic microwave background. 7.25. Figure 7.20 is a plot of CV (T ) against T for a solid, the limiting value CV (∞) being the classical result 3Nk. Show that the shaded area in the ﬁgure, namely ∞∫ 0 {CV (∞) − CV (T )}dT , is exactly equal to the zero-point energy of the solid. Interpret the result physically. Cv (`) 0 0Cv(T) T FIGURE 7.20 7.26. Show that the zero-point energy of a Debye solid composed of N atoms is equal to 9 8 Nk2D. [Note that this implies, for each vibrational mode of the solid, a mean zero-point energy 3 8 k2D, that is, ω = 3 4 ωD.] 7.27. Show that, for T ≪ 2D, the quantity (CP − CV ) of a Debye solid varies as T 7 and hence the ratio (CP/CV ) ≃ 1. 7.28. Determine the temperature T , in terms of the Debye temperature 2D, at which one-half of the oscillators in a Debye solid are expected to be in the excited states. 7.29. Determine the value of the parameter 2D for liquid He 4 from the empirical result (7.4.28). 7.30. (a) Compare the “mean thermal wavelength” λT of neutrons at a typical room temperature with the “minimum wavelength” λmin of phonons in a typical crystal. (b) Show that the frequency ωD for a sodium chloride crystal is of the same order of magnitude as the frequency of an electromagnetic wave in the infrared. 7.31. Proceeding under conditions (7.4.16) rather than (7.4.13), show that CV (T ) = Nk{D(x0,L) + 2D(x0,T )}, where x0,L = (ℏωD,L/kT ) and x0,T = (ℏωD,T /kT ). Compare this result with equation (7.4.17), and estimate the nature and the magnitude of the error involved in the latter. 7.32. A mechanical system consisting of n identical masses (each of mass m) connected in a straight line by identical springs (of stiffness K ) has natural vibrational frequencies given by ωr = 2 √ ( K m ) sin ( r n · π 2 ) ; r = 1, 2, . . . (n − 1). 228 Chapter 7 . Ideal Bose Systems Correspondingly, a linear molecule composed of n identical atoms may be regarded as having a vibrational spectrum given by νr = νc sin ( r n · π 2 ) ; r = 1, 2, . . . (n − 1), where vc is a characteristic vibrational frequency of the molecule. Show that this model leads to a vibrational speciﬁc heat per molecule that varies as T 1 at low temperatures and tends to the limiting value (n − 1)k at high temperatures. 7.33. Assuming the dispersion relation ω = Aks, where ω is the angular frequency and k the wave number of a vibrational mode existing in a solid, show that the respective contribution toward the speciﬁc heat of the solid at low temperatures is proportional to T 3/s. [Note that while s = 1 corresponds to the case of elastic waves in a lattice, s = 2 applies to spin waves propagating in a ferromagnetic system.] 7.34. Assuming the excitations to be phonons (ω = Ak), show that their contribution toward the speciﬁc heat of an n-dimensional Debye system is proportional to T n. [Note that the elements selenium and tellurium form crystals in which atomic chains are arranged in parallel so that in a certain sense they behave as one-dimensional; accordingly, over a certain range of temperatures, the T 1-law holds. For a similar reason, graphite obeys a T 2-law over a certain range of temperatures.] 7.35. The (minimum) potential energy of a solid, when all its atoms are “at rest” at their equilibrium positions, may be denoted by the symbol 80(V ), where V is the volume of the solid. Similarly, the normal frequencies of vibration, ωi (i = 1, 2, . . . , 3N − 6), may be denoted by the symbols ωi(V ). Show that the pressure of this solid is given by P = − ∂80 ∂V + γ U ′ V , where U ′ is the internal energy of the solid arising from the vibrations of the atoms, while γ is the Gr ¨uneisen constant: γ = − ∂ ln ω ∂ ln V ≈ 1 3 . Assuming that, for V ≃ V0, 80(V ) = (V − V0)2 2κ0V0 , where κ0 and V0 are constants and κ0CV T ≪ V0, show that the coefﬁcient of thermal expansion (at constant pressure P ≃ 0) is given by α ≡ 1 V ( ∂V ∂T ) N,P = γ κ0CV V0 . Also show that CP − CV = γ 2κ0C2 V T V0 . 7.36. Apply the general formula (6.4.3) for the kinetic pressure of a gas, namely P = 1 3 n⟨pu⟩, to a gas of rotons and verify that the result so obtained agrees with the Boltzmannian relationship P = nkT . 7.37. Show that the free energy A and the inertial density ρ of a roton gas in mass motion are given by A(v) = A(0) sinh x x Problems 229 and ρ(v) = ρ(0) 3(x cosh x − sinh x) x3 , where x = vp0/kT . 7.38. Integrating (7.6.17) by parts, show that the effective mass of an excitation, whose energy– momentum relationship is denoted by ε(p), is given by meff = 〈 1 3p2 { d dp ( p 4 dp dε )}〉 . Check the validity of this result by considering the examples of (i) an ideal-gas particle, (ii) a phonon, and (iii) a roton. 8 Ideal Fermi Systems 8.1 Thermodynamic behavior of an ideal Fermi gas According to Sections 6.1 and 6.2, we obtain for an ideal Fermi gas PV kT ≡ ln Q = ∑ ε ln(1 + ze−βε) (1) and N ≡ ∑ ε ⟨nε⟩ = ∑ ε 1 z−1eβε + 1 , (2) where β = 1/kT and z = exp(µ/kT ). Unlike the Bose case, the parameter z in the Fermi case can take on unrestricted values: 0 ≤ z < ∞. Moreover, in view of the Pauli exclusion principle, the question of a large number of particles occupying a single energy state does not even arise in this case; hence, there is no phenomenon like Bose–Einstein condensa- tion here. Nevertheless, at sufﬁciently low temperatures, Fermi gas displays its own brand of quantal behavior, a detailed study of which is of great physical interest. If we replace summations over ε by corresponding integrations, equations (1) and (2) in the case of a nonrelativistic gas become P kT = g λ3 f5/2(z) (3) and N V = g λ3 f3/2(z), (4) where g is a weight factor arising from the “internal structure” of the particles (e.g., spin), λ is the mean thermal wavelength of the particles λ = h/(2π mkT ) 1/2, (5) while fν(z) are Fermi–Dirac functions deﬁned by, see Appendix E, fν (z) = 1 0(ν) ∞∫ 0 xν−1dx z−1ex + 1 = z − z2 2ν + z3 3ν − · · · . (6) Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00008-6 © 2011 Elsevier Ltd. All rights reserved. 231 232 Chapter 8. Ideal Fermi Systems Eliminating z between equations (3) and (4), we obtain the equation of state of the Fermi gas. The internal energy U of the Fermi gas is given by U ≡ − ( ∂ ∂β ln Q ) z,V = kT 2 ( ∂ ∂T ln Q ) z,V = 3 2 kT gV λ3 f5/2(z) = 3 2 NkT f5/2(z) f3/2(z) ; (7) thus, quite generally, this system satisﬁes the relationship P = 2 3 (U/V ). (8) The speciﬁc heat CV of the gas can be obtained by differentiating (7) with respect to T , keeping N and V constant, and making use of the relationship 1 z ( ∂z ∂T ) v = − 3 2T f3/2(z) f1/2(z) , (9) which follows from equation (4) and the recurrence formula (E.6) in Appendix E. The ﬁnal result is CV Nk = 15 4 f5/2(z) f3/2(z) − 9 4 f3/2(z) f1/2(z) . (10) For the Helmholtz free energy of the gas, we get A ≡ Nµ − PV = NkT { ln z − f5/2(z) f3/2(z) } , (11) and for the entropy S ≡ U − A T = Nk { 5 2 f5/2(z) f3/2(z) − ln z} . (12) In order to determine the various properties of the Fermi gas in terms of the particle den- sity n (= N/V ) and the temperature T , we need to know the functional dependence of the parameter z on n and T ; this information is formally contained in the implicit relationship (4). For detailed studies, one is sometimes obliged to make use of numerical evaluation of the functions fν(z); for physical understanding, however, the various limiting forms of these functions serve the purpose well (see Appendix E). Now, if the density of the gas is very low and/or its temperature very high, then the situation might correspond to f3/2(z) = nλ3 g = nh3 g(2π mkT )3/2 ≪ 1; (13) 8.1 Thermodynamic behavior of an ideal Fermi gas 233 we then speak of the gas as being nondegenerate and, therefore, equivalent to a classical ideal gas discussed in Section 3.5. In view of expansion (6), this implies that z ≪ 1 and hence fν(z) ≃ z. Expressions for the various thermodynamic properties of the gas then become P = NkT /V , U = 3 2 NkT , CV = 3 2 Nk, (14) A = NkT { ln ( nλ3 g ) − 1 } , (15) and S = Nk { 5 2 − ln ( nλ3 g )} . (16) If the parameter z is small in comparison with unity but not very small, then we should make a fuller use of series (6) in order to eliminate z between equations (3) and (4). The procedure is just the same as in the corresponding Bose case, that is, we ﬁrst invert the series appearing in (4) to obtain an expansion for z in powers of (nλ3/g) and then substi- tute this expansion into the series appearing in (3). The equation of state then takes the form of the virial expansion PV NkT = ∞∑ l=1(−1)l−1al ( λ3 gv )l−1 , (17) where v = 1/n, while the coefﬁcients al are the same as quoted in (7.1.14) but alternate in sign compared to the Bose case. For the speciﬁc heat, in particular, we obtain CV = 3 2 Nk ∞∑ l=1(−1) l−1 5 − 3l 2 al ( λ3 gv )l−1 = 3 2 Nk  1 − 0.0884 ( λ3 gv ) + 0.0066 ( λ3 gv )2 − 0.0004 ( λ3 gv )3 + · · ·   . (18) Thus, at ﬁnite temperatures, the speciﬁc heat of the gas is smaller than its limiting value 3 2 Nk. As will be seen in the sequel, the speciﬁc heat of the ideal Fermi gas decreases mono- tonically as the temperature of the gas falls; see Figure 8.2 later in the section and compare it with the corresponding Figure 7.4 for the ideal Bose gas. If the density n and the temperature T are such that the parameter (nλ3/g) is of order unity, the foregoing expansions cannot be of much use. In that case, one may have to make recourse to numerical calculation. However, if (nλ3/g) ≫ 1, the functions involved can be expressed as asymptotic expansions in powers of (ln z)−1; we then speak of the gas as being degenerate. As (nλ3/g) → ∞, our functions assume a closed form, with the result that the expressions for the various thermodynamic quantities pertaining to the system become 234 Chapter 8. Ideal Fermi Systems highly simpliﬁed; we then speak of the gas as being completely degenerate. For simplicity, we ﬁrst discuss the main features of the system in a state of complete degeneracy. In the limit T → 0, which implies (nλ3/g) → ∞, the mean occupation numbers of the single-particle state ε(p) become ⟨nε⟩ ≡ 1 e(ε−µ)/kT + 1 = {1 for ε < µ0 0 for ε > µ0, (19) where µ0 is the chemical potential of the system at T = 0. The function ⟨nε⟩ is thus a step function that stays constant at the (highest) value 1 right from ε = 0 to ε = µ0 and then suddenly drops to the (lowest) value 0; see the dotted line in Figure 8.1. Thus, at T = 0, all single-particle states up to ε = µ0 are “completely” ﬁlled, with one particle per state (in accordance with the Pauli principle), while all single-particle states with ε > µ0 are empty. The limiting energy µ0 is generally referred to as the Fermi energy of the system and is denoted by the symbol εF ; the corresponding value of the single-particle momen- tum is referred to as the Fermi momentum and is denoted by the symbol pF . The deﬁning equation for these parameters is εF∫ 0 a(ε)dε = N, (20) where a(ε) denotes the density of states of the system and is given by the general expression a(ε) = gV h3 4πp2 dp dε . (21) We readily obtain N = 4π gV 3h3 p 3 F , (22) which gives pF = ( 3N 4πgV )1/3 h; (23) 1.0 0.5 0 0 \u0002 \u0002 4 \u0002 \u0002 2 \u0002 \u0003 2 \u0002 \u00034\u0002 x(ex\u0002\u0002\u00031)\u00021FIGURE 8.1 Fermi distribution at low temperatures, with x = ε/kT and ξ = µ/kT . The rectangle denotes the limiting distribution as T → 0; in that case, the Fermi function is unity for ε < µ0 and zero for ε > µ0. 8.1 Thermodynamic behavior of an ideal Fermi gas 235 accordingly, in the nonrelativistic case, εF = ( 3N 4π gV )2/3 h2 2m = ( 6π 2n g )2/3 ℏ2 2m . (24) The ground-state, or zero-point, energy of the system is then given by E0 = 4π gV h3 PF∫ 0 ( p2 2m ) p 2dp = 2π gV 5mh3 p 5 F , (25) which gives E0 N = 3p2 F 10m = 3 5 εF . (26) The ground-state pressure of the system is in turn given by P0 = 2 3 (E0/V ) = 2 5 nεF . (27) Substituting for εF , the foregoing expression takes the form P0 = ( 6π 2 g )2/3 ℏ2 5m n 5/3 ∝ n 5/3. (28) The zero-point motion seen here is clearly a quantum effect arising because of the Pauli principle, according to which, even at T = 0 K, the particles constituting the system cannot settle down into a single energy state (as we had in the Bose case) and are therefore spread over a requisite number of lowest available energy states. As a result, the Fermi system, even at absolute zero, is quite live! For a discussion of properties such as the speciﬁc heat and the entropy of the system, we must extend our study to ﬁnite temperatures. If we decide to restrict ourselves to low temperatures, then deviations from the ground-state results will not be too large; accord- ingly, an analysis based on the asymptotic expansions of the functions fν(z) would be quite appropriate. However, before we do that it seems useful to carry out a physical assessment of the situation with the help of the expression ⟨nε⟩ = 1 e(ε−µ)/kT + 1 . (29) The situation corresponding to T = 0 is summarized in equation (19) and is shown as a step function in Figure 8.1. Deviations from this, when T is ﬁnite (but still much smaller than the characteristic temperature µ0/k), will be signiﬁcant only for those values of ε for which 236 Chapter 8. Ideal Fermi Systems the magnitude of the quantity (ε − µ)/kT is of order unity (for otherwise the exponential term in (29) will not be much different from its ground-state value, namely, e±∞); see the solid curve in Figure 8.1. We, therefore, conclude that the thermal excitation of the particles occurs only in a nar- row energy range that is located around the energy value ε = µ0 and has a width O(kT ). The fraction of the particles that are thermally excited is, therefore, O(kT /εF ) — the bulk of the system remaining uninﬂuenced by the rise in temperature.1 This is the most characteris- tic feature of a degenerate Fermi system and is essentially responsible for both qualitative and quantitative differences between the physical behavior of this system and that of a corresponding classical system. To conclude the argument, we observe that since the thermal energy per “excited” par- ticle is O(kT ), the thermal energy of the whole system will be O(Nk2T 2/εF ); accordingly, the speciﬁc heat of the system will be O(Nk · kT /εF ). Thus, the low-temperature speciﬁc heat of a Fermi system differs from the classical value 3 2 Nk by a factor that not only reduces it considerably in magnitude but also makes it temperature-dependent (varying as T 1). It will be seen repeatedly that the ﬁrst-power dependence of CV on T is a typical feature of Fermi systems at low temperatures. For an analytical study of the Fermi gas at ﬁnite, but low, temperatures, we observe that the value of z, which was inﬁnitely large at absolute zero, is now ﬁnite, though still large in comparison with unity. The functions fν(z) can, therefore, be expressed as asymp- totic expansions in powers of (ln z)−1; see Sommerfeld’s lemma (E.17) in Appendix E. For the values of ν we are presently interested in, namely 5 2 , 3 2 , and 1 2 , we have to the ﬁrst approximation f5/2(z) = 8 15π 1/2 (ln z) 5/2 [ 1 + 5π 2 8 (ln z) −2 + · · · ] , (30) f3/2(z) = 4 3π 1/2 (ln z) 3/2 [ 1 + π 2 8 (ln z) −2 + · · · ] , (31) and f1/2(z) = 2 π 1/2 (ln z) 1/2 [ 1 − π 2 24 (ln z) −2 + · · · ] . (32) Substituting (31) into (4), we obtain N V = 4πg 3 ( 2m h2 )3/2 (kT ln z) 3/2 [ 1 + π 2 8 (ln z) −2 + · · · ] . (33) 1We, therefore, speak of the totality of the energy levels ﬁlled at T = 0 as “the Fermi sea” and the small fraction of the particles that are excited near the top, when T > 0, as a “mist above the sea.” Physically speaking, the origin of this behavior again lies in the Pauli exclusion principle, according to which a fermion of energy ε cannot absorb a quantum of thermal excitation εT if the energy level ε + εT is already ﬁlled. Since εT = O(kT ), only those fermions that occupy energy levels near the top level εF , up to a depth O(kT ), can be thermally excited to go over to the unﬁlled energy levels. 8.1 Thermodynamic behavior of an ideal Fermi gas 237 In the zeroth approximation, this gives kT ln z ≡ µ ≃ ( 3N 4π gV )2/3 h2 2m , (34) which is identical to the ground-state result µ0 = εF ; see equation (24). In the next approxi- mation, we obtain kT ln z ≡ µ ≃ εF [ 1 − π 2 12 ( kT εF )2] . (35) Substituting (30) and (31) into (7), we obtain U N = 3 5 (kT ln z) [ 1 + π 2 2 (ln z) −2 + · · · ] ; (36) with the help of (35), this becomes U N = 3 5 εF [ 1 + 5π 2 12 ( kT εF )2 + · · · ] . (37) The pressure of the gas is then given by P = 2 3 U V = 2 5 nεF [ 1 + 5π 2 12 ( kT εF )2 + · · · ] . (38) As expected, the main terms of equations (37) and (38) are identical to the ground-state results (26) and (27). From the temperature-dependent part of (37), we obtain for the low- temperature speciﬁc heat of the gas CV Nk = π 2 2 kT εF + · · · . (39) Thus, for T ≪ TF , where TF (= εF /k) is the Fermi temperature of the system, the speciﬁc heat varies as the ﬁrst power of temperature; moreover, in magnitude, it is consider- ably smaller than the classical value 3 2 Nk. The overall variation of CV with T is shown in Figure 8.2. The Helmholtz free energy of the system follows directly from equations (35) and (38): A N = µ − PV N = 3 5 εF [ 1 − 5π 2 12 ( kT εF )2 + · · · ] , (40) 238 Chapter 8. Ideal Fermi Systems (T/TF) 0 0 0.5 1.0 1.5 1 23 Cv Nk FIGURE 8.2 The speciﬁc heat of an ideal Fermi gas; the dotted line depicts the linear behavior at low temperatures. which gives S Nk = π 2 2 kT εF + · · · . (41) Thus, as T → 0, S → 0 in accordance with the third law of thermodynamics. 8.2 Magnetic behavior of an ideal Fermi gas We now turn our attention to studying the equilibrium state of a gas of noninteracting fermions in the presence of an external magnetic ﬁeld B. The main problem here is to determine the net magnetic moment M acquired by the gas (as a function of B and T ) and then calculate the susceptibility χ(T ). The answer naturally depends on the intrinsic mag- netic moment µ∗ of the particles and the corresponding multiplicity factor (2J + 1); see, for instance, the treatment given in Section 3.9. According to the Boltzmannian treatment, one obtains a (positive) susceptibility χ(T ) which, at high temperatures, obeys the Curie law : χ ∝ T −1; at low temperatures, one obtains a state of magnetic saturation. However, if we treat the problem on the basis of Fermi statistics we obtain signiﬁcantly different results, especially at low temperatures. In particular, since the Fermi gas is pretty live even at absolute zero, no magnetic sat- uration ever results; we rather obtain a limiting susceptibility χ0, which is independent of temperature but is dependent on the density of the gas. Studies along these lines were ﬁrst made by Pauli, in 1927, when he suggested that the conduction electrons in alkali metals be regarded as a “highly degenerate Fermi gas”; these studies enabled him to explain the physics behind the feeble and temperature-independent character of the paramagnetism of metals. Accordingly, this phenomenon is referred to as Pauli paramagnetism — in contrast to the classical Langevin paramagnetism. In quantum statistics, we encounter yet another effect which is totally absent in clas- sical statistics. This is diamagnetic in character and arises from the quantization of the orbits of charged particles in the presence of an external magnetic ﬁeld or, one may say, 8.2 Magnetic behavior of an ideal Fermi gas 239 from the quantization of the (kinetic) energy of charged particles associated with their motion perpendicular to the direction of the ﬁeld. The existence of this effect was ﬁrst established by Landau (1930); so, we refer to it as Landau diamagnetism. This leads to an additional susceptibility χ(T ), which, though negative in sign, is somewhat similar to the paramagnetic susceptibility, in that it obeys Curie’s law at high temperatures and tends to a temperature-independent but density-dependent limiting value as T → 0. In gen- eral, the magnetic behavior of a Fermi gas is determined jointly by the intrinsic magnetic moment of the particles and the quantization of their orbits. If the spin–orbit interaction is negligible, the resultant behavior is given by a simple addition of the two effects. 8.2.A Pauli paramagnetism The energy of a particle, in the presence of an external magnetic ﬁeld B, is given by ε = p2 2m − µ∗ · B, (1) where µ∗ is the intrinsic magnetic moment of the particle and m its mass. For simplicity, we assume that the particle spin is 1 2 ; the vector µ∗ will then be either parallel to the vector B or antiparallel. We thus have two groups of particles in the gas: (i) those having µ∗ parallel to B, with ε = p2/2m − µ∗B, and (ii) those having µ∗ antiparallel to B, with ε = p2/2m + µ∗B. At absolute zero, all energy levels up to the Fermi level εF will be ﬁlled, while all levels beyond εF will be empty. Accordingly, the kinetic energy of the particles in the ﬁrst group will range between 0 and (εF + µ∗B), while the kinetic energy of the particles in the second group will range between 0 and (εF − µ∗B). The respective numbers of occupied energy levels (and hence of particles) in the two groups will, therefore, be N + = 4πV 3h3 {2m(εF + µ∗B)}3/2 (2) and N − = 4πV 3h3 {2m(εF − µ∗B)}3/2. (3) The net magnetic moment acquired by the gas is then given by M = µ∗(N + − N −) = 4πµ∗V (2m)3/2 3h3 {(εF + µ∗B) 3/2 − (εF − µ∗B)3/2}. (4) We thus obtain for the low-ﬁeld susceptibility (per unit volume) of the gas χ0 = Lim B→0 ( M VB ) = 4πµ∗2(2m)3/2ε1/2 F h3 . (5) 240 Chapter 8. Ideal Fermi Systems Making use of formula (8.1.24), with g = 2, the foregoing result may be written as χ0 = 3 2 nµ∗2/εF . (6) For comparison, the corresponding high-temperature result is given by equation (3.9.26), with g = 2 and J = 1 2 : χ∞ = nµ∗2/kT . (7) We note that χ0/χ∞ = O(kT /εF ). To obtain an expression for χ that holds for all T , we proceed as follows. Denoting the number of particles with momentum p and magnetic moment parallel (or antiparallel) to the ﬁeld by the symbol n+ p (or n− p ), the total energy of the gas can be written as En = ∑ p [( p2 2m − µ∗B ) n+ p + ( p2 2m + µ∗B ) n − p ] = ∑ p (n + p + n − p ) p2 2m − µ∗B(N + − N −), (8) where N + and N − denote the total number of particles in the two groups, respectively. The partition function of the system is then given by Q(N) = ∑ {n+ p },{n− p } ′exp(−βEn), (9) where the primed summation is subject to the conditions n + p , n − p = 0 or 1, (10) and ∑ p n + p + ∑ p n − p = N + + N − = N. (11) To evaluate the sum in (9), we ﬁrst ﬁx an arbitrary value of the number N + (which auto- matically ﬁxes the value of N − as well) and sum over all n+ p and n− p that conform to the ﬁxed values of the numbers N + and N − as well as to condition (10). Next, we sum over all possible values of N +, namely from N + = 0 to N + = N. We thus have Q(N) = N∑ N += 0   eβµ∗B(2N +−N)    ∑ {n+ p } ′′ exp  −β ∑ p p2 2m n + p   ∑ {n − p } ′′′ exp  −β ∑ p p2 2m n − p         ; (12) 8.2 Magnetic behavior of an ideal Fermi gas 241 here, the summation ∑′′ is subject to the restriction ∑p n+ p = N +, while ∑′′′ is subject to the restriction ∑p n− p = N − N +. Now, let Q0(N ) denote the partition function of an ideal Fermi gas of N “spinless” particles of mass m; then, obviously, Q0(N ) = ∑ {np} ′ exp  −β ∑ p p2 2m np   ≡ exp{−βA0(N )}, (13) where A0(N ) is the free energy of this ﬁctitious system. Equation (12) can then be written as Q(N) = e−βµ∗BN N∑ N +=0 [e2βµ∗BN + Q0(N +)Q0(N − N +)], (14) which gives 1 N ln Q(N) = −βµ∗B + 1 N ln N∑ N +=0 [exp{2βµ∗BN + − βA0(N +) − βA0(N − N +)}]. (15) As before, the logarithm of the sum ∑N + may be replaced by the logarithm of the largest term in the sum; the error committed in doing so would be negligible in comparison with the term retained. Now, the value N +, of N +, which corresponds to the largest term in the sum, can be ascertained by setting the differential coefﬁcient of the general term, with respect to N +, equal to zero; this gives 2µ∗B − [ ∂A0(N +) ∂N + ] N +=N + − [ ∂A0(N − N +) ∂N + ] N +=N + = 0, that is µ0(N +) − µ0(N − N +) = 2µ∗B, (16) where µ0(N ) is the chemical potential of the ﬁctitious system of N “spinless” fermions. The foregoing equation contains the general solution being sought. To obtain an explicit expression for χ, we introduce a dimensionless parameter r, deﬁned by M = µ∗(N + − N −) = µ∗(2N + − N) = µ∗Nr (0 ≤ r ≤ 1); (17) equation (16) then becomes µ0 ( 1 + r 2 N) − µ0 ( 1 − r 2 N) = 2µ∗B. (18) If the magnetic ﬁeld B vanishes so does r, which corresponds to a completely random ori- entation of the elementary moments. For small B, r would also be small; so, we may carry 242 Chapter 8. Ideal Fermi Systems out a Taylor expansion of the left side of (18) about r = 0. Retaining only the ﬁrst term of the expansion, we obtain r ≃ 2µ∗B ∂µ0(xN) ∂x ∣ ∣ x=1/2 . (19) The low-ﬁeld susceptibility (per unit volume) of the system is then given by χ = M VB = µ∗Nr VB = 2nµ∗2 ∂µ0(xN) ∂x ∣ ∣ x=1/2 , (20) which is the desired result valid for all T . For T → 0, the chemical potential of the ﬁctitious system can be obtained from equation (8.1.34), with g = 1: µ0(xN) = ( 3xN 4πV )2/3 h2 2m , which gives ∂µ0(xN) ∂x ∣ ∣ ∣ ∣ x=1/2 = 24/3 3 ( 3N 4π V )2/3 h2 2m . (21) On the other hand, the Fermi energy of the actual system is given by the same equa- tion (8.1.34), with g = 2: εF = ( 3N 8π V )2/3 h2 2m . (22) Making use of equations (21) and (22), we obtain from (20) χ0 = 2nµ∗2 4 3 εF = 3 2 nµ∗2/εF , (23) in complete agreement with our earlier result (6). For ﬁnite but low temperatures, one has to use equation (8.1.35) instead of (8.1.34). The ﬁnal result turns out to be χ ≃ χ0 [ 1 − π 2 12 ( kT εF )2] . (24) On the other hand, for T → ∞, the chemical potential of the ﬁctitious system follows directly from equation (8.1.4), with g = 1 and f3/2(z) ≃ z, with the result µ0(xN) = kT ln(xNλ 3/V ), 8.2 Magnetic behavior of an ideal Fermi gas 243 which gives ∂µ0(xN) ∂x ∣ ∣ ∣ ∣ x=1/2 = 2kT . (25) Equation (20) then gives χ∞ = nµ∗2/kT , (26) in complete agreement with our earlier result (7). For large but ﬁnite temperatures, one has to take f3/2(z) ≃ z − (z2/23/2). The ﬁnal result then turns out to be χ ≃ χ∞ ( 1 − nλ3 25/2 ) ; (27) the correction term here is proportional to (TF /T )3/2 and tends to zero as T → ∞. 8.2.B Landau diamagnetism We now study the magnetism arising from the quantization of the orbital motion of (charged) particles in the presence of an external magnetic ﬁeld. In a uniform ﬁeld of intensity B, directed along the z-axis, a charged particle would follow a helical path whose axis is parallel to the z-axis and whose projection on the (x, y)-plane is a circle. Motion along the z-direction has a constant linear velocity uz, while that in the (x, y)-plane has a constant angular velocity eB/mc; the latter arises from the Lorentz force, e(u × B)/c, expe- rienced by the particle. Quantum-mechanically, the energy associated with the circular motion is quantized in units of eℏB/mc. The energy associated with the linear motion along the z-axis is also quantized but, in view of the smallness of the energy intervals, this may be taken as a continuous variable. We thus have for the total energy of the particle2 ε = eℏB mc ( j + 1 2 ) + p2 z 2m ( j = 0, 1, 2, . . .). (28) Now, these quantized energy levels are degenerate because they result from a “coalescing together” of an almost continuous set of zero-ﬁeld levels. A little reﬂection shows that all those levels for which the value of the quantity (p2 x + p2 y)/2m lay between eℏBj/mc and eℏB( j + 1)/mc now “coalesce together” into a single level characterized by the quantum number j. The number of these levels is given by 1 h2 ∫ dx dy dpxdpy = LxLy h2 π [2m eℏB mc {( j + 1) − j}] = LxLy eB hc , (29) 2See, for instance, Goldman et al. (1960); Problem 6.3. 244 Chapter 8. Ideal Fermi Systems eℏ mc B \u0002 0B \u0003 0 j \u0003 4 j \u0003 3 j \u0003 2 j \u0003 1 j \u0003 0 B eℏ mc B FIGURE 8.3 The single-particle energy levels, for a two-dimensional motion, in the absence of an external magnetic ﬁeld (B = 0) and in the presence of an external magnetic ﬁeld (B > 0). which is independent of j. The multiplicity factor (29) is a quantum-mechanical measure of the freedom available to the particle for the center of its orbit to be “located” anywhere in the total area LxLy of the physical space. Figure 8.3 depicts the manner in which the zero-ﬁeld energy levels of the particle group themselves into a spectrum of oscillator-like levels on the application of the external magnetic ﬁeld. The grand partition function of the gas is given by the standard formula ln Q = ∑ ε ln(1 + ze−βε), (30) where the summation has to be carried over all single-particle states in the system. Sub- stituting (28) for ε, making use of the multiplicity factor (29) and replacing the summation over pz by an integration, we get ln Q = ∞∫ −∞ Lzdpz h   ∞∑ j=0 ( LxLy eB hc ) ln {1 + ze−βeℏB[j+(1/2)]/mc−βp2 z /2m}   . (31) At high temperatures, z ≪ 1; so, the system is effectively Boltzmannian. The grand parti- tion function then reduces to ln Q = zVeB h2c ∞∫ −∞ e−βp2 z /2mdpz ∞∑ j=0 e−βeℏB[j+(1/2)]/mc = zVeB h2c ( 2πm β )1/2 { 2 sinh ( βeℏB 2mc )}−1 . (32) The equilibrium number of particles N and the magnetic moment M of the gas are then given by 8.2 Magnetic behavior of an ideal Fermi gas 245 N = (z ∂ ∂z ln Q ) B,V ,T , (33) and M = 〈− ∂H ∂B 〉 = 1 β ( ∂ ∂B ln Q ) z,V ,T , (34) where H is the Hamiltonian of the system; compare with equation (3.9.4). We thus obtain N = zV λ3 x sinh x , (35) and M = zV λ3 µeff { 1 sinh x − x cosh x sinh 2 x } , (36) where λ{= h/(2π mkT )1/2} is the mean thermal wavelength of the particles, while x = βµeffB ( µeff = eh/4π mc) . (37) Clearly, if e and m are the electronic charge and the electronic mass, then µeff is the familiar Bohr magneton µB. Combining (35) and (36), we get M = −NµeffL(x), (38) where L(x) is the Langevin function: L(x) = coth x − 1 x . (39) This result is very similar to the one obtained in the Langevin theory of paramagnetism; see Section 3.9. The presence of the negative sign, however, means that the effect obtained in the present case is diamagnetic in nature. We also note that this effect is a direct con- sequence of quantization; it vanishes if we let h → 0. This is in complete accord with the Bohr–van Leeuwen theorem, according to which the phenomenon of diamagnetism does not arise in classical physics; see Problem 3.43. If the ﬁeld intensity B and the temperature T are such that µeffB ≪ kT , then the foregoing results become N ≃ zV λ3 (40) and M ≃ −Nµ2 effB/3kT . (41) 246 Chapter 8. Ideal Fermi Systems Equation (40) is in agreement with the zero-ﬁeld formula z ≃ nλ3, while (41) leads to the diamagnetic counterpart of the Curie law: χ∞ = M VB = −nµ 2 eff/3kT ; (42) see equation (3.9.12). It should be noted here that the diamagnetic character of this phenomenon is independent of the sign of the electric charge on the particle. For an elec- tron gas, in particular, the net susceptibility at high temperatures is given by the sum of expression (7), with µ∗ replaced by µB, and expression (42): χ∞ = n (µ2 B − 1 3 µ′2 B ) kT , (43) where µ′ B = eh/4π m′c, m′ being the effective mass of the electron in the given system. We now look at this problem at all temperatures, though we will continue to assume the magnetic ﬁeld to be weak, so that µeffB ≪ kT . In view of the latter, the summation in (31) may be handled with the help of the Euler summation formula, ∞∑ j=0 f ( j + 1 2 ) ≃ ∞∫ 0 f (x)dx + 1 24 f ′(0), (44) with the result ln Q ≃ VeB h2c   ∞∫ 0 dx ∞∫ −∞ dpz ln {1 + ze−β(2µeffBx+p2 z /2m)} − 1 12 βµeffB ∞∫ −∞ dpz z−1eβ(p2 z /2m) + 1   . (45) The ﬁrst part here is independent of B, which can be seen by changing the variable from x to x′ = Bx. The second part, with the substitution βp2 z/2m = y, becomes − πV (2m)3/2 6h3 (µeffB) 2β1/2 ∞∫ 0 y−1/2dy z−1ey + 1 . (46) The low-ﬁeld susceptibility (per unit volume) of the gas is then given by χ = M VB = 1 βVB ( ∂ ∂B ln Q ) z,V ,T = − (2πm)3/2µ2 eff 3h3β1/2 f1/2(z), (47) 8.3 The electron gas in metals 247 which is the desired result. Note that, as before, the effect is diamagnetic in character — irrespective of the sign of the charge on the particle. For z ≪ 1, f1/2(z) ≃ z ≃ nλ3; we then recover our previous result (42). For z ≫ 1 (which corresponds to T ≪ TF ), f1/2(z) ≈ (2/π 1/2)(ln z)1/2; we then get χ0 ≈ − 2π(2m)3/2µ2 effε1/2 F 3h3 = − 1 2 nµ2 eff/εF ; (48) here, use has also been made of the fact that (β−1 ln z) ≃ εF . Note that, in magnitude, this result is precisely one-third of the corresponding paramagnetic result (6), provided that we take the µ∗ of that expression to be equal to the µeff of this one. 8.3 The electron gas in metals One physical system where the application of Fermi–Dirac statistics helped remove a number of inconsistencies and discrepancies is that of conduction electrons in metals. Historically, the electron theory of metals was developed by Drude (1900) and Lorentz (1904–1905), who applied the statistical mechanics of Maxwell and Boltzmann to the electron gas and derived theoretical results for the various properties of metals. The Drude–Lorentz model did provide a reasonable theoretical basis for a partial understand- ing of the physical behavior of metals; however, it encountered a number of serious problems of a qualitative as well as quantitative nature. For instance, the observed spe- ciﬁc heat of metals appeared to be almost completely accountable by the lattice vibrations alone and practically no contribution seemed to be coming from the electron gas. The theory, however, demanded that, on the basis of the equipartition theorem, each electron in the gas should possess a mean thermal energy 3 2 kT and hence make a contribution of 3 2 k to the speciﬁc heat of the metal. Similarly, one expected the electron gas to exhibit the phenomenon of paramagnetism arising from the intrinsic magnetic moment µB of the electrons. According to the classical theory, the paramagnetic susceptibility would be given by (8.2.7), with µ∗ replaced by µB. Instead, one found that the susceptibility of a normal nonferromagnetic metal was not only independent of temperature but had a magnitude which, at room temperatures, was hardly 1 percent of the expected value. The Drude–Lorentz theory was also applied to study transport properties of met- als, such as the thermal conductivity K and the electrical conductivity σ . While the results for the individual conductivities were not very encouraging, their ratio did con- form to the empirical law of Wiedemann and Franz (1853), as formulated by Lorenz (1872), namely that the quantity K /σ T was a (universal) constant. The theoretical value of this quantity, which is generally known as the Lorenz number, turned out to be 3(k/e)2 ≃ 2.48 × 10−13 e.s.u./deg 2; the corresponding experimental values for most alkali and alkaline–earth metals were, however, found to be scattered around a mean value of 2.72 × 10−13 e.s.u./deg2. A still more uncomfortable feature of the classical theory was the uncertainty in assigning an appropriate value to the mean free path of the electrons in 248 Chapter 8. Ideal Fermi Systems a given metal and in ascribing to it an appropriate temperature dependence. For these reasons, the problem of the transport properties of metals also remained in a rather unsatisfactory state until the correct lead was provided by Sommerfeld (1928). The most signiﬁcant change introduced by Sommerfeld was the replacement of Maxwell–Boltzmann statistics by Fermi–Dirac statistics for describing the electron gas in a metal. With this single stroke of genius, he was able to set most of the things right. To see how it worked, let us ﬁrst estimate the Fermi energy εF of the electron gas in a typical metal, say sodium. Referring to equation (8.1.24), with g = 2, εF = ( 3N 8πV )2/3 h2 2m′ , (1) where m′ is the effective mass of an electron in the gas.3 The electron density N/V , in the case of a cubic lattice, may be written as N V = nena a3 , (2) where ne is the number of conduction electrons per atom, na the number of atoms per unit cell and a the lattice constant (or the cell length).4 For sodium, ne = 1, na = 2, and a = 4.29 ˚A. Substituting these numbers into (2) and writing m′ = 0.98me, we obtain from (1) (εF )Na = 5.03 × 10 −12 erg = 3.14 eV. (3) Accordingly, for the Fermi temperature of the gas is (TF )Na = (1.16 × 104) × εF ( in eV) = 3.64 × 10 4K, (4) which is considerably larger than the room temperature T (∼ 3 × 102 K). The ratio T /TF being of the order of 1 percent, the conduction electrons in sodium constitute a highly degenerate Fermi system. This statement, in fact, applies to all metals because their Fermi temperatures are generally of order 104 − 105 K. Now, the very fact that the electron gas in metals is a highly degenerate Fermi system is sufﬁcient to explain away some of the basic difﬁculties of the Drude–Lorentz theory. For instance, the speciﬁc heat of this gas would no longer be given by the classical formula, 3To justify the assumption that the conduction electrons in a metal may be treated as “free” electrons, it is necessary to ascribe to them an effective mass m′ ̸= m. This is an indirect way of accounting for the fact that the electrons in a metal are not really free; the ratio m′/m accordingly depends on the structural details of the metal and, therefore, varies from metal to metal. In sodium, m′/m ≃ 0.98. 4Another way of expressing the electron density is to write N/V = f ρ/M, where f is the valency of the metal, ρ its mass density, and M the mass of an atom (ρ/M, thus, being the number density of the atoms). 8.3 The electron gas in metals 249 CV = 3 2 Nk, but rather by equation (8.1.39), namely CV = π 2 2 Nk(kT /εF ); (5) obviously, the new result is much smaller in value because, at ordinary temperatures, the ratio (kT /εF ) ≡ (T /TF ) = O(10−2). It is then hardly surprising that, at ordinary tem- peratures, the speciﬁc heat of metals is almost completely determined by the vibrational modes of the lattice and very little contribution comes from the conduction electrons. Of course, as temperature decreases, the speciﬁc heat due to lattice vibrations also decreases and ﬁnally becomes considerably smaller than the classical value; see Section 7.4, espe- cially Figure 7.14. A stage comes when the two contributions, both nonclassical, become comparable in value. Ultimately, at very low temperatures, the speciﬁc heat due to lattice vibrations, being proportional to T 3, becomes even smaller than the electronic speciﬁc heat, which is proportional to T 1. In general, we may write, for the low-temperature speciﬁc heat of a metal, CV = γ T + δT 3, (6) where the coefﬁcient γ is given by equation (5) or, more generally, can be shown to be proportional to the density of states at the Fermi energy (see Problem 8.13), while the coef- ﬁcient δ is given by equation (7.4.23). An experimental determination of the speciﬁc heat of metals at low temperatures is, therefore, expected not only to verify the theoretical result based on quantum statistics but also to evaluate some of the parameters of the problem. Such determinations have been made, among others, by Corak et al. (1955) who worked with copper, silver and, gold in the temperature range 1 to 5 K. Their results for copper are shown in Figure 8.4. The very fact that the (CV /T ) versus T 2 plot is well approximated by a straight line vindicates the theoretical formula (6). Furthermore, the slope of this line gives the value of the coefﬁcient δ, from which one can extract the Debye temperature 2D of 0 0.4 0.8 1.2 1.6 2.0 2.4 2468 10 12 14 16 18 T 2 (in K2)Cv/T (in millijoules mole\u00021 K\u00022) FIGURE 8.4 The observed speciﬁc heat of copper at low temperatures (after Corak et al., 1955). 250 Chapter 8. Ideal Fermi Systems the metal. One thus gets for copper: 2D = (343.8 ± 0.5) K, which compares favorably with Leighton’s theoretical estimate of 345 K (based on the elastic constants of the metal). The intercept on the (CV /T )-axis yields the value of the coefﬁcient γ , namely (0.688 ± 0.002) millijoule mole −1 deg−2, which agrees favorably with Jones’ estimate of 0.69 millijoule mole −1 deg−2 (based on a density-of-states calculation). The general pattern of the magnetic behavior of the electron gas in nonferromagnetic metals can be understood likewise. In view of the highly degenerate nature of the gas, the magnetic susceptibility χ is given by the Pauli result (8.2.6) plus the Landau result (8.2.48), and not by the classical result (8.2.7). In complete agreement with the observation, the new result is (i) independent of temperature and (ii) considerably smaller in magnitude than the classical one. As regards transport properties K and σ , the new theory again led to the Wiedemann– Franz law ; the Lorenz number, however, became (π 2/3)(k/e)2, instead of the classical 3(k/e)2. The resulting theoretical value, namely 2.71 × 10−13 e.s.u./deg2, turned out to be much closer to the experimental mean value quoted earlier. Of course, the situa- tion regarding individual conductivities and the mean free path of the electrons did not improve until Bloch (1928) developed a theory that took into account interactions among the electron gas and the ion system in the metal. The theory of metals has continued to become more and more sophisticated; the important point to note here is that this development has all along been governed by the new statistics! Before leaving this topic, we would like to give a brief account of the phenomena of thermionic and photoelectric emission of electrons from metals. In view of the fact that electronic emission does not take place spontaneously, we infer that the electrons inside a metal ﬁnd themselves caught in some sort of a “potential well” created by the ions. The detailed features of the potential energy of an electron in this well must depend on the structure of the given metal. For a study of electronic emission, however, we need not worry about these details and may assume instead that the potential energy of an elec- tron stays constant (at a negative value, −W , say) throughout the interior of the metal and changes discontinuously to zero at the surface. Thus, while inside the metal, the electrons move about freely and independently of one another; however, as soon as any one of them approaches the surface of the metal and tries to escape, it encounters a potential barrier of height W . Accordingly, only those electrons whose kinetic energy (associated with the motion perpendicular to the surface) is greater than W can expect to escape through this barrier. At ordinary temperatures, especially in the absence of any external stimulus, such electrons are too few in any given metal, with the result that there is practically no spon- taneous emission from metals. At high temperatures, and more so if there is an external stimulus present, the population of such electrons in a given metal could become large enough to yield a sizeable emission. We then speak of phenomena such as thermionic effect and photoelectric effect. Strictly speaking, these phenomena are not equilibrium phenomena because electrons are ﬂowing out steadily through the surface of the metal. However, if the number of elec- trons lost in a given interval of time is small in comparison with their total population in 8.3 The electron gas in metals 251 the metal, then the magnitude of the emission current may be calculated on the assump- tion that the gas inside continues to be in a state of quasistatic thermal equilibrium. The mathematical procedure for this calculation is very much the same as the one followed in Section 6.4 (for determining the rate of effusion R of the particles of a gas through an open- ing in the walls of the container). There is one difference, however; whereas in the case of effusion any particle that reached the opening with uz > 0 could escape unquestioned, here we must have uz > (2W /m)1/2, so that the particle in question could successfully cross over the potential barrier at the surface. Moreover, even if this condition is satisﬁed, there is no guarantee that the particle will really escape because the possibility of an inward reﬂection cannot be ruled out. In the following discussion, we shall disregard this possi- bility; however, if one is looking for a numerical comparison of theory with experiment, the results derived here must be multiplied by a factor (1 − r), where r is the reﬂection coefﬁcient of the surface. 8.3.A Thermionic emission (the Richardson effect) The number of electrons emitted per unit area of the metal surface per unit time is given by R = ∞∫ pz=(2mW )1/2 ∞∫ px=−∞ ∞∫ py =−∞ { 2dpxdpydpz h3 1 e(ε−µ)/kT + 1 } uz; (7) compare with the corresponding expression in Section 6.4. Integration over the variables px and py may be carried out by changing over to polar coordinates (p′, φ), with the result R = 2 h3 ∞∫ pz=(2mW )1/2 pz m dpz ∞∫ p′=0 2π p′dp′ exp{[(p′2/2m) + (p2 z /2m) − µ]/kT } + 1 = 4πkT h3 ∞∫ pz=(2mW )1/2 pzdpz ln[1 + exp {(µ − p 2 z /2m)/kT }] = 4πmkT h3 ∞∫ εz=W dεz ln[1 + e(µ−εz)/kT ]. (8) It so happens that the exponential term inside the logarithm, at all temperatures of inter- est, is much smaller than unity; see Note 5. We may, therefore, write ln(1 + x) ≃ x, with the 252 Chapter 8. Ideal Fermi Systems result R = 4πmkT h3 ∞∫ εz=W dεze(µ−εz)/kT = 4πmk2T 2 h3 e(µ−W )/kT . (9) The thermionic current density is then given by J = eR = 4πmek2 h3 T 2e(µ−W )/kT . (10) It is only now that the difference between the classical statistics and the Fermi statistics really shows up! In the case of classical statistics, the fugacity of the gas is given by (see equation (8.1.4), with f3/2(z) ≃ z) z ≡ eµ/kT = nλ3 g = nh3 2(2πmkT )3/2 ; (11) accordingly, Jclass = ne ( k 2π m )1/2 T 1/2e−φ/kT (φ = W ). (12) In the case of Fermi statistics, the chemical potential of the (highly degenerate) electron gas is practically independent of temperature and is very nearly equal to the Fermi energy of the gas (µ ≃ µ0 ≡ εF ); accordingly, JF.D. = 4π mek2 h3 T 2e−φ/kT (φ = W − εF ). (13) The quantity φ is generally referred to as the work function of the metal. According to (12), φ is exactly equal to the height of the surface barrier; according to (13), it is equal to the height of the barrier over and above the Fermi level (see Figure 8.5). \u0002 Outside W Outside \u0003 0 Fermi level Fermi sea FIGURE 8.5 The work function φ of a metal represents the height of the surface barrier over and above the Fermi level. 8.3 The electron gas in metals 253 The theoretical results embodied in equations (12) and (13) differ in certain important respects. The most striking difference seems to be in regard to the temperature depen- dence of the thermionic current density J. However, the major dependence on T comes through the factor exp(−φ/kT ) — so much so that whether we plot ln( J/T 1/2) against (1/T ) or ln( J/T 2) against (1/T ) we obtain, in each case, a fairly good straight-line ﬁt. Thus, from the point of view of the temperature dependence of J, a choice between formulae (12) and (13) is rather hard to make. However, the slope of the experimental line should give us directly the value of W if formula (12) applies or of (W − εF ) if formula (13) applies! Now, the value of W can be determined independently, for instance, by studying the refractive index of a given metal for de Broglie waves associated with an electron beam impinging on the metal. For a beam of electrons whose initial kinetic energy is E, we have λout = h √ (2mE) and λin = h √ [2m(E + W )] , (14) so that the refractive index of the metal is given by n = λout λin = ( E + W E )1/2. (15) By studying electron diffraction for different values of E, one can derive the relevant value of W . In this manner, Davisson and Germer (1927) derived the value of W for a number of metals. For instance, they obtained for tungsten: W ≃ 13.5 eV. The experimental results on thermionic emission from tungsten are shown in Figure 8.6. The value of φ resulting from the slope of the experimental line was about 4.5 eV. The large difference between these 4.3 0 0.5 1.0 2.0 1.5 4.4 4.5 4.6 4.7 4.8 4.9 5.0 5.1 5.2 (104/T in K21)In(J/T2), in arbitrary units FIGURE 8.6 Thermionic current from tungsten as a function of the temperature of the metal. The continuous line corresponds to r = 1 2 while the broken line corresponds to r = 0, r being the reﬂection coefﬁcient of the surface. 254 Chapter 8. Ideal Fermi Systems two values clearly shows that the classical formula (12) does not apply. That the quantum- statistical formula (13) applies is shown by the fact that the Fermi energy of tungsten is very nearly 9 eV; so, the value 4.5 eV for the work function of tungsten is correctly given by the difference between the depth W of the potential well and the Fermi energy εF . To quote another example, the experimental value of the work function for nickel was found to be about 5.0 eV, while the theoretical estimate for its Fermi energy turns out to be about 11.8 eV. Accordingly, the depth of the potential well in the case of nickel should be about 16.8 eV. The experimental value of W , obtained by studying electron diffraction in nickel, is indeed (17 ± 1) eV. 5 The second point of difference between formulae (12) and (13) relates to the actual value of the current obtained. In this respect, the classical formula turns out to be a com- plete failure while the quantum-statistical formula fares reasonably well. The constant factor in the latter formula is 4πmek2 h3 = 120.4 amp cm −2 deg −2; (16) of course, this has yet to be multiplied by the transmission coefﬁcient (1 − r). The corre- sponding experimental number, for most metals with clean surfaces, turns out to be in the range 60 to 120 amp cm−2 deg−2. Finally, we examine the inﬂuence of a moderately strong electric ﬁeld on the thermionic emission from a metal — the so-called Schottky effect. Denoting the strength of the electric ﬁeld by F and assuming the ﬁeld to be uniform and directed perpendicular to the metal surface, the difference 1 between the potential energy of an electron at a distance x above the surface and of one inside the metal is given by 1(x) = W − eFx − e2 4x (x > 0), (17) where the ﬁrst term arises from the potential well of the metal, the second from the (attrac- tive) ﬁeld present, and the third from the attraction between the departing electron and the “image” induced in the metal; see Figure 8.7. The largest value of the function 1(x) occurs at x = (e/4F)1/2, so that 1max = W − e3/2F 1/2; (18) thus, the ﬁeld has effectively reduced the height of the potential barrier by an amount e3/2F 1/2. A corresponding reduction should take place in the work function as well. 5In light of the numbers quoted here, one can readily see that the quantity e(µ−εz)/kT in equation (8), being at most equal to e(µ0−W )/kT ≡ e−φ/kT , is, at all temperatures of interest, much smaller than unity. This means that we are oper- ating here in the (Maxwellian) tail of the Fermi–Dirac distribution and hence the approximation made in going from equation (8) to equation (9) was justiﬁed. 8.3 The electron gas in metals 255 F x x F 2e 1e FIGURE 8.7 A schematic diagram to illustrate the Schottky effect. Accordingly, the thermionic current density in the presence of the ﬁeld F would be higher than the one in the absence of the ﬁeld: JF = J0 exp(e3/2F 1/2/kT ). (19) A plot of ln( JF /J0) against (F 1/2/T ) should, therefore, be a straight line, with slope e3/2/k. Working along these lines, De Bruyne (1928) obtained for the electronic charge a value of 4.84 × 10−10 e.s.u., which is remarkably close to the actual value of e. The theory of the Schottky effect, as outlined here, holds for ﬁeld strengths up to about 106 volts/cm. For ﬁelds stronger than that, one obtains the so-called cold emission, which means that the electric ﬁeld is now strong enough to make the potential barrier practically ineffective; for details, see Fowler and Nordheim (1928). 8.3.B Photoelectric emission (the Hallwachs effect) The physical situation in the case of photoelectric emission is different from that in the case of thermionic emission, in that there exists now an external agency, the photon in the incoming beam of light, that helps an electron inside the metal in overcoming the potential barrier at the surface. The condition to be satisﬁed by the momentum component pz of an electron in order that it could escape from the metal now becomes (p 2 z /2m) + hν > W , (20)6 where ν is the frequency of the incoming light (assumed monochromatic). Proceeding in the same manner as in the case of thermionic emission, we obtain, instead of (8), R = 4π mkT h3 ∞∫ εz=W −hν dεz ln[1 + e(µ−εz)/kT ]. (21) We cannot, in general, approximate this integral the way we did there; so the integrand here stays as it is. It is advisable, however, to change over to a new variable x, deﬁned by x = (εz − W + hν)/kT , (22) 6In writing this condition, we have tacitly assumed that the momentum components px and py of the electron remain unchanged on the absorption of a photon. 256 Chapter 8. Ideal Fermi Systems whereby equation (21) becomes R = 4πm(kT )2 h3 ∞∫ 0 dx ln [1 + exp { h(ν − ν0) kT − x}] , (23) where hν0 = W − µ ≃ W − εF = φ. (24) The quantity φ will be recognized as the (thermionic) work function of the metal; accord- ingly, the characteristic frequency ν0(= φ/h) may be referred to as the threshold frequency for (photoelectric) emission from the metal concerned. The current density of photoelectric emission is thus given by J = 4πmek2 h3 T 2 ∞∫ 0 dx ln(1 + eδ−x), (25) where δ = h(ν − ν0)/kT . (26) Integrating by parts, we ﬁnd that ∞∫ 0 dx ln(1 + eδ−x) = ∞∫ 0 xdx ex−δ + 1 ≡ f2(eδ); (27) see equation (8.1.6). Accordingly, J = 4π mek2 h3 T 2f2(eδ). (28) For h(ν − ν0) ≫ kT , eδ ≫ 1 and the function f2(eδ) ≈ δ2/2; see Sommerfeld’s lemma (E.17) in Appendix E. Equation (28) then becomes J ≈ 2πme h (ν − ν0) 2, (29) which is completely independent of T ; thus, when the energy of the light quantum is much greater than the work function of the metal, the temperature of the electron gas becomes a “dead” parameter of the problem. At the other extreme, when ν < ν0 and h|ν − ν0| ≫ kT , then eδ ≪ 1 and the function f2(eδ) ≈ eδ. Equation (28) then becomes J ≈ 4πmek2 h3 T 2e(hν−φ)/kT , (30) 8.3 The electron gas in metals 257 which is just the thermionic current density (13), enhanced by the photon factor exp(hν/kT ); in other words, the situation now is very much the same as in the case of thermionic emission, except for a diminished work function φ′(= φ − hν). At the threshold frequency (ν = ν0), δ = 0 and the function f2(eδ) = f2(1) = π 2/12; see equation (E.16), with j = 1. Equation (28) then gives J0 = π 3mek2 3h3 T 2. (31) Figure 8.8 shows a plot of the experimental results for photoelectric emission from palladium (φ = 4.97 eV). The agreement with theory is excellent. It will be noted that the plot includes some observations with ν < ν0. The fact that we obtain a ﬁnite photocur- rent even for frequencies less than the so-called threshold frequency is fully consistent with the model considered here. The reason for this lies in the fact that, at any ﬁnite tem- perature T , there exists in the system a reasonable fraction of electrons whose energy ε exceeds the Fermi energy εF by amounts O(kT ). Therefore, if the light quantum hν gets absorbed by one of these electrons, then condition (20) for photoemission can be satisﬁed even if hν < (W − εF ) = hν0. Of course, the energy difference h(ν0 − ν) must not be much more than a few times kT , for otherwise the availability of the right kind of electrons will be extremely low. We, therefore, do expect a ﬁnite photocurrent for radiation with frequencies less than the threshold frequency ν0, provided that h(ν0 − ν) = O(kT ). The plot shown in Figure 8.8, namely ln( J/T 2) versus δ, is generally known as the “Fowler plot.” Fitting the observed photoelectric data to this plot, one can obtain the characteristic frequency ν0 and hence the work function φ of the given metal. We have previously seen that the work function of a metal can be derived from thermionic data as well. It is gratifying to note that there is complete agreement between the two sets of results obtained for the work function of the various metals. \u000250 0 1 2 3 4 510 20 2515In(J/T2), in arbitrary units 305 K 400 K 830 K 1008 K h(\u0002 \u0002 \u00020)kT FIGURE 8.8 Photoelectric current from palladium as a function of the quantity h(ν − ν0)/kT . The plot includes data taken at several temperatures T for different frequencies ν. 258 Chapter 8. Ideal Fermi Systems 8.4 Ultracold atomic Fermi gases After the demonstration of Bose–Einstein condensation in ultracold atomic gases in 1995 (Section 7.2), researchers began using laser cooling and magnetic traps to cool gases of fermions to create degenerate Fermi gases of atoms. DeMarco and Jin (1999) created the ﬁrst degenerate atomic Fermi gas by cooling a dilute vapor of 40K in an atomic trap into the nanokelvin temperature range. The density of states in a harmonic trap is a quadratic function of the energy: a(ε) = ε2 2 (ℏω0)3 , (1) where ω0 = (ω1ω2ω3)1/3 is the geometric mean of the trap frequencies in the cartesian directions; see equation (7.2.3). The chemical potential and the number of fermions in the trap are related by N(µ, T ) = 1 2 (ℏω0)3 ∞∫ 0 ε2dε eβ(ε−µ) + 1 , (2) which gives for the Fermi energy εF = ℏω0(6N) 1/3 , (3) a Fermi temperature TF = εF /k = 870 nK for 106 atoms in a 100 Hz trap, and a ground-state energy U0 = 3 4 NεF . The internal energy of the trapped gas can be obtained by time-of- ﬂight measurements as described in Section 7.2 and can be directly compared with the theoretical result U U0 = 4 ( T TF )4 ∞∫ 0 x3dx exe−βµ + 1 , (4) where the temperature and the chemical potential are related by 3 ( T TF )3 ∞∫ 0 x2dx exe−βµ + 1 = 1; (5) see Figures 8.9 and 8.10. At low enough temperatures, attractive interactions lead to BEC- BCS condensation, as discussed in Section 11.9. 8.5 Statistical equilibrium of white dwarf stars 259 2 1 0 0.0 0.2 0.4 0.6 T/TFU/U0 0.8 1.0 3 4 FIGURE 8.9 Scaled internal energy (U/U0) versus scaled temperature (T /TF ) for an ideal Fermi gas in a harmonic trap from equations (4) and (5). The dotted line is the corresponding classical result U(T ) = 3NkT . 2.0 1.8 1.6 1.4 1.2 1.0 0.0 0.2 0.4 classical 0.6 0.8 1.0E/3kT T/TF FIGURE 8.10 Experimental results for the mean energy per particle divided by the equipartition value of 3kT versus scaled temperature (T /TF ) for ultracold 40K atoms in a harmonic trap compared to the theoretical Fermi gas value from equations (4) and (5). This shows the development of the Fermi degeneracy of the gas at low temperatures; from Jin (2002). Figure courtesy of the IOP. Reprinted with permission; copyright ©2002, American Institute of Physics. 8.5 Statistical equilibrium of white dwarf stars Historically, the ﬁrst application of Fermi statistics appeared in the ﬁeld of astrophysics (Fowler, 1926). It related to the study of thermodynamic equilibrium of white dwarf stars — the small-sized stars that are abnormally faint for their (white) color. The general pattern of color–brightness relationship among stars is such that, by and large, a star with red color is expected to be a “dull” star, while one with white color is expected to be a “brilliant” star. However, white dwarf stars constitute an exception to this rule. The reason for this lies in the fact that these stars are relatively old whose hydrogen content is more or less used up, 260 Chapter 8. Ideal Fermi Systems with the result that the thermonuclear reactions in them are now proceeding at a rather low pace, thus making these stars a lot less bright than one would expect on the basis of their color. The material content of white dwarf stars, at the present stage of their career, is mostly helium. And whatever little brightness they presently have derives mostly from the gravitational energy released as a result of a slow contraction of these stars — a mechanism ﬁrst proposed by Kelvin, in 1861, as a “possible” source of energy for all stars! A typical, though somewhat idealized, model of a white dwarf star consists of a mass M(∼ 1033g) of helium, packed into a ball of mass density ρ(∼ 107g cm−3), at a central temperature T (∼ 107K). Now, a temperature of the order of 107K corresponds to a mean thermal energy per particle of the order of 103 eV, which is much greater than the energy required for ionizing a helium atom. Thus, practically the whole of the helium in the star exists in a state of complete ionization. The microscopic constituents of the star may, therefore, be taken as N electrons (each of mass m) and 1 2 N helium nuclei (each of mass ≃ 4mp). The mass of the star is then given by M ≃ N(m + 2mp) ≃ 2Nmp (1) and, hence, the electron density by n = N V ≃ M/2mp M/ρ = ρ 2mp . (2) A typical value of the electron density in white dwarf stars would, therefore, be O(1030) electrons per cm3. We thus obtain for the Fermi momentum of the electron gas [see equation (8.1.23), with g = 2] pF = ( 3n 8π )1/3 h = O(10 −17) g cm sec−1, (3) which is rather comparable with the characteristic momentum mc of an electron. The Fermi energy εF of the electron gas will, therefore, be comparable with the rest energy mc2 of an electron, that is, εF = O(106) eV and hence the Fermi temperature TF = O(1010) K. In view of these estimates, we conclude that (i) the dynamics of the electrons in this problem is relativistic, and (ii) the electron gas, though at a temperature large in comparison with terrestrial standards, is, statistically speaking, in a state of (almost) complete degeneracy : (T /TF ) = O(10−3). The second point was fully appreciated, and duly taken into account, by Fowler himself; the ﬁrst one was taken care of later, by Anderson (1928) and by Stoner (1929, 1930). The problem, in full generality, was attacked by Chandrasekhar (1931–1935) to whom the ﬁnal picture of the theory of white dwarf stars is chieﬂy due; for details, see Chandrasekhar (1939), where a complete bibliography of the subject is given. Now, the helium nuclei do not contribute as signiﬁcantly to the dynamics of the prob- lem as do the electrons; in the ﬁrst approximation, therefore, we may neglect the presence of the nuclei in the system. For a similar reason, we may neglect the effect of the radia- tion as well. We may thus consider the electron gas alone. Further, for simplicity, we may assume that the electron gas is uniformly distributed over the body of the star; we are thus 8.5 Statistical equilibrium of white dwarf stars 261 ignoring the spatial variation of the various parameters of the problem — a variation that is physically essential for the very stability of the star! The contention here is that, in spite of neglecting the spatial variation of the parameters involved, we expect that the results obtained here will be correct, at least in a qualitative sense. We study the ground-state properties of a degenerate Fermi gas composed of N relativistic electrons (g = 2). First of all, we have N = 8πV h3 pF∫ 0 p 2dp = 8π V 3h3 p 3 F , (4) which gives pF = ( 3n 8π )1/3 h. (5) The energy–momentum relation for a relativistic particle is ε = mc2[{1 + (p/mc) 2}1/2 − 1], (6) the speed of the particle being u ≡ dε dp = (p/m) {1 + (p/mc)2}1/2 ; (7) here, m denotes the rest mass of the electron. The pressure P0 of the gas is then given by, see equation (6.4.3), P0 = 1 3 N V ⟨pu⟩0 = 8π 3h3 pF∫ 0 (p2/m) {1 + (p/mc)2}1/2 p 2dp. (8) We now introduce a dimensionless variable θ, deﬁned by p = mc sinh θ , (9) which makes u = c tanh θ . (10) Equations (4) and (8) then become N = 8π Vm3c3 3h3 sinh 3 θF = 8πVm3c3 3h3 x3 (11) and P0 = 8πm4c5 3h3 θF∫ 0 sinh 4 θ dθ = π m4c5 3h3 A(x), (12) 262 Chapter 8. Ideal Fermi Systems where A(x) = x(x2 + 1) 1/2(2x2 − 3) + 3 sinh−1 x, (13) with x = sinh θF = pF /mc = (3n/8π) 1/3(h/mc). (14) The function A(x) can be computed for any desired value of x. However, asymptotic results for x ≪ 1 and x ≫ 1 are often useful; these are given by (see Kothari and Singh, 1942) A(x) = 8 5 x5 − 4 7 x7 + 1 3 x9 − 5 22 x11 + · · · for x ≪ 1 = 2x4 − 2x2 + 3(ln 2x − 7 12 ) + 5 4 x−2 + · · · for x ≫ 1    . (15) We shall now consider, somewhat crudely, the equilibrium conﬁguration of this model. In the absence of gravitation, it would be necessary to have “external walls” for keeping the electron gas at a given density n. The gas will exert a pressure P0(n) on the walls and any compression or expansion (of the gas) will involve an expenditure of work. Assuming the conﬁguration to be spherical, an adiabatic change in V will cause a change in the energy of the gas, as given by dE0 = −P0(n)dV = −P0(R) · 4πR2dR. (16) In the presence of gravitation, no external walls are needed, but the change in the kinetic energy of the gas, as a result of a change in the size of the sphere, will still be given by for- mula (16); of course, the expression for P0, as a function of the “mean” density n, must now take into account the nonuniformity of the system — a fact being disregarded in the present simple-minded treatment. However, equation (16) alone no longer gives us the net change in the energy of the system; if that were the case, the system would expand indeﬁ- nitely till both n and P0(n) → 0. Actually, we have now a change in the potential energy as well; this is given by dEg = ( dEg dR ) dR = α GM 2 R2 dR, (17) where M is the total mass of the gas, G the constant of gravitation, while α is a number (of the order of unity) whose exact value depends on the nature of the spatial variation of n inside the sphere. If the system is in equilibrium, then the net change in its total energy (E0 + Eg ), for an inﬁnitesimal change in its size, should be zero; thus, for equilibrium, P0(R) = α 4π GM 2 R4 . (18) 8.5 Statistical equilibrium of white dwarf stars 263 For P0(R), we may substitute from equation (12), where the parameter x is now given by x = ( 3n 8π )1/3 h mc = ( 9N 32π 2 )1/3 h/mc R or, in view of (1), by x = ( 9M 64π 2mp )1/3 h/mc R = ( 9πM 8mp )1/3 ℏ/mc R . (19) Equation (18) then takes the form A ({ 9π M 8mp }1/3 ℏ/mc R ) = 3αh3 4π 2m4c5 GM 2 R4 = 6πα ( ℏ/mc R )3 GM 2/R mc2 ; (20) the function A(x) is given by equations (13) and (15). Equation (20) establishes a one-to-one correspondence between the masses M and the radii R of white dwarf stars; it is, therefore, known as the mass–radius relationship for these stars. It is rather interesting to see the combinations of parameters that appear in this relationship; we have here (i) the mass of the star in terms of the proton mass, (ii) the radius of the star in terms of the Compton wavelength of the electron, and (iii) the grav- itational energy of the star in terms of the rest energy of the electron. This relationship, therefore, exhibits a remarkable blending of quantum mechanics, special relativity, and gravitation. In view of the implicit character of relationship (20), we cannot express the radius of the star as an explicit function of its mass, except in two extreme cases. For this, we note that, since M ∼ 1033g, mp ∼ 10−24g, and ℏ/mc ∼ 10−11 cm, the argument of the function A(x) will be of the order of unity when R ∼ 108 cm. We may, therefore, deﬁne the two extreme cases as follows: (i) R ≫ 108 cm, which makes x ≪ 1 and hence A(x) ≈ 8 5 x5, with the result R ≈ 3(9π)2/3 40α ℏ2M −1/3 Gmm5/3 p ∝ M −1/3. (21) (ii) R ≪ 108 cm, which makes x ≫ 1 and hence A(x) ≈ 2x4 − 2x2, with the result R ≈ (9π)1/3 2 ℏ mc ( M mp )1/3 { 1 − ( M M0 )2/3}1/2 , (22) 264 Chapter 8. Ideal Fermi Systems where M0 = 9 64 ( 3π α3 )1/2 (ℏc/G)3/2 m2 p . (23) We thus ﬁnd that the greater the mass of the white dwarf star, the smaller its size. Not only that, there exists a limiting mass M0, given by expression (23), that corresponds to a vanishing size of the star. Obviously, for M > M0, our mass–radius relationship does not possess any real solution. We, therefore, conclude that all white dwarf stars in equilibrium must have a mass less than M0 — a conclusion fully upheld by observation. The correct limiting mass of a white dwarf star is generally referred to as the Chandrasekhar limit. The physical reason for the existence of this limit is that for a mass exceeding this limit the ground-state pressure of the electron gas (that arises from the fact that the electrons obey the Pauli exclusion principle) would not be sufﬁcient to support the star against its “tendency toward a gravitational collapse.” The numerical value of the limiting mass, as given by expression (23), turns out to be ∼ 1033g. Detailed investigations by Chandrasekhar led to the result: M0 = 5.75 µ2 e ⊙, (24) where ⊙ denotes the mass of the sun, which is about 2 × 1033g, while µe is a number that represents the degree of ionization of helium in the gas. By deﬁnition, µe = M/NmH ; compare to equation (1). Thus, in most cases, µe ≃ 2; accordingly M0 ≃ 1.44⊙. Figure 8.11 shows a plot of the theoretical relationship between the masses and the radii of white dwarf stars. One can see that the behavior in the two extreme regions, namely for R ≫ l and R ≪ l, is described quite well by formulae (21) and (22) of the treatment given here. The Chandrasekhar limit (24) is the mechanism responsible for stellar collapse into neutron stars and black holes. In particular, white dwarf stars whose mass exceeds the Chandrasekhar limit due to inﬂux of matter from a companion binary star are thought to be the primary mechanism for type Ia supernovae; see Hillebrandt and Niemeyer (2000). Such events happen in a typical galaxy on the order of once per hundred years. For a few days after the collapse and subsequent explosion, these supernovae can be comparable in brightness to the remainder of the stars in the galaxy combined. Their well-calibrated light curves provide a bright “standard candle” for determining the distance to remote galaxies used to measure the expansion rate of the universe; see Chapter 9. 8.6 Statistical model of the atom Another application of the Fermi statistics was made by Thomas (1927) and Fermi (1928) for calculating the charge distribution and the electric ﬁeld in the extra-nuclear space of a heavy atom. Their approach was based on the observation that the electrons in this sys- tem could be regarded as a completely degenerate Fermi gas of nonuniform density n(r). 8.6 Statistical model of the atom 265 M /M0 0 0.5 1.0 2.0 3.0 4.0 5.0 1.5 2.5 3.5 4.5 5.5 0.1 0.2 0.3 0.4 0.5 0.6 0.8 0.9 1.00.7R/ FIGURE 8.11 The mass–radius relationship for white dwarfs (after Chandrasekhar, 1939). The masses are expressed in terms of the limiting mass M0 and the radii in terms of a characteristic length l, which is given by 7.71µ−1 e × 108cm ≃ 3.86 × 108 cm. By considering the equilibrium state of the conﬁguration, one arrives at a differential equa- tion whose solution gives directly the electric potential φ(r) and the electron density n(r) at point r. By the very nature of the model, which is generally referred to as the Thomas– Fermi model of the atom, the resulting function n(r) is a smoothly varying function of r, devoid of the “peaks” that would remind one of the electron orbits of the Bohr theory. Nevertheless, the model has proved quite useful in deriving composite properties such as the binding energy of the atom. And, after suitable modiﬁcations, it has been success- fully applied to molecules, solids, and nuclei as well. Here, we propose to outline only the simplest treatment of the model, as applied to an atomic system; for further details and other applications, see Gomb´as (1949, 1952) and March (1957), where references to other contributions to the subject can also be found. According to the statistics of a completely degenerate Fermi gas, we have exactly two electrons (with opposite spins) in each elementary cell of the phase space, with p ≤ pF ; the Fermi momentum pF of the electron gas is determined by the electron density n, according to the formula pF = (3π 2n) 1/3ℏ. (1) In the system under study, the electron density varies from point to point; so would the value of pF . We must, therefore, speak of the limiting momentum pF as a function of r, which is clearly a “quasiclassical” description of the situation. Such a description is jus- tiﬁable if the de Broglie wavelength of the electrons in a given region of space is much 266 Chapter 8. Ideal Fermi Systems smaller than the distance over which the functions pF (r), n(r), and φ(r) undergo a signiﬁ- cant variation; later on, it will be seen that this requirement is satisﬁed reasonably well by the heavier atoms. Now, the total energy ε of an electron at the top of the Fermi sea at the point r is given by ε(r) = 1 2m p 2 F (r) − eφ(r), (2) where e denotes the magnitude of the electronic charge. When the system is in a stationary state, the value of ε(r) should be the same throughout, so that electrons anywhere in the system do not have an overall tendency to “ﬂow away” toward other parts of the system. Now, at the boundary of the system, pF must be zero; by a suitable choice of the zero of energy, we can also have φ = 0 there. Thus, the value of ε at the boundary of the system is zero; so must, then, be the value of ε throughout the system. We thus have, for all r, 1 2m p 2 F (r) − eφ(r) = 0. (3) Substituting from (1) and making use of the Poisson equation, ∇2φ(r) = −4πρ(r) = 4π en(r), (4) we obtain ∇2φ(r) = 4e(2me)3/2 3πℏ3 {φ(r)}3/2. (5) Assuming spherical symmetry, equation (5) takes the form 1 r2 d dr {r2 d dr φ(r) } = 4e(2me)3/2 3πℏ3 {φ(r)}3/2, (6) which is known as the Thomas–Fermi equation of the system. Introducing dimensionless variables x and 8, deﬁned by x = 2 ( 4 3π )2/3 Z 1/3 me2 ℏ2 r = Z 1/3 0.88534aB r (7) and 8(x) = φ(r) Ze/r , (8) where Z is the atomic number of the system and aB the ﬁrst Bohr radius of the hydrogen atom, equation (6) reduces to d28 dx2 = 83/2 x1/2 . (9) 8.6 Statistical model of the atom 267 Equation (9) is the dimensionless Thomas–Fermi equation of the system. The boundary conditions on the solution to this equation can be obtained as follows. As we approach the nucleus of the system (r → 0), the potential φ(r) approaches the unscreened value Ze/r; accordingly, we must have: 8(x → 0) = 1. On the other hand, as we approach the bound- ary of the system (r → r0), φ(r) in the case of a neutral atom must tend to zero; accordingly, we must have: 8(x → x0) = 0. In principle, these two conditions are sufﬁcient to determine the function 8(x) completely. However, it would be helpful if one knew the initial slope of the function as well, which in turn would depend on the precise location of the boundary. Choosing the boundary to be at inﬁnity (r0 = ∞), the appropriate initial slope of the func- tion 8(x) turns out to be very nearly −1.5886; in fact, the nature of the solution near the origin is 8(x) = 1 − 1.5886x + 4 3 x3/2 + · · · (10) For x > 10, the approximate solution has been determined by Sommerfeld (1932): 8(x) ≈   1 + ( x3 144 )λ   −1/λ , (11) where λ = √ (73) − 7 6 ≃ 0.257. (12) As x → ∞, the solution tends to the simple form: 8(x) ≈ 144/x3. The complete solution, which is a monotonically decreasing function of x, has been tabulated by Bush and Cald- well (1931). As a check on the numerical results, we note that the solution must satisfy the integral condition ∞∫ 0 8 3/2x1/2dx = 1, (13) which expresses the fact that the integral of the electron density n(r) over the whole of the space available to the system must be equal to Z, the total number of electrons present. From the function 8(x), one readily obtains the electric potential φ(r) and the electron density n(r): φ(r) = Ze r 8 ( rZ 1/3 0.88534aB ) ∝ Z 4/3 (14) and n(r) = (2me)3/2 3π 2ℏ3 {φ(r)}3/2 ∝ Z 2. (15) 268 Chapter 8. Ideal Fermi Systems 140 120 100 80 60 40 20 0.2 0.4 0.6 0.8 r /aD(r) FIGURE 8.12 The electron distribution function D(r) for an atom of mercury. The distance r is expressed in terms of the atomic unit of length a (= ℏ2/me2). A Thomas–Fermi plot of the electron distribution function D(r){= n(r) · 4π r2} for an atom of mercury is shown in Figure 8.12; the actual “peaked” distribution, which conveys unmis- takably the preference of the electrons to be in the vicinity of their semiclassical orbits, is also shown in the ﬁgure. To calculate the binding energy of the atom, we should determine the total energy of the electron cloud. Now, the mean kinetic energy of an electron at the point r would be 3 5 εF (r); by equation (3), this is equal to 3 5 eφ(r). The total kinetic energy of the electron cloud is, therefore, given by 3 5 e ∞∫ 0 φ(r)n(r) · 4πr2dr. (16) For the potential energy of the cloud, we note that a part of the potential φ(r) at the point r is due to the nucleus of the atom while the rest of it is due to the electron cloud itself; the former is clearly (Ze/r), so the latter must be {φ(r) − Ze/r}. The total potential energy of the cloud is, therefore, given by −e ∞∫ 0 [ Ze r + 1 2 { φ(r) − Ze r }] n(r) · 4πr2dr. (17) We thus obtain for the total energy of the cloud E0 = ∞∫ 0 { 1 10 eφ(r) − 1 2 Ze2 r } n(r) · 4πr2dr; (18) Problems 269 of course, the electron density n(r), in terms of the potential function φ(r), is given by equation (15). Now, Milne (1927) has shown that the integrals ∞∫ 0 {φ(r)} 5/2r2dr and ∞∫ 0 {φ(r)} 3/2rdr, (19) which appear in the expression for E0, can be expressed directly in terms of the initial slope of the function 8(x), that is, in terms of the number −1.5886 of equation (10). After a little calculus, one ﬁnds that E0 = 1.5886 0.88534 ( e2 2aB ) Z 7/3 ( 1 7 − 1 ) , (20) from which one obtains for the (Thomas–Fermi) binding energy of the atom: EB = −E0 = 1.538Z 7/3χ , (21) where χ(= e2/2aB ≃ 13.6 eV) is the (actual) binding energy of the hydrogen atom. It is clear that our statistical result (21) cannot give us anything more than just the ﬁrst term of an “asymptotic expansion” of the binding energy EB in powers of the parameter Z −1/3. For practical values of Z, other terms of the expansion are also important; however, they cannot be obtained from the simple-minded treatment given here. The interested reader may refer to the review article by March (1957). In the end we observe that, since the total energy of the electron cloud is proportional to Z 7/3, the mean energy per electron would be proportional to Z 4/3; accordingly, the mean de Broglie wavelength of the electrons in the cloud would be proportional to Z −2/3. At the same time, the overall linear dimensions of the cloud are proportional to Z −1/3; see equation (7). We thus ﬁnd that the quasiclassical description adopted in the Thomas– Fermi model is more appropriate for heavier atoms (so that Z −2/3 ≪ Z −1/3). Otherwise, too, the statistical nature of the approach demands that the number of particles in the system be large. Problems 8.1 Let the Fermi distribution at low temperatures be represented by a broken line, as shown in Figure 8.13, the line being tangential to the actual curve at ε = µ. Show that this approximate representation yields a “correct” result for the low-temperature speciﬁc heat of the Fermi gas, except that the numerical factor turns out to be smaller by a factor of 4/π 2. Discuss, in a qualitative manner, the origin of this numerical discrepancy. 8.2 For a Fermi–Dirac gas, we may deﬁne a temperature T0 at which the chemical potential of the gas is zero (z = 1). Express T0 in terms of the Fermi temperature TF of the gas. [Hint: Use equation (E.16).] 270 Chapter 8. Ideal Fermi Systems 1.0 0.5 0 0 \u0002 2 4 \u0002 2 2 \u0002 1 2 \u0002 1 4\u0002 x(ex2\u000211)21 FIGURE 8.13 An approximate representation of the Fermi distribution at low temperatures: here, x = ε/kT and ξ = µ/kT . 8.3 Show that for an ideal Fermi gas 1 z ( ∂z ∂T ) P = − 5 2T f5/2(z) f3/2(z) ; compare with equation (8.1.9). Hence show that γ ≡ CP CV = (∂z/∂T )P (∂z/∂T )v = 5 3 f5/2(z)f1/2(z) { f3/2(z)}2 . Check that at low temperatures γ ≃ 1 + π 2 3 ( kT εF )2 . 8.4 (a) Show that the isothermal compressibility κT and the adiabatic compressibility κS of an ideal Fermi gas are given by κT = 1 nkT f1/2(z) f3/2(z) , κS = 3 5nkT f3/2(z) f5/2(z) , where n (= N/V ) is the particle density in the gas. Check that at low temperatures κT ≃ 3 2nεF [ 1 − π 2 12 ( kT εF )2] , κS ≃ 3 2nεF [ 1 − 5π 2 12 ( kT εF )2] . (b) Making use of the thermodynamic relation CP − CV = T ( ∂P ∂T ) V ( ∂V ∂T ) P = TV κT ( ∂P ∂T )2 V , show that CP − CV CV = 4 9 CV Nk f1/2(z) f3/2(z) ≃ π 2 3 ( kT εF )2 (kT ≪ εF ). Problems 271 (c) Finally, making use of the thermodynamic relation γ = κT /κS, verify the results of Problem 8.3. 8.5 Evaluate (∂ 2P/∂T 2)v, (∂ 2µ/∂T 2)v, and (∂ 2µ/∂T 2)P of an ideal Fermi gas and check that your results satisfy the thermodynamic relations CV = VT ( ∂ 2P ∂T 2 ) v − NT ( ∂ 2µ ∂T 2 ) v and CP = −NT ( ∂ 2µ ∂T 2 ) P . Examine the low-temperature behavior of these quantities. 8.6 Show that the velocity of sound w in an ideal Fermi gas is given by w2 = 5kT 3m f5/2(z) f3/2(z) = 5 9 ⟨u2⟩, where ⟨u2⟩ is the mean square speed of the particles in the gas. Evaluate w in the limit z → ∞ and compare it with the Fermi velocity uF . 8.7 Show that for an ideal Fermi gas ⟨u⟩ 〈 1 u 〉 = 4 π f1(z)f2(z) { f3/2(z)}2 , u being the speed of a particle. Further show that at low temperatures ⟨u⟩ 〈 1 u 〉 ≃ 9 8 [ 1 + π 2 12 ( kT εF )2] ; compare with Problem 6.6. 8.8 Obtain numerical estimates of the Fermi energy (in eV) and the Fermi temperature (in K) for the following systems: (a) conduction electrons in silver, lead, and aluminum; (b) nucleons in a heavy nucleus, such as 80Hg 200, and (c) He3 atoms in liquid helium-3 (atomic volume: 63 ˚A3 per atom). 8.9 Making use of another term of the Sommerfeld lemma (E.17), show that in the second approximation the chemical potential of a Fermi gas at low temperatures is given by µ ≃ εF [ 1 − π 2 12 ( kT εF )2 − π 4 80 ( kT εF )4] , (8.1.35a) and the mean energy per particle by U N ≃ 3 5 εF [ 1 + 5π 2 12 ( kT εF )2 − π 4 16 ( kT εF )4] . (8.1.37a) Hence determine the T 3-correction to the customary T 1-result for the speciﬁc heat of an electron gas. Compare the magnitude of the T 3-term, in a typical metal such as copper, with the low- temperature speciﬁc heat arising from the Debye modes of the lattice. For further terms of these expansions, see Kiess (1987). 272 Chapter 8. Ideal Fermi Systems 8.10 Consider an ideal Fermi gas, with energy spectrum ε ∝ ps, contained in a box of “volume” V in a space of n dimensions. Show that, for this system, (a) PV = s n U; (b) CV Nk = n s ( n s + 1 ) f(n/s)+1(z) fn/s(z) − ( n s )2 fn/s(z) f(n/s)−1(z) ; (c) CP − CV Nk = ( sCV nNk )2 f(n/s)−1(z) f(n/s)(z) ; (d) the equation of an adiabat is PV 1+(s/n) = const., and (e) the index (1 + (s/n)) in the foregoing equation agrees with the ratio (CP/CV ) of the gas only when T ≫ TF . On the other hand, when T ≪ TF , the ratio (CP/CV ) ≃ 1 + (π 2/3)(kT /εF )2, irrespective of the values of s and n. 8.11 Examine results (b) and (c) of the preceding problem in the high-temperature limit (T ≫ TF ) as well as in the low-temperature limit (T ≪ TF ), and compare the resulting expressions with the ones pertaining to a nonrelativistic gas and an extreme relativistic gas in three dimensions. 8.12 Show that, in two dimensions, the speciﬁc heat CV (N, T ) of an ideal Fermi gas is identical to the speciﬁc heat of an ideal Bose gas, for all N and T . [Hint: It will sufﬁce to show that, for given N and T , the thermal energies of the two systems differ at most by a constant. For this, ﬁrst show that the fugacities, zF and zB, of the two systems are mutually related: (1 + zF )(1 − zB) = 1, i.e., zB = zF /(1 + zF ). Next, show that the functions f2(zF ) and g2(zB) are also related: f2(zF ) = zF∫ 0 ln(1 + z) z dz = g2 ( zF 1 + zF ) + 1 2 ln 2(1 + zF ). It is now straightforward to show that EF (N, T ) = EB(N, T ) + const., the constant being EF (N, 0).] 8.13 Show that, quite generally, the low-temperature behavior of the chemical potential, the speciﬁc heat, and the entropy of an ideal Fermi gas is given by µ ≃ εF [ 1 − π 2 6 ( ∂ ln a(ε) ∂ ln ε ) ε=εF ( kT εF )2] , and CV ≃ S ≃ π 2 3 k2T a(εF ), where a(ε) is the density of (the single-particle) states in the system. Examine these results for a gas with energy spectrum ε ∝ ps, conﬁned to a space of n dimensions, and discuss the special cases: s = 1 and 2, with n = 2 and 3. [Hint: Use equation (E.18) from Appendix E.] 8.14 Investigate the Pauli paramagnetism of an ideal gas of fermions with intrinsic magnetic moment µ∗ and spin Jℏ( J = 1 2 , 3 2 , . . .), and derive expressions for the low-temperature and high-temperature susceptibilities of the gas. Problems 273 8.15 Show that expression (8.2.20) for the paramagnetic susceptibility of an ideal Fermi gas can be written in the form χ = nµ∗2 kT f1/2(z) f3/2(z) . Using this result, verify equations (8.2.24) and (8.2.27). 8.16 The observed value of γ , see equation (8.3.6), for sodium is 4.3 × 10−4 cal mole −1K−2. Evaluate the Fermi energy εF and the number density n of the conduction electrons in the sodium metal. Compare the latter result with the number density of atoms (given that, for sodium, ρ = 0.954 g cm−3 and M = 23). 8.17 Calculate the fraction of the conduction electrons in tungsten (εF = 9.0 eV) at 3000 K whose kinetic energy ε (= 1 2 mu2) is greater than W (= 13.5 eV). Also calculate the fraction of the electrons whose kinetic energy associated with the z-component of their motion, namely ( 1 2 mu2 z ), is greater than 13.5 eV. 8.18 Show that the ground-state energy E0 of a relativistic gas of electrons is given by E0 = π Vm4c5 3h3 B(x), where B(x) = 8x3{(x2 + 1) 1/2 − 1} − A(x), A(x) and x being given by equations (8.5.13) and (8.5.14). Check that the foregoing result for E0 and equation (8.5.12) for P0 satisfy the thermodynamic relations E0 + P0V = Nµ0 and P0 = −(∂E0/∂V )N . 8.19 Show that the low-temperature speciﬁc heat of the relativisitic Fermi gas, studied in Section 8.5, is given by CV Nk = π 2 (x2 + 1)1/2 x2 kT mc2 ( x = pF mc ) . Check that this formula gives correct results for the nonrelativistic case as well as for the extreme relativistic one. 8.20 Express the integrals (8.6.19) in terms of the initial slope of the function 8(x), and verify equation (8.6.20). 8.21 The total energy E of the electron cloud in an atom can be written as E = K + Vne + Vee, where K is the kinetic energy of the electrons, Vne the interaction energy between the electrons and the nucleus, and Vee the mutual interaction energy of the electrons. Show that, according to the Thomas–Fermi model of a neutral atom, K = −E, Vne = + 7 3 E, and Vee = − 1 3 E, so that total V = Vne + Vee = 2E. Note that these results are consistent with the virial theorem; see Problem 3.20, with n = −1. 8.22 Derive equations (8.4.3) through (8.4.5) for a Fermi gas in a harmonic trap. Evaluate equations (8.3.4) and (8.3.5) numerically to reproduce the theoretical curves shown in Figures 8.9 and 8.10. 9 Thermodynamics of the Early Universe Over the course of the twentieth century, astronomers and astrophysicists gathered a vast body of evidence that indicates the universe began abruptly 13.75 ± 0.11 billion years ago in what became known as the “Big Bang.” 1,2 The intense study of the origin and evolution of the universe has led to a convergence of physics and astrophysics. Thermodynamics and statistical mechanics play a crucial role in our understanding of the sequence of transi- tions that the universe went though shortly after the Big Bang. These transitions left behind mileposts that astrophysicists have exploited to look back into the earliest moments of the universe. The early universe provides particularly good examples for utilizing the proper- ties of ideal classical, Bose, and Fermi gases developed in Chapters 6, 7, and 8, and the theory of chemical equilibrium developed in Section 6.6. 9.1 Observational evidence of the Big Bang Observational evidence of the Big Bang has grown steadily since Edwin Hubble’s discovery in the late 1920s that the universe was expanding. Since that time a coherent standard model for the beginning of the universe has emerged. The following three items describe the key bodies of evidence. 1. Nearly every galaxy in the universe is moving away from every other galaxy and the recessional velocities display an almost linear dependence on the distance between galaxies; see Figure 9.1. Hubble was the ﬁrst to observe this by measuring both the distances to nearby galaxies and their velocities relative to our own galaxy. The former is based on standard candles, in Hubble’s case Cepheid variable stars with known absolute mean luminosity. The latter is based on measurements of the Doppler red shift of spectral lines. Type Ia supernovae are used as the standard candle in the most distant observations made using the Hubble Space Telescope. The data are 1For excellent overviews and history of the study of the Big Bang, see The First Three Minutes: A Modern View of the Origin of the Universe by Weinberg (1993) and The Big Bang by Singh (2005). Cosmology by Weinberg (2008) provides an excellent technical survey. The organization of this chapter is based on Weinberg (1993). The 2010 decadal survey of astrophysics New Worlds, New Horizons in Astronomy and Astrophysics by the National Academies Press provides an overview of the current state of the ﬁeld; see www.nap.edu. 2Steady state cosmology advocate Fred Hoyle coined the term “Big Bang” derisively in a BBC radio broadcast in 1950. To his eternal dismay, the name quickly became popular. Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00009-8 © 2011 Elsevier Ltd. All rights reserved. 275 276 Chapter 9. Thermodynamics of the Early Universe 3 \u0002104 H0 \u0003 72H0(km/s/Mpc)Velocity (km/s) v \u0004 5,000 km/s 2 \u0002104 79 I-band Tully–Fisher Fundamental plane Surface brightness Supernovae Ia Supernovae II 72 65 104 0 100 80 60 40 0 100 200 Distance (Mpc) 300 400 FIGURE 9.1 Hubble diagram of the spectral red-shift velocity of relatively nearby galaxies versus their distance using several astronomical standard candles. The velocity is in km/s and the distance is measured in megaparsecs, where 1 Mpc = 3.26 × 106 light-years. The best ﬁt to the data gives a value of the Hubble parameter as H0 = 72 ± 8 km s−1Mpc−1. The Hubble parameter has been recently updated by Riess et al. (2009) to give H0 = 74.2 ± 3.6 km s−1 Mpc−1. The ﬁgure is from Freedman et al. (2001) and is reproduced by permission of the AAS. encapsulated in the Hubble–Friedmann relation (Friedmann, 1922, 1924), v = da dt = Ha = √ 8πGu 3c2 a. (1) Here a represents the distance between any two points in space that grows with time as the universe expands, v is the recessional velocity, G is the universal constant of gravitation, c is the speed of light, and u is the energy density of the universe.3 The Hubble parameter, H, is the characteristic expansion rate and is of the order of the inverse of the age of the universe. The particular form of equation (1) assumes, as appears to be the case, that the energy density u is equal to the critical value so that the 3Cosmological and general relativistic calculations are usually expressed in terms of the equivalent mass density ρ = u/c2 = T 00 where T is the energy-momentum tensor. Astrophysicists usually describe the length scale parameter a in terms of the Doppler shift factor z = (λ/λlab − 1), where λlab is the laboratory wavelength of a spectral line and λ is the red-shifted value. This gives z = (T /T0 − 1) where T0 is the current cosmic microwave background temperature and T is the photon temperature of that era. For example, the Doppler shift from the era of last scattering is z = 3000 K 2.725 K − 1 ≃ 1100, so the universe has expanded by a factor of 1100 since that time. 9.1 Observational evidence of the Big Bang 277 space-time is ﬂat. This means that the universe is balanced on a knife edge between expanding forever and recollapsing due to gravity. For excellent technical surveys, see B¨orner (2003) and Weinberg (2008). The measured value of the Hubble parameter is H0 = 74.2 ± 3.6 km s−1 Mpc −1, (2) where Mpc is a megaparsec, about 3.26 × 106 light-years; see Freedman et al. (2001) and Riess et al. (2009). 2. Penzias and Wilson (1965) observed a nearly uniform and isotropically distributed microwave radiation noise coming from deep space with a blackbody temperature of about 3 K. This cosmic microwave background (CMB) was quickly identiﬁed as the remnant blackbody radiation from the era following the Big Bang. Later, balloon experiments and space-based measurements by the Cosmic Background Explorer (COBE) NASA mission showed that the CMB is extremely uniform and isotropic with an average temperature of TCMB = 2.725 ± 0.002 K; see Mather et al. (1994, 1999), Wright et al. (1994), Fixsen et al. (1996), and Figure 9.2. The NASA Wilkinson Microwave Anisotropy Probe (WMAP) mission mapped the angular variation of the CMB temperature. Figure 9.3 shows the ±200 µK CMB temperature variations mapped onto galactic coordinates. The CMB represents the photons that were in thermal equilibrium with the high-temperature plasma that existed from the very ﬁrst moments of the universe until it cooled down to approximately 3000 K about 380,000 years after the Big Bang. 1.0 0.8 0.6 0.4 0.2Intensity, 10\u00024ergs/cm2sr sec cm\u00021 0.005 10 Wavenumber, cm\u0002115 20 1.2 FIGURE 9.2 Cosmic microwave background spectrum from COBE ﬁt numerically to the Planck distribution with an average temperature T = 2.725 ± 0.002 K; see equations (7.3.8) and (7.3.9), and Figure 7.13. The error bars at the 43 equally spaced frequencies from the Far Infrared Absolute Spectrophotometer (FIRAS) data are too small to be seen on this scale. Figure courtesy of NASA. 278 Chapter 9. Thermodynamics of the Early Universe FIGURE 9.3 Measurement of temperature variations in the CMB using 7 years of data from WMAP. This shows the distribution of the CMB blackbody temperature mapped onto galactic coordinates. The variations represent temperature ﬂuctuations of ±200 µK. Figure courtesy of NASA and the WMAP Science Team. As the temperature fell below 3000 K, the electrons and protons in the plasma combined for the ﬁrst time into neutral hydrogen atoms, a period that is known rather oxymoronically as the era of recombination. After this era of “last scattering” of photons by free electrons, the quantum structure of the atoms prevented them from absorbing radiation except at their narrow spectral frequencies, so the universe became transparent and the blackbody radiation quickly fell out of equilibrium with the neutral atoms. As the universe continued to expand, the wavelengths of the blackbody radiation grew linearly with the expansion scale of the universe a. The photon number density fell as a−3 and the energy density as a−4, so the Planck distribution, equations (7.3.8) and (7.3.9), was preserved with a blackbody temperature that scaled as T (t)a(t) = const. (3) Measurements of the Hubble parameter and the COBE and WMAP measurements of the temperature and temperature ﬂuctuations of the CMB allow a determination of the current total energy density of the universe and its composition. The current energy density of the universe is u = 3c2H 2 0 8π G = 8.36 × 10 −10 J m−3, (4) 9.1 Observational evidence of the Big Bang 279 and is comprised of approximately 72.8 percent dark energy, 22.7 percent dark matter, and 4.56 percent baryonic matter (protons and neutrons).4 This gives a baryon number density nB of 0.26 m−3. The number density of photons in a blackbody enclosure as a function of temperature is given by equation (7.3.23): nγ (T ) = 2ζ (3) π 2 ( kT ℏc )3 . (5) At the current temperature of 2.725 K, this gives a CMB photon number density of nγ = 4.10 × 108 m−3, so the current baryon-to-photon ratio is η = nB nγ ≈ 6 × 10−10. (6) The ratio η has remained constant as the universe has expanded since both these quantities scale as a−3(t). As we will see later, the numerical value of η played a very important role in the thermal evolution of the early universe.5 3. The relative abundances of the light elements 1H, 2H, 3He, 4He, 7Li, and so on created during the ﬁrst few minutes of the universe are sensitive functions of the baryon-to-photon ratio η; see Figure 9.4. This connection was ﬁrst explored by George Gamow, Ralph Alpher, and Robert Herman in the late 1940s and early 1950s; see Alpher, Bethe, and Gamow (1948), and Alpher and Herman (1948, 1950).6 4The energy content of the universe is parameterized in terms of the fraction of the critical density contained in the various constituents. The current values are dark energy: \u00003 = 0.728 ± 0.016; baryonic matter: \u0000b = 0.0456 ± 0.0016; and cold dark matter: \u0000c = 0.227 ± 0.014. The current age of the universe, or lookback time, is t0 = 13.75 ± 0.11 × 109 years. The relative contribution from blackbody radiation is about 6 × 10−5. These concordance values of the parameters are based on WMAP 7-year data and are tabulated in Komatsu et al. (2010). The dark energy is responsible for the accelerating expansion of the universe. The energy density proportions were vastly different in the early universe because they scale differently with the expansion parameter a. At the time of recombination, the proportions were: dark matter 63 percent, baryonic matter 12 percent, relativistic radiation (photons and neutrinos) 25 percent. During the ﬁrst few moments, relativistic particles provided the dominant contribution to the energy. Using the photon:neutrino:electron ratios of 2 : 21/4 : 7/2 from Table 9.2, the energy content was photons 18.6 percent, neutrinos and antineutrinos 48.8 percent, and electrons and positrons 32.5 percent. While dark energy is currently the dominant contribution to the energy density of the universe, it played only a small role in the early evolution of the universe. Cold dark matter was crucial for the development of the ﬁrst stars and galaxies at the end of the “dark ages” 100 to 200 million years after the last scattering. 5The proper measure here is the ratio of the baryon number density to photon entropy density but, since the CMB photon entropy density and number density both scale as T 3, the ratio is usually quoted in terms of the ratio of the number densities. 6George Gamow and Ralph Alpher in 1948, and Alpher and Robert Herman in 1950, proposed a model for nucleo- synthesis in a hot, expanding primordial soup of protons, neutrons, and electrons. Alpher and Gamow called this material “ylem.” To account for the present abundance of 4He in the universe, Alpher and Herman (1950) proposed a baryon-to-photon ratio of roughly 10−9 and predicted a current cosmic microwave background temperature of about 5 K. Gamow added his friend Hans Bethe’s name as second author to Alpher, Bethe, and Gamow (1948) as a pun on the Greek alphabet. The paper was published, perhaps not coincidentally, on April 1; see Alpher and Herman (2001), Weinberg (1993), and Singh (2005). 280 Chapter 9. Thermodynamics of the Early Universe 1AbundancesCritical density forH0=65 km/s/Mpc 0.1 10 \u00021 10\u00022 10\u00023 10\u00024 10\u00025 10\u00026 10\u00027 10\u00028 10\u00029 10\u000210 10\u000232 10\u000231 10\u000230 \u0002B (g cm\u00023) 10\u000229 0.010.001 \u0003Bh 2 7Li 3He 4He D FIGURE 9.4 Calculated primordial abundances of light elements (4He, D=2H, 3He, and 7Li) as functions of the baryon-to-photon ratio. The baryon-to-photon ratio is given by η = 2.7 × 10−8\u0000bh2, where h is the Hubble parameter in units of 100(km/s)/Mpc and \u0000b = 0.046 is the current baryonic fraction of the mass-energy density of the universe; see Copi, Schramm, and Turner (1997), Schramm and Turner (1998), and Steigman (2006). The experimentally allowed range is in the grey vertical bands. Figure from Schramm and Turner (1998). Reprinted with permission; copyright © 1998, American Physical Society. 9.2 Evolution of the temperature of the universe As the universe expanded and cooled, the cooling rate was proportional to the Hubble parameter, that is, of the order of the inverse of the age of the universe at that point in its expansion. This led to a sequence of important events when different particles and interactions fell out of equilibrium with the gas of blackbody photons. The neutrinos and neutron-proton conversion reactions fell out of equilibrium at t ≈ 1 second. Nuclear reac- tions that formed light nuclei fell out of equilibrium at t ≈ 3 minutes. Neutral atoms fell out of equilibrium at t ≈ 380, 000 years. All these degrees of freedom froze out when the reaction rates that had kept them in equilibrium with the blackbody photons fell far below the cooling rate of the expanding universe. Each component that fell out of equilibrium left behind a marker of the properties of the universe characteristic of that era. It is these 9.2 Evolution of the temperature of the universe 281 markers that provide evidence of the properties and behavior of the universe during its earliest moments. From the ﬁrst moments of the universe up until the recombination era 380,000 years later, the cosmic plasma was in thermal equilibrium with the blackbody radiation through Thomson scattering. Due to the high density of charged particles, the photon scattering mean free time was much shorter than the time scale for temperature changes of the uni- verse as it expanded and cooled, which kept the plasma in thermal equilibrium with the photons. For the ﬁrst few hundred thousand years of its expansion, the energy density of the universe was dominated by photons and other relativistic particles. This is because the energy density of the blackbody radiation scales as a−4 whereas the energy density of non- relativistic matter scales as a−3. The temperature of the blackbody photons as a function of the age of the universe is shown in Figure 9.5 and Table 9.1. During the ﬁrst one-hundredth of a second, the universe expanded and cooled from its singular beginning to a temperature of about 1011 K. The physics from this time onward was controlled by the weak and electromagnetic interactions. The strong interactions could be ignored since the baryon-to-photon ratio was so small and the temperature was 1010 108T (K)106 104 102 100 100 105 t (seconds) 1010 1015 FIGURE 9.5 Sketch of the photon temperature versus the age of the universe. At early times, radiation dominated the energy density, so T ∼ t−1/2. At later times (t > 1013 s) nonrelativistic matter dominated the energy density, so T ∼ t−2/3. In the current dark energy dominated stage, the universe is beginning to expand exponentially with time, so the photon temperature is beginning to fall exponentially. 282 Chapter 9. Thermodynamics of the Early Universe Table 9.1 Temperature vs. Age of the Universe Time (s) Temperature (K) 0.01 1 × 1011 0.1 3 × 1010 1.0 1 × 1010 12.7 3 × 109 168 1 × 109 1980 3 × 108 1.78 × 104 108 1.20 × 1013 3000 4.34 × 1017 2.725 Source: Weinberg (2008). too low to create additional hadrons. 7,8 We will follow the thermodynamic behavior of the universe from t = 0.01 second when the temperature was 1011 K to t = 380, 000 years when the temperature fell below 3000 K. At that point neutral atoms formed, photon scattering ended, and the universe became transparent to radiation. After recombination and last scattering there were no new sources of radiation in the universe since the baryonic mat- ter consisted entirely of neutral atoms. This state of affairs lasted until atoms were ﬁrst reionized by the gravitational clumping that formed the ﬁrst stars and galaxies 100 to 200 million years after the Big Bang. This reionization epoch ended the so-called cosmic dark ages. 9.3 Relativistic electrons, positrons, and neutrinos During the earliest moments of the universe, the temperature was high enough to cre- ate several kinds of relativistic particles and antiparticles. If kT ≫ mc2, then particle- antiparticle pairs each with mass m can be created from photon-photon interactions. At these temperatures, almost all of the particles that are created will have an energy- momentum relation described by the relativistic limit, namely εk ≈ ℏck, (1) 7Before time t = 0.01 s, the analysis is more difﬁcult due to the production of strongly interacting particles and antiparticles. At even earlier times, when the temperature was above kT ≈ 300 MeV (T = 4 × 1012 K), hadrons would have broken apart into a strongly interacting relativistic quark-gluon plasma. The Relativistic Heavy Ion Collider at Brookhaven National Laboratory has succeeded in creating a quark-gluon plasma with the highest temperature matter ever created in the laboratory, T = 4 × 1012 K; see Adare et al. (2010). 8The exact mechanism for baryogenesis (i.e., nonzero baryon-to-photon ratio η) is unsettled. It requires, as shown by Sakharov (1967), three things: baryon number nonconservation, C and CP violation, and deviation from equilibrium. All these conditions were satisﬁed in the earliest moments of the universe (far earlier than the time scales we examine here) but a consensus theory that allows for a baryon asymmetry nearly as large as the observed value of η = 6 × 10−10 has not yet emerged. 9.3 Relativistic electrons, positrons, and neutrinos 283 where ℏk is the magnitude of the momentum. This relation applies to photons, neutrinos, antineutrinos, electrons, and positrons. The threshold for electron-positron pair forma- tion is mec2/k = 5.9 × 109 K. Neutrinos are very light, so we can safely assume that they are relativistic. 9 The relativistic dispersion relation 1 gives essentially the same density of states for all species of relativistic particles: a(ε) = gs (2π)3 ∫ δ(ε − εk)dk = 4π gs (2π)3 ∞∫ 0 k2δ(ε − ℏck)dk = gsε2 2π 2(ℏc)3 , (2) where gs is the spin degeneracy. Photons have a spin degeneracy gs = 2 (left and right cir- cularly polarized). The other species are all spin- 1 2 fermions. Electrons and positrons have spin degeneracy gs = 2 while neutrinos and antineutrinos have spin degeneracy gs = 1 since all neutrinos have left-handed helicity. During this era, because of the charge neutrality of the universe and the small size of the baryon-to-photon ratio η, the number densities of the electrons and positrons were nearly equal, so their chemical potentials were both rather small. Assuming that the net lepton number of the universe is also small, the same applies to the neutrinos and antineutrinos. As explained in Section 7.3, the chemical potential for photons is exactly zero. The pres- sure, number density, energy density, and entropy density of a relativistic gas of fermions (+) or bosons (−) with zero chemical potential are are given by P(T ) = ±kT ∫ a(ε) ln(1 ± e−βε)dε = gs ( kT )4 2π 2 (ℏc) 3 ∞∫ 0 x2 ln ( 1 ± e−x) dx, (3a) n(T ) = ∫ a(ε) 1 eβε ± 1 dε = gs 2π 2 ( kT ℏc )3 ∞∫ 0 x2 ex ± 1 dx , (3b) u(T ) = ∫ a(ε) ε eβε ± 1 dε = gs (kT )4 2π 2 (ℏc)3 ∞∫ 0 x3 ex ± 1 dx, (3c) s(T ) = ( ∂P ∂T ) µ = 2gsk π 2 ( kT ℏc )3 ∞∫ 0 x2 ln ( 1 ± e−x) dx. (3d) 9All three neutrino families are known to have small (but nonzero) mass from neutrino oscillation observations. The electron neutrino is probably the lightest with the experimental limit of mνe c2 < 2.2 eV. The distribution of angular ﬂuctuations of the CMB measured by WMAP puts a limit on the sum of the masses of the neutrinos, ∑ mν c2 < 0.58 eV, so we can safely assume that all neutrino species are far lighter than the value of kT during the early universe. 284 Chapter 9. Thermodynamics of the Early Universe Using the values of the Bose integrals from Appendix D, we arrive at the following expressions for the blackbody photons: Pγ (T ) = π 2 45 (kT )4 (ℏc)3 , (4a) nγ (T ) = 2ζ (3) π 2 ( kT ℏc )3 , (4b) uγ (T ) = π 2 15 (kT )4 (ℏc)3 , (4c) sγ (T ) = 4π 2k 45 ( kT ℏc )3. (4d) All relativistic species with µ = 0 have the same power law temperature dependences for the pressure, energy density, and so on, as the photons, while the Fermi and Bose integrals are the same except for a constant prefactor: ∞∫ 0 xn−1 ex + 1 dx = ( 1 − 1 2n−1 ) ∞∫ 0 xn−1 ex − 1 dx; (5) see Appendices D and E. The contributions to the pressure, energy density, and entropy density result from counting the spin degeneracies, the number of particles and antiparti- cles, and accounting for the different Fermi/Bose factors (1 for bosons, 7/8 for fermions). The photons, three generations of neutrinos (electron, muon, and tau neutrinos and their antiparticles), and the electrons and positrons contribute to the total pressure, number density, energy density, and entropy density in the proportions shown in Table 9.2. The counting is presented here, as is usually done in the literature, relative to the contribu- tion per spin state of the photons. The contributions to the number densities are the same except that the Fermi/Bose factor is now 3/4. Table 9.2 Relativistic Contributions to Pressure, Energy Density, and Entropy Density Particles Fermi/Bose Factor Spin Degeneracy Number of Species 2 Ptotal/Pγ γ 1 2 1 2 νe,νµ,ντ 7 8 1 3 21 8 ¯νe,¯νµ,¯ντ 7 8 1 3 21 8 e− 7 8 2 1 7 4 e+ 7 8 2 1 7 4 9.4 Neutron fraction 285 The totals then are Ptotal(T ) = ( 2 + 21 4 + 7 2 ) Pγ (T ) 2 = ( 43 8 ) Pγ (T ), (6a) utotal(T ) = ( 2 + 21 4 + 7 2 ) uγ (T ) 2 = ( 43 8 ) uγ (T ), (6b) stotal(T ) = ( 2 + 21 4 + 7 2 ) sγ (T ) 2 = ( 43 8 ) sγ (T ), (6c) ntotal(T ) = ( 2 + 9 2 + 3 ) nγ (T ) 2 = ( 19 4 ) nγ (T ). (6d) The density of the universe was high enough in this era, so the weak and electromagnetic interaction rates kept all these species in thermal equilibrium with one other. Therefore, as the universe expanded adiabatically, the entropy in a comoving volume of linear size a remained constant as the volume expanded from some initial value a3 0 to a ﬁnal volume a3 1: stotal(T0)a3 0 = stotal(T1)a3 1. (7) Since the entropy density is proportional to T 3, the temperature and length scale at time t are related by T (t)a(t) = const. (8) This is the same relation that applies for a freely expanding photon gas, see equa- tion (9.1.3), but here it arises from an adiabatic equilibrium process. From equations (9.1.1) and (8), the temperature of the universe as a function of the age of the universe t during this era is T (t) = 10 10 K √ 0.992s t ; (9) see Problem 9.1. 9.4 Neutron fraction During the ﬁrst second of the universe, when T > 1010 K, and before protons and neu- trons combined into nuclei, the weak interaction kept the free neutrons and protons in thermal “beta-equilibrium” with each other and with the photons, neutrinos, electrons, and positrons through the processes n + νe ⇄ p + e− + γ , (1a) n + e+ ⇄ p + ¯ν + γ , (1b) n ⇄ p + e− + ¯ν + γ . (1c) 286 Chapter 9. Thermodynamics of the Early Universe We can treat this as a chemical equilibrium process, as described in Section 6.6. Since the chemical potentials of the photons, electrons, positrons, neutrinos, and antineutrinos are all zero, the neutron and proton chemical potentials must be equal at equilibrium: µn = µp. (2) At these temperatures (≈ 1011 K) and densities (≈ 1032 m−3), the protons and neutrons can be treated as a classical nonrelativistic ideal gas. Following equation (6.6.5), the spin- 1 2 proton and neutron chemical potentials are µp = mpc2 + kT ln (npλ3 p) − kT ln 2, (3a) µn = mnc2 + kT ln (nnλ3 n) − kT ln 2. (3b) where λ(= h/√ 2π mkT ) is the thermal deBroglie wavelength. The rest energy of the neutron is greater than the rest energy of the proton by mnc2 − mpc2 = 1ε = 1.293MeV. (4) Ignoring the small mass difference in the thermal deBroglie wavelength in equations (3a) and (3b) gives nn = npe−β1ε. (5) The baryon number density is the sum of the neutron and proton number densities nB = nn + np, (6) so the equilibrium neutron fraction is given by q = nn nB = 1 eβ1ε + 1 . (7) The mass difference gives a crossover temperature Tnp = 1ε/k ≈ 1.50 × 1010 K, so the neutron fraction drops from 46 percent when T = 1011 K to 16 percent when T = 9 × 109 K at t1 ≈ 1 second. As the temperature fell below 1010 K (kT = 0.86 MeV), the weak interaction rate began to fall far below the cooling rate of the universe, so the baryons quickly fell out of equilibrium with the neutrinos. From that time onward the neutrons began to beta-decay with their natural radioactive decay lifetime of τn = 886 seconds, so the neutron fraction 9.5 Annihilation of the positrons and electrons 287 fell exponentially: q ≈ 0.16 exp( −(t − t1) τn ) for t > t1 = 1s. (8) By the time of nucleosynthesis, about 3.7 minutes later, the neutron fraction had dropped to q ≈ 0.12. At that point, the remaining neutrons bound with protons to form deuterons and other light nuclei. For a discussion of nucleosynthesis, see Section 9.7. 9.5 Annihilation of the positrons and electrons About one second after the Big Bang, the temperature approached the crossover tempera- ture Te for creating electron-positron pairs: kTe = mec2 = 0.511 MeV, (1) with Te = 5.93 × 109 K. As the temperature fell below Te, the rate of creating e+e− pairs began to fall below the rate at which pairs annihilated. The full relativistic dispersion relation for electrons is εk = √ (ℏck)2 + (mec2)2 , (2) which gives for density of states ae(ε) = 8π (2π)3 ∞∫ 0 k2δ(ε − εk)dk = ε√ ε2 − (mec2)2 π 2(ℏc)3 for ε ≥ mec2. (3) Since the electrons and positrons were in equilibrium with the blackbody photons via the reaction e+ + e− ⇄ γ + γ , (4) the equilibrium equation (6.6.3) implied that the chemical potentials of the species were related by µ− + µ+ = 2µγ = 0. (5) The ratio of the number density of the electrons to that of the photons then was n− nγ = 1 2ζ (3) ∞∫ βmec2 x√ x2 − (βmec2)2 exe−βµ− + 1 dx, (6) 288 Chapter 9. Thermodynamics of the Early Universe while the positron density ratio was n+ nγ = 1 2ζ (3) ∞∫ βmec2 x√ x2 − (βmec2)2 exeβµ− + 1 dx; (7) see equation (9.1.5). The electron and positron densities became unbalanced as the universe cooled. Eventually all the positrons got annihilated leaving behind the electrons that currently remain. Charge neutrality of the universe required the difference between the number density of electrons and the number density of positrons to be equal to the number density of protons, (1 − q)nB, where q is deﬁned in Section 9.4; hence (n− − n+) nγ = sinh(βµ−) 2ζ (3) ∞∫ βmec2 x√ x2 − (βmec2)2 cosh(x) + cosh(βµ−) dx = (1 − q)η. (8) We can use equation (8) to determine the electron chemical potential as a function of tem- perature numerically and then use that value in equations (6) and (7) to determine the electron and positron densities; see Figure 9.6. Initially, the electron and positron densities both decreased proportional to exp(−βmec2) as the temperature fell below the electron-positron pair threshold, but they Electrons Positrons 0 10\u000215 \u0002mc 2 10\u000210 10\u00025 n/n\u0003 100 10 20 30 FIGURE 9.6 The ratio of the electron and positron densities to the photon density as a function of βmec2 during the e+e− annihilation for η = 6 × 10−10. This era began around temperature 1010 K (βmec2 = 1.7) at time t = 1 second and ended when the temperature was about 3 × 108 K (βmec2 = 20) at time t = 33 minutes when the electron number density leveled off at the proton number density. 9.6 Neutrino temperature 289 remained nearly equal to each other until T ≈ mec2/k ln [1/(1 − q)η] ≈ 3 × 108 K. At that temperature, the electron density began to level off at the proton density while the positron density continued to fall. Using the baryon-to-photon ratio η = 6 × 10−10, we infer that during the ﬁrst second of the universe that for every 1.7 billion positrons there must have been one extra elec- tron. It is these few extra electrons that will combine with nuclei during the recombination era composing all the atoms now present in the universe. All baryonic matter currently in the universe is the result of this initial asymmetry between matter and antimatter; see footnote 8. 9.6 Neutrino temperature For temperatures above T = 1010 K, the rates for the weak interaction reactions (9.4.1) kept the neutrinos in “beta-equilibrium” with the electrons, positrons, and photons. Starting at time t ≈ 1 s, when T = 1010 K, the weak interaction rates began to fall far below the expan- sion rate of the universe so the neutrinos quickly fell out of equilibrium. Following the decoupling, the neutrinos expanded freely so the neutrino temperature scaled with the expansion length scale following equation (9.1.3). The system of electrons, positrons, and photons remained in thermal equilibrium with each other and expanded adiabatically during the electron-positron annihilation era from temperature T0 = 1010 K when the annihilations began, until temperature T1 = 3 × 108 K when nearly all of the positrons had been annihilated. Since this was an adiabatic expan- sion, we can determine the temperature evolution using entropy conservation. Consider a comoving cubical volume that expanded from an initial linear size a0 to a ﬁnal size a1 during the same time period. The total entropy in the comoving volume at temperature T0 was due to the photons, electrons, and positrons (refer to Table 9.2): S(T0) = 11 4 sγ (T0)a3 0, (1) while the entropy at temperature T1 was due solely to the photons since, by then, nearly all of the electrons and positrons had been annihilated: S(T1) = sγ (T1)a3 1. (2) Entropy conservation during the adiabatic expansion relates the initial and ﬁnal tem- peratures as ( 11 4 )1/3 T0a0 = T1a1. (3) In essence, the entropy of the annihilating electrons and positrons was transferred to the photons. Since the neutrino and photon temperatures were equal before the electron- positron annihilation and the neutrinos expanded freely during the annihilation, the 290 Chapter 9. Thermodynamics of the Early Universe neutrino temperature decreased more than the photon temperature during the annihi- lation era: Tν1 = (4/11) 1/3 T1. (4) After the e+e− annihilation, both the neutrino and the photon temperatures evolved according to equation (9.1.3) and (9.3.8), so the current temperature of the relic Big Bang neutrinos should be Tν = (4/11) 1/3 TCMB ≃ 1.945 K. (5) A measurement of the cosmic neutrino background would provide an excellent additional test of the standard model of the Big Bang but we do not currently have a viable means to measure these very low-energy neutrinos. 10 9.7 Primordial nucleosynthesis Light nuclei other than hydrogen ﬁrst formed between 3 and 4 minutes after the Big Bang when the temperature had cooled to about 109 K. Prior to that time, the high-temperature blackbody radiation rapidly photodissociated any deuterium nuclei that happened to form. The ﬁrst step for the formation of light nuclei from the protons and neutrons is the formation of deuterium because all of the rates for forming nuclei at these densities are dominated by two-body collisions. Once deuterons formed, most of these nuclei would have been quickly converted to helium and other more stable light nuclei in a series of two-body collisions with the remaining protons, neutrons, and with each other. As dis- cussed in Section 9.4, the proton/neutron mixture at this time was about q = 12 percent neutrons and 1 − q = 88 percent protons. By t ≈ 3 minutes the temperature had fallen to T ≈ 109 K so protons and neutrons could begin to bind themselves into deuterons via the process p + n ⇄ d + γ . (1) The chemical equilibrium relation for this reaction, see equation (6.6.3), is µp + µn = µd, (2) since the chemical potential of the blackbody photons is zero. At these temperatures and densities the protons, neutrons, and deuterons can be treated as classical ideal gases. 10The neutrino elastic scattering cross-section scales like the fourth power of the energy, so the collisions are both very rare and involve very small energy and momentum transfers. This makes direct laboratory detection of the cosmic neutrino background (CνB) infeasible at present; see Gelmini (2005). 9.7 Primordial nucleosynthesis 291 The proton and neutron are spin- 1 2 particles so they have two spin states each while the deuteron is spin-1 and has three spin states: µp = mpc2 + kT ln ( npλ3 p) − kT ln 2, (3a) µn = mnc2 + kT ln (nnλ3 n) − kT ln 2, (3b) µd = mdc2 + kT ln ( ndλ 3 d) − kT ln 3. (3c) The binding energy of the deuteron is εb = mpc2 + mnc2 − mdc2 = 2.20 MeV. Since the deuteron is approximately twice as massive as protons or neutrons, the deuteron number density is given by nd = 3 4 npnn λ3 pλ3 n λ3 d eβεb ≈ 3 √ 2 npnnλ 3 peβεb . (4) The total number density of baryons is determined by the baryon-to-photon ratio: η: nB = ηnγ = np + nn + 2nd. The neutron number density is qnB = nn + nd, so the deuteron fraction is given by fd = nd nB = (1 − q − fd)(q − fd)s, (5) where the parameter s is s = 12ζ (3) √ π ( kT mpc2 )3/2 ηeβεb ; (6) see also equation (9.1.5). Equation (5) is similar to the Saha equation for the ionization of hydrogen atoms that will be discussed in Section 9.8 and has solution fd = 1 + s − √ (1 + s)2 − 4s2q(1 − q) 2s . (7) For high temperatures, s is small and fd ≈ q(1 − q)s while for low temperatures, s is large and fd ≈ q, that is, all the neutrons are bound into deuterons. The deuterium fraction as a function of temperature is shown in Figure 9.7. The small values of the baryon-to-photon ratio η and εb/mpc2 delayed the nucleosynthesis until the temperature had fallen to kTn ≈ εb ln ( 1 η ( mpc2 εb )3/2) , (8) providing the time for the neutron fraction to have decayed to q = 0.12. 292 Chapter 9. Thermodynamics of the Early Universe 0.12 0.10 0.08 0.06 0.04 0.02 fd 0.0 0.5 1.0 T (10 9 kelvin) 1.5 2.0 0.00 FIGURE 9.7 Plot of the equilibrium deuterium fraction fd versus temperature T for neutron fraction q = 0.12 and baryon-to-photon ratio η = 6 × 10−10. As T falls below about 6 × 108 K the neutrons are nearly all bound into deuterons. Further two-body reactions convert most of the deuterium into heavier nuclei, primarily 4He. The simple equilibrium calculation presented here assumes that no further reactions take place. Including the fast nonequilibrium two-body reactions, namely d + d → 3H + p + γ , (9a) d + d → 3He + n + γ , (9b) d + 3H → 4He + n + γ , (9c) d + 3He → 4He + p + γ , (9d) results in almost all of the deuterons being cooked into the very stable isotope 4He and small amounts of other light nuclei. Since each 4He nucleus is composed of two protons and two neutrons, this gives a helium mass fraction of 2q = 24 percent and proton mass fraction of 1 − 2q = 76 percent. The complete calculation involves nonequilibrium effects modeled with rate equations for each of the nuclear interactions, including those for heav- ier isotopes, but that only changes the predicted concentration for 4He slightly;11 see Weinberg (2008). The largest theoretical uncertainty is, remarkably, the uncertainty in the radioactive decay time of the neutron in equation (9.4.8); see Copi, Schramm, and Turner (1997). Calculations of this type were ﬁrst performed by Gamow, Alpher, and Herman in the late 1940s and early 1950s. Based on current amounts of helium and other light elements 11Nuclear reactions continued slowly at a rate that had fallen out of equilibrium and shifted the isotopic ratios until about t ≈ 10 minutes. 9.8 Recombination 293 in the universe, Alpher and Herman predicted a 5 K cosmic microwave background over a decade before Penzias and Wilson’s discovery; see footnote 6. 9.8 Recombination After the nucleosynthesis took place in the ﬁrst few minutes, the universe continued to cool, with the nuclei and electrons remaining as an ordinary plasma in thermal equilib- rium with the photons. It took several hundred thousand years for the temperature to drop below the atomic ionization energies of a few electron volts needed for nuclei to capture electrons and form atoms. Hydrogen was the last neutral species to form since it has the smallest ionization energy of a Rydberg (1Ry = mee4/8ϵ2 0 h2 = 13.6057 eV). At ﬁrst glance, one would think that atoms form when the temperature falls below Ry/k = 158,000 K but, as we will see, the huge number of photons per proton delayed recombination until T ≈ 3000 K. Once all the electrons and protons formed into neutral hydrogen atoms, the universe became transparent due to the last scattering of radiation from free electrons. These CMB blackbody photons were suddenly free to propagate and hence have been traveling unscattered since that time. The recombination reaction (that is, the inverse of the hydrogen photoionization reaction) is p + e ⇄ H + γ , (1) so the chemical equilibrium relation from Section 6.6 gives µp + µe = µH (2) since, again, the chemical potential of the blackbody photons is zero. 12 At the temperatures and densities prevailing during this era (a few thousand degrees Kelvin and only about 109 atoms per cubic meter), the electrons, protons, and hydrogen atoms can all be treated as classical ideal gases, with the result µp = mpc2 + kT ln(npλ 3 p) − kT ln 2, (3a) µe = mec2 + kT ln(neλ3 e ) − kT ln 2, (3b) µH = mHc2 + kT ln(nHλ3 H) − kT ln 4. (3c) The binding energy of hydrogen is mpc2 + mec2 − mHc2 = 1 Ry. The equilibrium condition (6.6.3) and the ideal gas chemical potential (6.6.5) then give a simple relation between the number densities of the three species: nH = npneλ3 e eβRy, (4) 12The same reaction occured for the deuterons that remained after nucleosynthesis at t ≈ 3 minutes but the density of the deuterons was 3 × 10−5 times the proton density; refer to Figure 9.4. 294 Chapter 9. Thermodynamics of the Early Universe where λe = h √ 2π mekT (5) is the electron thermal deBroglie wavelength. The number densities of free electrons and protons are the same due to charge neutrality: ne = np. (6) The protons remaining after nucleosynthesis are either free or combined into hydrogen atoms, so np + nH = (1 − 2q)nB = (1 − 2q)ηnγ . (7) Putting equations (3), (4), (6), and (7) together and making use of (9.1.5) gives the Saha equation for the neutral hydrogen fraction: fH = nH np + nH = (1 − fH)2s, (8) where the parameter s is s = 4ζ (3) √ 2 π (1 − 2q)η ( kT mec2 )3/2 eβRy. (9) The solution to equation (8), namely fH = 1 + 2s − √1 + 4s 2s , (10) is shown in Figure 9.8. At temperatures above the recombination temperature, s is small so fH is small, making the plasma fully ionized. At low temperatures s is large so fH approaches unity, leaving just neutral atoms. The small values of the baryon-to-photon ratio η and Ry/mec2 make the onset of recombination at temperature kTr ≈ Ry ln( 1 η ( mec2 Ry )3/2) , (11) which delays the last scattering until T ≈ 3000 K; see Figure 9.8. 9.9 Epilogue 295 2000 0.0 0.2 0.4 0.6 0.8 1.0 3000 4000 T (kelvin) 5000 fH FIGURE 9.8 The equilibrium neutral hydrogen fraction as a function of temperature for baryon-to-phonon ratio η = 6 × 10−10 and proton fraction 1 − 2q = 0.76. By the time temperature T = 3000 K, 99.5 percent of the free protons and electrons had combined into neutral hydrogen resulting in “last scattering” and the universe became transparent. The age of the universe at that time was about 380,000 years. 9.9 Epilogue The formation of neutral atoms about 380,000 years after the Big Bang effectively ended the scattering of photons from free charges. The universe became transparent and entered the “dark ages” before the ﬁrst star formation. The CMB photons were no longer in equilibrium but maintained their Planck distribution as the universe expanded. Small density ﬂuctuations that were present in the electron–proton plasma just before recom- bination were imprinted on the CMB as temperature ﬂuctuations. The CMB shown in Figure 9.3 earlier displays temperature ﬂuctuations of the order of ±200 µK that represent the density ﬂuctuations in the plasma at the time of recombination. These small mass density ﬂuctuations led to gravitational clumping that resulted in the formation of the ﬁrst stars and galaxies 100 to 200 million years after the Big Bang. The large fraction of nonbary- onic cold dark matter was crucial in this process. Early stars that exploded as supernovae spewed their heavy elements (carbon, oxygen, silicon, iron, gold, uranium, etc.) into the cosmos. Our own solar system formed from a gas and dust cloud that included heavy elements that had been created in an earlier supernova event. Indeed, “we are stardust.”13 13Joni Mitchell, Woodstock; copyright © Siquomb Publishing Company: “We are stardust Billion year old carbon We are golden Caught in the devil’s bargain And we’ve got to get ourselves back to the garden” 296 Chapter 9. Thermodynamics of the Early Universe Problems 9.1. Use the Hubble expansion relation (9.1.1), the temperature scaling relation (9.1.3), and the energy density relation before the electron-positron annihilation (9.3.6b) to show that the temperature as a function of time during the ﬁrst second of the universe was T (t) ≈ 1010 K √ 0.992s t . 9.2. Determine the average energy per particle and average entropy per particle for the photons, electrons, positrons and neutrinos during the ﬁrst second of the universe. 9.3. While the electromagnetic interaction between the photons and the charged electrons and positrons kept them in equilibrium with each other during the early universe, show that the direct electromagnetic Coulomb interaction energy between the electrons and positrons was small compared to the relativistic kinetic energy of those species. Show that the ratio between the Coulomb and kinetic energies is of the order of the ﬁne structure constant: ucoulomb ue ≈ α = e2 4πϵ0ℏc = 1 137.036 . 9.4. Show that during the early part of the electron-positron annihilation era, the ratio of the electron number density to the photon number density scaled with temperature as n− nγ ≈ n+ nγ ∼ ( kT mec2 )3/2 exp( −βmec2) . 9.5. Show that after nearly all of the positrons were annihilated and the electron number density had nearly leveled off at the proton density, the ratio of the positron number density to the photon number density scaled with temperature as n+ nγ ∼ ( kT mec2 )3/2 exp( −2βmec2) . 9.6. After the positrons were annihilated, the energy density of the universe was dominated by the photons and the neutrinos. Show that the energy density in that era was: utotal = (1 + (4/11)4/3)uγ . Next, use the Hubble expansion relation (9.1.1), the temperature scaling relation (9.1.3), and the energy density after the electron-positron annihilation to show that the photon temperature as a function of time was T (t) ≈ 1010 K √ 1.788s t . This relation held from t ≈ 100 s until t ≈ 200, 000 years when the energy density due to baryonic and cold dark matter began to dominate. 9.7. How would the primordial helium content of the universe have been affected if the present cosmic background radiation temperature was 27 K instead of 2.7 K? What about 0.27 K? 9.8. Gold-on-gold nuclear collisions at the Relativistic Heavy Ion Collider (RHIC) at the Brookhaven National Laboratory create a quark-gluon plasma with an energy density of about 4 GeV/fm3; see Adare et al. (2010). Treat nuclear matter as composed of a noninteracting relativistic gas of quarks and gluons. Include the low-mass up and down quarks and their antiparticles (all spin- 1 2 ), and spin-1 massless gluons. Like photons, the gluons are bosons, have two spin states each, and are their own antiparticle. There are eight varieties of gluons that change the three color states of the quarks. Only the strongly interacting particles need to be considered due to the tiny size of the plasmas. What is the temperature of the quark-gluon plasma? 9.9. Calculate the energy density versus temperature very early in the universe when the tempera- tures were above kT = 300 MeV. At those temperatures, quarks and gluons were released from individual nuclei. Treat the quark-gluon plasma as a noninteracting relativistic gas. At those Problems 297 temperatures, the species that are in equilibrium with one other are: photons, the three neutrino species, electrons and positrons, muons and antimuons, up and down quarks and their antiparticles (all spin- 1 2 ), and spin-1 massless gluons. Like photons, the gluons are bosons, have two spin states each, and are their own antiparticle. There are eight varieties of gluons that change the three color states of the quarks. The strange, charm, top, and bottom quarks and tau leptons are heavier than 300 MeV, so they do not contribute substantially at this temperature. Use your result and equation (9.1.1) to determine the temperature evolution as a function of the age of the universe during this era and its age when kT ≈ 300 MeV. 10 Statistical Mechanics of Interacting Systems: The Method of Cluster Expansions All the systems considered in the previous chapters were composed of, or could be regarded as composed of, noninteracting entities. Consequently, the results obtained, though of considerable intrinsic importance, may have limitations when applied to sys- tems that actually exist in nature. For a real contact between the theory and experiment, one must take into account the interparticle interactions operating in the system. This can be done with the help of the formalism developed in Chapters 3 through 5 which, in principle, can be applied to an unlimited variety of physical systems and problems; in practice, however, one encounters in most cases serious difﬁculties of analysis. These difﬁculties are less stringent in the case of systems such as low-density gases, for which a corresponding noninteracting system can serve as an approximation. The mathema- tical expressions for the various physical quantities pertaining to such a system can be written in the form of series expansions, whose main terms describe the correspond- ing ideal-system results while the subsequent terms provide corrections arising from the interparticle interactions in the system. A systematic method of carrying out such expan- sions, in the case of real gases obeying classical statistics, was developed by Mayer and his collaborators (1937 onward) and is known as the method of cluster expansions. Its gener- alization, which equally well applies to gases obeying quantum statistics, was initiated by Kahn and Uhlenbeck (1938) and was perfected by Lee and Yang (1959a,b; 1960a,b,c). 10.1 Cluster expansion for a classical gas We start with a relatively simple physical system, namely a single-component, classical, monatomic gas whose potential energy is given by a sum of two-particle interactions uij. The Hamiltonian of the system is then given by H = ∑ i ( 1 2m p 2 i ) + ∑ i<j uij (i, j = 1, 2, . . . , N); (1) the summation in the second part goes over all the N(N − 1)/2 pairs of particles in the system. In general, the potential uij is a function of the relative position vector rij(= rj − ri); Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00010-4 © 2011 Elsevier Ltd. All rights reserved. 299 300 Chapter 10. Statistical Mechanics of Interacting Systems however, if the two-body force is a central one, then the function uij depends only on the interparticle distance rij. With the preceding Hamiltonian, the partition function of the system is given by, see equation (3.5.5), QN (V , T ) = 1 N! h3N ∫ exp    −β ∑ i ( 1 2m p 2 i ) − β ∑ i<j uij    d3N p d3N r. (2) Integration over the momenta of the particles can be carried out straightforwardly, with the result QN (V , T ) = 1 N! λ3N ∫ exp [ − β ∑ i<j uij ] d3N r = 1 N! λ3N ZN (V , T ), (3) where λ{= h/(2π mkT )1/2} is the mean thermal wavelength of the particles, while the function ZN (V , T ) stands for the integral over the space coordinates r1, r2, . . . , rN : ZN (V , T ) = ∫ exp [ − β ∑ i<j uij ]d3N r = ∫ ∏ i<j(e−βuij ) d3N r. (4) The function ZN (V , T ) is generally referred to as the conﬁguration integral of the system. For a gas of noninteracting particles, the integrand in (4) is unity; we then have Z (0) N (V , T ) = V N and Q(0) N (V , T ) = V N N! λ3N , (5) in agreement with our earlier result (3.5.9). To treat the nonideal case we introduce, after Mayer, the two-particle function fij, deﬁned by the relationship fij = e−βuij − 1. (6) In the absence of interactions, the function fij is identically zero; in the presence of interac- tions, it is nonzero but at sufﬁciently high temperatures it is quite small in comparison with unity. We, therefore, expect that the functions fij would be quite appropriate for carrying out a high-temperature expansion of the integrand in (4). A typical plot of the functions uij and fij is shown in Figure 10.1; we note that (i) the function fij is everywhere bounded and (ii) it becomes negligibly small as the interparticle distance rij becomes large in comparison with the “effective” range, r0, of the potential. 10.1 Cluster expansion for a classical gas 301 r0 r0 rijuij fij rij 0 0 \u00021 \u00031 FIGURE 10.1 A typical plot of the two-body potential function uij and the corresponding Mayer function fij. Now, to evaluate the conﬁguration integral (4), we expand its integrand in ascending powers of the functions fij: ZN (V , T ) = ∫ ∏ i<j(1 + fij) d3r1 · · · d3rN = ∫ [ 1 + ∑ fij + ∑ fijfkl + · · · ] d3r1 · · · d3rN . (7) A convenient way of enumerating the various terms in (7) is to associate each term with a corresponding N-particle graph. For instance, if N were 8, the terms tA = ∫ f34 f68d3r1 · · · d3r8 and tB = ∫ f12 f14 f67d3r1 · · · d3r8 (8) in the expansion of the conﬁguration integral Z8 could be associated with the 8-particle graphs 1 2 3 4 5 6 7 and 8 1 2 3 4 5 6 7 8 , (9) respectively. A closer look at the terms tA and tB (and at the corresponding graphs) suggests that we better regard these terms as suitably factorized (and the graphs correspondingly 302 Chapter 10. Statistical Mechanics of Interacting Systems decomposed), that is, tA = ∫ d3r1 ∫ d3r2 ∫ d3r5 ∫ d3r7 ∫ f34d3r3d3r4 ∫ f68d3r6d3r8 ≡ .[ ]1 [ ]2 [ ]5 [ ]7 [ 3 ]4. ... [ 6 ]8 (10) and similarly tB = ∫ d3r3 ∫ d3r5 ∫ d3r8 ∫ f12f14d3r1d3r2d3r4 ∫ f67d3r6d3r7 ≡ 2 4 1 [ ]3 [ ]5 [ ]8 [ 6 ]7... . .][ (11) We may then say that the term tA in the expansion of the integral Z8 represents a “conﬁguration” in which there are four “clusters” of one particle each and two “clusters” of two particles each, while the term tB represents a “conﬁguration” in which there are three “clusters” of one particle each, one “cluster” of two particles and one “cluster” of three particles. In view of this, we may introduce the notion of an N-particle graph which, by deﬁnition, is a “collection of N distinct circles, numbered 1, 2, . . . , N, with a number of lines linking some (or all) of the circles”; if the distinct pairs (of circles), which are linked through these lines, are denoted by the symbols α, β, . . . , λ (each of these symbols denoting a distinct pair of indices out of the set 1, 2, . . . , N), then the graph represents the term ∫ ( fαfβ · · · fλ)d3r1 · · · d3rN (12) of expansion (7). A graph having the same number of linked pairs as this one but with the set (α′, β′, . . . , λ′) distinct from the set (α, β, . . . , λ) will be counted as a distinct graph, for it represents a different term in the expansion; of course, these terms will belong to one and the same group in the expansion. Now, in view of the one-to-one correspondence between the various terms in the expansion (7) and the various N-particle graphs, we have ZN (V , T ) = sum of all distinct N-particle graphs. (13) Further, in view of the possible factorization of the various terms (or the possible decom- position of the various graphs), we may introduce the notion of an l-cluster which, by deﬁnition, is an “l-particle graph in which each of the l circles, numbered 1, 2, . . . , l, is directly or indirectly linked with every other circle.” As an example, we write here a 10.1 Cluster expansion for a classical gas 303 5-particle graph, which is also a 5-cluster: 1 2 3 4 5 ≡ ∫ f12 f14 f15 f25 f34 d3 r1 · · · d3 r5. (14) It is obvious that a cluster as such cannot be decomposed into simpler graphs inasmuch as the corresponding term cannot be factorized into simpler terms. Furthermore, a group of l particles (except when l = 1 or 2) can lead to a variety of l-clusters, some of which may be equal in value; for instance, a group of three particles leads to four different 3-clusters, namely and2 3 1 2 3 1 2 3 1 2 3 1 , (15) of which the ﬁrst three are equal in value. In view of the variety of ways in which an l-cluster can appear, we may introduce the notion of a cluster integral bl, deﬁned by bl(V , T ) = 1 l! λ3(l−1)V × (the sum of all possible l-clusters). (16) So deﬁned, the cluster integral bl(V , T ) is dimensionless and, in the limit V → ∞, approaches a ﬁnite value, bl(T ), which is independent of the size and the shape of the container (unless the latter is unduly abnormal). The ﬁrst property is quite obvious. The second one follows by noting that if we hold one of the l particles ﬁxed, at the point r1 say, and carry out integration over the coordinates of the remaining (l − 1) particles, then, because of the fact that the functions fij extend only over a small ﬁnite range of distances, this integration would extend only over a limited region of the space available — a region whose linear dimensions are of the order of the range of the functions fij; 1 the result of this integration will be practically independent of the volume of the container.2 Finally, we integrate over the coordinates r1 of the particle that was held ﬁxed and obtain a straight factor of V ; this cancels out the V in the denominator of the deﬁning formula (16). Thus, the dependence of the cluster integral bl(V , T ) on the size of the container is no more than a mere “surface effect” — an effect that disappears as V → ∞, and we end up with a volume-independent number bl(T ). 1Hence the name “cluster.” 2Of course, some dependence on the geometry of the container will indeed arise if the ﬁxed particle happened to be close to the walls of the container. This is, however, unimportant when V → ∞. 304 Chapter 10. Statistical Mechanics of Interacting Systems Some of the simpler cluster integrals are b1 = 1 V [ 1 ] = 1 V ∫ d3r1 ≡ 1, b2 = 1 2λ3V [ 1 2 ] = 1 2λ3V ∫∫ f12d3r1 d3r2 ≈ 1 2λ3 ∫ f12d3r12 = 2π λ3 ∞∫ 0 f (r)r2 dr (17) = 2π λ3 ∞∫ 0 (e−u(r)/kT − 1)r2dr, (18) b3 = 1 6λ6V × [sum of the clusters (15)] = 1 6λ6V ∫ ( f12f13 + f12f23 + f13f23 ︸ ︷︷ ︸ + f12f13f23)d3r1d3r2d3r3 ≈ 1 6λ6V [3V ∫∫ f12f13d3r12d3r13 + V ∫∫ f12f13f23d3r12d3r13 ] = 2b2 2 + 1 6λ6 ∫∫ f12f13f23d3r12d3r13, (19) and so on. We now proceed to evaluate the crucial expression in (13). Obviously, an N-particle graph will consist of a number of clusters of which, say, m1 are l-clusters, m2 are 2-clusters, m3 are 3-clusters, and so on; the numbers {ml} must satisfy the restrictive condition N∑ l=1 lml = N, ml = 0, 1, 2, . . . , N. (20) However, a given set of numbers {ml} does not specify a unique, single graph; it represents a “collection of graphs” the sum total of which may be denoted by the symbol S{ml}. We may then write ZN (V , T ) = ∑′ {ml}S{ml}, (21) where the primed summation ∑′ goes over all sets {ml} that conform to the restrictive condition (20). Equation (21) represents a systematic regrouping of the graphs, as opposed to the simple-minded grouping that ﬁrst appeared in equation (7). 10.1 Cluster expansion for a classical gas 305 Our next task consists of evaluating the sum S{ml}. To do this, we observe that the “family of graphs” under the distribution set {ml} arises essentially from the following two causes: (i) there are, in general, many different ways of assigning the N particles of the system to the ∑l ml clusters, and (ii) for any given assignment, there are, in general, many different ways of forming the various clusters, for even with a given group of l particles an l-cluster (if l > 2) can be formed in a number of different ways; see, for example, the four different ways of forming a 3-cluster with a given group of three particles, as listed in (15). For cause (i), we obtain a straightforward factor of N! (1! )m1 (2! )m2 · · · = N! ∏ l (l! )ml . (22) Now, if cause (ii) were not there, that is, if all l-clusters were unique in their formation, then the sum S{ml} would be given by the product of the combinatorial factor (22) with the value of any one graph in the setup, namely ∏ l (the value of an l-cluster) ml , (23) further corrected for the fact that any two arrangements that differ merely in the exchange of all the particles in one cluster with all the particles in another cluster of the same size, must not be counted as distinct, the corresponding correction factor being ∏ l (1/ml! ). (24) A little reﬂection now shows that cause (ii) is completely and correctly taken care of if we replace the product of the expressions (23) and (24) by the expression3 ∏ l [ (the sum of the values of all possible l-clusters)ml /ml! ] (25) which, with the help of equation (16), may be written as ∏ l [ (bll! λ3(l−1)V )ml /ml! ] . (26) 3To appreciate the logic behind this replacement, consider expression [ ] in (25) as a multinomial expansion and interpret the various terms of this expansion in terms of the variety of the l-clusters. 306 Chapter 10. Statistical Mechanics of Interacting Systems The sum S{ml} is now given by the product of factor (22) and expression (26). Substituting this result into (21), we obtain for the conﬁguration integral ZN (V , T ) = N! λ 3N ∑′ {ml}   ∏ l {(bl V λ3 )ml 1 ml! }  . (27) Here, use has been made of the fact that ∏ l (λ 3l) ml = λ36llml = λ3N ; (28) see the restrictive condition (20). The partition function of the system now follows from equations (3) and (27), with the result QN (V , T ) = ∑′ {ml}   N∏ l=1 {(bl V λ3 )ml 1 ml! }  . (29) The evaluation of the primed sum in (29) is complicated by the restrictive condi- tion (20), which must be obeyed by every set {ml}. We, therefore, move over to the grand partition function of the system: Q(z, V , T ) = ∞∑ N=0 zN QN (V , T ). (30) Writing zN = z6llml = ∏ l (zl)ml , (31) substituting for QN (V , T ) from (29), and noting that a restricted summation over sets {ml}, subject to the condition ∑l lml = N, followed by a summation over all values of N ( from N = 0 to N = ∞) is equivalent to an unrestricted summation over all possible sets {ml}, we obtain Q(z, V , T ) = ∞∑ m1,m2,...=0   ∞∏ l=1 {( blzl V λ3 )ml 1 ml! }  = ∞∏ l=1   ∞∑ ml=0 {( blzl V λ3 )ml 1 ml! }   = ∞∏ l=1 [exp ( blzl V λ3 )] = exp   ∞∑ l=1 blzl V λ3   (32) 10.2 Virial expansion of the equation of state 307 and, hence, 1 V ln Q = 1 λ3 ∞∑ l=1 blzl. (33) In the limit V → ∞, P kT ≡ Lim V →∞ ( 1 V ln Q) = 1 λ3 ∞∑ l=1 blzl, (34) and N V ≡ Lim V →∞ ( z V ∂ ln Q ∂z ) = 1 λ3 ∞∑ l=1 l blzl. (35) Equations (34) and (35) constitute the famous cluster expansions of the Mayer–Ursell for- malism. Eliminating the fugacity z among these equations, we obtain the equation of state of the system. 10.2 Virial expansion of the equation of state The approach developed in the preceding section leads to exact results only if we apply it to the gaseous phase alone. If we attempt to include in our study the phenomena of conden- sation, the critical point, and the liquid phase, we encounter serious difﬁculties relating to (i) the limiting procedure involved in equations (10.1.34) and (10.1.35), (ii) the conver- gence of the summations over l, and (iii) the volume dependence of the cluster integrals bl. We, therefore, restrict our study to the gaseous phase alone. The equation of state may then be written in the form Pv kT = ∞∑ l=1 al(T ) ( λ3 v )l−1 , (1) where v (= V /N) denotes the volume per particle in the system. Expansion (1), which is supposed to have been obtained by eliminating z between equations (10.1.34) and (10.1.35), is called the virial expansion of the system and the numbers al(T ) the virial coef- ﬁcients.4 To determine the relationship between the coefﬁcients al and the cluster integrals bl, we invert equation (10.1.35) to obtain z as a power series in (λ3/v) and substitute this 4For various manipulations of the virial equation of state, see Kilpatrick and Ford (1969). 308 Chapter 10. Statistical Mechanics of Interacting Systems into (10.1.34). This leads to equation (1), with a1 = b1 ≡ 1, (2) a2 = − b2 = − 2π λ3 ∞∫ 0 ( e−u(r)/kT − 1 ) r2dr, (3) a3 = 4 b 2 2 − 2 b3 = − 1 3λ6 ∞∫ 0 ∞∫ 0 f12f13f23d3r12d3r13, (4) a4 = −20 b 3 2 + 18 b2 b3 − 3 b4 = · · · , (5) and so on; here, use has also been made of formulae (10.1.17) to (10.1.19). We note that the coefﬁcient al is completely determined by the quantities b1, b2, . . . , bl, that is, by the sequence of conﬁguration integrals Z1, Z2, . . . , Zl; see also equations (10.4.5) to (10.4.8). From equation (4) we observe that the third virial coefﬁcient of the gas is determined solely by the 3-cluster 1 32 . This suggests that the higher-order virial coefﬁcients may also be determined solely by a special “subgroup” of the various l-clusters. This is indeed true, and the relevant result is that, in the limit of inﬁnite volume,5 al = − l − 1 l βl−1 (l ≥ 2), (6) where βl−1 is the so-called irreducible cluster integral, deﬁned as βl−1 = 1 (l − 1)! λ3(l−1)V × (the sum of all irreducible l-clusters); (7) by an irreducible l-cluster we mean an “l-particle graph that is multiply-connected (in the sense that there are at least two entirely independent, nonintersecting paths linking each pair of circles in the graph).” For instance, of the four possible 3-clusters, see (10.1.15), only the last one is irreducible. Indeed, if we express equation (4) in terms of this particular cluster and make use of deﬁnition (7) for β2, we do obtain for the third virial coefﬁcient a3 = − 2 3 β2, (8) in agreement with the general result (6). 6 The quantities βl−1, like bl, are dimensionless and, in the limit V → ∞, approach ﬁnite values that are independent of the size and the shape of the container (unless the 5For a proof of this result, see Hill (1956, Sections 24 and 25); see also Section 10.4 of the present text. 6It may be mentioned here that a 2-cluster is also regarded as an irreducible cluster. Accordingly, β1 = 2b2; see equations (10.1.16) and (10.2.7). Equation (3) then gives: a2 = −b2 = − 1 2 β1, again in agreement with the general result (6). 10.3 Evaluation of the virial coefﬁcients 309 latter is unduly abnormal). Moreover, the two sets of quantities are mutually related; see equations (10.4.27) and (10.4.29). 10.3 Evaluation of the virial coefﬁcients If a given system does not depart much from the ideal-gas behavior, its equation of state is given adequately by the ﬁrst few virial coefﬁcients. Now, since a1 ≡ 1, the lowest-order virial coefﬁcient that we need to consider here is a2, which is given by equation (10.2.3): a2 = − b2 = 2π λ3 ∞∫ 0 (1 − e−u(r)/kT ) r2 dr, (1) u(r) being the potential energy of interparticle interaction. A typical plot of the function u(r) was shown earlier in Figure 10.1; a typical semi-empirical formula (Lennard-Jones, 1924) is given by u(r) = 4ε [( σ r )12 − ( σ r )6] . (2) The most signiﬁcant features of an actual interparticle potential are well-simulated by the Lennard-Jones formula (2). For instance, the function u(r) given by (2) exhibits a “mini- mum,” of value −ε, at a distance r0(= 21/6σ ) and rises to an inﬁnitely large (positive) value for r < σ and to a vanishingly small (negative) value for r ≫ σ . The portion to the left of the “minimum” is dominated by repulsive interaction that comes into play when two particles come too close to one another, while the portion to the right is dominated by attractive interaction that operates between particles when they are separated by a respectable dis- tance. For most practical purposes, the precise form of the repulsive part of the potential is not very important; it may as well be replaced by the crude approximation u(r) = +∞ (for r < r0), (3) which amounts to attributing an impenetrable core, of diameter r0, to each particle. The precise form of the attractive part is, however, important; in view of the fact that there exists good theoretical basis for the sixth-power attractive potential (see Problem 3.36), this part may simply be written as u(r) = −u0(r0/r)6 (r ≥ r0). (4) The potential given by expressions (3) and (4) may, therefore, be used if one is only inter- ested in a qualitative assessment of the situation and not in a quantitative comparison between the theory and experiment. 310 Chapter 10. Statistical Mechanics of Interacting Systems Substituting (3) and (4) into (1), we obtain for the second virial coefﬁcient a2 = 2π λ3    r0∫ 0 r2dr + ∞∫ r0 [1 − exp { u0 kT ( r0 r )6}] r2 dr   . (5) The ﬁrst integral is straightforward; the second one is considerably simpliﬁed if we assume that (u0/kT ) ≪ 1, which makes the integrand very nearly equal to −(u0/kT )(r0/r)6. Equation (5) then gives a2 ≃ 2πr3 0 3λ3 (1 − u0 kT ). (6) Substituting (6) into the expansion (10.2.1), we obtain a ﬁrst-order improvement on the ideal-gas law, namely P ≃ kT v { 1 + 2π r3 0 3v (1 − u0 kT ) } (7a) = kT v { 1 + B2(T ) v } , say. (7b) The coefﬁcient B2, which is also sometimes referred to as the second virial coefﬁcient of the system, is given by B2 ≡ a2λ 3 ≃ 2πr3 0 3 (1 − u0 kT ) . (8) In our derivation it was explicitly assumed that (i) the potential function u(r) is given by the simpliﬁed expressions (3) and (4), and (ii) (u0/kT ) ≪ 1. We cannot, therefore, expect formula (8) to be a faithful representation of the second virial coefﬁcient of a real gas. Nev- ertheless, it does correspond, almost exactly, to the van der Waals approximation to the equation of state of a real gas. This can be seen by rewriting (7a) in the form ( P + 2πr3 0 u0 3v2 ) ≃ kT v ( 1 + 2π r3 0 3v ) ≃ kT v ( 1 − 2π r3 0 3v )−1 , which readily leads to the van der Waals equation of state ( P + a v2 ) (v − b) ≃ kT , (9) where a = 2π r3 0 u0 3 and b = 2πr3 0 3 ≡ 4v0. (10) 10.3 Evaluation of the virial coefﬁcients 311 1.5 0 \u00021.5 \u00023.0 \u00024.5 \u00026.0 12 5 10 H2 Classical Ar N2 CH4 He H2 Ne He 20 50 100 (kT/\u0002)(B2/r03) FIGURE 10.2 A dimensionless plot showing the temperature dependence of the second virial coefﬁcient of several gases (after Hirschfelder et al., 1954). We note that the parameter b in the van der Waals equation of state is exactly four times the actual molecular volume v0, the latter being the “volume of a sphere of diameter r0”; compare with Problem 1.4. We also note that in this derivation we have assumed that b ≪ v, which means that the gas is sufﬁciently dilute for the mean interparticle distance to be much larger than the effective range of the interparticle interaction. Finally, we observe that, according to this simple-minded calculation, the van der Waals parameters a and b are temperature-independent, which in reality is not true. A realistic study of the second virial coefﬁcient requires the use of a realistic potential, such as the one given by Lennard-Jones, for evaluating the integral in (1). This has indeed been done and the results obtained are shown in Figure 10.2, where the reduced coefﬁcient B′ 2(= B2/r3 0) is plotted against the reduced temperature T ′(= kT /ε): B′ 2(T ′) = 2π ∞∫ 0 ( 1 − e−u′(r′)/T ′ ) r′2 dr′, (11) with u ′(r′) = {( 1 r′ )12 − 2 ( 1 r′ )6} , (12) r′ being equal to (r/r0); expressed in this form, the quantity B′ 2 is a universal function of T ′. Included in the plot are experimental results for several gases. We note that in most cases the agreement is reasonably good; this is especially satisfying in view of the fact that in each case we had only two adjustable parameters, r0 and ε, against a much larger number of experimental points available. In the ﬁrst place, this agreement vindicates 312 Chapter 10. Statistical Mechanics of Interacting Systems the adequacy of the Lennard-Jones potential for providing an analytical description of a typical interparticle potential. Secondly, it enables one to derive empirical values of the respective parameters of the potential; for instance, one obtains for argon: r0 = 3.82 ˚A and ε/k = 120 K.7 One cannot fail to observe that the lighter gases, hydrogen and helium, constitute exceptions to the rather general rule of agreement between the theory and experiment. The reason for this lies in the fact that in the case of these gases quantum- mechanical effects assume considerable importance — more so at low temperatures. To substantiate this point, we have included in Figure 10.2 theoretical curves for H2 and He taking into account the quantum-mechanical effects as well; as a result, we ﬁnd once again a fairly good agreement between the theory and experiment. As regards higher-order virial coefﬁcients (l > 2), we conﬁne our discussion to a gas of hard spheres with diameter D. We then have u(r) = {0 if r > D, ∞ if r ≤ D, (13) and, hence, f (r) = { 0 if r > D, −1 if r ≤ D. (14) The second virial coefﬁcient of the gas is then given by a2 = 2πD3 3λ3 = 4 v0 λ3 ; (15) compare with equation (6). The third virial coefﬁcient can be determined with the help of equation (10.2.4), namely a3 = − 1 3λ6 ∞∫ 0 ∞∫ 0 f12 f13 f23 d3r12 d3 r13. (16) To evaluate this integral, we ﬁrst ﬁx the positions of particles 1 and 2 (such that r12 < D) and let particle 3 take all possible positions so that we can effect an integration over the variable r13; see Figure 10.3. Since our integrand is equal to −1 when each of the distances r13 and r23 (like r12) is less than D and 0 otherwise, we have a3 = 1 3λ6 D∫ r12=0 {∫ ′ d3r13 } d3r12, (17) where the primed integration arises from particle 3 taking all possible positions of interest. In view of the conditions r13 < D and r23 < D, this integral is precisely equal to the “volume 7Corresponding values for various other gases have been summarized in Hill (1960, p. 484). 10.3 Evaluation of the virial coefﬁcients 313 2 1 3 r23 r13 r12 FIGURE 10.3 dy 12 D\u0002r12 r12 D\u0002r12 y FIGURE 10.4 common to the spheres S1 and S2, each of radius D, centered at the ﬁxed points 1 and 2”; see Figure 10.4. This in turn can be obtained by calculating the “volume swept by the shaded area in the ﬁgure on going through a complete revolution about the line of centers.” One gets: ∫ ′ d3r13 = √[D2−(r12/2)2]∫ 0 {2 ( D2 − y2)1/2 − r12} 2πy dy. (18) While the quantity within the curly brackets denotes the length of the strip shown in the ﬁgure, the element of area 2π y dy arises from the revolution; the limits of integration for y can be checked rather easily. The evaluation of the integral (18) is straightforward; we get ∫ ′ d3r13 = 4π 3 { D3 − 3D2r12 4 + r3 12 16 } . (19) Substituting (19) into (17) and carrying out integration over r12, we ﬁnally obtain a3 = 5π 2D6 18λ6 = 5 8 a2 2. (20) 314 Chapter 10. Statistical Mechanics of Interacting Systems The fourth virial coefﬁcient of the hard-sphere gas has also been evaluated exactly. It is given by (Boltzmann, 1899; Majumdar, 1929) 8 a4 = { 1283 8960 + 3 2 · 73 √(2) + 1377{tan−1 √ (2) − π/4} 1120π } a3 2 = 0.28695a3 2. (21) The ﬁfth and sixth virial coefﬁcients of this system have been computed numerically, with the results (Ree and Hoover, 1964) a5 = (0.1103 ± 0.003)a4 2, (22) and a6 = (0.0386 ± 0.004)a5 2. (23) Ree and Hoover’s estimate of the seventh virial coefﬁcient is 0.0127a6 2. Terms up through 10th order have been determined numerically; see Hansen and McDonald (1986) and Malijevsky and Kolafa (2008). If the virial equation of state for hard spheres is written in terms of the volume packing fraction η = π nD3/6, the ﬁrst ten terms are P nkT = 1 + 4η + 10η2 + 18.364768η3 + 28.22445η4 + 39.81545η5 + 53.3418η6 + 68.534η7 + 85.805η8 + 105.8η9 + · · · . (24) Carnahan and Starling (1969) proposed a simple form for the equation of state that closely approximates all of the known virial coefﬁcients: P nkT ≈ 1 + η + η2 − η3 (1 − η)3 = 1 + 4η + 10η2 + 18η3 + 28η4 + 40η5 + 54η6 + 70η7 + 88η8 + 108η9 + 130η10 + · · · (25) This gives an excellent ﬁt to the hard sphere equation of state for the entire ﬂuid phase as determined in computer simulations. The ﬂuid phase is the equilibrium phase for 0 < η ≲ 0.491. The high-density equilibrium phase of hard spheres is a face-centered cubic solid; see Chapter 16. Many other approximate analytical forms have also been proposed to closely reproduce the virial series; see for instance Mulero et al. (2008). 8See also Katsura (1959). 10.4 General remarks on cluster expansions 315 10.4 General remarks on cluster expansions Shortly after the pioneering work of Mayer and his collaborators, Kahn and Uhlenbeck (1938) initiated the development of a similar treatment for quantum-mechanical systems. Of course, their treatment applied to the limiting case of classical systems as well but it faced certain inherent difﬁculties of analysis, some of which were later removed by the formal methods developed by Lee and Yang (1959a,b; 1960a,b,c). We propose to examine these developments in the next three sections of this chapter. First, however, we would like to make a few general observations on the problem of cluster expansions. These obser- vations, due primarily to Ono (1951) and Kilpatrick (1953), are of considerable interest insofar as they hold for a very large class of physical systems. For instance, the system may be quantum-mechanical or classical, it may be a multicomponent one or single- component, its molecules may be polyatomic or monatomic, and so on. All we have to assume is that (i) the system is gaseous in state and (ii) its partition functions QN (V , T ), for some low values of N, can somehow be obtained. We can then calculate the “cluster integrals” bl, and the virial coefﬁcients al, of the system in the following straightforward manner. Quite generally, the grand partition function of the system can be written as Q(z, V , T ) ≡ ∞∑ N=0 QN (V , T )zN = ∞∑ N=0 ZN (V , T ) N! ( z λ3 )N , (1) where we have introduced the “conﬁguration integrals” ZN (V , T ), deﬁned in analogy with equation (10.1.3) of the classical treatment: ZN (V , T ) ≡ N! λ3N QN (V , T ). (2) Dimensionally, the quantity ZN is like (a volume)N ; moreover, the quantity Z0 (like Q0) is supposed to be identically equal to 1, while Z1(≡ λ3Q1) is identically equal to V . We then have, in the limit V → ∞, P kT ≡ 1 V ln Q = 1 V ln {1 + Z1 1! ( z λ3 )1 + Z2 2! ( z λ3 )2 + · · · } (3) = 1 λ3 ∞∑ l=1 blzl, say. (4) Again, the last expression has been written in analogy with the classical expansion (10.1.34); the coefﬁcients bl may, therefore, be looked upon as the cluster integrals of the given system. Expanding (3) as a power series in z and equating respective coefﬁcients with 316 Chapter 10. Statistical Mechanics of Interacting Systems the bl of (4), we obtain b1 = 1 V Z1 ≡ 1, (5) b2 = 1 2! λ3V (Z2 − Z 2 1 ), (6) b3 = 1 3! λ6V (Z3 − 3Z2Z1 + 2Z 3 1 ), (7) b4 = 1 4! λ9V (Z4 − 4Z3Z1 − 3Z 2 2 + 12Z2Z 2 1 − 6Z 4 1 ), (8) and so on. We note that, for all l > 1, the sum of the coefﬁcients appearing within the parentheses is identically equal to zero. Consequently, in the case of an ideal classical gas, for which Zi ≡ V i, see equation (10.1.4), all cluster integrals with l > 1 vanish. This, in turn, implies the vanishing of all the virial coefﬁcients of the gas (except, of course, a1, which is identically equal to unity). Comparing equations (6) through (8) with equation (10.1.16), we ﬁnd that the expres- sions involving the products of the various Zi that appear within the parentheses play the same role here as “the sum of all possible l-clusters” does in the classical case. We there- fore expect that, in the limit V → ∞, the bl here would also be independent of the size and the shape of the container (unless the latter is unduly abnormal). This, in turn, requires that the various combinations of the Zi appearing within the parentheses here must all be proportional to the ﬁrst power of V . This observation leads to the very interesting result, ﬁrst noticed by Rushbrooke, namely bl = 1 l! λ3(l−1) × (the coefﬁcient of V l in the volume expansion of Zl). (9) At this stage, it seems worthwhile to point out that the expressions appearing within the parentheses of equations (6) through (8) are well-known in mathematical statistics as the semi-invariants of Thiele. The general formula for these expressions is (. . .)l ≡ bl{ l! λ3(l−1)V } = l! ∑′ {mi}(−1) 6imi−1 [(∑ i mi − 1 ) ! ∏ i { (Zi/i! )mi mi! }] , (10) where the primed summation goes over all sets {mi} that conform to the condition l∑ i=1 imi = l; mi = 0, 1, 2, . . . . (11) 10.4 General remarks on cluster expansions 317 Relations inverse to (10) can be written down by referring to equation (10.1.29) of the classical treatment; thus ZM ≡ M! λ3M QM = M! λ 3M ∑′ {ml} M∏ l=1    (V bl/λ3)ml ml!    , (12) where the primed summation goes over all sets {ml} that conform to the condition M∑ l=1 lml = M; ml = 0, 1, 2 . . . . (13) The calculation of the virial coefﬁcients al now consists of a straightforward step that involves a use of formulae (5) through (8) in conjunction with formulae (10.2.2) through (10.2.5). It appears, however, of interest to demonstrate here the manner in which the gen- eral relationship (10.2.6) between the virial coefﬁcients al and the “irreducible cluster inte- grals” βl−1 arises mathematically. As a bonus, we will acquire yet another interpretation of the βk. Now, in view of the relations P kT ≡ Lim V →∞ ( 1 V ln Q) = 1 λ3 ∞∑ l=1 blzl (14) and 1 v ≡ Lim V →∞ ( z V ∂ ln Q ∂z ) = 1 λ3 ∞∑ l=1 l blzl, (15) we can write P(z) kT = z∫ 0 1 v(z) dz z . (16) We introduce a new variable x, deﬁned by x = nλ 3 = λ3/v. (17) In terms of this variable, equation (15) becomes x(z) = ∞∑ l=1 l blzl, (18) the inverse of which may be written (see Mayer and Harrison, 1938; Harrison and Mayer, 1938; also Kahn, 1938) as z(x) = x exp{−φ(x)}. (19) 318 Chapter 10. Statistical Mechanics of Interacting Systems In view of the fact that, for z ≪ 1, the variables z and x are practically the same, the function φ(x) must tend to zero as x → 0; it may, therefore, be expressed as a power series in x: φ(x) = ∞∑ k=1 βkxk. (20) It may be mentioned beforehand that the coefﬁcients βk of this expansion are ulti- mately going to be identiﬁed with the “irreducible cluster integrals” βl−1. Substituting from equations (17), (19), and (20) into equation (16), we get P(x) kT = x∫ 0 x λ3 { 1 x − φ′(x) } dx = 1 λ3  x − x∫ 0    ∞∑ k=1 kβkxk    dx   = x λ3  1 − ∞∑ k=1 ( k k + 1 βkxk)  . (21) Combining (17) and (21), we obtain Pv kT = 1 − ∞∑ k=1 ( k k + 1 βkxk) . (22) Comparing this result with the virial expansion (10.2.1), we arrive at the desired relation- ship: al = − l − 1 l βl−1 (l > 1). (23) For obvious reasons, the βk appearing here may be regarded as a generalization of the irreducible cluster integrals of Mayer. Finally, we would like to derive a relationship between the βk and the bl. For this, we make use of a theorem due to Lagrange which, for the present purpose, states that “the solution x(z) to the equation z(x) = x/f (x) (24) is given by the series x(z) = ∞∑ j=1 zj j! [ dj−1 dξ j−1 {f (ξ )} j] ” ξ =0 ; (25) it is obvious that the expression within the square brackets is ( j − 1)! times “the coefﬁcient of ξ j−1 in the Taylor expansion of the function { f (ξ )}j about the point ξ = 0.” Applying this 10.4 General remarks on cluster expansions 319 theorem to the function f (x) = exp{φ(x)} = exp    ∞∑ k=1 βkxk    = ∞∏ k=1 exp(βkxk), (26) we obtain x(z) = ∞∑ j=1 zj j! ( j − 1)! ×    the coefﬁcient ofξ j−1 in the Taylor expansion of ∞∏ k=1 exp( jβkξ k) about ξ = 0    . Comparing this with equation (18), we get bj = 1 j2 ×    the coefﬁcient of ξ j−1 in ∞∏ k=1   ∑ mk≥0 ( jβk)mk mk! ξ kmk      = 1 j2 ∑′ {mk} j−1∏ k=1 ( jβk)mk mk! , (27) where the primed summation goes over all sets {mk} that conform to the condition j−1∑ k=1 kmk = j − 1; mk = 0, 1, 2, . . . . (28) Formula (27) was ﬁrst obtained by Maria Goeppert-Mayer in 1937. Its inverse, however, was established much later (Mayer et al., 1942; Kilpatrick, 1953): βl−1 = ∑′ {mi}(−1) 6imi−1 (l − 2 + 6imi)! (l − 1)! ∏ i (i bi)mi mi! , (29) where the primed summation goes over all sets {mi} that conform to the condition l∑ i=2(i − 1)mi = l − 1; mi = 0, 1, 2, . . . . (30) It is not difﬁcult to see that the highest value of the index i in the set {mi} would be l (the corresponding set having all its mi equal to 0, except ml which would be equal to 1); accordingly, the highest order to which the quantities bi would appear in the expression for βl−1 is that of bl. We thus see, once again, that the virial coefﬁcient al is completely determined by the quantities b1, b2, . . . , bl. 320 Chapter 10. Statistical Mechanics of Interacting Systems 10.5 Exact treatment of the second virial coefﬁcient We now present a formulation, originally from Uhlenbeck and Beth (1936) and Beth and Uhlenbeck (1937), that enables us to make an exact calculation of the second virial coefﬁ- cient of a quantum-mechanical system from a knowledge of the two-body potential u(r). 9 In view of equation (10.4.6), b2 = −a2 = 1 2λ3V (Z2 − Z 2 1 ) . (1) For the corresponding noninteracting system, one would have b (0) 2 = −a(0) 2 = 1 2λ3V ( Z (0) 2 − Z (0)2 1 ) ; (2) the superscript (0) on the various symbols here implies that they pertain to the noninteract- ing system. Combining (1) and (2), and remembering that Z1 = Z (0) 1 = V , we obtain b2 − b (0) 2 = 1 2λ3V (Z2 − Z (0) 2 ) (3) which, by virtue of relation (10.4.2), becomes b2 − b(0) 2 = λ3 V (Q2 − Q(0) 2 ) = λ3 V Tr ( e−β ˆH2 − e−β ˆH(0) 2 ). (4) For evaluating the trace in (4), we need to know the eigenvalues of the two-body Hamiltonian which, in turn, requires solving the Schr¨odinger equation10 ˆH29α(r1, r2) = Eα9α(r1, r2), (5) where ˆH2 = − ℏ2 2m ( ∇2 1 + ∇2 2 ) + u(r12). (6) Transforming to the center-of-mass coordinates R {= 1 2 (r1 + r2) } and the relative coordi- nates r{= (r2 − r1)}, we have 9α(R, r) = ψj(R)ψn(r) = { 1 V 1/2 ei(Pj·R)/ℏ} ψn(r), (7) with Eα = P2 j 2(2m) + εn. (8) 9For a discussion of the third virial coefﬁcient, see Pais and Uhlenbeck (1959). 10For simplicity, we assume the particles to be “spinless.” For the inﬂuence of spin, see Problems 10.11 and 10.12. 10.5 Exact treatment of the second virial coefﬁcient 321 Here, P denotes the total momentum of the two particles and 2m their total mass, while ε denotes the energy associated with the relative motion of the particles; the symbol α refers to the set of quantum numbers j and n that determine the actual values of the variables P and ε. The wave equation for the relative motion will be   − ℏ2 2 ( 1 2 m) ∇2 r + u(r)    ψn(r) = εnψn(r), (9) 1 2 m being the reduced mass of the particles; the normalization condition for the relative wavefunction will be ∫ |ψn(r)|2d3r = 1. (10) Equation (4) thus becomes b2 − b (0) 2 = λ3 V ∑ α { e−βEα − e−βE(0) α } = λ3 V ∑ j e−βP2 j /4m ∑ n {e−βεn − e−βε(0) n } . (11) For the ﬁrst sum, we obtain ∑ j e−βP2 j /4m ≈ 4π V h3 ∞∫ 0 e−βP2/4mP2dP = 81/2V λ3 , (12) so that equation (11) becomes b2 − b (0) 2 = 8 1/2 ∑ n { e−βεn − e−βε(0) n } . (13) The next step consists of examining the energy spectra, εn and ε(0) n , of the two systems. In the case of a noninteracting system, all we have is a “continuum” ε(0) n = p2 2 ( 1 2 m ) = ℏ2k2 m (k = p/ℏ), (14) with the standard density of states g(0)(k). In the case of an interacting system, we may have a set of discrete eigenvalues εB (that correspond to “bound” states), along with a “continuum” εn = ℏ2k2 m (k = p/ℏ), (15) 322 Chapter 10. Statistical Mechanics of Interacting Systems with a characteristic density of states g(k). Consequently, equation (13) can be written as b2 − b (0) 2 = 8 1/2 ∑ B e−βεB + 8 1/2 ∞∫ 0 e−βℏ2k2/m{g(k) − g(0)(k)} dk, (16) where the summation in the ﬁrst part goes over all bound states made possible by the two-body interaction. The next thing to consider here is the density of states g(k). For this, we note that, since the two-body potential is assumed to be central, the wavefunction ψn(r) for the relative motion may be written as a product of a radial function χ(r) and a spherical harmonic Y (θ , ϕ): ψklm(r) = Aklm χkl(r) r Yl,m(θ , ϕ). (17) Moreover, the requirement of symmetry, namely ψ(−r) = ψ(r) for bosons and ψ(−r) = −ψ(r) for fermions, imposes the restriction that the quantum number l be even for bosons and odd for fermions. The (outer) boundary condition on the wavefunction may be written as χkl(R0) = 0, (18) where R0 is a fairly large value (of the variable r) that ultimately goes to inﬁnity. Now, the asymptotic form of the function χkl(r) is well-known: χkl(r) ∝ sin { kr − lπ 2 + ηl(k) } ; (19) accordingly, we must have kR0 − lπ 2 + ηl(k) = nπ, n = 0, 1, 2, . . . . (20) The symbol ηl(k) here stands for the scattering phase shift due to the two-body potential u(r) for the lth partial wave of wave number k. Equation (20) determines the full spectrum of the partial waves. To obtain from it an expression for the density of states gl(k), we observe that the wave number difference 1k between two consecutive states n and n + 1 is given by the formula { R0 + dηl(k) dk } 1k = π , (21) with the result that gl(k) = 2l + 1 1k = 2l + 1 π {R0 + ∂ηl(k) ∂k } ; (22) 10.5 Exact treatment of the second virial coefﬁcient 323 the factor (2l + 1) has been included here to take account of the fact that each eigenvalue k pertaining to an lth partial wave is (2l + 1)-fold degenerate (because the magnetic quan- tum number m can take any of the values l, (l − 1), . . . , −l, without affecting the eigenvalue). The total density of states, g(k), of all partial waves of wave numbers around the value k is then given by g(k) = ∑′ l gl(k) = 1 π ∑′ l (2l + 1) { R0 + ∂ηl(k) ∂k } ; (23) note that the primed summation ∑′ goes over l = 0, 2, 4, . . . in the case of bosons and over l = 1, 3, 5, . . . in the case of fermions. For the corresponding noninteracting case, we have (since all ηl(k) = 0) g(0)(k) = R0 π ∑′ l (2l + 1). (24) Combining (23) and (24), we obtain g(k) − g(0)(k) = 1 π ∑′ l (2l + 1) ∂ηl(k) ∂k . (25) Substituting (25) into (16), we obtain the desired result b2 − b (0) 2 = 8 1/2 ∑ B e−βεB + 81/2 π ∑′ l (2l + 1) ∞∫ 0 e−βℏ2k2/m ∂ηl(k) ∂k dk (26) which, in principle, is calculable for any given potential u(r) through the respective phase shifts ηl(k). Equation (26) can be used for determining the quantity b2 − b (0) 2 . To determine b2 itself, we must know the value of b(0) 2 . This has already been obtained in Section 7.1 for bosons and in Section 8.1 for fermions; see equations (7.1.13) and (8.1.17). Thus b (0) 2 = −a(0) 2 = ± 1 25/2 , (27) where the upper sign holds for bosons and the lower sign for fermions. It is worthwhile to note that the foregoing result can be obtained directly from the relationship b (0) 2 = 1 2λ3V (Z (0) 2 − Z (0)2 1 ) = λ3 V (Q(0) 2 − 1 2 Q(0)2 1 ) 324 Chapter 10. Statistical Mechanics of Interacting Systems by substituting for Q(0) 2 the exact expression (5.5.25): b (0) 2 = λ3 V [{ 1 2 ( V λ3 )2 ± 1 25/2 ( V λ3 )1} − 1 2 ( V λ3 )2] = ± 1 25/2 . (28)11 It is of interest to note that this result can also be obtained by using the classical for- mula (10.1.18) and substituting for the two-body potential u(r) the “statistical potential” (5.5.28); thus b (0) 2 = 2π λ3 ∞∫ 0 (e−us(r)/kT − 1 ) r2dr = ± 2π λ3 ∞∫ 0 e−2πr2/λ2 r2dr = ± 1 25/2 . (29) As an illustration of this method, we now calculate the second virial coefﬁcient of a gas of hard spheres. The two-body potential in this case may be written as u(r) = { +∞ for r < D 0 for r > D. (30) The scattering phase shifts ηl(k) can now be determined by making use of the (inner) boundary condition, namely χ(r) = 0 for all r < D and hence it vanishes as r → D from the above. We thus obtain (see, for example, Schiff, 1968) ηl(k) = tan −1 jl(kD) nl(kD) , (31) where jl(x) and nl(x) are, respectively, the “spherical Bessel functions” and the “spherical Neumann functions”: j0(x) = sin x x , j1(x) = sin x − x cos x x2 , j2(x) = (3 − x2) sin x − 3x cos x x3 , . . . and n0(x) = − cos x x , n1(x) = − cos x + x sin x x2 , n2(x) = − (3 − x2) cos x + 3x sin x x3 , . . . . 11This calculation incidentally veriﬁes the general formula (10.4.9) for the case l = 2. By that formula, the “cluster integral” b2 of a given system would be equal to 1/(2λ3) times the coefﬁcient of V 1 in the volume expansion of the “conﬁguration integral” Z2 of the system. In the case under study, this coefﬁcient is ±λ3/23/2; hence the result. 10.6 Cluster expansion for a quantum-mechanical system 325 Accordingly, η0(k) = tan −1{− tan(kD)} = −kD, (32) η1(k) = tan −1 { − tan(kD) − kD 1 + kD tan(kD) } = −{kD − tan −1(kD)} = − (kD) 3 3 + (kD)5 5 − · · · , (33) η2(k) = tan −1 { − tan(kD) − 3(kD)/[3 − (kD)2] 1 + 3(kD) tan(kD)/[3 − (kD)2] } = − { kD − tan −1 3(kD) 3 − (kD)2 } = − (kD)5 45 + · · · , (34) and so on. We now have to substitute these results into formula (26). However, before doing that we should point out that, in the case of hard-sphere interaction, (i) we cannot have bound states at all and (ii) since, for all l, ηl(0) = 0, the integral in (26) can be simpliﬁed by a prior integration by parts. Thus, we have b2 − b (0) 2 = 81/2λ2 π 2 ∑′ l (2l + 1) ∞∫ 0 e−βℏ2k2/mηl(k)k dk. (35) Substituting for l = 0 and 2 in the case of bosons and for l = 1 in the case of fermions, we obtain (to ﬁfth power in D/λ) b2 − b (0) 2 = −2 ( D λ )1 − 10π 2 3 ( D λ )5 − · · · (Bose) (36) = −6π ( D λ )3 + 18π 2 ( D λ )5 − · · · (Fermi), (37) which may be compared with the corresponding classical result −(2π/3)(D/λ)3. 10.6 Cluster expansion for a quantum-mechanical system When it comes to calculating bl for l > 2 we have no formula comparable in simplicity to formula (10.5.26) for b2. This is due to the fact that we have no treatment of the l-body problem (for l > 2) that is as neat as the phase-shift analysis of the two-body problem. Nevertheless, a formal theory for the calculation of higher-order “cluster integrals” has been developed by Kahn and Uhlenbeck (1938); an elaboration by Lee and Yang (1959a,b; 1960a,b,c) has made this theory almost as good for treating a quantum-mechanical sys- tem as Mayer’s theory has been for a classical gas. The basic approach in this theory is to 326 Chapter 10. Statistical Mechanics of Interacting Systems evolve a scheme for expressing the grand partition function of the given system in essen- tially the same way as Mayer’s cluster expansion does for a classical gas. However, because of the interplay of quantum-statistical effects and the effects arising from interparticle interactions, the mathematical structure of this theory is considerably involved. We consider here a quantum-mechanical system of N identical particles enclosed in a box of volume V . The Hamiltonian of the system is assumed to be of the form ˆHN = − ℏ2 2m N∑ i=1 ∇2 i + ∑ i<j u(rij). (1) Now, the partition function of the system is given by QN (V , T ) ≡ Tr(e−β ˆHN ) = ∑ α e−βEα = ∑ α ∫ V {9∗ α(1, . . . , N)e−β ˆHN 9α(1, . . . , N)}d3N r, (2) where the functions 9α are supposed to form a complete set of (properly symmetrized) orthonormal wavefunctions of the system, while the numbers 1, . . . , N denote the posi- tion coordinates r1, . . . , rN , respectively. We may as well introduce the probability density operator ˆWN of the system through the matrix elements ⟨1′, . . . , N ′| ˆWN |1, . . . , N⟩ ≡ N! λ3N ∑ α {9α(1 ′, . . . , N ′)e−β ˆHN 9∗ α(1, . . . , N)} = N! λ3N ∑ α {9α(1 ′, . . . , N ′)9∗ α(1, . . . , N)}e−βEα . (3) We denote the diagonal elements of the operator ˆWN by the symbols WN (1, . . . , N); thus WN (1, . . . , N) = N! λ 3N ∑ α {9α(1, . . . , N)9∗ α(1, . . . , N)}e−βEα , (4) whereby equation (2) takes the form QN (V , T ) = 1 N! λ3N ∫ V WN (1, . . . , N)d3N r = 1 N! λ3N Tr ( ˆWN ). (5) A comparison of equation (5) with equations (10.1.3) and (10.4.2) shows that the “trace of the probability density operator ˆWN ” is the analogue of the “conﬁguration integral” ZN , and the quantity WN (1, . . . , N)d3N r is a measure of the probability that the “conﬁguration” of the given system is found to be within the interval [(r1, . . . , rN ), (r1 + dr1, . . . , rN + drN )]. Before we proceed further, let us acquaint ourselves with some of the basic properties of the matrix elements (3): 10.6 Cluster expansion for a quantum-mechanical system 327 (i) ⟨1 ′| ˆW1|1⟩ = λ 3 ∑ p { 1 √ V ei(p·r′ 1)/ℏ 1 √ V e−i(p·r1)/ℏ} e−βp2/2m ≃ λ3 V +∞∫∫∫ −∞ Vd3p h3 e{ip·(r′ 1−r1)/ℏ−βp2/2m} = e−π |r′ 1−r1|2/λ2 ; (6) compare with equation (5.3.14) for the density matrix of a single particle. The foregoing result is a manifestation of the quantum-mechanical, not quantum-statistical, correlation between the positions r and r′ of a given particle (or, for that matter, any particle in the system). This correlation extends over distances of the order of λ which is, therefore, a measure of the linear dimensions of the wave packet representing the particle. As T → ∞, and hence λ → 0, the matrix element (6) tends to zero for all ﬁnite values of |r′ 1 − r1|. (ii) ⟨1| ˆW1|1⟩ = 1; (7) consequently, by equation (5), Q1(V , T ) = 1 λ3 ∫ V 1d3r = V λ3 . (8) (iii) Whatever the symmetry character of the wavefunctions 9, the diagonal elements WN (1, . . . , N) of the probability density operator ˆWN are symmetric in respect of a permutation among the arguments (1, . . . , N). (iv) The elements WN (1, . . . , N) are invariant under a unitary transformation of the set {9α}. (v) Suppose that the coordinates r1, . . . , rN are such that they can be divided into two groups, A and B, with the property that any two coordinates, say ri and rj, of which one belongs to group A and the other to group B, satisfy the conditions that (a) the separation rij is much larger than the mean thermal wavelength λ of the particles, and (b) it is also much larger than the effective range r0 of the two-body potential, then WN (r1, . . . , rN ) ≃ WA(rA)WB(rB), (9) where rA and rB denote collectively the coordinates in group A and group B, respectively. It is not easy to furnish here a rigorous mathematical proof of this property, though physically it is quite understandable. One can see this by noting that, in view of conditions (a) and (b), there does not exist any spatial correlation between the particles of group A on one hand and the particles of group B on the other (either by virtue of statistics or by virtue of interparticle interactions). The two groups, therefore, behave toward each other like two independent entities. It is then 328 Chapter 10. Statistical Mechanics of Interacting Systems natural that, to a very good approximation, the probability density WN of the composite conﬁguration be equal to the product of the probability densities WA and WB. We now proceed with the formulation. First of all, to ﬁx ideas about the approach to be followed, we may consider the case with N = 2. In that case, as r12 → ∞, we expect, in view of property (v), that W2(1, 2) → W1(1)W1(2) = 1. (10) In general, however, W2(1, 2) will be different from W1(1)W1(2). Now, if we denote the difference between W2(1, 2) and W1(1)W1(2) by the symbol U2(1, 2), then, as r12 → ∞, U2(1, 2) → 0. (11) It is not difﬁcult to see that the quantity U2(1, 2) is the quantum-mechanical analogue of the Mayer function fij. With this in mind, we introduce a sequence of cluster functions ˆUl deﬁned by the hierarchy12 ⟨1 ′| ˆW1|1⟩ = ⟨1′| ˆU1|1⟩, (12) ⟨1 ′, 2′| ˆW2|1, 2⟩ = ⟨1′| ˆU1|1⟩⟨2′| ˆU1|2⟩ + ⟨1 ′, 2′| ˆU2|1, 2⟩, (13) ⟨1 ′, 2′, 3′| ˆW3|1, 2, 3⟩ = ⟨1′| ˆU1|1⟩⟨2′| ˆU1|2⟩⟨3′| ˆU1|3⟩ + ⟨1 ′| ˆU1|1⟩⟨2 ′, 3′| ˆU2|2, 3⟩ + ⟨2′| ˆU1|2⟩⟨1′, 3′| ˆU2|1, 3⟩ + ⟨3′| ˆU1|3⟩⟨1′, 2′| ˆU2|1, 2⟩ + ⟨1′, 2′, 3′| ˆU3|1, 2, 3⟩, (14) and so on. A particular ˆUl is thus deﬁned with the help of the ﬁrst l equations of the hierarchy. The last equation in this hierarchy will be (writing only the diagonal elements) WN (1, . . . , N) = ∑′ {ml} {∑ P [U1( ) · · · U1( ) m1 factors ][U2( ) · · · U2( ) m2 factors ] · · · } , (15) where the primed summation goes over all sets {ml} that conform to the condition N∑ l=1 lml = N; ml = 0, 1, 2, . . . . (16) 12The functions Ul were ﬁrst introduced by Ursell, in 1927, in order to simplify the classical conﬁguration integral. Their introduction into the quantum-mechanical treatment is due to Kahn and Uhlenbeck (1938). 10.6 Cluster expansion for a quantum-mechanical system 329 Moreover, in selecting the arguments of the various Ul appearing in (15), out of the num- bers 1, . . . , N, one has to remember that a permutation of the arguments within the same bracket is not regarded as leading to anything distinctly different from what one had before the permutation; the symbol ∑P then denotes a summation over all distinct ways of selecting the arguments under the set {ml}. Relations inverse to the preceding ones are easy to obtain. One gets ⟨1 ′| ˆU1|1⟩ = ⟨1 ′| ˆW1|1⟩, (17) ⟨1 ′, 2′| ˆU2|1, 2⟩ = ⟨1 ′, 2′| ˆW2|1, 2⟩ − ⟨1 ′| ˆW1|1⟩⟨2 ′| ˆW1|2⟩, (18) ⟨1 ′, 2′, 3′| ˆU3|1, 2, 3⟩ = ⟨1 ′, 2′, 3′| ˆW3|1, 2, 3⟩ − ⟨1 ′| ˆW1|1⟩⟨2 ′, 3′| ˆW2|2, 3⟩ − ⟨2 ′| ˆW1|2⟩⟨1 ′, 3′| ˆW2|1, 3⟩ − ⟨3 ′| ˆW1|3⟩⟨1 ′, 2′| ˆW2|1, 2⟩ + 2⟨1′| ˆW1|1⟩⟨2′| ˆW1|2⟩⟨3 ′| ˆW1|3⟩, (19) and so on; compare the right sides of these equations with the expressions appear- ing within the parentheses in equations (10.4.5) through (10.4.7). We note that (i) the coefﬁcient of a general term here is (−1) ∑ l ml−1( ∑ l ml − 1 )! , (20) where ∑l ml is the number of the Wn in the term, and (ii) the sum of the coefﬁcients of all the terms on the right side of equations (18), (19), . . . is identically zero. Moreover, the diagonal elements Ul(1, . . . , l), just like the diagonal elements of the operators ˆWn, are sym- metric in respect of permutations among the arguments (1, . . . , l), and are determined by the sequence of the diagonal elements W1, W2, . . . , Wl. Finally, in view of property (v) of the Wn, as embodied in formula (9), the Ul possess the following property: Ul(1, . . . , l) ≃ 0 if rij ≫ λ, r0; (21) here, rij is the separation between any two of the coordinates (1, . . . , l ). 13 We now deﬁne the “cluster integral” bl by the formula bl(V , T ) = 1 l! λ3(l−1)V ∫ Ul(1, . . . , l )d3lr; (22) compare with equation (10.1.16). Clearly, the quantity bl(V , T ) is dimensionless and, by virtue of property (21) of the diagonal elements Ul(1, . . . , l), is practically independent of V (so long as V is large). In the limit V → ∞, bl(V , T ) tends to a ﬁnite volume-independent 13This can be seen by examining the break-up of the structure on the right side of any equation in the hierarchy (18, 19, . . .) when one or more of the l coordinates in the “cluster” get sufﬁciently separated from the rest. 330 Chapter 10. Statistical Mechanics of Interacting Systems value, which may be denoted by bl(T ). We then obtain for the partition function of the system, see equations (5) and (15), QN (V , T ) = 1 N! λ3N ∫ d3N r {∑′ {ml} [ ∑ P [U1 · · · U1][U2 · · · U2] · · · ]} (23) = 1 N! λ3N ∑′ {ml} N! (1! )m1 (2! )m2 · · · m1! m2! · · · × ∫ d3N r{[U1 · · · U1][U2 · · · U2] · · · }. (24) In writing the last result we have made use of the fact that, since a permutation among the arguments of the functions Ul does not affect the value of the integral concerned, the summation over P may be replaced by any one term of the summation, multiplied by the number of distinct permutations allowed by the set {ml}; compare with the corre- sponding product of the numbers (10.1.22) and (10.1.24). Making use of the deﬁnition (22), equation (24) can be written as QN (V , T ) = 1 λ3N ∑′ {ml}   N∏ l=1 {blλ3(l−1)V )ml /ml! }   = ∑′ {ml}   N∏ l=1 {( bl V λ3 )ml 1 ml! }   ; (25) again, use has been made of the fact that ∏ l (λ 3l) ml = λ 3 ∑ l lml = λ 3N . (26) Equation (25) is formally identical to equation (10.1.29) of Mayer’s theory. The subsequent development of the formalism, leading to the equation of state of the system, is formally identical to that theory. Thus, we ﬁnally obtain P kT = 1 λ3 ∞∑ l=1 blzl and 1 v = 1 λ3 ∞∑ l=1 l blzl. (27) There are, however, important physical differences. We may recall that the calculation of the cluster integrals bl in the classical case involved the evaluation of a number of ﬁnite, 3l-dimensional integrals. The corresponding calculation in the quantum-mechanical case requires a knowledge of the functions Ul and hence of all Wn, with n ≤ l; this in turn requires solutions of the n-body Schr¨odinger equation for all n ≤ l. The case l = 2 can be handled neatly, as was done in Section 10.5. For l > 2, the mathematical procedure is rather cumbersome. Nevertheless, Lee and Yang (1959a,b; 1960a,b,c) have evolved a scheme that enables us to calculate the higher bl in successive approximations. According 10.7 Correlations and scattering 331 to that scheme, the functions Ul of a given system can be evaluated by “separating out” the effects of statistics from those of interparticle interactions, that is, we ﬁrst take care of the statistical aspect of the problem and then tackle the dynamical aspect of it. Thus, the whole feat is accomplished in two steps. First, the U-functions pertaining to the given system are expressed in terms of U- functions pertaining to a corresponding quantum-mechanical system obeying Boltzmann statistics, that is, a (ﬁctitious) system described by unsymmetrized wavefunctions. This step takes care of the statistics of the given system, that is, of the symmetry properties of the wavefunctions describing the system. Next, the U-functions of the (ﬁctitious) Boltz- mannian system are expanded, loosely speaking, in powers of a binary kernel B which is obtainable from a solution of the two-body problem with the given interaction. A com- mendable feature of this method is that it can be applied even if the given interaction contains a singular, repulsive core, that is, even if the potential energy for certain conﬁgu- rations of the system becomes inﬁnitely large. Though the method is admirably systematic and fairly straightforward in principle, its application to real systems is quite complicated. We will, therefore, turn to a more practical method — the method of quantized ﬁelds (see Chapter 11) — which has been extremely useful in the study of quantum-mechanical sys- tems composed of interacting particles. For a detailed exposition of the (binary collision) method of Lee and Yang, see Sections 9.7 and 9.8 of the ﬁrst edition of this book. In passing, we note yet another important difference between the quantum- mechanical case and the classical one. In the latter case, if interparticle interactions are absent, then all bl, with l ≥ 2, vanish. This is not true in the quantum-mechanical case; here, see Sections 7.1 and 8.1, b (0) l = (±1) l−1l−5/2, (28) of which equation (10.5.27) was a special case. 10.7 Correlations and scattering Correlations and scattering play an extremely important role in modern statistical mechanics. Different phases most are easily distinguished by different spatial orderings they display. Molecules in a low-density vapor are nearly uncorrelated whereas molecules in a dense liquid can be strongly correlated and display short-range order due to their strong steric repulsions but the correlations decay away rapidly at large distances. In crys- talline solids, the location of every particle is highly correlated with the location of all the others, and these correlations do not decay away to zero at large distances between the particles; this is called long-range order. At a critical point, systems display order that lies between short-range and long-range, with so-called quasi-long-range order characterized by a power-law decay of correlations. Crystals and liquid-crystal phases display molecu- lar orientational correlations that can be short-range, long-range, or quasi-long-range in addition to the various spatial orderings of the molecules. Different phases of magnets 332 Chapter 10. Statistical Mechanics of Interacting Systems are distinguished by the spatial orderings of the magnetic dipoles: short-range ordering in paramagnets, long-range ordering in ferromagnets and antiferromagnets, and power-law decay of correlations at magnetic critical points. Spatial correlation functions are based on n-particle densities. The one-body number density is deﬁned by the average quantity n1(r) = 〈∑ i δ(r − ri) 〉 . (1) This deﬁnes the local number density in which n1(r)dr is a measure of the probabil- ity of ﬁnding a particle inside an inﬁnitesimal volume dr located at position r. If the system is translationally invariant, the one-body density is the usual number density n1(r) = n = ⟨N⟩/V . The spatial integral of the one-body density over volume V gives the average number of particles in that volume: ∫ n1(r)dr = ⟨N⟩ . (2) The two-body number density is deﬁned as n2(r, r′) = 〈 ∑ i̸=j δ(r − ri)δ(r ′ − rj) 〉 . (3) The quantity n2(r, r ′)drdr ′ is a measure of the probability of ﬁnding one particle inside the inﬁnitesimal volume dr located at position r and another particle inside the inﬁnitesimal volume dr ′ located at position r ′. In a dilute classical gas, the particles interact only when they are close to one another, so the probability of ﬁnding two different particles at two different locations many atomic diameters apart is simply the product of ﬁnding either particle individually, that is, n2(r, r ′) → n1(r)n1(r ′) as |r − r′| → ∞. It is the deviation from this uncorrelated behavior that is both interesting and important. The integral of the two- body density over volume V gives ∫ n2(r, r′)drdr ′ = 〈N 2〉 − ⟨N⟩ . (4) If the system is translationally and rotationally invariant, the one-body number density is independent of position and the two-body number density depends only on the magni- tude of the distance between r and r ′. This allows us to deﬁne the pair correlation function g(r): n2(r, r ′) = n 2g (∣ ∣r − r ′∣ ∣ ) . (5) 10.7 Correlations and scattering 333 6 5 4 3 2 1 0012 3 4 5 r/D g (r) FIGURE 10.5 An approximate pair correlation function for hard spheres with diameter D in three dimensions. The volume fraction η = πnD3/6 ≃ 0.49 is the fraction of the volume occupied by the particles and is close to the liquid side of the solid-liquid phase transition in the model. The correlation function is calculated using the exact solution of the Percus–Yevick approximation; see Percus and Yevick (1958), Wertheim (1963), and Hansen and McDonald (1986). The correlation length for this case is ξ ≈ 2D. In three dimensions, 4πnr2 g(r) dr is the probability of ﬁnding a particle in a spherical shell of radius r and thickness dr, given that another particle is simultaneously located at the origin. The pair correlation function of a classical ideal gas is equal to unity; see the footnote to Problem 10.17. Figure 10.5 displays the pair correlation function g(r) for a system of hard spheres interacting via pair potential u(r) = {0 if r > D, ∞ if r ≤ D. (6) Clearly, the pair correlation function vanishes for r < D since no two particles in the system can be closer to each other than D due to the inﬁnite repulsion. These steric repulsions result in an oscillatory decay of g(r). The pair correlation function is greater than unity at separations slightly greater than D since the local geometry of the ﬂuid enhances the probability of ﬁnding two particles a distance slightly more than D apart; for illustration, see Figure 10.6. The pair correlation function is less than unity at slightly larger distances due to the repulsion of the cluster of particles just outside the hard repulsion distance. The oscillating correlations decay rapidly with distance, so that g(r) approaches unity at large separations. This behavior of the pair correlation function is typical of all dense ﬂuids 334 Chapter 10. Statistical Mechanics of Interacting Systems FIGURE 10.6 An equilibrium conﬁguration of hard disks that displays steric effects leading to oscillations in the pair correlation function. The inner dashed circle with radius D is the closest approach distance to the central disk. In this case, the centers of ﬁve disks are close to the distance D which contributes to the enhancement in g(r) near r = D. The outer dashed circle shows the next shell of particles that contribute to the second peak in g(r). In-between these distances, we have a reduced probability of ﬁnding the center of a particle, leading to g(r) < 1. and is called short-range order since the correlations decay exponentially with distance: g(r) − 1 ∼ exp (−r/ξ ), where ξ is called the correlation length. The pair correlation function can be used to directly calculate the pressure in a ﬂuid. For a classical ﬂuid whose potential energy can be written as a sum of pair potentials, UN (r1, r2, . . . , rN ) = ∑ i<j u(rij), (7) the pressure is determined by the average of the quantity r(∂u/∂r) between pairs of par- ticles, as discussed in Section 3.7. In the canonical ensemble, the pressure P is given by P ≡ − ( ∂A ∂V ) T ,N = kT ZN ( ∂ZN ∂V ) T ,N , (8) where ZN is the conﬁgurational partition function ZN = 1 N! ∫ dN r exp  −β ∑ i<j u(rij)  . (9) The d-dimensional integrals over the volume V can be rewritten in terms of a set of scaled variables {si} deﬁned by ri = V 1/dsi, so the scaled integrals are over regions with unit 10.7 Correlations and scattering 335 volume: ZN = V N N! ∫ dN s exp  −β ∑ i<j u(V 1/dsij)  . (10) Equations (8) and (10) then give P = nkT ( 1 − n 2dkT ∫ du dr rg(r)dr) . (11) This is called the virial equation of state and is useful for determining pressure from approximate expressions for the pair correlation function. Compare equation (11) with the form of the virial equation of state in equation (3.7.15). For the particular case of hard spheres, the discontinuous potential results in the pres- sure being determined by the pair correlation function at contact. In one, two, and three dimensions, the hard sphere pressure is given by PHS nkT =    1 + ηg(D+) η = nD d = 1, 1 + 2ηg(D+) η = π 4 nD2 d = 2, 1 + 4ηg(D+) η = π 6 nD3 d = 3, (12) where g(D+) is the correlation function at contact and η is the volume fraction, that is, the fraction of the d-dimensional volume of the sample occupied by the spheres; see Problem 10.14. Likewise, the internal energy of the ﬂuid can be written as an integral over the pair correlation function and the pair potential: U(N, V , T ) = ⟨H⟩ = dNkT 2 + nN 2 ∫ u(r)g(r)dr. (13) The pair correlation function itself contains all the statistical information needed to construct the full thermodynamic behavior of the system. For example, equation (4) can be used to show that the isothermal compressibility, which is proportional to the number density ﬂuctuations, is also proportional to an integral over the pair correlation function: nkT κT = κT κ ideal T = 1 + n ∫ (g(r) − 1)dr = 〈 N 2〉 − ⟨N⟩2 ⟨N⟩ ; (14) this is known as the compressibility equation of state. Since κ −1 T = n ( ∂P ∂n ) T , one can use equation (14) to determine the pressure and free energy of the system by performing thermodynamic integrations with respect to the particle density. 10.7.A Static structure factor The pair correlation function g(r) can be measured experimentally using quasielastic scattering. If a sample is illuminated with a monochromatic beam of x-rays, neutrons, vis- ible light, and so on, the scattered intensity as a function of the angle from the incident 336 Chapter 10. Statistical Mechanics of Interacting Systems beam direction is proportional to the Fourier transform of g(r). The quasielastic scattering amplitude from a single particle at location ri illuminated by a plane wave with amplitude φ0 and wavevector k0 into a detector at location R is 81(k) = φ0f (k) eik0·ri eik1·(R−ri) |R − ri| , (15) where k = k1 − k0 is the wavevector transfer and f (k) is the single-particle scattering form factor; see Figure 10.7. The total scattering amplitude from the N particles in the sample is 8N (k) ≈ φ0f (k) |R| eik1·R ∑ i e−ik·ri , (16) where we have assumed that the detector is far from the sample. The scattered intensity from the N-particle sample is IN (k) = ∣ ∣8N (k) ∣ ∣2 ≈ ∣ ∣φ0f (k)∣ ∣2 |R|2 〈 ∑ i,j e−ik·(ri−rj)〉 = NI1(k)S(k), (17) k1 k0 \u0002 FIGURE 10.7 Scattering from two particles. The incident wavevector is k0, the scattered wavevector toward the detector is k1, and the wavevector transfer is k = k1 − k0. Since |k1| = |k0| for quasielastic scattering, the magnitude of the wavevector transfer is k = 2k0 sin(θ/2), where θ is the angle between k0 and k1. 10.7 Correlations and scattering 337 where I1(k) is the scattering intensity from a single particle and S(k) = 1 N 〈 ∑ i,j exp ( −ik · (ri − rj) )〉 (18) is the static structure factor. It represents the actual scattering intensity divided by the scattering intensity from an imaginary randomly distributed and, therefore, uncorrelated sample of atoms at the same particle density n. If the sample is translationally invariant and isotropic, as in a uniform ﬂuid, the static structure factor depends only on the magnitude of the wavevector transfer, that is S(k) = S(k). For that case, S(k) can be written as the Fourier transform of the pair correla- tion function: S(k) = 1 + N V ∫ (g(r) − 1)eik·rdr + N V 2 ∣ ∣ ∣ ∣ ∫ eik·rdr∣ ∣ ∣ ∣ 2 . (19) The ﬁnal term in equation (19) represents the forward shape scattering of the sample volume. The shape scattering term is negligible for k ≫ 1/L, so in the thermodynamic limit it can be ignored for k ̸= 0. The structure factor for isotropic ﬂuids in one, two, and three dimensions is then given by S(k) = 1 + 2n ∞∫ 0 (g(r) − 1) cos(kr)dr d = 1, (20a) S(k) = 1 + 2π n ∞∫ 0 r(g(r) − 1)J0(kr)dr d = 2, (20b) S(k) = 1 + 4πn k ∞∫ 0 r(g(r) − 1) sin(kr)dr d = 3. (20c) The pair correlation function g(r) can be determined using the inverse Fourier trans- form of the measured structure factor, as shown in Figure 10.8. For liquids and other short-range ordered materials, the structure factor tends to unity as k → ∞. The value of S(k) as k → 0 is a measure of the number density ﬂuctuations in the sample: lim k→0 S(k) = 1 + n ∫ (g(r) − 1)dr = κT κ ideal T = 〈 N 2〉 − ⟨N⟩2 ⟨N⟩ . (21) Equation (21) is called the ﬂuctuation-compressibility relation and is the equilibrium limit of the ﬂuctuation-dissipation theorem we will discuss in Section 15.6. 338 Chapter 10. Statistical Mechanics of Interacting Systems 3 2 1 0 02 4 6 810 12S(k) (b) k (Å\u00021) 3 2 1g(r) 0 0 5 10 15 r (Å) (a) 20 25 FIGURE 10.8 Experimentally measured pair correlation function g(r) and structure factor S(k) for liquid argon at 85 K. The structure factor (b) is determined from neutron scattering and the pair correlation function (a) is determined from the inverse Fourier transform of the structure factor. The small oscillations in g(r) near r = 0 are an experimental artifact of the Fourier transformation of the scattering data. This ﬁgure displays the typical features of correlations in ﬂuids: nearly zero g(r) at short distances, large g(r) for particles separated by approximately a molecular diameter, oscillatory decay of correlations to unity at large separations, small S(k) at small wavevector due to the small compressibility of dense ﬂuids, and S(k) approaching unity at large wavevectors. Figures from Yarnell, Katz, Wenzel, and Koenig (1973). Reprinted with permission; copyright ©1973, American Physical Society. 10.7.B Scattering from crystalline solids In an ideal crystalline solid, the atoms in the crystal are located at the sites of a periodic structure. For a simple crystal, identical atoms are sited on a Bravais lattice {R}. For exam- ple, a simple cubic lattice has lattice vectors R ∈ {(n1 ˆx + n2 ˆy + n3 ˆz)a}, where n1, n2, and n3 are integers and a is the lattice constant. The reciprocal lattice {G} is deﬁned by the set of reciprocal lattice vectors G — such that G · R = 2π m, where m is an integer for all {G} and {R}. The reciprocal lattice of the simple cubic lattice is also a simple cubic lat- tice: G ∈ {(m1 ˆx + m2 ˆy + m3 ˆz) 2π a }, where m1, m2, and m3, are integers. For a perfect Bravais lattice, the structure factor S(k) is of the form S(k) = 1 N 〈∑ R,R′ eik·(R−R′)〉 = N ∑ G δk,G, (22) where δk,G is the Kronecker delta. The structure factor is enhanced by a factor of N on each reciprocal lattice vector due to the coherent constructive interference of scattering from the long-range ordered array of atoms. One can determine the crystal structure of the solid from the experimental pattern of these sharp Bragg peaks; see Ashcroft and Mermin (1976). Thermal excitations cause atoms to deviate from their equilibrium positions. The dis- placed position of an atom whose equilibrium position is R can be written R + u(R), where u(R) denotes the displacement from equilibrium. As long as the atoms remain close to their lattice sites, the sharp Bragg peaks in the structure factor will also remain 10.7 Correlations and scattering 339 but the intensity of each peak will be reduced by an amount dependent on the aver- age of the squares of the deviations 〈 |u(R)|2〉 . This turns out to be the case for normal three-dimensional solids. The structure factor then takes the form S(k) = 1 N ∑ R,R′ eik·(R−R′) 〈 eik·(u(R)−u(R′))〉 . (23) If the excitations about the equilibrium positions are Gaussian (i.e., the terms in the Hamil- tonian higher than second order in u(R) can be ignored), then the average of the deviations in the exponential can be simpliﬁed to give 〈 eik·(u(R)−u(R′))〉 = e− 1 2 〈|k·(u(R)−u(R′)|2〉. (24) If the displacements of the atoms far from each other on the lattice are uncorrelated, as they are in three-dimensional crystals, 1 2 〈 |k · (u(R) − u(R′)| 2〉 ≈ k2 〈u2〉 3 for |R − R′| → ∞, (25) then the structure factor takes the form S(k) = N ∑ G WGδk,G, (26) where WG = exp ( − G2 〈 u2〉 3 ) (27) is called the Debye–Waller factor. The random atomic deviations from lattice sites reduces the intensity in the Bragg peaks but the sharp scattering indicative of long-range crystalline order remains intact; see Ashcroft and Mermin (1976). An interesting variant of this calculation occurs in two-dimensional solids. Peierls (1935) and Landau (1937) showed that harmonic thermal ﬂuctuations in two dimensions destroy crystalline long-range order. This was generalized by Mermin (1968) to show that long-range crystalline order was not possible for any two-dimensional system of parti- cles with short-range interactions. Two-dimensional solids exhibit power-law decay of translational correlations while maintaining long-range order in the lattice orientational correlations. This leads to power-law singularities rather than delta-functions in the static structure factor. It is possible for the solid to melt via two Kosterlitz–Thouless-like continu- ous transitions rather than a single ﬁrst-order transition. The intervening “hexatic” phase exhibits short-range translational correlations and quasi-long-range orientational corre- lations; see Section 13.7, Kosterlitz and Thouless (1972, 1973), Halperin and Nelson (1978), and Young (1979). 340 Chapter 10. Statistical Mechanics of Interacting Systems Problems 10.1. For imperfect-gas calculations, one sometimes employs the Sutherland potential u(r) = { ∞ for r < D −ε(D/r)6 for r > D. Using this potential, determine the second virial coefﬁcient of a classical gas. Also determine ﬁrst-order corrections to the ideal-gas law and to the various thermodynamic properties of the system. 10.2. According to Lennard-Jones, the physical behavior of most real gases can be well understood if the intermolecular potential is assumed to be of the form u(r) = A rm − B rn , where n is very nearly equal to 6 while m ranges between 11 and 13. Determine the second virial coefﬁcient of a Lennard-Jones gas and compare your result with that for a van der Waals gas; see equation (10.3.8). 10.3. (a) Show that for a gas obeying van der Waals equation of state (10.3.9), CP − CV = Nk {1 − 2a kTv3 (v − b) 2}−1 . (b) Also show that, for a van der Waals gas with constant speciﬁc heat CV , an adiabatic process conforms to the equation (v − b)T CV /Nk = const; compare with equation (1.4.30). (c) Further show that the temperature change resulting from an expansion of the gas (into vacuum) from volume V1 to volume V2 is given by T2 − T1 = N 2a CV ( 1 V2 − 1 V1 ) . 10.4. The coefﬁcient of volume expansion α and the isothermal bulk modulus B of a gas are given by the empirical expressions α = 1 T ( 1 + 3a′ vT 2 ) and B = P ( 1 + a′ vT 2 )−1 , where a′ is a constant parameter. Show that these expressions are mutually compatible. Also derive the equation of state of this gas. 10.5. Show that the ﬁrst-order Joule–Thomson coefﬁcient of a gas is given by the formula ( ∂T ∂P ) H = N CP ( T ∂(a2λ3) ∂T − a2λ 3) , where a2(T ) is the second virial coefﬁcient of the gas and H its enthalpy; see equation (10.2.1). Derive an explicit expression for the Joule–Thomson coefﬁcient in the case of a gas with interparticle interaction u(r) =    +∞ for 0 < r < D, −u0 for D < r < r1, 0 for r1 < r < ∞, and discuss the temperature dependence of this coefﬁcient. Problems 341 10.6. Assume that the molecules of the nitrogen gas interact through the potential of the previous problem. Making use of the experimental data given next, determine the “best” empirical values for the parameters D, r1, and u0/k: T (in K) 100 200 300 400 500 a2λ3 (in K per atm) −1.80 −4.26 × 10−1 −5.49 × 10−2 +1.12 × 10−1 +2.05 × 10−1. 10.7. Determine the lowest-order corrections to the ideal-gas values of the Helmholtz free energy, the Gibbs free energy, the entropy, the internal energy, the enthalpy, and the (constant-volume and constant-pressure) speciﬁc heats of a real gas. Discuss the temperature dependence of these corrections in the case of a gas whose molecules interact through the potential of Problem 10.5. 10.8. The molecules of a solid attract one another with a force F(r) = α(l/r)5. Two semi-inﬁnite solids composed of n molecules per unit volume are separated by a distance d, that is, the solids ﬁll the whole of the space with x ≤ 0 and x ≥ d. Calculate the force of attraction, per unit area of the surface, between the two solids. 10.9. Referring to equation (10.5.31) for the phase shifts ηl(k) of a hard-sphere gas, show that for kD ≪ 1 ηl(k) ≃ − (kD)2l+1 (2l + 1){1 · 3 · · · (2l − 1)}2 . 10.10. Using the wavefunctions up(r) = 1 √ V ei(p·r)ℏ to describe the motion of a free particle, write down the symmetrized wavefunctions for a pair of noninteracting bosons/fermions, and show that ⟨1 ′, 2′| ˆU S/A 2 |1, 2⟩ = ±⟨2 ′| ˆW1|1⟩⟨1 ′| ˆW1|2⟩. 10.11. Show that for a gas composed of particles with spin J b S 2( J) = ( J + 1)(2J + 1) bS 2(0) + J(2J + 1) b A 2 (0) and bA 2 ( J) = J(2J + 1) bS 2(0) + ( J + 1)(2J + 1) b A 2 (0). 10.12. Show that the coefﬁcient b2 for a quantum-mechanical Boltzmannian gas composed of “spinless” particles satisﬁes the following relations: b2 = Lim J→∞ { 1 (2J + 1)2 b S 2( J)} = Lim J→∞ { 1 (2J + 1)2 b A 2 ( J)} = 1 2 { bS 2(0) + b A 2 (0)}. Obtain the value of b2, to ﬁfth order in (D/λ), by using the Beth–Uhlenbeck expressions in equations (10.5.36) and (10.5.37), and compare your result with the classical value of b2, namely −(2π/3)(D/λ)3. 10.13. Use a virial expansion approach to determine the ﬁrst few nontrivial order contributions to the pair correlation function g(r) in d dimensions. Show that the pair correlation function is of the form g(r) = e−βu(r)y(r), where u(r) is the pair potential and y(r) is a smooth function of r. Show that even for the case of hard sphere interaction, y(r) and its ﬁrst few derivatives are continuous. 10.14. For the particular case of hard spheres, the pressure in the virial equation of state is determined by evaluating the pair correlation function at contact. Write the pair correlation function as g(r) = e−βu(r)y(r) and derive equations (10.7.12) for hard spheres in one, two, and three dimensions. [Hint: For hard spheres, the Boltzmann factor e−βu(r) is a Heaviside step function]. 342 Chapter 10. Statistical Mechanics of Interacting Systems 10.15. Derive the probability distribution w(r) for the distance to the closest neighboring particle using the pair correlation function g(r) and the number density n. Show that in three dimensions w(r) = 4π nr2g(r) exp  − r∫ 0 4π ns2g(s)ds   , and the average closest-neighbor distance for an ideal gas is r1 = ∞∫ 0 rw(r)dr = 0 ( 4 3 ) ( 4πn 3 )−1/3 . 10.16. Consider a gas, of inﬁnite extent, divided into regions A and B by an imaginary sheet running through the system. The molecules of the gas interact through a potential energy function u(r). Show that the average net force F experienced by all the molecules on the A-side of the sheet caused by all the molecules on the B-side are perpendicular to the plane of the sheet, and that its magnitude (per unit area) is given by F A = − 2π n2 3 ∞∫ 0 ( du dr ) g(r)r3dr. 10.17. Show that for a gas of noninteracting bosons, or fermions, the pair correlation function g(r) is given by the expression g(r) = 1 ± gs n2h6 ∣ ∣ ∣ ∣ ∣ ∣ ∞∫ −∞ ei(p·r)/ℏ d3p e(p2/2m−µ)/kT ∓ 1 ∣ ∣ ∣ ∣ ∣ ∣ 2 , where gs (= 2s + 1) is the spin multiplicity factor. Note that the upper sign here applies to bosons, the lower one to fermions.14 [Hint: To solve this problem, one may use the method of second quantization, as developed in Chapter 11. The particle density operator ˆn is then given by the sum, ∑ α,β a† αaβ u ∗ α(r)uβ (r), whose diagonal terms are directly related to the mean particle density n in the system. The nondiagonal terms give the density ﬂuctuation operator ( ˆn − n), and so on; see equation (11.1.25).] 10.18. Show that, in the case of a degenerate gas of fermions (T ≪ TF ), the correlation function g(r), for r ≫ ℏ/pF , reduces to the expression g(r) − 1 = − 3(mkT )2 4p3 F ℏr2 {sinh ( π mkTr pF ℏ )}−2 . Note that, as T → 0, this expression tends to the limiting form g(r) − 1 = − 3ℏ 4π 2pF r4 ∝ 1 r4 . 14Note that, in the classical limit (ℏ → 0), the inﬁnitely rapid oscillations of the factor exp{i(p · r)/ℏ} make the integral vanish. Consequently, for an ideal classical gas, the function g(r) is identically equal to 1. Quantum-mechanical systems of identical particles exhibit spatial correlations due to Bose and Fermi statistics even in the absence of interactions. It is not difﬁcult to see that, for nλ3 ≪ 1 where λ = h/√ (2π mkT ), g(r) ≃ 1 ± 1 gs exp(−2πr2/λ2); compare with equation (5.5.27). Problems 343 10.19. (a) For a dilute gas, the pair correlation function g(r) may be approximated as g(r) ≃ exp{−u(r)/kT }. Show that, under this approximation, the virial equation of state (10.7.11) takes the form PV NkT ≃ 1 − 2πn ∞∫ 0 f (r)r2dr, where f (r) [= exp{−u(r)/kT } − 1] is the Mayer function, equation (10.1.6). (b) What form will this result take for a gas of hard spheres? Compare your result with that of Problem 1.4. 10.20. Show that the pressure and Helmholtz free energy of a ﬂuid at temperature T can be determined by performing a thermodynamic integration of the inverse of the isothermal compressibility from the chosen density to the ideal gas reference state. 10.21. Show that, for a general Gaussian distribution of variables uj, the average of the exponential of a linear combination of the variables obeys the relation 〈 exp ( ∑ j ajuj)〉 = exp   1 2 〈( ∑ j ajuj )2〉  . 10.22. Calculate the isothermal compressibility and Helmholtz free energy for the Carnahan–Starling equation of state (10.3.25) and show that the Helmholtz free energy is given by βA N = βAideal N + η(4 − 3η) (1 − η)2 , where Aideal is the Helmholtz free energy of a classical monatomic ideal gas at the same density. 10.23. The virial expansion for a two-dimensional system of hard disks gives the following series when expressed in terms of the two-dimensional packing fraction η = π nD2/4: P nkT = 1 + 2η + 3.128018η2 + 4.257854η3 + 5.33689664η4 + 6.363026η5 + 7.352080η6 + 8.318668η7 + 9.27236η8 + 10.2161η9 + · · · ; see Malijevsky and Kolafa (2008). Propose some simple analytical functions f (η) that closely approximate this series. 11 Statistical Mechanics of Interacting Systems: The Method of Quantized Fields In this chapter we present another method of dealing with systems composed of interact- ing particles. This method is based on the concept of a quantized ﬁeld that is characterized by the ﬁeld operators ψ(r), and their hermitian conjugates ψ †(r), which satisfy a set of well-deﬁned commutation rules. In terms of these operators, one deﬁnes a number oper- ator ˆN and a Hamiltonian operator ˆH that provide a suitable representation for a system composed of any ﬁnite number of particles and possessing any ﬁnite amount of energy. In view of its formal similarity with the Schr¨odinger formulation, the formulation in terms of a quantized ﬁeld is generally referred to as the second quantization of the system. For convenience of calculation, the ﬁeld operators ψ(r) and ψ †(r) are often expressed as superpositions of a set of single-particle wavefunctions {uα(r)}, with coefﬁcients aα and a† α; the latter turn out to be the annihilation and creation operators, which again satisfy a set of well-deﬁned commutation rules. The operators ˆN and ˆH then ﬁnd a convenient expression in terms of the operators aα and a† α, and the ﬁnal formulation is well-suited for a treatment based on operator algebra; as a result, many calculations, which would otherwise be tedious, can be carried out in a more or less straightforward manner. 11.1 The formalism of second quantization To represent a system of particles by a quantized ﬁeld, we invoke the ﬁeld operators ψ(r) and ψ †(r), which are deﬁned for all values of the position coordinate r and which operate on a Hilbert space; a vector in this space corresponds to a particular state of the quantized ﬁeld. The values of the quantities ψ and ψ †, at all r, represent the degrees of freedom of the ﬁeld; since r is a continuous variable, the number of these degrees of freedom is innumer- ably inﬁnite. Now, if the given system is composed of bosons, the ﬁeld operators ψ(r) and ψ †(r) satisfy the commutation rules [ψ(r), ψ †(r′)] = δ(r − r′) (1a) [ψ(r), ψ(r′)] = [ψ †(r), ψ †(r′)] = 0, (1b) Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00011-6 © 2011 Elsevier Ltd. All rights reserved. 345 346 Chapter 11. Statistical Mechanics of Interacting Systems where the symbol [A, B] stands for the commutator (AB − BA) of the given operators A and B. If, on the other hand, the given system is composed of fermions, then the ﬁeld operators satisfy the rules {ψ(r), ψ †(r′)} = δ(r − r′) (2a) {ψ(r), ψ(r′)} = {ψ †(r), ψ †(r′)} = 0, (2b) where the symbol {A, B} stands for the anticommutator (AB + BA) of the given operators A and B. In the case of fermions, the operators ψ(r) and ψ †(r) possess certain explicit properties that follow directly from (2b), namely ψ(r)ψ(r′) = −ψ(r′)ψ(r), ∴ ψ(r)ψ(r) = 0 for all r ; (2c) similarly, ψ †(r)ψ †(r′) = −ψ †(r′)ψ †(r), ∴ ψ †(r)ψ †(r) = 0 for all r. (2d) Clearly, no such property holds for the ﬁeld operators pertaining to bosons. In the sequel we shall see that the mathematical difference between the commutation rules (1) for the boson ﬁeld operators and rules (2) for the fermion ﬁeld operators is intimately related to the fundamental difference in the symmetry properties of the respective wavefunctions in the Schr¨odinger formulation. Of course, in their own place, both sets of rules, (1) and (2), are essentially axiomatic. We now introduce two hermitian operators, the particle-number operator ˆN and the Hamiltonian operator ˆH, through deﬁnitions that hold for bosons as well as fermions: ˆN ≡ ∫ d3rψ †(r)ψ(r) (3) and ˆH ≡ − ℏ2 2m ∫ d3rψ †(r)∇2ψ(r) + 1 2 ∫∫ d3r1d3r2ψ †(r1)ψ †(r2)u(r1, r2)ψ(r2)ψ(r1), (4) where u(r1, r2) denotes the two-body interaction potential in the given system. It is quite natural to interpret the product ψ †(r)ψ(r) as the number density operator of the ﬁeld. The similarity between the foregoing deﬁnitions and the expressions for the expectation values of the corresponding physical quantities in the Schr¨odinger formulation is fairly obvious. However, the similarity is only “formal” because, while there we are concerned with the wavefunctions of the given system (which are c-numbers), here we are concerned with the operators of the corresponding matter ﬁeld. We can easily verify that, irrespective of 11.1 The formalism of second quantization 347 the commutation rules obeyed by the operators ψ(r) and ψ †(r), the operators ˆN and ˆH do commute: [ ˆN, ˆH] = 0; (5) accordingly, the operators ˆN and ˆH can be diagonalized simultaneously. We now choose a complete orthonormal basis of the Hilbert space, such that any vec- tor |8n⟩ among the basis is a simultaneous eigenstate of the operators ˆN and ˆH. We may, therefore, denote any particular member of the basis by the symbol |9NE⟩, with the properties ˆN|9NE ⟩ = N|9NE ⟩, ˆH|9NE ⟩ = E|9NE ⟩ (6) and ⟨9NE |9NE ⟩ = 1. (7) The vector |900⟩, which represents the vacuum state of the ﬁeld and is generally denoted by the symbol |0⟩, is assumed to be unique; it possesses the obvious properties ˆN|0⟩ = ˆH|0⟩ = 0 and ⟨0|0⟩ = 1. (8) Next we observe that, regardless of whether we employ the boson commutation rules (1) or the fermion rules (2), the operator ˆN and the operators ψ(r) and ψ †(r) satisfy the commutation properties [ψ(r), ˆN] = ψ(r) and [ψ †(r), ˆN] = −ψ †(r), (9) from which it follows that ˆNψ(r)|9NE ⟩ = ( ψ(r) ˆN − ψ(r) ) |9NE ⟩ = (N − 1)ψ(r)|9NE ⟩ (10) and ˆNψ †(r)|9NE ⟩ = (ψ †(r) ˆN + ψ †(r) ) |9NE ⟩ = (N + 1)ψ †(r)|9NE ⟩. (11) Clearly, the state ψ(r)|9NE⟩ is also an eigenstate of the operator ˆN, but with eigenvalue (N − 1); thus, the application of the operator ψ(r) onto the state |9NE⟩ of the ﬁeld anni- hilates one particle from the ﬁeld. Similarly, the state ψ †(r)|9NE⟩ is an eigenstate of the operator ˆN, with eigenvalue (N + 1); thus, the application of the operator ψ †(r) onto the state |9NE⟩ of the ﬁeld creates a particle in the ﬁeld. In each case, the process (of annihi- lation or creation) is tied down to the point r of the ﬁeld; however, the energy associated with the process, which also means the change in the energy of the ﬁeld, remains undeter- mined; see equations (18) and (19). By a repeated application of the operator ψ † onto the vacuum state |0⟩, we ﬁnd that the eigenvalues of the operator ˆN are 0, 1, 2, . . .. 348 Chapter 11. Statistical Mechanics of Interacting Systems On the other hand, the application of the operator ψ onto the vacuum state |0⟩ gives nothing but zero because, for obvious reasons, we cannot admit negative eigenvalues for the operator ˆN. Of course, if we apply the operator ψ onto the state |9NE⟩ repeatedly N times, we end up with the vacuum state; we then have, by virtue of the orthonormality of the basis chosen, ⟨8n|ψ(r1)ψ(r2) . . . ψ(rN )|9NE ⟩ = 0 (12) unless the state |8n⟩ is itself the vacuum state, in which case we would obtain a nonzero result instead. In terms of this latter result, we may deﬁne a function of the N coordinates r1, r2, . . . , rN , namely 9NE (r1, . . . , rN ) = (N! )−1/2⟨0|ψ(r1) . . . ψ(rN )|9NE ⟩. (13) Obviously, the function 9NE(r1, . . . , rN ) has something to do with an assemblage of N par- ticles located at the points r1, . . . , rN of the ﬁeld because their annihilation from those very points of the ﬁeld has led us to the vacuum state of the ﬁeld. To obtain the precise meaning of this function, we ﬁrst note that in the case of bosons (fermions) this function is sym- metric (antisymmetric) with respect to an interchange of any two of the N coordinates; see equations (1b) and (2b), respectively. Secondly, its norm is equal to unity, which can be seen as follows. By the very deﬁnition of 9NE(r1, . . . , rN ), ∫ d3N r9∗ NE (r1, . . . , rN )9NE (r1, . . . , rN ) = (N! ) −1 ∫ d3N r⟨9NE |ψ †(rN ) . . . ψ †(r1)|0⟩⟨0|ψ(r1) . . . ψ(rN )|9NE ⟩ = (N! )−1 ∫ d3N r ∑ n ⟨9NE |ψ †(rN ) . . . ψ †(r1)|8n⟩⟨8n|ψ(r1) . . . ψ(rN )|9NE ⟩ = (N! )−1 ∫ d3N r⟨9NE |ψ †(rN ) . . . ψ †(r2)ψ †(r1)ψ(r1)ψ(r2) . . . ψ(rN )|9NE ⟩; here, use has been made of equation (12), which holds for all |8n⟩ except for the vacuum state, and of the fact that the summation of |8n⟩⟨8n| over the complete orthonormal set of the basis chosen is equivalent to a unit operator. We now carry out integration over r1, yielding the factor ∫ d3r1ψ †(r1)ψ(r1) = ˆN. Next, we carry out integration over r2, yielding the factor ∫ d3r2ψ †(r2) ˆNψ(r2) = ∫ d3r2ψ †(r2)ψ(r2)( ˆN − 1) = ˆN( ˆN − 1); 11.1 The formalism of second quantization 349 see equation (10). By iteration, we obtain ∫ d3N r9∗ NE (r1, . . . , rN )9NE (r1, . . . , rN ) = (N! )−1⟨9NE | ˆN( ˆN − 1)( ˆN − 2) . . . up to N factors|9NE ⟩ = (N! )−1N! ⟨9NE |9NE ⟩ = 1. (14) Finally, we can show that, for bosons as well as fermions, the function 9NE(r1, . . . , rN ) satisﬁes the differential equation, see Problem 11.1,  − ℏ2 2m N∑ i=1 ∇2 i + ∑ i<j uij   9NE (r1, . . . , rN ) = E9NE (r1, . . . , rN ), (15) which is simply the Schr¨odinger equation of an N-particle system. The function 9NE(r1, . . . , rN ) is, therefore, the Schr¨odinger wavefunction of the system, with energy eigenvalue E; accordingly, the product 9∗ NE9NE is the probability density for the particles of the system to be in the vicinity of the coordinates (r1, . . . , rN ), when the system hap- pens to be in an eigenstate with energy E. This establishes the desired correspondence between the quantized ﬁeld formulation and the Schr¨odinger formulation. In passing, we place on record the quantized-ﬁeld expression for the function 9∗ NE(r1, . . . , rN ), which is the complex conjugate of the wavefunction 9NE(r1, . . . , rN ), namely 9∗ NE (r1, . . . , rN ) = (N! )−1/2⟨9NE |ψ †(rN ) . . . ψ †(r1)|0⟩. (16) We now introduce a complete orthonormal set of single-particle wavefunctions uα(r), where the sufﬁx α provides a label for identifying the various single-particle states; it could, for instance, be the energy eigenvalue of the state (or the momentum p, along with the spin component σ pertaining to the state). In view of the orthonormality of these wavefunctions, ∫ d3r u∗ α(r)uβ (r) = δαβ . (17) The ﬁeld operators ψ(r) and ψ †(r) may now be expanded in terms of the functions uα(r): ψ(r) = ∑ α aαuα(r) (18) and ψ †(r) = ∑ α a† αu ∗ α(r). (19) 350 Chapter 11. Statistical Mechanics of Interacting Systems Relations inverse to equation (18) and (19) are aα = ∫ d3rψ(r)u ∗ α(r) (20) and a† α = ∫ d3rψ †(r)uα(r). (21) The coefﬁcients aα and a† α, like the ﬁeld variables ψ(r) and ψ †(r), are operators that oper- ate on the elements of the relevant Hilbert space. Indeed, the operators aα and a† α now take over the role of the degrees of freedom of the ﬁeld. Substituting (18) and (19) into the set of rules (1) or (2), and making use of the closure property of the uα, namely ∑ α uα(r)u ∗ α(r′) = δ(r − r′), (22) we obtain 1 for the operators aα and a† α the commutation relations [aα, a† β ] = δαβ (23a) [aα, aβ ] = [a† α, a† β ] = 0 (23b) in the case of bosons, and {aα, a† β } = δαβ (24a) {aα, aβ } = {a† α, a† β } = 0 (24b) in the case of fermions. In the latter case, the operators aα and a† α possess certain explicit properties that follow directly from (24b), namely aαaβ = −aβ aα, ∴ aαaα = 0 for all α; (24c) similarly a† αa† β = −a† β a† α, ∴ a† αa† α = 0 for all α. (24d) No such property holds for operators pertaining to bosons. We will see very shortly that this vital difference between the commutation rules for the boson operators and those for the fermion operators is closely linked with the fact that while fermions have to conform to the restrictions imposed by the Pauli exclusion principle, there are no such restrictions for bosons. 1Alternatively, one may employ equations (20) and (21), and make use of rules (1) or (2) along with equation (17). 11.1 The formalism of second quantization 351 We now proceed to express operators ˆN and ˆH in terms of aα and a† α. Substituting (18) and (19) into (3), we obtain ˆN = ∫ d3r ∑ α,β a† αaβ u ∗ α(r)uβ (r) = ∑ α,β a† αaβ δαβ = ∑ α a† αaα. (25) It seems natural to speak of the operator a† αaα as the particle-number operator pertaining to the single-particle state α. We denote this operator by the symbol ˆNα: ˆNα = a† αaα. (26) It is easy to verify that, for bosons as well as fermions, the operators ˆNα commute with one another; hence, they can be simultaneously diagonalized. Accordingly, we may choose a complete orthonormal basis of the Hilbert space in such a way that any vector belonging to the basis is a simultaneous eigenstate of all the operators ˆNα. 2 Let a particular member of the basis be denoted by the vector |n0, n1, . . . , nα, . . .⟩, or by the shorter symbol |8n⟩, with the properties ˆNα|8n⟩ = nα|8n⟩ (27) and ⟨8n|8n⟩ = 1; (28) the number nα, being the eigenvalue of the operator ˆNα in the state |8n⟩ of the ﬁeld, denotes the number of particles in the single-particle state α of the given system. One par- ticular member of the basis, for which nα = 0 for all α, will represent the vacuum state of the ﬁeld; denoting the vacuum state by the symbol |80⟩, we have ˆNα|80⟩ = 0 for all α, and ⟨80|80⟩ = 1. (29) Next we observe that, regardless of whether we employ the boson commutation rules (23) or the fermion rules (24), the operator ˆNα and the operators aα and a† α satisfy the commutation properties [aα, ˆNα] = aα and [a† α, ˆNα] = −a† α, (30) from which it follows that ˆNαaα|8n⟩ = (aα ˆNα − aα)|8n⟩ = (nα − 1)aα|8n⟩ (31) 2This representation of the ﬁeld is generally referred to as the particle-number representation. 352 Chapter 11. Statistical Mechanics of Interacting Systems and ˆNαa† α|8n⟩ = (a† α ˆNα + a† α)|8n⟩ = (nα + 1)a† α|8n⟩. (32) Clearly, the state aα|8n⟩ is also an eigenstate of the operator ˆNα, but with eigenvalue (nα − 1); thus, the application of the operator aα onto the state |8n⟩ of the ﬁeld annihi- lates one particle from the ﬁeld. Similarly, the state a† α|8n⟩ is an eigenstate of the operator ˆNα, with eigenvalue (nα + 1); thus, the application of the operator a† α onto the state |8n⟩ creates a particle in the ﬁeld. The operators aα and a† α are, therefore, referred to as the annihilation and creation operators. Of course, in each case the process (of annihilation or creation) is tied down to the single-particle state α; however, the precise location of the event (in the coordinate space) remains undetermined; see equations (20) and (21). Now, since the application of the operator aα or a† α onto the state |8n⟩ of the ﬁeld does not affect the eigenvalues of the particle-number operators other than ˆNα, we may write aα|n0, n1, . . . , nα, . . .⟩ = A(nα)|n0, n1, . . . , nα − 1, . . .⟩ (33) and a† α|n0, n1, . . . , nα, . . .⟩ = B(nα)|n0, n1, . . . , nα + 1, . . .⟩, (34) where the factors A(nα) and B(nα) can be determined with the help of the commutation rules governing the operators aα and a† α. For bosons, A(nα) = √ nα, B(nα) = √ (nα + 1); (35) consequently, if we regard the state |8n⟩ to have arisen from the vacuum state |80⟩ by a repeated application of the creation operators, we can write |8n⟩ = 1 √ (n0! n1! . . . nα! . . .) (a† 0)n0 (a† 1) n1 · · · (a† α)nα · · · |80⟩. (36) In the case of fermions, the operators a† α anticommute, with the result that a† αa† β = −a† β a† α; consequently, there would remain an uncertainty of a phase factor ±1 unless the order in which the a† α operate on the vacuum state is speciﬁed. To be deﬁnite, let us agree that, as indicated in equation (36), the a† α are arranged in the order of increasing sub- scripts and the phase factor is then +1. Second, since the product a† αa† α now vanishes, none of the nα in (36) can exceed unity; the eigenvalues of the fermion operators ˆNα are, therefore, restricted to 0 and 1, which is precisely the requirement of the Pauli exclusion principle. 3 Accordingly, the factor [5α(nα! )]−1/2 in (36) would be identically equal to unity. 3This can also be seen by noting that the fermion operators ˆNα satisfy the identity ˆN 2 α = a† α aαa† αaα = a† α(1 − a† αaα)aα = a† αaα = ˆNα (since a† αa† αaαaα ≡ 0). The same would be true of the eigenvalues nα. Hence, n2 α = nα, which means that nα = 0 or 1. 11.1 The formalism of second quantization 353 In passing, we note that in the case of fermions, operation (33) has meaning only if nα = 1 and operation (34) has meaning only if nα = 0. Finally, the substitution of expressions (18) and (19) into (4) gives for the Hamiltonian operator of the ﬁeld ˆH = − ℏ2 2m ∑ α,β ⟨α|∇2|β⟩a† αaβ + 1 2 ∑ α,β,γ ,λ⟨αβ|u|γ λ⟩a† αa† β aγ aλ, (37) where ⟨α|∇2|β⟩ = ∫ d3ru∗ α(r)∇2uβ (r) (38) and ⟨αβ|u|γ λ⟩ = ∫∫ d3r1d3r2u ∗ α(r1)u ∗ β (r2)u12uγ (r2)uλ(r1). (39) Now, if the single-particle wavefunctions are chosen to be uα(r) = 1 √ V eipα ·r/ℏ, (40) where pα denotes the momentum of the particle (assumed “spinless”), then the matrix elements (38) and (39) become ⟨α|∇2|β⟩ = 1 V ∫ d3re−ipα ·r/ℏ ( − p2 β ℏ2 ) eipβ ·r/ℏ = − p2 β ℏ2 δαβ (41) and ⟨αβ|u|γ λ⟩ = 1 V 2 ∫∫ d3r1d3r2e−i(pα −pλ)·r1/ℏu(r2 − r1)e−i(pβ −pγ )·r2/ℏ. (42) In view of the fact that the total momentum is conserved in each collision, pα + pβ = pγ + pλ, (43) the matrix element (42) takes the form ⟨αβ|u|γ λ⟩ = 1 V 2 ∫∫ d3r1d3r2ei( pγ −pβ )·(r2−r1)/ℏu(r2 − r1) = 1 V ∫ d3reip·r/ℏu(r), (44) where p denotes the momentum transfer during the collision: p = (pγ − pβ ) = −(pλ − pα). (45) 354 Chapter 11. Statistical Mechanics of Interacting Systems Substituting (41) and (44) into (37), we ﬁnally obtain ˆH = ∑ p p2 2m a† pap + 1 2 ∑′ u p′ 1,p′ 2 p1,p2 a† p′ 1 a† p′ 2 ap2 ap1, (46) where up′ 1,p′ 2 p1,p2 denotes the matrix element (44), with p = (p2 − p′ 2) = −(p1 − p′ 1); (47) note that the primed summation in the second term of (46) goes only over those values of p1, p2, p′ 1, and p′ 2 that conserve the total momentum of the particles: p′ 1 + p′ 2 = p1 + p2. It is obvious that the main term in (46) represents the kinetic energy of the ﬁeld (a† pap being the particle-number operator pertaining to the single-particle state p), while the second term represents the potential energy. In the case of spin-half fermions, the single-particle states have to be characterized not only by the value p of the particle momentum but also by the value σ of the z-component of its spin; accordingly, the creation and annihilation operators would carry double indices. The operator ˆH then takes the form ˆH = ∑ p,σ p2 2m a† pσ apσ + 1 2 ∑′ u p′ 1σ ′ 1,p′ 2σ ′ 2 p1σ1,p2σ2 a† p′ 1σ ′ 1 a† p′ 2σ ′ 2 ap2σ2 ap1σ1 ; (48) the summation in the second term now goes only over those states (of the two particles) that conform to the conditions of both momentum conservation and spin conservation. In the following sections we shall apply the formalism of second quantization to inves- tigate low-temperature properties of systems composed of interacting particles. In most cases we shall study these systems under the approximating conditions a/λ ≪ 1 and na3 ≪ 1, where a is the scattering length of the two-body interaction, λ the mean thermal wavelength of the particles, and n the particle density in the system. Now, the effective scattering cross-section for the collision of two particles, each of mass m, is primarily determined by the “scattering amplitude” a(p), where a(p) = m 4π ℏ2 ∫ u(r)eip·r/ℏd3r, (49) p being the momentum transfer during the collision; if the potential is central, equa- tion (49) takes the form a(p) = m 4πℏ2 ∞∫ 0 u(r) sin(kr) kr 4πr2dr (k = p ℏ ) . (50) For low-energy scattering (which implies “slow” collisions), we have the limiting result a = mu0 4πℏ2 , u0 = ∫ u(r)d3r, (51) 11.2 Low-temperature behavior of an imperfect Bose gas 355 the quantity a being the scattering length of the given potential.4 Alternatively, one may employ the S-wave scattering phase shift η0(k), see Section 10.5, and write on one hand tan η0(k) ≃ − mk 4πℏ2 ∞∫ 0 u(r) sin2(kr) (kr)2 4πr2dr (52) and on the other cot η0(k) = − 1 ka + 1 2 kr∗ + · · · , (53) where a is the “scattering length” and r∗ the “effective range” of the potential. For low- energy scattering, equations (52) and (53) once again lead to (51). In passing, we note that a is positive or negative according as the potential in question is predominantly repulsive or predominantly attractive; unless a statement is made to the contrary, we shall assume a to be positive. 11.2 Low-temperature behavior of an imperfect Bose gas The Hamiltonian of the quantized ﬁeld for spinless bosons is given by the expression (11.1.46), where the matrix element up′ 1,p′ 2 p1,p2 is a function of the momentum p transferred during the collision and is given by formula (11.1.44). At low temperatures the particle momenta are small, so we may insert for the matrix elements u(p) their value at p = 0, namely u0/V , where u0 is given by equation (11.1.51). At the same time, we may retain only those terms in the sum ∑′ that pertain to a vanishing momentum transfer. We then have ˆH = ∑ p p2 2m a† pap + 2π aℏ2 mV  ∑ p a† pa† papap + ∑ p1̸=p2 ( a† p1 a† p2 ap2 ap1 + a† p2 a† p1 ap2 ap1 ) . (1) Now ∑ p a† pa† papap = ∑ p a† p(apa† p − 1)ap = ∑ p (n 2 p − np) = ∑ p n 2 p − N, (2) 4This result is consistent with the pseudopotential approach of Huang and Yang (1957) in which u(r) is replaced by the singular potential (4πaℏ2/m)δ(r), so the integral u0 becomes 4πaℏ2/m. For an exposition of the pseudopotential approach, see Chapter 10 of the ﬁrst edition of this book. 356 Chapter 11. Statistical Mechanics of Interacting Systems whereas ∑ p1̸=p2a† p1 a† p2 ap2 ap1 = ∑ p1̸=p2np1 np2 = ∑ p1 np1 (N − np1 ) = N 2 − ∑ p n 2 p , (3) the same being true of the sum over the exchange terms a† p2 a† p1ap2ap1. Collecting these results, the energy eigenvalues of the system turn out to be E{np} = ∑ p np p2 2m + 2π aℏ2 mV  2N 2 − N − ∑ p n 2 p   ≃ ∑ p np p2 2m + 2πaℏ2 mV (2N 2 − n 2 0). (4)5 We ﬁrst examine the ground state of the given system, which corresponds to the dis- tribution set np ≃ {N for p = 0 0 for p ̸= 0, (5) with the result that E0 ≃ 2πaℏ2N 2 mV . (6) The ground-state pressure is then given by P0 = − ( ∂E0 ∂V ) N = 2π aℏ2N 2 mV 2 = 2πaℏ2n2 m , (7) where n (= N/V ) is the particle density in the system. This leads to the velocity of sound, c0, given by c2 0 = 1 m dP0 dn = 4πaℏ2n m2 . (8) Inserting numbers relevant to liquid He4, namely a ≃ 2.2 ˚A, n = 1/v where v ≃ 45 ˚A 3 and m ≃ 6.65 × 10−24 g, we obtain: c0 ≃ 125 m/s. A comparison with the actual velocity of sound in the liquid, which is about 240 m/s, should not be too disheartening, for the theory 5In the last step we have replaced the sum ∑ p n2 p by the single term n2 0, thus neglecting the partial sum ∑ p̸=0 n2 p in comparison with the number (2N 2 − n2 0). Justiﬁcation for this step lies in the fact that, by the theory of ﬂuctuations, the neglected part here will be O(N), and not O(N 2). 11.2 Low-temperature behavior of an imperfect Bose gas 357 developed here was never intended to be applicable to a liquid. Finally, the chemical potential of the system at T = 0 K turns out to be µ0 = ( ∂E0 ∂N ) V = 4πaℏ2N mV = 4π aℏ2n m . (9) At ﬁnite but low temperatures, the physical behavior of the system may be studied through its partition function Q(N, V , T ) = ∑ {np} exp(−βE{np}) = ∑ {np} exp  −β    ∑ p np p2 2m + 2π aℏ2N 2 mV ( 2 − n2 0 N 2 )    . (10) In the lowest approximation, the quantity (n0/N) appearing here may be replaced by its ideal-gas value, as given in Section 7.1, namely n0 N = 1 − λ3 c λ3 [λ = h (2π mkT )1/2 , λc = {vζ (3/2)} 1/3] (11a) = 1 − v vc [ v = V N , vc = λ3 ζ (3/2) ] . (11b) We thus obtain, to ﬁrst order in a, ln Q(N, V , T ) ≃ ln Qid(N, V , T ) − β 2πaℏ2N 2 mV ( 1 + 2v vc − v2 v2 c ) . (12) The Helmholtz free energy, per particle, is then given by6 1 N A(N, V , T ) = − kT N ln Q(N, V , T ) ≃ 1 N Aid(N, V , T ) + 2π aℏ2 m ( 1 v + 2 vc − v v2 c ) . (13) The pressure P and the chemical potential µ now follow straightforwardly: P = − ( ∂A ∂V ) N,T = − ( ∂(A/N) ∂v ) T = Pid + 2πaℏ2 m ( 1 v2 + 1 v2 c ) , (14) and µ = A N + Pv = µid + 4π aℏ2 m ( 1 v + 1 vc ) , (15) which may be compared with the ground-state results (7) and (9) that pertain to vc = ∞. 6This and the subsequent results were ﬁrst derived by Lee and Yang (1958, 1960c) using the binary collision method and by Huang (1959, 1960) using the pseudopotential method. 358 Chapter 11. Statistical Mechanics of Interacting Systems At the transition point (where v = vc and λ = λc), the pressure Pc and the chemical potential µc turn out to be Pc = Pid + 4π aℏ2 mλ6 c { ζ ( 3 2 )}2 = kTc λ3 c [ ζ ( 5 2 ) + 2 {ζ ( 3 2 )}2 a λc ] (16) and µc = µid + 8π aℏ2 mλ3 c ζ ( 3 2 ) = 4ζ ( 3 2 ) kTc a λc ; (17) the corresponding value of the fugacity, zc, is given by zc = exp(µc/kTc) ≃ 1 + 4ζ (3/2)(a/λc). (18) For a slightly different approach to this result, see Problem 11.2. 11.2.A Effects of interactions on ultracold atomic Bose–Einstein condensates In Section 7.2 we discussed Bose–Einstein condensation of noninteracting bosons con- ﬁned in magnetic traps. The low-energy interactions between atoms are described by the scattering length a, see equation (11.1.51), and the effect of the scattering length on the Bose-condensed ground state of a uniform gas is described by equations (6) through (9). We can include the effect of atomic interactions on the spatially nonuniform ground state using the Gross–Pitaevskii equation; see Pitaevskii (1961), Gross (1961, 1963), Pitaevskii and Stringari (2003), and Leggett (2006). The magnetic trap potential can be approximated by an anisotropic harmonic oscillator potential V (r) = 1 2 m(ω2 1x2 + ω2 2y2 + ω2 3z2), (19) which leads to the unperturbed single-particle ground-state wavefunction φ(r) = 1 π 3/4√a1a2a3 exp [ − 1 2 ( x2 a2 1 + y2 a2 2 + z2 a2 3 )] , (20) where aα = √ℏ/mωα is the linear size of the unperturbed harmonic oscillator ground state in Cartesian direction α. For the noninteracting case at T = 0, all the N atoms in the trap occupy this same single- particle state to form a macroscopic quantum state 9(r) = √Nφ(r). At low energies, the interactions can be approximated by an effective contact potential u0δ(r − r′) with scat- tering length a and coupling u0 = 4π aℏ2/m. This provides a fairly accurate description of interactions in ultracold gases since the kinetic energies and densities of the particles are so small; see equation (11.1.51). If the scattering length a is positive, the interaction is repulsive while if a is negative the interaction is attractive. For atoms, the scattering length is normally of the order of a few Bohr radii but in some atomic isotopes the scattering 11.2 Low-temperature behavior of an imperfect Bose gas 359 length can be tuned over a large range, including a change of sign, with only small changes in the magnetic ﬁeld via a Feshbach resonance. When interactions are included, the mean ﬁeld energy can be written in terms of the macroscopic quantum-state wavefunction 9(r), where the macroscopic ground-state number density is given by n(r) = |9(r)|2. The Gross–Pitevskii energy functional then is E[9] = ∫ dr [ ℏ2 2m |∇9(r)|2 + V (r) |9(r)| 2 + 1 2 u0 |9(r)| 4] ; (21) see Bahm and Pethick (1996), Pitaevskii and Stringari (2003), Leggett (2006), and Pethick and Smith (2008). The energy E[9] can be minimized with respect to 9∗, with the constraint N = ∫ n(r)dr = ∫ |9(r)| 2 dr, (22) using a Lagrange multiplier µ. Setting δE − µδN = 0 gives the Gross–Pitaevskii equation − ℏ2 2m ∇29(r) + V (r)9(r) + u0 |9(r)| 2 9(r) = µ9(r). (23) Equations (21) and (23) are quite appropriate for describing the zero-temperature nonuniform Bose gas when the scattering length a is much smaller than the average spac- ing between the particles. Equation (23) is in the form of a single-particle Schr¨odinger equation with the addition of a nonlinear term proportional to u0 |9(r)|2 that gives a mean ﬁeld coupling of one particle to all the remaining particles in the condensate. To determine the mean ﬁeld ground-state energy, one solves equation (23) for 9(r) and uses that solution to evaluate (21). When a = 0, the solution is the noninteracting ground- state wavefunction 9(r) = √ Nφ(r). The dimensionless parameter that controls the size of the interaction term is Na/aosc where aosc = (a1a2a3)1/3, so the effects of interactions are largest in systems with large numbers of atoms in the condensate. Equation (23) can be analyzed analytically in several limiting cases; it can also be stud- ied numerically. In particular, solving equations (21) and (23) for a uniform system with V = 0 reproduces the results given in equations (6) through (9). For a > 0, the conden- sate wavefunction expands in every direction relative to the noninteracting Bose–Einstein condensate. For Na/aosc ≫ 1, the kinetic energy term can be neglected in the style of a Thomas-Fermi analysis, so the wavefunction becomes approximately 9(r) ≈ √ (µ − V (r))/u0 , (24) where the Thomas–Fermi wavefunction vanishes for V (r) > µ. The chemical potential µ and the number of bosons N are related by N = 8π 15 ( 2µ mω2 0 )3/2 µ u0 , (25) 360 Chapter 11. Statistical Mechanics of Interacting Systems where ω0 = (ω1ω2ω3)1/3, so µ = 1 2 ( 15Na aosc )2/5 ℏω0. (26) The total energy of the condensate in this limit is E = 5 7 µN. (27) The linear extents of the condensate in the three directions of the trap are given by Rα = √ 2µ mω2 α = aosc ( 15Na aosc )1/5 ω0 ωα , (28) so the repulsive interactions expand the size of the condensate, making the aniostropy of the system larger than that of the noninteracting Bose–Einstein condensate; see Pitaevskii and Stringari (2003); Leggett (2006), and Pethick and Smith (2008). In time-of-ﬂight mea- surements, the repulsive interactions result in higher velocities in the directions that were most conﬁned in the trap, so the time-of-ﬂight distributions are also more anisotropic than in the noninteracting case; see Holland and Cooper (1996) and Holland et al. (1997). For attractive interactions with negative scattering lengths, the condensate is ultimately unstable because of the formation of pairs, but a long-lived atomic condensate exists for small negative Na/aosc. For the isotropic case, the atomic condensate is metastable in the mean ﬁeld theory for −0.575 ≲ Na/aosc < 0. Even in the anisotropic case, the condensate is 7 (b)6 5 4 3 2 1 0 0 204060 \u00022 \u00021.5 \u00021 \u00020.5 0.50 0.5 1 1.5 Nonlinear ConstantGround-State Energy 80 100 FIGURE 11.1 Ground-state energy of a Bose–Einstein condensate in an isotropic harmonic trap as a function of the scattering length a. The energy is plotted in units of Nℏω0, where ω0 is the trap frequency. The “nonlinear constant” is proportional to Na/aosc, where N is the number of atoms and aosc = √ℏ/mω0 is the width of the harmonic oscillator ground state wavefunction. Figure from Ruprecht et al. (1995). Reprinted with permission; copyright © 1995, American Physical Society. 11.3 Low-lying states of an imperfect Bose gas 361 nearly spherical since the solution of equation (23) is dominated by the kinetic and inter- action terms; see Ruprecht et al. (1995) and Figure 11.1. Roberts et al. (2001) have used a Feshbach resonance to tune the scattering length of 85Rb to ﬁnd that the condensate becomes unstable at N|a|/aosc ≃ 0.46. 11.3 Low-lying states of an imperfect Bose gas In the preceding section we examined ﬁrst-order corrections to the low-temperature behavior of an imperfect Bose gas arising from interparticle interactions in the system. One important result emerging in that study was a nonzero velocity of sound, as given by equation (11.2.8). This raises the possibility that phonons, the quanta of sound ﬁeld, might play an important role in determining the low-temperature behavior of this system — a role not seen in Section 11.2. To look into this question, we explore the nature of the low-lying states of an imperfect Bose gas, in the hope that we thus discover an energy- momentum relation ε(p) obeyed by the elementary excitations of the system, of which phonons may be an integral part. For this, we have to go a step beyond the approximation adopted in Section 11.2 which, in turn, requires several signiﬁcant improvements. To keep matters simple, we conﬁne ourselves to situations in which the fraction of particles occu- pying the state with p = 0 is fairly close to 1 while the fraction of particles occupying states with p ̸= 0 is much less than 1. Going back to equations (11.2.1) through (11.2.4), we ﬁrst write 2N 2 − n2 0 = N 2 + (N 2 − n 2 0) ≃ N 2 + 2N(N − n0) = N 2 + 2N ∑ p̸=0 a† pap. (1) Next, we retain another set of terms from the sum ∑′ in equation (11.1.46) — terms that involve a nonzero momentum transfer, namely ∑ p̸=0 u(p)[a† pa† −pa0a0 + a† 0a† 0apa−p]. (2) Now, since a† 0a0 = n0 = O(N) and (a0a† 0 − a† 0a0) = 1 ≪ N, it follows that a0a† 0 = (n0 + 1) ≃ a† 0a0. The operators a0 and a† 0 may, therefore, be treated as c-numbers, each equal to n1/2 0 ≃ N 1/2. At the same time, the amplitude u(p) in the case of low-lying states may be replaced by u0/V , as before. Expression (2) then becomes u0N V ∑ p̸=0 (a† pa† −p + apa−p). (3) 362 Chapter 11. Statistical Mechanics of Interacting Systems In view of these results, the Hamiltonian of the system assumes the form ˆH = ∑ p p2 2m a† pap + u0 2V  N 2 + N ∑ p̸=0 (2a† pap + a† pa† −p + apa−p)  . (4) Our next task consists of determining an improved relationship between the quantity u0 and the scattering length a. While the (approximate) result stated in equation (11.1.51) is good enough for evaluating the term involving N ∑p̸=0, it is not so for evaluating the term involving N 2. For this, we note that “if the probability of a particular quantum tran- sition in a given system under the inﬂuence of a constant perturbation ˆV is, in the ﬁrst approximation, determined by the matrix element V 0 0 , then in the second approximation we have instead V 0 0 + ∑ n̸=0 V 0 n V n 0 E0 − En , the summation going over the various states of the unperturbed system.” In the present case, we are dealing with a collision process in the two-particle system (with reduced mass 1 2 m), and the role of V 0 0 is played by the quantity u 00 00 = 1 V ∫ u(r)d3r = u0 V ; see equation (11.1.44) for the matrix element up′ 1,p′ 2 p1,p2. Making use of the other matrix ele- ments, we ﬁnd that in going from the ﬁrst to second approximation, we have to replace u0/V by u0 V + 1 V 2 ∑ p̸=0 | ∫ d3reip·r/ℏu(r)|2 −p2/m ≃ u0 V − u2 0m V 2 ∑ p̸=0 1 p2 . (5) Equating (5) with the standard expression 4π aℏ2/mV , we obtain, instead of (11.1.51), u0 ≃ 4πaℏ2 m  1 + 4π aℏ2 V ∑ p̸=0 1 p2  . (6) Substituting (6) into (4), we get ˆH = 2π aℏ2 m N 2 V  1 + 4π aℏ2 V ∑ p̸=0 1 p2   + 2πaℏ2 m N V ∑ p̸=0 (2a† pap + a† pa† −p + apa−p) + ∑ p̸=0 p2 2m a† pap. (7) 11.3 Low-lying states of an imperfect Bose gas 363 To evaluate the energy levels of the system one would have to diagonalize the Hamilton- ian (7), which can be done with the help of a linear transformation of the operators ap and a† p, ﬁrst employed by Bogoliubov (1947): bp = ap + αpa† −p √(1 − α2 p) , b† p = a† p + αpa−p √ (1 − α2 p) , (8) where αp = mV 4πaℏ2N { 4π aℏ2N mV + p2 2m − ε(p) } , (9) with ε(p) =    4πaℏ2N mV p2 m + ( p2 2m )2   1/2 ; (10) clearly, each αp < 1. Relations inverse to (8) are ap = bp − αpb† −p √ (1 − α2 p) , a† p = b † p − αpb−p √(1 − α2 p) . (11) It is straightforward to check that the new operators bp and b† p satisfy the same commuta- tion rules as the old operators ap and a† p did, namely [bp, b † p′ ] = δpp′ (12a) [bp, bp′ ] = [b† p, b† p′ ] = 0. (12b) Substituting (11) into (7), we obtain our Hamiltonian in the diagonalized form: ˆH = E0 + ∑ p̸=0 ε(p)b † pbp, (13) where E0 = 2πaℏ2N 2 mV + 1 2 ∑ p̸=0    ε(p) − p2 2m − 4πaℏ2N mV + ( 4πaℏ2N mV )2 m p2    . (14) In view of the commutation rules (12) and expression (13) for the Hamiltonian oper- ator ˆH, it seems natural to infer that the operators bp and b † p are the annihilation and creation operators of certain “quasiparticles” — which represent elementary excitations of the system — with the energy–momentum relation given by (10); it is also clear that these quasiparticles obey Bose–Einstein statistics. The quantity b † pbp is then the particle-number 364 Chapter 11. Statistical Mechanics of Interacting Systems operator for the quasiparticles (or elementary excitations) of momentum p, whereby the second part of the Hamiltonian (13) becomes the energy operator corresponding to the elementary excitations present in the system. The ﬁrst part of the Hamiltonian, given explicitly by equation (14), is therefore the ground-state energy of the system. Replacing the summation over p by integration and introducing a dimensionless variable x, deﬁned by x = p ( V 8π aℏ2N )1/2 , we obtain for the ground-state energy of the system E0 = 2πaℏ2N 2 mV  1 + ( 128Na3 π V )1/2 × ∞∫ 0 dx [x2 (x√ (x2 + 2) − x2 − 1 + 1 2x2 )]   . (15) The value of the integral turns out to be (128)1/2/15, with the result E0 N = 2π aℏ2n m [1 + 128 15π 1/2 (na3) 1/2] , (16) where n denotes the particle density in the system. Equation (16) represents the ﬁrst two terms of the expansion of the quantity E0/N in terms of the low-density parameter (na3)1/2; the ﬁrst term was already obtained in Section 11.2.7 The foregoing result was ﬁrst derived by Lee and Yang (1957) using the binary collision method; the details of this calculation, however, appeared somewhat later (see Lee and Yang, 1960a; see also Problem 11.6). Using the pseudopotential method, this result was rederived by Lee, Huang, and Yang (1957). The ground-state pressure of the system is now given by P0 = − ( ∂E0 ∂V ) N = n2 ∂(E0/N) ∂n = 2πaℏ2n2 m [1 + 64 5π 1/2 (na3) 1/2] , (17) 7The evaluation of higher-order terms of this expansion necessitates consideration of three-body collisions as well; hence, in general, they cannot be expressed in terms of the scattering length alone. The exceptional case of a hard-sphere gas has been studied by Wu (1959), who obtained (using the pseudopotential method) E0 N = 2πaℏ2n m [ 1 + 128 15π 1/2 (na3) 1/2 + 8 ( 4π 3 − √ 3) (na3) ln(12πna3) + O(na3) ] , which shows that the expansion does not proceed in simple powers of (na3)1/2. 11.3 Low-lying states of an imperfect Bose gas 365 from which one obtains for the velocity of sound c2 0 = 1 m dP0 dn = 4πaℏ2n m2 [ 1 + 16 π 1/2 (na3)1/2] . (18) Equations (17) and (18) are an improved version of the results obtained in Section 11.2. The ground state of the system is characterized by a total absence of excitations; accordingly, the eigenvalue of the (number) operator b † pbp of the quasiparticles must be zero for all p ̸= 0. As for the real particles, there must be some that possess nonzero ener- gies even at absolute zero, for otherwise the system cannot have a ﬁnite amount of energy in the ground state. The momentum distribution of the real particles can be determined by evaluating the ground-state expectation values of the number operators a† pap. Now, in the ground state of the system, ap|90⟩ = 1 √ (1 − α2 p) (bp − αpb † −p)|90⟩ = −αp √(1 − α2 p) b † −p|90⟩ (19) because bp|90⟩ ≡ 0. Constructing the hermitian conjugate of (19) and remembering that αp is real, we have ⟨90|a† p = −αp √ (1 − α2 p) ⟨90|b−p. (20) The scalar product of expressions (19) and (20) gives ⟨90|a† pap|90⟩ = α2 p 1 − α2 p ⟨90|b−pb † −p|90⟩ = α2 p 1 − α2 p ; (21) here, use has been made of the facts that (i) bpb † p − b † pbp = 1 and (ii) in the ground state, for all p ̸= 0, b † pbp = 0 (and hence bpb † p = 1). Thus, for p ̸= 0, np = α2 p 1 − α2 p = x2 + 1 2x√ (x2 + 2) − 1 2 , (22) where x = p(8π aℏ2n)−1/2. The total number of “excited” particles in the ground state of the system is, therefore, given by ∑ p̸=0 np = ∑ p̸=0 α2 p 1 − α2 p = ∑ x>0 1 2 ( x2 + 1 x√(x2 + 2) − 1 ) ≃ N { 32 π (na3)}1/2 ∞∫ 0 dx [ x2 ( x2 + 1 x√(x2 + 2) − 1 )] . (23) 366 Chapter 11. Statistical Mechanics of Interacting Systems The value of the integral turns out to be (2)1/2/3, with the result ∑ p̸=0 np ≃ N 8 3π 1/2 (na3) 1/2. (24) Accordingly, n0 = N − ∑ p̸=0 np ≃ N [1 − 8 3π 1/2 (na3)1/2] . (25) The foregoing result was ﬁrst obtained by Lee, Huang, and Yang (1957), using the pseu- dopotential method. It may be noted here that the importance of the real-particle occupa- tion numbers np in the study of the ground state of an interacting Bose system had been emphasized earlier by Penrose and Onsager (1956). 11.4 Energy spectrum of a Bose liquid In this section we propose to study the most essential features of the energy spectrum of a Bose liquid and to examine the relevance of this study to the problem of liquid He4. In this context we have seen that the low-lying states of a low-density gaseous system composed of weakly interacting bosons are characterized by the presence of the so-called elementary excitations (or “quasiparticles”), which are themselves bosons and whose energy spectrum is given by ε(p) = {p 2u 2 + (p 2/2m)2}1/2, (1) where u = (4πan) 1/2(ℏ/m); (2) see equations (11.3.10), (11.3.12), and (11.3.13). 8 For p ≪ mu, that is, p ≪ ℏ(an)1/2, the spectrum is essentially linear: ε ≃ pu. The initial slope of the (ε, p)-curve is, therefore, given by the parameter u, which is identical to the limiting value of the velocity of sound in the system; compare (2) with (11.3.18). It is then natural that these low-momentum excita- tions be identiﬁed as phonons — the quanta of the sound ﬁeld. For p ≫ mu, the spectrum approaches essentially the classical limit: ε ≃ p2/2m + 1∗, where 1∗ = mu2 = 4π anℏ2/m. It is important to note that, all along, this energy–momentum relationship is strictly mono- tonic and does not display any “dip” of the kind propounded by Landau (1941, 1947) (for 8Spectrum (1) was ﬁrst obtained by Bogoliubov (1947) by the method outlined in the preceding sections. Using the pseudopotential method, it was rederived by Lee, Huang, and Yang (1957). 11.4 Energy spectrum of a Bose liquid 367 liquid He 4) and observed experimentally by Yarnell et al. (1959), and by Henshaw and Woods (1961); see Section 7.6. Thus, the spectrum provided by the theory of the preceding sections simulates the Landau spectrum only to the extent of phonons; it does not account for rotons. This should not be surprising, for the theory in question was intended only for a low-density Bose gas (na3 ≪ 1) and not for liquid He4(na3 ≃ 0.2). The problem of elementary excitations in liquid He 4 was tackled successfully by Feynman who, in 1953 to 1954, developed an atomic theory of a Bose liquid at low tem- peratures. In a series of three fundamental papers starting from ﬁrst principles, Feynman established the following important results.9 (i) In spite of the presence of interatomic forces, a Bose liquid undergoes a phase transition analogous to the momentum-space condensation occurring in the ideal Bose gas; in other words, the original suggestion of London (1938a,b) regarding liquid He4, see Section 7.1, is essentially correct. (ii) At sufﬁciently low temperatures, the only excited states possible in the liquid are the ones related to compressional waves, namely phonons. Long-range motions, which leave the density of the liquid unaltered (and consequently imply nothing more than a simple “stirring” of the liquid), do not constitute excited states because they differ from the ground state only in the “permutation” of certain atoms. Motions on an atomic scale are indeed possible, but they require a minimum energy 1 for their excitation; clearly, these excitations would show up only at comparatively higher temperatures (T ∼ 1/k) and might well turn out to be Landau’s rotons. (iii) The wavefunction of the liquid, in the presence of an excitation, should be approximately of the form 9 = 8 ∑ i f (ri), (3) where 8 denotes the ground-state wavefunction of the system while the summation of f (ri) goes over all the N coordinates r1, . . . , rN ; the wavefunction 9 is, clearly, symmetric in its arguments. The exact character of the function f (r) can be determined by making use of a variational principle that requires the energy of the state 9 (and hence the energy associated with the excitation in question) to be a minimum. The optimal choice for f (r) turns out to be, see Problem 11.8, f (r) = exp i(k · r), (4) 9The reader interested in pursuing Feynman’s line of argument should refer to Feynman’s original papers or to a review of Feynman’s work on superﬂuidity by Mehra and Pathria (1994). 368 Chapter 11. Statistical Mechanics of Interacting Systems with the (minimized) energy value ε(k) = ℏ2k2 2mS(k) , (5) where S(k) is the structure factor of the liquid, that is, the Fourier transform of the pair correlation function g(r): S(k) = 1 + n ∫ (g(r) − 1)eik·rdr; (6) it may be recalled here that the function ng(r2 − r1) is the probability density for ﬁnding an atom in the neighborhood of the point r2 when another one is known to be at the point r1; see Section 10.7. The optimal wavefunction is, therefore, given by 9 = 8 ∑ i eik·ri . (7) Now the momentum associated with this excited state is ℏk because P9 = ( −iℏ ∑ i ∇i ) 9 = ℏk9, (8) P8 being identically equal to zero. Naturally, this would be interpreted as the momentum p associated with the excitation. One thus obtains, from ﬁrst principles, the energy– momentum relationship for the elementary excitations in a Bose liquid. On physical grounds one can show that, for small k, the structure factor S(k) rises lin- early as ℏk/2mc, reaches a maximum near k = 2π/r0 (corresponding to a maximum in the pair correlation function at the nearest-neighbor spacing r0, which for liquid He4 is about 3.6 ˚A) and thereafter decreases to approach, with minor oscillations (corresponding to the subsidiary maxima in the pair correlation function at the spacings of the next near- est neighbors), the limiting value 1 for large k; the limiting value 1 arises from the presence of a delta function in the expression for g(r) (because, as r2 → r1, one is sure to ﬁnd an atom there). 10 Accordingly, the energy ε(k) of an elementary excitation in liquid He 4 would start linearly as ℏkc, show a “dip” at k0 ≃ 2 ˚A −1 and rise again to approach the eventual limit of ℏ2k2/2m. 11 These features are shown in Figure 11.2. Clearly, Feynman’s approach merges both phonons and rotons into a single, uniﬁed scheme in which they represent 10For a microscopic study of the structure factor S(k), see Huang and Klein (1964); also Jackson and Feenberg (1962). 11It is natural that at some value of k < k0, the (ε, k)-curve passes through a maximum; this happens when dS/dk = 2S/k. 11.4 Energy spectrum of a Bose liquid 369 0 5 10 20 30 40 0.5 0 1.5 1.0 15 25 35 0.5 1.0 1.5 2.0 2.5 3.0 exptl exptl T 51.06 K 2 1 3.5 4.0 k, in A21´(k), in KS(k) FIGURE 11.2 The energy spectrum of the elementary excitations in liquid He 4. The upper portion shows the structure factor of the liquid, as derived by Henshaw (1960) from experimental data on neutron diffraction. Curve 1 in the lower portion shows the energy–momentum relationship based on the Feynman formula (5) while curve 2 is based on an improved formula by Feynman and Cohen (1956). For comparison, the experimental results of Woods (1966) obtained directly from neutron scattering are also included. different parts of a common (and continuous) energy spectrum ε(k), as determined by the structure of the liquid through the function S(k). Since no motion of a rotational character is involved here, the name “roton” is clearly a misnomer. It seems appropriate to mention here that, soon after the work of London, which advo- cated a connection between the phase transition in liquid He4 and the phenomenon of Bose–Einstein condensation, Bijl (1940) investigated the mathematical structure of the wavefunctions appropriate to an interacting Bose gas and the excitation energy associ- ated with those wavefunctions. His picture corresponded very closely to Feynman’s and indeed led to the wavefunction (7). Bijl also derived an expression for ε(k) that was exactly the same as (5). Unfortunately, he could not make much use of his results — primarily because he leaned too heavily on the expansion S(k) = S(0) + C2k2 + C4k4 + · · ·, (9) which, as we now know, represents neither phonons nor rotons. 370 Chapter 11. Statistical Mechanics of Interacting Systems 11.5 States with quantized circulation We now proceed to examine the possibility of “organized motion” in the ground state of a Bose ﬂuid. In this context, the most important concept is embodied in the cir- culation theorem of Feynman (1955), which establishes a physical basis for the existence of “quantized vortex motion” in the ﬂuid. In the case of liquid helium II, this concept has successfully resolved some of the vital questions that bafﬂed superﬂuid physicists for a long time. The ground-state wavefunction of a superﬂuid, composed of N bosons, may be denoted by a symmetric function 8(r1, . . . , rN ); if the superﬂuid does not partake in any organized motion, then 8 will be a pure real number. If, on the other hand, it possesses a uniform mass-motion with velocity vs, then its wavefunction would be 9 = 8ei(Ps·R)/ℏ = 8eim(vs·6iri)/ℏ, (1) where Ps denotes the total momentum of the ﬂuid and R its center of mass: Ps = Nmvs; R = N −1 ∑ i ri. (2) The wavefunction (1) is exact if the drift velocity vs is uniform throughout the ﬂuid. If vs is nonuniform, then the present wavefunction would still be good locally — in the sense that the phase change 1φ resulting from a “set of local displacements” of the atoms (over distances too small for velocity variations to be appreciable) would be practically the same as the one following from expression (1). Thus, for a given set of displacements 1ri of the atoms constituting the ﬂuid, the change in the phase of the wavefunction would very nearly be 1φ = m ℏ ∑ i (vsi · 1ri), (3) where vs is now a function of r. The foregoing result may be used for calculating the net phase change resulting from a displacement of atoms along a ring, from their original positions in the ring to the neighboring ones, so that after displacement we obtain a conﬁguration that is physically identical to the one we started with; see Figure 11.3. In view of the symmetry of the wave- function, the net phase change resulting from such a displacement must be an integral multiple of 2π (so that the wavefunction after the displacement is identical to the one before the displacement): m ℏ ∑′ i(vsi · 1ri) = 2πn, n = 0, ±1, ±2, . . . ; (4) the summation ∑′ here goes over all the atoms constituting the ring. We note that, for the foregoing result to be valid, it is only the individual 1ri that have to be small, not the whole perimeter of the ring. Now, for a ring of a macroscopic size, one may regard the ﬂuid as a 11.5 States with quantized circulation 371 FIGURE 11.3 The wavefunction of the ﬂuid must not change as a result of a permutation of the atoms. If all the atoms are displaced around a ring, as shown, the phase change must be a multiple of 2π. continuum; equation (4) then becomes ∮ vs · dr = n h m , n = 0, ±1, ±2, . . . . (5) The quantity on the left side of this equation is, by deﬁnition, the circulation (of the ﬂow) associated with the circuit of integration and is clearly quantized, the “quantum of circu- lation” being h/m. Equation (5) constitutes the circulation theorem of Feynman; it bears a striking resemblance to the quantum condition of Bohr, namely ∮ p dq = nh, (6) though the region of application here is macroscopic rather than microscopic.12 By Stokes’ theorem, equation (5) may be written as ∫ S (curl vs) · dS = n h m , n = 0, ±1, ±2, . . . , (7) where S denotes the area enclosed by the circuit of integration. If this area is “simply- connected” and the velocity vs is continuous throughout the area, then the domain of integration can be shrunk in a continuous manner without limit. The integral on the left side is then expected to decrease continuously and ﬁnally tend to zero. The right side, however, cannot vary continuously. We infer that in this particular case the quan- tum number n must be zero, that is, our integral must be identically vanishing. Thus, “in a simply-connected region, in which the velocity ﬁeld is continuous throughout, the condition curl vs = 0 (8) 12That the vortices in a superﬂuid may be quantized, the quantum of circulation being h/m, was ﬁrst suggested by Onsager (1949) in a footnote to a paper dealing with the classical vortex theory and the theory of turbulence! 372 Chapter 11. Statistical Mechanics of Interacting Systems holds everywhere.” This is precisely the condition postulated by Landau (1941), which has been the cornerstone of our understanding of the hydrodynamic behavior of superﬂuid helium. 13 Clearly, the Landau condition is only a special case of the Feynman theorem. It is quite possible that in a “multiply-connected” domain, which cannot be shrunk continuously to zero (without encountering singularities in the velocity ﬁeld), the Landau condition may not hold everywhere. A typical example of such a domain is provided by the ﬂow of a vortex, which is a planar ﬂow with cylindrical symmetry, such that vρ = 0, vφ = K 2πρ , vz = 0, (9) where ρ is the distance measured perpendicular to the axis of symmetry while K is the circulation of the ﬂow: ∮ v · dr = ∮ vφ(ρ dφ) = K ; (10) note that the circuit of integration in (10) must enclose the axis of the vortex. Another version of the foregoing result is ∫ S (curl v) · dS = ∫ S { 1 ρ d dρ (ρvφ) } (2πρ dρ) = K . (11) Now, at all ρ ̸= 0, curl v = 0 but at ρ = 0, where vφ is singular, curl v appears to be indeter- minate; it is not difﬁcult to see that, at ρ = 0, curl v diverges (in such a way that the integral in (11) turns out to be ﬁnite). In this context, it seems worthwhile to point out that if we carry out the integration in (10) along a circuit that does not enclose the axis of the vortex, or in (11) over a region that does not include the point ρ = 0, the result would be identically zero. At this stage we note that the energy associated with a unit length of a classical vortex is given by E L = b∫ a 1 2 {2πρ dρ(mn0)} ( K 2πρ )2 = mn0K 2 4π ln(b/a). (12) 13Drawing on the well-known analogy between the phenomena of superﬂuidity and superconductivity, and the resulting correspondence between the mechanical momentum mvs of a superﬂuid particle and the electromagnetic momentum 2eA/c of a Cooper pair of electrons, we observe that the relevant counterpart of the Landau condition, in superconductors, would be curl A ≡ B = 0, (8a) which is precisely the Meissner effect; furthermore, the appropriate counterpart of the Feynman theorem would be ∫ S B · dS = n hc 2e , (7a) which leads to the “quantization of the magnetic ﬂux,” the quantum of ﬂux being hc/2e. 11.5 States with quantized circulation 373 Here, (mn0) is the mass density of the ﬂuid (which is assumed to be uniform), the upper limit b is related to the size of the container while the lower limit a depends on the structure of the vortex; in our study, a would be comparable to the interatomic separation. In the quantum-mechanical case we may describe our vortex through a self-consistent wavefunction ψ(r), which, in the case of cylindrical symmetry, see equation (9), may be written as ψ(r) = n ∗1/2eisφfs(ρ), (13) so that n(r) ≡ |ψ(r)|2 = n ∗f 2 s (ρ). (14) As ρ → ∞, fs(ρ) → 1, so that n∗ becomes the limiting particle density in the ﬂuid in regions far away from the axis of the vortex. The velocity ﬁeld associated with this wavefunction will be v(r) = ℏ 2im(ψ ∗ψ) (ψ ∗∇ψ − ψ∇ψ ∗) = ℏ m ∇(sφ) = (0, s ℏ mρ , 0). (15)14 Comparing (15) with (9), we conclude that the circulation K in the present case is sh/m; by the circulation theorem, s must be an integer: s = 0, ±1, ±2, . . . . (16) Clearly, the value 0 is of no interest to us. Furthermore, the negative values of s differ from the positive ones only in the “sense of rotation” of the ﬂuid. It is, therefore, sufﬁcient to consider the positive values alone, namely s = 1, 2, 3, . . . . (17) The function fs(ρ) appearing in equation (13) may be determined with the help of a Schr¨odinger equation in which the potential term is itself ψ-dependent, namely ( − ℏ2 2m ∇2 + u0|ψ|2) ψ = εψ, (18) 14It is of interest to see that the angular momentum per particle in the ﬂuid is given by 1 ψ ( ℏ i ∂ ∂φ ψ) = sℏ (= mvφ ρ); this is again reminiscent of the quantum condition of Bohr. 374 Chapter 11. Statistical Mechanics of Interacting Systems where u0 is given by equation (11.1.51): u0 = 4πaℏ2/m, (19) a being the scattering length of the interparticle interaction operating in the ﬂuid. The characteristic energy ε follows from the observation that, at large distances from the axis of the vortex, the ﬂuid is essentially uniform in density, with n(r) → n∗; equation (18) then gives ε = u0n∗ = 4π aℏ2n ∗/m, (20) which may be compared with equation (11.2.9). Substituting (20) into (18) and remember- ing that the ﬂow is cylindrically symmetrical, we get − [ 1 ρ d dρ { ρ d dρ fs(ρ) } − s2 ρ2 fs(ρ) ] + 8πan∗f 3 s (ρ) = 8π an ∗fs(ρ). (21) Expressing ρ in terms of a characteristic length l, ρ = lρ′ {l = (8π an ∗)−1/2}, (22) we obtain d2fs dρ′2 + 1 ρ′ dfs dρ′ + ( 1 − s2 ρ′2 ) fs − f 3 s = 0. (23) Toward the axis of the vortex, where ρ → 0, the very high velocity of the ﬂuid (and the very large centrifugal force accompanying it) will push the particles outward, thus causing an enormous decrease in the density of the ﬂuid. Consequently, the function fs should tend to zero as ρ → 0. This will make the last term in equation (23) negligible and thereby reduce it to the familiar Bessel’s equation. Accordingly, for small ρ, fs(ρ′) ∼ Js(ρ′) ∼ ρs, (24) Js being the ordinary Bessel function of order s. For ρ′ ≫ 1, fs ≃ 1; then, the ﬁrst two terms of equation (23) become negligible, with the result fs(ρ′) ≃ 1 − s2 2ρ′2 . (25) The full solution is obtained by integrating the equation numerically; the results so obtained are shown in Figure 11.4 where solutions for s = 1, 2, and 3 are displayed. We thus ﬁnd that our model of an imperfect Bose gas does allow for the presence of quantized vortices in the system. Not only that, we do not have to invoke here any special assumptions regarding the nature of the “core” of the vortex (as one has to do in the classi- cal theory); our treatment naturally leads to a continual diminution of the particle density 11.5 States with quantized circulation 375 0 0 0.2 0.4 0.6 0.8 1.0 123 s 51 s 52 s 53 45678 \u0002\u0003fs(\u0002\u0003) FIGURE 11.4 Solutions of equation (23) for various values of s (after Kawatra and Pathria, 1966). n as the axial line is approached, so that there does not exist any speciﬁc distribution of vorticity around this line. The distance scale, which governs the spatial variation of n, is provided by the parameter l of equation (22); for liquid He4, l ≃ 1 ˚A. Pitaevskii (1961), who was among the ﬁrst to demonstrate the possibility of obtaining solutions whose natural interpretation lay in quantized vortex motion (see also Gross, 1961; Weller, 1963), also evaluated the energy per unit length of the vortex. Employ- ing wavefunction (13), with known values of the functions fs(ρ), Pitaevskii obtained the following results for the energy per unit length of the vortex, with s = 1, 2, or 3, n∗h2 4π m { 1 ln(1.46R/l ), 4 ln(0.59R/l ), 9 ln(0.38R/l ) } , (26) where R denotes the outer radius of the domain involved. The above results may be compared with the “semiclassical” ones, namely n0h2 4π m { 1 ln(R/a), 4 ln(R/a), 9 ln(R/a)} , (27) which follow from formula (12), with K replaced by sh/m and b by R. It is obvious that vortices with s > 1 would be relatively unstable because energetically it would be cheaper for a system to have s vortices of unit circulation rather than a single vortex of circulation s. The existence of quantized vortex lines in liquid helium II has been demonstrated con- vincingly by the ingenious experiments of Vinen (1958–1961) in which the circulation K around a ﬁne wire immersed in the liquid was measured through the inﬂuence it exerts on the transverse vibrations of the wire. Vinen found that while vortices with unit circulation were exceptionally stable those with higher circulation too made an appearance. Repeat- ing Vinen’s experiment with thicker wires, Whitmore and Zimmermann (1965) were able 376 Chapter 11. Statistical Mechanics of Interacting Systems to observe stable vortices with circulation up to three quantum units. For a survey of this and other aspects of the superﬂuid behavior, see Vinen (1968) and Betts et al. (1969). Kim and Chan (2004) have even observed a “supersolid” phase of helium-4 at low temperatures that has the crystalline structure of a solid while also exhibiting superfuid-like ﬂow. For the relevance of quantized vortex lines to the problem of “rotation” of the super- ﬂuid, see Section 10.7 of the ﬁrst edition of this book. 11.6 Quantized vortex rings and the breakdown of superﬂuidity Feynman (1955) was the ﬁrst to suggest that the formation of vortices in liquid helium II might provide the mechanism responsible for the breakdown of superﬂuidity in the liquid. He considered the ﬂow of liquid helium II from an oriﬁce of diameter D and, by tentative arguments, found that the velocity v0 at which the ﬂow energy available would just be sufﬁcient to create quantized vortices in the liquid is given by v0 = ℏ mD ln(D/l). (1) Thus, for an oriﬁce of diameter 10−5 cm, v0 would be of the order of 1 m/s.15 It is tempting to identify v0 with vc, the critical velocity of superﬂow through the given capillary, despite the fact that this theoretical estimate for v0 is an order of magnitude higher than the cor- responding experimental values of vc; the latter, for instance, are 13 cm/s, 8 cm/s, and 4 cm/s for capillary diameters 1.2 × 10−5 cm, 7.9 × 10−5 cm, and 3.9 × 10−4 cm, respec- tively. Nevertheless, the present estimate is far more desirable than the prohibitively large ones obtained earlier on the basis of a possible creation of phonons or rotons in the liquid; see Section 7.6. Moreover, one obtains here a deﬁnitive dependence of the critical veloc- ity of superﬂow on the width of the capillary employed which, at least qualitatively, agrees with the trend seen in the experimental ﬁndings. In what follows, we propose to develop Feynman’s idea further along the lines suggested by the preceding section. So far we have been dealing with the so-called linear vortices whose velocity ﬁeld pos- sesses cylindrical symmetry. More generally, however, a vortex line need not be straight — it may be curved and, if it does not terminate on the walls of the container or on the free surface of the liquid, may close on itself. We then speak of a vortex ring, which is very much like a smoke ring. Of course, the quantization condition (11.5.5) is as valid for a vortex ring as for a vortex line. However, the dynamical properties of a ring are quite different from those of a line; see, for instance, Figure 11.5, which shows schematically a vortex ring in cross-section, the radius r of the ring being much larger than the core dimension l. The ﬂow velocity vs at any point in the ﬁeld is determined by a superposition of the ﬂow velo- cities due to the various elements of the ring. It is not difﬁcult to see that the velocity ﬁeld 15We have taken here: l ≃ 1 ˚A, so that ln(D/l) ≃ 7. 11.6 Quantized vortex rings and the breakdown of superﬂuidity 377 r v v r FIGURE 11.5 Schematic illustration of a quantized vortex ring in cross-section. of the ring, including the ring itself, moves in a direction perpendicular to the plane of the ring, with a velocity16 v ∼ ℏ/2mr; (2) see equation (11.5.15), with s = 1 and ρ ∼ 2r. An estimate of the energy associated with the ﬂow may be obtained from expression (11.5.12), with L = 2π r, K = h/m, and b ∼ r; thus ε ∼ 2π 2ℏ2n0m −1r ln(r/l). (3) Clearly, the dependence of ε on r arises mainly from the factor r and only slightly from the factor ln(r/l). Therefore, with good approximation, v ∝ ε−1, that is, a ring with larger energy moves slower! The reason behind this somewhat startling result is that ﬁrstly the larger the ring the larger the distances between the various circulation-carrying elements of the ring (thus reducing the velocity imparted by one element to another) and secondly a larger ring carries with it a larger amount of ﬂuid (M ∝ r3), so the total energy associated with the ring is also larger (essentially proportional to Mv2, i.e., ∝ r). The product vε, apart from the slowly varying factor ln(r/l), is thus a constant, which is equal to π 2ℏ3n0/m2. It is gratifying that vortex rings such as the ones discussed here have been observed and the circulation around them is found to be as close to the quantum h/m as one could expect under the conditions of the experiment. Figure 11.6 shows the experimental results of Rayﬁeld and Reif (1964) for the velocity–energy relationship of free-moving, charge- carrying vortex rings created in liquid helium II by suitably accelerated helium ions. Vortex rings carrying positive as well as negative charge were observed; dynamically, however, they behaved alike, as one indeed expects because both the velocity and the energy asso- ciated with a vortex ring are determined by the properties of a large amount of ﬂuid carried 16This result would be exact if we had a pair of oppositely directed linear vortices, with the same cross-section as shown in Figure 11.5. In the case of a ring, the velocity would be somewhat larger. 378 Chapter 11. Statistical Mechanics of Interacting Systems 010 20 20 40 60 80 100 \u0002 charges \u0003 charges 120 140 30 40 50 \u0004 (in electron volts)v (in cm/sec) FIGURE 11.6 The velocity–energy relationship of the vortex rings formed in liquid helium II (after Rayﬁeld and Reif, 1964). The points indicate the experimental data, while the curve represents the theoretical relationship based on the “quantum of circulation” h/m. along with the ring rather than by the small charge coupled to it. Fitting experimental results with the notion of the vortex rings, Rayﬁeld and Reif concluded that their rings carried a circulation of (1.00 ± 0.03) × 10−3 cm2/s, which is close to the Onsager–Feynman unit h/m (= 0.997 × 10−3 cm2/s); moreover, these rings seemed to have a core radius of about 1.2 ˚A, which is comparable with the characteristic parameter l of the ﬂuid. We shall now show that the dynamics of the quantized vortex rings is such that their creation in liquid helium II does provide a mechanism for the breakdown of superﬂuidity. To see this, it is simplest to consider the case of a superﬂuid ﬂowing through a capillary of radius R. As the velocity of ﬂow increases and approaches the critical value vc, quantized vortex rings begin to form and energy dissipation sets in, which in turn brings about the rupture of the superﬂow. By symmetry, the rings will be so formed that their central plane will be perpendicular to the axis of the capillary and they will be moving in the direction of the main ﬂow. Now, by the Landau criterion (7.6.24), the critical velocity of superﬂow is directly determined by the energy spectrum of the excitations created: vc = (ε/p)min. (4) We, therefore, require an expression for the momentum p of the vortex ring. In analogy with the classical vortex ring, we may take p = 2π 2ℏn0r2, (5) which seems satisfactory because (i) it conforms to the general result: v = (∂ε/∂p), though only to a ﬁrst approximation, and (ii) it leads to the (approximate) dispersion relation: 11.7 Low-lying states of an imperfect Fermi gas 379 ε ∝ p1/2, which has been separately veriﬁed by Rayﬁeld and Reif by subjecting their rings to a transverse electric ﬁeld. Substituting (3) and (5) into (4), we obtain vc ∼ { ℏ mr ln(r/l)} min . (6) Now, since the r-dependence of the quantity ε/p arises mainly from the factor 1/r, the minimum in (6) will be obtained when r has its largest value, namely R, the radius of the capillary. We thus obtain vc ∼ ℏ mR ln(R/l), (7) which is very much the same as the original estimate of Feynman — with D replaced by R. Naturally, then, the numerical values of vc obtained from the new expression (7) continue to be signiﬁcantly larger than the corresponding experimental values; however, the theory is now much better founded. Fetter (1963) was the ﬁrst to account for the fact that, as the radius r of the ring approaches the radius R of the capillary, the inﬂuence of the “image vortex” becomes important. The energy of the ﬂow now falls below the asymptotic value given by (3) by a factor of 10 or so which, in turn, reduces the critical velocity by a similar factor. The actual result obtained by Fetter was vc ≃ 11 24 ℏ mR = 0.46 ℏ mR . (8) Kawatra and Pathria (1966) extended Fetter’s calculation by taking into account the boundary effects arising explicitly from the walls of the capillary as well as the ones aris- ing implicitly from the “image vortex”; moreover, in the computation of ε, they employed actual wavefunctions, obtained by solving equation (11.5.23), rather than the analytical approximation employed by Fetter. They obtained vc ≃ 0.59 ℏ mR , (9) which is about 30 percent higher than Fetter’s value; for comments regarding the “most favorable” location for the formation of the vortex ring in the capillary, see the original reference of Kowatra and Pathria (1966). 11.7 Low-lying states of an imperfect Fermi gas The Hamiltonian of the quantized ﬁeld for spin-half fermions (σ = + 1 2 or − 1 2 ) is given by equation (11.1.48), namely ˆH = ∑ p,σ p2 2m a† pσ apσ + 1 2 ∑′ u p′ 1σ ′ 1,p′ 2σ ′ 2 p1σ1,p2σ2 a† p′ 1σ ′ 1 a† p′ 2σ ′ 2 ap2σ2 ap1σ1 , (1) 380 Chapter 11. Statistical Mechanics of Interacting Systems where the matrix elements u are related to the scattering length a of the two-body inter- action; the summation in the second part of this expression goes only over those states (of the two particles) that conform to the principles of momentum and spin conservation. As in the Bose case, the matrix elements u in the second sum may be approximated by their values at p = 0, that is, u p′ 1σ ′ 1,p′ 2σ ′ 2 p1σ1,p2σ2 ≃ u0σ ′ 1,0σ ′ 2 0σ1,0σ2 . (2) Then, in view of the antisymmetric character of the product ap1σ1 ap2σ2, see equa- tion (11.1.24c), all those terms of the second sum in (1) that contain identical indices σ1 and σ2 vanish on summation over p1 and p2. Similarly, all those terms that contain iden- tical indices σ ′ 1 and σ ′ 2 vanish on summation over p′ 1 and p′ 2.17 Thus, for a given set of values of the particle momenta, the only choices for the spin components remaining in the sum are (i) σ1 = + 1 2 , σ2 = − 1 2 ; σ ′ 1 = + 1 2 , σ ′ 2 = − 1 2 (ii) σ1 = + 1 2 , σ2 = − 1 2 ; σ ′ 1 = − 1 2 , σ ′ 2 = + 1 2 (iii) σ1 = − 1 2 , σ2 = + 1 2 ; σ ′ 1 = − 1 2 , σ ′ 2 = + 1 2 (iv) σ1 = − 1 2 , σ2 = + 1 2 ; σ ′ 1 = + 1 2 , σ ′ 2 = − 1 2 . It is not difﬁcult to see that the contribution arising from choice (i) will be identi- cally equal to the one arising from choice (iii), while the contribution arising from choice (ii) will be identically equal to the one arising from choice (iv). We may, therefore, write ˆH = ∑ p,σ p2 2m a† pσ apσ + u0 V ∑′ a† p′ 1+a† p′ 2−ap2−ap1+, (3) where u0 V = (u 0+,0− 0+,0− − u 0−,0+ 0+,0−) , (4) while the indices + and − denote the spin states σ = + 1 2 and σ = − 1 2 , respectively; the summation in the second part of (3) now goes over all momenta that conform to the conservation law p′ 1 + p′ 2 = p1 + p2. (5) To evaluate the eigenvalues of Hamiltonian (3), we shall employ the techniques of the perturbation theory. 17Physically, this means that in the limiting case of slow collisions only particles with opposite spins interact with one another. 11.7 Low-lying states of an imperfect Fermi gas 381 First of all, we note that the main term in the expression for ˆH is already diagonal, and its eigenvalues are E(0) = ∑ p,σ p2 2m npσ, (6) where npσ is the occupation number of the single-particle state (p, σ ); its mean value, in equilibrium, is given by the Fermi distribution function npσ = 1 z−1 0 exp(p2/2mkT ) + 1 . (7) The sum in (6) may be replaced by an integral, with the result (see Section 8.1, with g = 2) E(0) = V 3kT λ3 f5/2(z0), (8) where λ is the mean thermal wavelength of the particles, λ = h/(2π mkT ) 1/2, (9) while fν(z0) is the Fermi–Dirac function fν (z0) = 1 0(ν) ∞∫ 0 xν−1dx z−1 0 ex + 1 = ∞∑ l=1(−1) l−1 zl 0 lν ; (10) the ideal-gas fugacity z0 is determined by the total number of particles in the system: N = ∑ p,σ npσ = V 2 λ3 f3/2(z0). (11) The ﬁrst-order correction to the energy of the system is given by the diagonal elements of the interaction term, namely the ones for which p′ 1 = p1 and p′ 2 = p2; thus E(1) = u0 V ∑ p1,p2 np1+ np2− = u0 V N +N −, (12) where N +(N −) denotes the total number of particles with spin up (down). Substituting the equilibrium values N + = N − = 1 2 N, we obtain E(1) = u0 4V N 2 = V u0 λ6 { f3/2(z0)}2 . (13) Substituting u0 ≃ 4π aℏ2/m, see equation (11.1.51), we obtain to ﬁrst order in a E(1) 1 = π aℏ2 m N V N = V 2kT λ3 ( a λ ) { f3/2(z0) }2 . (14) 382 Chapter 11. Statistical Mechanics of Interacting Systems The second-order correction to the energy of the system can be obtained with the help of the formula E(2) n = ∑ m̸=n |Vnm|2 En − Em , (15) where the indices n and m pertain to the unperturbed states of the system. A simple calculation yields: E(2) = 2 u2 0 V 2 ∑ p1,p2,p′ 1 np1+np2− (1 − np′ 1+) (1 − np′ 2−) ( p2 1 + p2 2 − p′2 1 − p′2 2 ) /2m , (16) where the summation goes over all p1, p2, and p′ 1 (the value of p′ 2 being ﬁxed by the requirement of momentum conservation); it is understood that we do not include in the sum (16) any terms for which p2 1 + p2 2 = p′2 1 + p′2 2 . It will be noted that the numerator of the summand in (16) is closely related to the fact that the squared matrix element for the transition (p1, p2) → (p′ 1, p′ 2) is directly proportional to the probability that “the states p1 and p2 are occupied and at the same time the states p′ 1 and p′ 2 are unoccupied.” Now, expression (16) does not in itself exhaust terms of second order in a. A contribution of the same order of magnitude arises from expression (12) if for u0 we employ an expres- sion more accurate than the one just employed. The desired expression can be obtained in the same manner as in the Bose case; check the steps leading to equations (11.2.5) and (11.2.6). In the present case, we obtain 4πaℏ2 mV ≃ u0 V + 2 u2 0 V 2 ∑ p1,p2,p′ 1 1 (p2 1 + p2 2 − p′2 1 − p′2 2 ) /2m , from which it follows that u0 ≃ 4π aℏ2 m      1 − 8πaℏ2 mV ∑ p1,p2,p′ 1 1 ( p2 1 + p2 2 − p′2 1 − p′2 2 ) /2m     . (17) Substituting (17) into (12), we obtain, apart from the ﬁrst-order term already given in (14), a second order term, namely E(1) 2 = −2 ( 4π aℏ2 mV )2 ∑ p1,p2,p′ 1 np1+np2− ( p2 1 + p2 2 − p′2 1 − p′2 2 )/2m . (18) 11.7 Low-lying states of an imperfect Fermi gas 383 For a comparable term given in (16), the approximation u0 ≃ 4π aℏ2/m is sufﬁcient, with the result E(2) 2 = 2 ( 4πaℏ2 mV )2 ∑ p1,p2,p′ 1 np1+np2− (1 − np′ 1+) (1 − np′ 2−) (p2 1 + p2 2 − p′2 1 − p′2 2 ) /2m . (19) Combining (18) and (19), we obtain 18 E2 = E(1) 2 + E(2) 2 = −2 ( 4π aℏ2 mV )2 ∑ p1,p2,p′ 1 np1+np2− ( np′ 1+ + np′ 2−) ( p2 1 + p2 2 − p′2 1 − p′2 2 )/2m . (20) To evaluate the sum in (20), we prefer to write it as a symmetrical summation over the four momenta p1, p2, p′ 1, and p′ 2 by introducing a Kronecker delta to take care of the momentum conservation; thus E2 = −2 ( 4πaℏ2 mV )2 ∑ p1,p2,p′ 1,p′ 2 np1+np2− (np′ 1+ + np′ 2−) δp1+p2,p′ 1+p′ 2 (p2 1 + p2 2 − p′2 1 − p′2 2 ) /2m . (21) It is obvious that the two parts of the sum (21), one arising from the factor np′ 1+ and the other from the factor np′ 2−, would give identical results on summation. We may, therefore, write E2 = −4 ( 4π aℏ2 mV )2 ∑ p1,p2,p′ 1,p′ 2 np1+np2−np′ 1+δp1+p2,p′ 1+p′ 2(p2 1 + p2 2 − p′2 1 − p′2 2 ) /2m . (22) The sum in (22) can be evaluated by following a procedure due to Huang, Yang, and Luttinger (1957), with the result 19 E2 = V 8kT λ3 ( a2 λ2 ) F(z0), (23) where F(z0) = − ∞∑ r,s,t=1 (−z0)r+s+t √(rst)(r + s)(r + t) . (24) 18We have omitted here terms containing a “product of four n’s” for the following reason: in view of the fact that the numerator of such terms would be symmetric and the denominator antisymmetric with respect to the exchange operation (p1, p2) ↔ (p′ 1, p′ 2), their sum over the variables p1, p2, p′ 1 (and p′ 2) would vanish identically. 19For a direct evaluation of the sum (22), in the limit T → 0, see Abrikosov and Khalatnikov (1957). See also Problem 11.12. 384 Chapter 11. Statistical Mechanics of Interacting Systems Combining (8), (14), and (23), we obtain to second order in the scattering length a E = V kT λ3 [ 3f5/2(z0) + 2a λ {f3/2(z0)}2 + 8a2 λ2 F(z0) ] , (25) where z0 is determined by (11). It is now straightforward to obtain the ground-state energy of the imperfect Fermi gas (z0 → ∞); we have simply to know the asymptotic behavior of the functions involved. For the functions fν(z0), we have from the Sommerfeld lemma (see Appendix E) fν (z0) ≈ (ln z0) ν / 0(ν + 1), (26) so that f5/2(z0) ≈ 8 15π 1/2 (ln z0) 5/2; f3/2(z0) ≈ 4 3π 1/2 (ln z0)3/2. (27) Equation (11) then gives n = N V ≈ 8 3π 1/2λ3 (ln z0) 3/2, (28) so that ln z0 ≈ λ2 ( 3π 1/2n 8 )2/3 . (29) The asymptotic behaviour of F(z0) is given by F(z0) ≈ 16(11 − 2 ln 2) 105π 3/2 (ln z0) 7/2; (30) see Problem 11.12. Substituting (27) and (30) into (25), and making use of relation (29), we ﬁnally obtain E0 N = 3 10 ℏ2 m (3π 2n) 2/3 + π aℏ2 m n { 1 + 6 35 (11 − 2 ln 2) ( 3 π )1/3 n1/3a } . (31) The ground-state pressure of the gas is then given by P0 = n 2 ∂(E0/N) ∂n = 1 5 ℏ2 m (3π 2n) 2/3n + πaℏ2 m n 2 { 1 + 8 35 (11 − 2 ln 2) ( 3 π )1/3 n 1/3a } . (32) 11.8 Energy spectrum of a Fermi liquid 385 We may also calculate the velocity of sound, which directly involves the compressibility of the system, with the result c2 0 = ∂P0 ∂(mn) = 1 3 ℏ2 m2 (3π 2n) 2/3 + 2πaℏ2 m2 n { 1 + 4 15 (11 − 2 ln 2) ( 3 π )1/3 n 1/3a } . (33) The leading terms of the foregoing expressions represent the ground-state results for an ideal Fermi gas, while the remaining terms represent corrections arising from the interparticle interactions. The result embodied in equation (31) was ﬁrst obtained by Huang and Yang (1957) by the method of pseudopotentials; Martin and De Dominicis (1957) were the ﬁrst to attempt an estimate of the third-order correction.20 Lee and Yang (1957) obtained (31) on the basis of the binary collision method; for the details of their calculation, see Lee and Yang (1959b, 1960a). The same result was derived somewhat later by Galitskii (1958) who employed the method of Green’s functions. 11.8 Energy spectrum of a Fermi liquid: Landau’s phenomenological theory21 In Section 11.4 we discussed the main features of the energy spectrum of a Bose liquid; such a spectrum is generally referred to as a Bose type spectrum. A liquid consisting of spin-half fermions, such as liquid He3, is expected to have a different kind of spectrum which, by contrast, may be called a Fermi type spectrum. Right away we should emphasize that a liquid consisting of fermions may not neces- sarily possess a spectrum of the Fermi type; the spectrum actually possessed by such a liquid depends crucially on the nature of the interparticle interactions operating in the liquid. The discussion here assumes that the interactions are strictly repulsive so that the fermions have no opportunity to form bosonic pairs. In the present section, we propose to discuss the main features of a spectrum which is characteristically of the Fermi type. The effects of attractive interactions will be discussed in Section 11.9 According to Landau (1956), whose work provides the basic framework for our discus- sion, the Fermi type spectrum of a quantum liquid is constructed in analogy with the spectrum of an ideal Fermi gas. As is well-known, the ground state of the ideal Fermi gas corresponds to a “complete ﬁlling up of the single-particle states with p ≤ pF and a complete absence of particles in the states with p > pF ”; the excitation of the system corre- sponds to a transition of one or more particles from the occupied states to the unoccupied states. The limiting momentum pF is related to the particle density in the system and, for 20The third-order correction has also been discussed by Mohling (1961). 21For a microscopic theory of a Fermi liquid, see Nozi`eres (1964); see also Tuttle and Mohling (1966). 386 Chapter 11. Statistical Mechanics of Interacting Systems spin-half particles, is given by pF = ℏ(3π 2N/V )1/3. (1) In a liquid, we cannot speak of quantum states of individual particles. However, as a basis for constructing the desired spectrum, we may assume that, as interparticle inter- actions are gradually “switched on” and a transition made from the gaseous to the liquid state, the ordering of the energy levels (in the momentum space) remains unchanged. Of course, in this ordering, the role of the gas particles is passed on to the “elementary exci- tations” of the liquid (also referred to as “quasiparticles”), whose number coincides with the number of particles in the liquid and which also obey Fermi statistics. Each “quasipar- ticle” possesses a deﬁnite momentum p, so we can speak of a distribution function n(p) such that ∫ n(p)dτ = N/V , (2) where dτ = 2d3p/h3. We then expect that the speciﬁcation of the function n(p) uniquely determines the total energy E of the liquid. Of course, E will not be given by a simple sum of the energies ε(p) of the quasiparticles; it will rather be a functional of the distribution func- tion n(p). In other words, the energy E will not reduce to the simple integral ∫ ε(p)n(p)Vdτ , though in the ﬁrst approximation a variation in its value may be written as δE = V ∫ ε(p)δn(p)dτ , (3) where δn(p) is an assumed variation in the distribution function of the “quasiparticles.” The reason E does not reduce to an integral of the quantity ε(p)n(p) is related to the fact that the quantity ε(p) is itself a functional of the distribution function. If the initial distri- bution function is a step function (which corresponds to the ground state of the system), then the variation in ε(p) due to a small deviation of the distribution function from the step function (which implies only low-lying excited states of the system) would be given by a linear functional relationship: δε(p) = ∫ f (p, p′)δn(p′)dτ ′. (4) Thus, the quantities ε(p) and f (p, p′) are the ﬁrst and second functional derivatives of E with respect to n(p). Inserting spin dependence, we may now write δE = ∑ p,σ ε(p, σ )δn(p, σ ) + 1 2V ∑ p,σ ;p′,σ ′ f (p, σ ; p′, σ ′)δn(p, σ )δn(p′, σ ′), (5) where δn are small variations in the distribution function n(p) from the step function (that characterizes the ground state of the system); it is obvious that these variations will be sig- niﬁcant only in the vicinity of the limiting momentum pF , which continues to be given 11.8 Energy spectrum of a Fermi liquid 387 by equation (1). It is thus understood that the quantity ε(p, σ ) in (5) corresponds to the distribution function n(p, σ ) being inﬁnitesimally close to the step function (of the ground state). One may also note that the function f (p, σ ; p′, σ ′), being a second functional deriva- tive of E, must be symmetric in its arguments; often, it is of the form a + b ˆs1 · ˆs2, where the coefﬁcients a and b depend only on the angle between the momenta p and p′.22 The function f plays a central role in the theory of the Fermi liquid; for an ideal gas, f vanishes. To discover the formal dependence of the distribution function n(p) on the energy ε(p), we note that, in view of the one-to-one correspondence between the energy levels of the liquid and of the ideal gas, the number of microstates (and hence the entropy) of the liquid is given by the same expression as for the ideal gas; see equation (6.1.15), with all gi = 1 and a = +1, or Problem 6.1: S k = − ∑ p {n ln n + (1 − n) ln(1 − n)} ≈ −V ∫ {n ln n + (1 − n) ln(1 − n)}dτ . (6) Maximizing this expression, under the constraints δE = 0 and δN = 0, we obtain for the equilibrium distribution function n = 1 exp{(ε − µ)/kT } + 1 . (7) It should be noted here that, despite its formal similarity with the standard expression for the Fermi–Dirac distribution function, formula (7) is different insofar as the quantity ε appearing here is itself a function of n; consequently, this formula gives only an implicit, and probably a very complicated, expression for the function n. A word may now be said about the quantity ε appearing in equation (5). Since this ε cor- responds to the limiting case of n being a step function, it is expected to be a well-deﬁned function of p. Equation (7) then reduces to the usual Fermi–Dirac distribution function, which is indeed an explicit function of ε. It is not difﬁcult to see that this reduction remains valid so long as expression (5) is valid, that is, so long as the variations δn are small, which in turn means that T ≪ TF . As mentioned earlier, the variation δn will be signiﬁcant only in the vicinity of the Fermi momentum pF ; accordingly, we will not have much to do with the function ε(p) except when p ≃ pF . We may, therefore, write ε(p ≃ pF ) = εF + ( ∂ε ∂p ) p=pF (p − pF ) + · · · ≃ εF + uF (p − pF ), (8) where uF denotes the “velocity” of the quasiparticles at the Fermi surface. In the case of an ideal gas (ε = p2/2m), uF = pF /m. By analogy, we deﬁne a parameter m∗ such that m ∗ ≡ pF uF = pF (∂ε/∂p)p=pF (9) 22Of course, if the functions involved here are spin-dependent, then the factor 2 in the element dτ (as well as in dτ ′) must be replaced by a summation over the spin variable(s). 388 Chapter 11. Statistical Mechanics of Interacting Systems and call it the effective mass of the quasiparticle with momentum pF (or with p ≃ pF ). Another way of looking at the parameter m∗ is due to Brueckner and Gammel (1958), who wrote ε(p ≃ pF ) = p2 2m + V (p) = p2 2m∗ + const.; (10) the philosophy behind this expression is that “for quasiparticles with p ≃ pF , the modiﬁ- cation, V (p), brought into the quantity ε(p) by the presence of inter-particle interactions in the liquid may be represented by a constant term while the kinetic energy, p2/2m, is modiﬁed so as to replace the particle mass m by an effective, quasiparticle mass m∗”; in other words, we adopt a mean ﬁeld point of view. Differentiating (10) with respect to p and setting p = pF , we obtain 1 m∗ = 1 m + 1 pF ( dV (p) dp ) p=pF . (11) The quantity m∗, in particular, determines the low-temperature speciﬁc heat of the Fermi liquid. We can readily see that, for T ≪ TF , the ratio of the speciﬁc heat of a Fermi liquid to that of an ideal Fermi gas is precisely equal to the ratio m∗/m: (CV )real (CV )ideal = m∗ m . (12) This follows from the fact that (i) expression (6) for the entropy S, in terms of the distri- bution function n, is the same for the liquid as for the gas, (ii) the same is true of relation (7) between n and ε, and (iii) for the evaluation of the integral in (6) at low temperatures only momenta close to pF are important. Consequently, the result stated in Problem 8.13, namely CV ≃ S ≃ π 2 3 k2T a(εF ), (13) continues to hold — with the sole difference that in the expression for the density of states a(εF ), in the vicinity of the Fermi surface, the particle mass m gets replaced by the effective mass m∗; see equation (8.1.21). We now proceed to establish a relationship between the parameters m and m∗ in terms of the characteristic function f . In doing so, we neglect the spin-dependence of f , if any; the necessary modiﬁcation can be introduced without any difﬁculty. The guiding principle here is that, in the absence of external forces, the momentum density of the liquid must be equal to the density of mass transfer. The former is given by ∫ pn dτ , while the latter is given by m ∫ (∂ε/∂p)n dτ , (∂ε/∂p) being the “velocity” of the quasiparticle with momentum 11.8 Energy spectrum of a Fermi liquid 389 p and energy ε. 23 Thus ∫ pn dτ = m ∫ ∂ε ∂p n dτ . (14) Varying the distribution function by δn and making use of equation (4), we obtain ∫ pδn dτ = m ∫ ∂ε ∂p δn dτ + m ∫∫ { ∂f (p, p′) ∂p δn ′dτ ′} n dτ = m ∫ ∂ε ∂p δn dτ − m ∫∫ f (p, p′) ∂n′ ∂p′ δn dτ dτ ′; (15) in obtaining the last expression, we have interchanged the variables p and p′ and have also carried out an integration by parts. In view of the arbitrariness of the variation δn, equation (15) requires that p m = ∂ε ∂p − ∫ f (p, p′) ∂n′ ∂p′ dτ ′. (16) We apply this result to quasiparticles with momenta close to pF ; at the same time, we replace the distribution function n′ by a “step” function, whereby ∂n′ ∂p′ = − p′ p′ δ(p ′ − pF ). This enables us to carry out integration over the magnitude p′ of the momentum, so that ∫ f (p, p′) ∂n′ ∂p′ 2p′2dp′dω′ h3 = − 2pF h3 ∫ f (θ)p′ F dω′, (17) dω′ being the element of a solid angle; note that we have contracted the arguments of the function f because in simple situations it depends only on the angle between the two momenta. Inserting (17) into (16), with p = pF , making a scalar product with pF and dividing by p2 F , we obtain the desired result 1 m = 1 m∗ + pF 2h3 · 4 ∫ f (θ) cos θ dω′. (18) If the function f depends on the spins s1 and s2 of the particles involved, then the factor 4 in front of the integral will have to be replaced by a summation over the spin variables. 23Since the total number of quasiparticles in the liquid is the same as the total number of real particles, to obtain the net transport of mass by the quasiparticles one has to multiply their number by the mass m of the real particle. 390 Chapter 11. Statistical Mechanics of Interacting Systems We now derive a formula for the velocity of sound at absolute zero. From ﬁrst principles, we have 24 c2 0 = ∂P0 ∂(mN/V ) = − V 2 mN ( ∂P0 ∂V ) N . In the present context, it is preferable to have an expression in terms of the chemical poten- tial of the liquid. This can be obtained by making use of the formula Ndµ0 = VdP0, see Problem 1.16, from which it follows that 25 ( ∂µ0 ∂N ) V = − V N ( ∂µ0 ∂V ) N = − V 2 N 2 ( ∂P0 ∂V ) N and hence c2 0 = N m ( ∂µ0 ∂N ) V . (19) Now, µ0 = ε(pF ) = εF ; therefore, the change δµ0 arising from a change δN in the total number of particles in the system is given by δµ0 = ∂εF ∂pF δpF + ∫ f (pF , p′)δn ′ dτ ′. (20) The ﬁrst part in (20) arises from the fact that a change in the total number of particles in the system inevitably alters the value of the limiting momentum pF ; see equation (1), from which (for constant V ) δpF /pF = 1 3 δN/N and hence ∂εF ∂pF δpF = p2 F 3m∗ δN N . (21) 24At T = 0, S = 0; so there is no need to distinguish between the isothermal and adiabatic compressibilities of the liquid. 25Since µ0 is an intensive quantity and, therefore, it depends on N and V only through the ratio N/V , we can write: µ0 = µ0(N/V ). Consequently, ( ∂µ0 ∂N ) V = µ′ 0 ( ∂(N/V ) ∂N ) V = µ ′ 0 1 V and ( ∂µ0 ∂V ) N = µ′ 0 ( ∂(N/V ) ∂V ) N = −µ ′ 0 N V 2 . Hence ( ∂µ0 ∂N ) V = − V N ( ∂µ0 ∂V ) N . 11.8 Energy spectrum of a Fermi liquid 391 The second part arises from equation (4). It will be noted that the variation δn′ appearing in the integral of equation (20) is signiﬁcant only for p′ ≃ pF ; we may, therefore, write ∫ f (pF , p′)δn ′dτ ′ ≃ δN 4π V ∫ f (θ)dω′. (22) Substituting (21) and (22) into (20), we obtain ( ∂µ0 ∂N ) V = p2 F 3m∗N + 1 4πV ∫ f (θ)dω′. (23) Making use of equations (18) and (1), we ﬁnally obtain c2 0 = N m ( ∂µ0 ∂N ) V = p2 F 3m2 + p3 F 6mh3 · 4 ∫ f (θ)(1 − cos θ) dω′. (24) Once again, if the function f depends on the spins of the particles, then the factor 4 in front of the integral will have to be replaced by a summation over the spin variables. For illustration, we shall apply this theory to the imperfect Fermi gas studied in Section 11.7. To calculate f (p, σ ; p′, σ ′), we have to differentiate twice the sum of expres- sion (11.7.12), with u0 = 4π aℏ2/m, and expression (11.7.22) with respect to the distribution function n(p, σ ) and then substitute p = p′ = pF . Performing the desired calculation, then changing summations into integrations and carrying out integrations by simple means, we ﬁnd that the function f is spin-dependent — the spin-dependent term being in the nature of an exchange term, proportional to ˆs1 · ˆs2. The complete result, according to Abrikosov and Khalatnikov (1957), is f (p, σ ; p′, σ ′) = A(θ) + B(θ)ˆs1 · ˆs2, (25) where A(θ) = 2π aℏ2 m [ 1 + 2a ( 3N π V )1/3 { 2 + cos θ 2 sin(θ/2) ln 1 + sin(θ/2) 1 − sin(θ/2) }] and B(θ) = − 8π aℏ2 m [ 1 + 2a ( 3N π V )1/3 {1 − 1 2 sin ( θ 2 ) ln 1 + sin(θ/2) 1 − sin(θ/2) }] , a being the scattering length of the two-body potential and θ the angle between the momentum vectors pF and p′ F . Substituting (25) into formulae (18) and (24), in which the factor 4 is now supposed to be replaced by a summation over the spin variables, we ﬁnd that while the spin-dependent term B(θ)ˆs1 · ˆs2 does not make any contribution toward the 392 Chapter 11. Statistical Mechanics of Interacting Systems ﬁnal results, the spin-independent term A(θ) leads to 26 1 m∗ = 1 m − 8 15m (7 ln 2 − 1) ( 3N π V )2/3 a2 (26) and c2 0 = p2 F 3m2 + 2πaℏ2 m2 N V [ 1 + 4 15 (11 − 2 ln 2) ( 3N πV )1/3 a ] ; (27) the latter result is identical to expression (11.7.33) derived in the preceding section. Pro- ceeding backward, one can obtain from equation (27) corresponding expressions for the ground-state pressure P0 and the ground-state energy E0, namely equations (11.7.32) and (11.7.31), as well as the ground-state chemical potential µ0, as quoted in Problem 11.15. 11.9 Condensation in Fermi systems The discussion of the T = 0 Fermi liquid in Sections 11.7 and 11.8 applies when the inter- actions between the fermions are strictly repulsive. The resulting Fermi liquid has a ground state and quasiparticle excitations that are qualitatively similar to the ideal Fermi gas. However, for fermions with attractive interactions, no matter how weak, the degenerate Fermi gas is unstable due to the formation of bosonic pairs. This leads to a number of important phenomena including superconductivity in metals, superﬂuidity in 3He, and condensation in ultracold Fermi gases. In low-temperature superconductors, screening and the electron-phonon interaction result in a retarded attraction between quasiparti- cles on opposite sides of the Fermi surface. The formation of these so-called Cooper pairs leads to the creation of a superconducting state with critical temperature kTc ≈ ℏωD exp ( − 1 N(ϵF )|u0| ), (1) where N(ϵF ) is the density of states per spin conﬁguration at the Fermi surface, u0 is the weak attractive coupling between electrons, and ℏωD is the Debye energy discussed in Section 7.4 since the coupling is due to the acoustic phonons. As can be seen from equation (1), the phase transition temperature is nonperturbative in u0. A complete treat- ment of superconductivity is far beyond the scope of this section, so we refer the reader to the original papers by Cooper (1956) and Bardeen, Cooper, and Schrieffer (1957) and the texts on superconductivity by Tilley and Tilley (1990) and Tinkham (1996). The case of superﬂuidity in 3He is surveyed by Vollhardt and W¨olﬂe (1990). Bosonic condensation has also recently been observed in trapped ultracold atomic Fermi gases. The sign and size of the atomic interactions in ultracold gases can be tuned 26In a dense system, such as liquid He 3, the ratio m∗/m would be signiﬁcantly larger than unity. The experimen- tal work of Roberts and Sydoriak (1955), on the speciﬁc heat of liquid He 3, and the theoretical work of Brueckner and Gammel (1958), on the thermodynamics of a dense Fermi gas, suggest that the ratio (m∗/m)He3 ≃ 1.85. 11.9 Condensation in Fermi systems 393 with a magnetic ﬁeld near Feshbach resonance allowing unprecedented experimental control of interactions. In particular, experimenters can create a low-lying molecular bound state or a weakly attractive interaction without allowing a molecular bound state to form. If interaction between pairs of fermions allows the formation of bound bosonic molecules, the ground state of a degenerate Fermi gas will be destablized since molecules will form and, if the density of the bosonic molecules is large enough, they will Bose- condense — see Greiner, Regal, and Jin (2003); Jochim et al. (2003); and Zwierlein et al. (2003). For weakly attractive interactions, the fermionic system condenses into a BCS-like state and provides an excellent experimental environment for testing theoretical predictions due to the well-understood nature and experimental control of the atomic interactions. Theory predicts a smooth crossover from BCS to Bose–Einstein condensation (BEC) behavior as the magnitude of the attractive interaction parameter u0 is varied from values small to large. BCS theory describes the behavior for weak coupling. For broad Fesh- bach resonances of trapped fermions, the most common experimental situation, the BCS critical temperature is given by kTc ℏω0 ≈ ϵF ℏω0 exp ( − π 2kF |a| ) ∼ N 1/3 exp ( − aosc 1.214N 1/6 |a| ) , (2) where ω0 = (ω1ω2ω3)1/3 is the average oscillation frequency of atoms in the trap, aosc = √ ℏ/mω0, and kF = √2mϵF /ℏ is the Fermi wavevector; see Pitaevskii and Stringari (2003), Leggett (2006), and Pethick and Smith (2008). For large negative scattering lengths, the transition temperature smoothly crosses over to the BEC limit with noninteracting Bose- condensation temperature, see equation (7.2.6), kTc ℏω0 ≈ ( N 2ζ (3) )1/3 , (3) since the number of Cooper pairs is N/2. The ratio of the transition temperature in the BEC limit and the Fermi temperature from equation (8.4.3) is kTc ϵF ≈ ( 1 12ζ (3) )1/3 ≃ 0.41. (4) Mean-ﬁeld analysis of the broad resonance limit (Leggett, 2006) and analytical analysis of the narrow resonance limit (Gurarie and Radzihovsky, 2007) both indicate that the phase transition temperature has a maximum at intermediate coupling. Figure 11.7 is a sketch of the critical temperature as a function of the coupling parameter u0. Experimental observations of condensation in a degenerate Fermi gas in the BEC–BCS crossover region by Regal, Greiner, and Jin (2004) are shown in Figure 11.8. They used a Feshbach resonance to tune the scattering length of 40K into an attractive range (a < 0) that 394 Chapter 11. Statistical Mechanics of Interacting Systems BCS limit BEC–BCS kTc 0 Fermi liquid u0 FIGURE 11.7 Sketch of the BEC–BCS phase diagram on the BCS side of the Feshbach resonance for ultracold fermions in an atomic trap. The scattering length a and coupling u0 = 4π ℏ2a/m can be tuned from positive values to negative with the help of a magnetic ﬁeld. Positive (repulsive) couplings result in a Fermi liquid. Negative (attractive) couplings result in a BCS condensation at low temperatures. The nature of the condensed phase varies smoothly from BCS behavior for small negative coupling to Bose–Einstein behavior for large negative coupling. The phase transition temperature has a maximum at intermediate coupling. FIGURE 11.8 Time-of-ﬂight images showing condensation of fermions in an ultracold atomic gas. The images show the quantum mechanical projection of the fermionic system onto a molecular gas and are shown for three values of the magnetic ﬁeld on the BCS side of the Feshbach resonance for an ultracold trapped gas of 40K. The temperature of the Fermi gas is (kT /ϵF ) ≈ 0.07. The condensed fraction varies from about 1 to 10 percent of the original cold fermions in the trap; see Regal, Greiner, and Jin (2004). Figure courtesy of NIST/JILA/University of Colorado. does not allow a two-particle molecular bound state and observed the fermions condens- ing into a BCS-like macroscopic quantum state. They explored the BEC–BCS crossover behavior by tuning |a| from small values to large. Problems 11.1. (a) Show that, for bosons as well as fermions, [ψ(rj), ˆH] = ( − ℏ2 2m ∇2 j + ∫ d3rψ †(r)u(r, rj)ψ(r) ) ψ(rj), where ˆH is the Hamiltonian operator deﬁned by equation (11.1.4). Problems 395 (b) Making use of the foregoing result, show that the equation 1 √ N! ⟨0|ψ(r1) . . . ψ(rN ) ˆH|9NE ⟩ = E 1 √ N! ⟨0|ψ(r1) . . . ψ(rN )|9NE ⟩ = E9NE (r1, . . . rN ) is equivalent to the Schr¨odinger equation (11.1.15). 11.2. The grand partition function of a gaseous system composed of mutually interacting bosons is given by ln Q ≡ PV kT = V λ3 [ g5/2(z) − 2{g3/2(z)} 2 a λ + O ( a2 λ2 )] . Study the analytic behavior of this expression near z = 1 and show that the system exhibits the phenomenon of Bose–Einstein condensation when its fugacity assumes the critical value zc = 1 + 4ζ ( 3 2 ) a λc + O ( a2 λ2 c ) . Further show that the pressure of the gas at the critical point is given by (Lee and Yang 1958, 1960b) Pc kTc = 1 λ3 c [ ζ ( 5 2 ) + 2 { ζ ( 3 2 )}2 a λc + O ( a2 λ2 c )] ; compare these results to equations (11.2.16) through (11.2.18). 11.3. For the imperfect Bose gas studied in Section 11.2, calculate the speciﬁc heat CV near absolute zero and show that, as T → 0, the speciﬁc heat vanishes in a manner characteristic of a system with an “energy gap” 1 = 4π aℏ2n/m. 11.4. (a) Show that, to ﬁrst order in the scattering length a, the discontinuity in the speciﬁc heat CV of an imperfect Bose gas at the transition temperature Tc is given by (CV )T =Tc− − (CV )T =Tc+ = Nk 9a 2λc ζ (3/2), while the discontinuity in the bulk modulus K is given by (K )T =Tc− − (K )T =Tc+ = − 4π aℏ2 mv2 c . (b) Examine the discontinuities in the quantities (∂ 2P/∂T 2)v and (∂ 2µ/∂T 2)v as well, and show that your results are consistent with the thermodynamic relationship CV = VT ( ∂ 2P ∂T 2 ) v − NT ( ∂ 2µ ∂T 2 ) v . 396 Chapter 11. Statistical Mechanics of Interacting Systems 11.5. (a) Complete the mathematical steps leading to equations (11.3.15) and (11.3.16). (b) Complete the mathematical steps leading to equations (11.3.23) and (11.3.24). 11.6. The ground-state pressure of an interacting Bose gas (see Lee and Yang, 1960a) turns out to be P0 = µ2 0m 8π aℏ2 [ 1 − 64 15π µ 1/2 0 m1/2a ℏ + · · · ] , where µ0 is the ground-state chemical potential of the gas. It follows that n ≡ ( dP0 dµ0 ) = µ0m 4π aℏ2 [ 1 − 16 3π µ 1/2 0 m1/2a ℏ + · · · ] and E0 V ≡ (nµ0 − P0) = µ2 0m 8π aℏ2 [ 1 − 32 5π µ 1/2 0 m1/2a ℏ + · · · ] . Eliminating µ0 from these results, derive equations (11.3.16) and (11.3.17). 11.7. Show that in an interacting Bose gas the mean occupation number np of the real particles and the mean occupation number N p of the quasiparticles are connected by the relationship np = N p + α2 p(N p + 1) 1 − α2 p (p ̸= 0), where αp is given by equations (11.3.9) and (11.3.10). Note that equation (11.3.22) corresponds to the special case N p = 0. 11.8. The excitation energy of liquid He4, carrying a single excitation above the ground state, is determined by the minimum value of the quantity ε = ∫ 9∗ { − ℏ2 2m ∑ i ∇2 i + V − E0 } 9d3N r∕ ∫ 9∗9d3N r, where E0 denotes the ground-state energy of the liquid while 9, according to Feynman, is given by equation (11.4.3). Show that the process of minimization of this expression leads to equation (11.4.5) for the energy of the excitation. [Hint: First express ε in the form ε = ℏ2 2m ∫ |∇f (r)|2d3r∕ ∫ f ∗(r1)f (r2)g(r2 − r1)d3r1d3r2. Then show that ε is minimum when f (r) is of the form (11.4.4).] 11.9. Show that, for a sufﬁciently large momentum ℏk (in fact, such that the slope dε/dk of the energy spectrum is greater than the initial slope ℏc), a state of double excitation in liquid He 4 is energetically more favorable than a state of single excitation, that is, there exist wavevectors k1 and k2 such that, while k1 + k2 = k, ε(k1) + ε(k2) < ε(k). 11.10. Using Fetter’s analytical approximation, f1(ρ′) = ρ′ √ (1 + ρ′2) , Problems 397 for the solution of equation (11.5.23) with s = 1, calculate the energy (per unit length) associated with a quantized vortex line of unit circulation. Compare your result with the one quoted in (11.5.26). 11.11. (a) Study the nature of the velocity ﬁeld arising from a pair of parallel vortex lines, with s1 = +1 and s2 = −1, separated by a distance d. Derive and discuss the general equation of the stream lines. (b) Again, using Fetter’s analytical approximation for the functions f (ρ′ 1) and f (ρ′ 2), calculate the energy (per unit length) of the system and show that its limiting value, as d → 0, is 11πℏ2n0/12m. Making use of this result, derive expression (11.6.8) for the critical velocity of superﬂow. 11.12. Establish the asymptotic formula (11.7.30) for the function F(z0). [Hint: Write the coefﬁcient that appears in the sum (11.7.24) in the form 1 √ (rst)(r + s)(r + t) = ( 2 √ π )3 ∞∫ 0 e−X 2r−Y 2s−Z 2t−ξ(r+s)−η(r+t)dX dY dZ dξ dη. Insert this expression into (11.7.24) and carry out summations over r, s, and t, with the result F(z0) = 8 π 3/2 ∞∫ 0 1 z−1 0 eX 2+ξ +η + 1 1 z−1 0 eY 2+ξ + 1 1 z−1 0 eZ 2+η + 1 dX dY dZ dξ dη. In the limit z0 → ∞, the integrand is essentially equal to 1 in the region R deﬁned by X 2 + ξ + η < ln z0, Y 2 + ξ < ln z0, and Z 2 + η < ln z0; outside this region, it is essentially 0. Hence, the dominant term of the asymptotic expansion is 8 π 3/2 ∫ R 1 · dX dY dZ dξ dη, which, in turn, reduces to the double integral 8 π 3/2 ∫∫ (ln z0 − ξ − η)1/2(ln z0 − ξ )1/2(ln z0 − η) 1/2dξ dη; the limits of integration here are such that not only ξ < (ln z0) and η < (ln z0), but also (ξ + η) < (ln z0). The rest of the calculation is straightforward.] 11.13. The grand partition function of a gaseous system composed of mutually interacting, spin-half fermions has been evaluated by Lee and Yang (1957), with the result27 ln Q ≡ PV kT = V λ3 [ 2f5/2(z) − 2a λ { f3/2(z)} 2 + 4a2 λ2 f1/2(z){ f3/2(z)} 2 − 8a2 λ2 F(z) + · · · ] , 27For the details of this calculation, see Lee and Yang (1959b) where the case of bosons, as well as of fermions, with spin J has been treated using the binary collision method. The second-order result for the case of spinless bosons was ﬁrst obtained by Huang, Yang, and Luttinger (1957) using the method of pseudopotentials. 398 Chapter 11. Statistical Mechanics of Interacting Systems where z is the fugacity of the actual system (not of the corresponding noninteracting system, which was denoted by the symbol z0 in the text); the functions fν (z) and F(z) are deﬁned in a manner similar to equations (11.7.10) and (11.7.24). From this result, one can derive expressions for the quantities E(z, V , T ) and N(z, V , T ) by using the formulae E(z, V , T ) ≡ kT 2 ∂(ln Q) ∂T and N(z, V , T ) ≡ ∂(ln Q) ∂(ln z) { = 2V λ3 f3/2(z0) }. (a) Eliminating z between these two results, derive equation (11.7.25) for E. (b) Obtain the zero-point value of the chemical potential µ, correct to second order in (a/λ), and verify, with the help of equations (11.7.31) and (11.7.32), that (E + PV )T =0 = N(µ)T =0. [Hint: At T = 0 K, µ = (∂E/∂N)V .] (c) Show that the low-temperature speciﬁc heat and the low-temperature entropy of this gas are given by (see Pathria and Kawatra, 1962) CV Nk ≃ S Nk ≃ π 2 2 ( kT εF ) [1 + 8 15π 2 (7 ln 2 − 1)(kF a) 2 + · · · ] , where kF = (3π 2n)1/3. Clearly, the factor within square brackets is to be identiﬁed with the ratio m∗/m; see equations (11.8.12) and (11.8.26). [Hint: To determine CV to the ﬁrst power in T , we must know E to the second power in T . For this, we require higher-order terms of the asymptotic expansions of the functions fν (z) and F(z); these are given by f5/2(z) = 8 15 √ π (ln z) 5/2 + π 3/2 3 (ln z)1/2 + O(1), f3/2(z) = 4 3 √ π (ln z)3/2 + π 3/2 6 (ln z) −1/2 + O(ln z)−5/2, f1/2(z) = 2 √ π (ln z)1/2 − π 3/2 12 (ln z)−3/2 + O(ln z)−7/2, and F(z) = 16(11 − 2 ln 2) 105π 3/2 (ln z)7/2 − 2(2 ln 2 − 1) 3 π 1/2(ln z) 3/2 + O(ln z)5/4. The ﬁrst three results here follow from the Sommerfeld lemma (E.17); for the last one, see Yang (1962).] Problems 399 11.14. The energy spectrum ε(p) of a gas composed of mutually interacting, spin-half fermions is given by (Galitskii, 1958; Mohling, 1961) ε(p) p2 F /2m ≃ x2 + 4 3π (kF a) + 4 15π 2 (kF a) 2 × [ 11 + 2x4 ln x2 |x2 − 1| − 10 ( x − 1 x ) ln ∣ ∣ ∣ ∣ x + 1 x − 1 ∣ ∣ ∣ ∣ − (2 − x2)5/2 x ln ( 1 + x√ (2 − x2) 1 − x√ (2 − x2) )] , where x = p/pF ≤ √ 2 and k = p/ℏ. Show that, for k close to kF , this spectrum reduces to ε(p) p2 F /2m ≃ x2+ 4 3π (kF a) + 4 15π 2 (kF a) 2 [ (11 − 2 ln 2) − 4(7 ln 2 − 1) ( k kF − 1 )] . Using equations (11.8.10) and (11.8.11), check that this expression leads to the result m∗ m ≃ 1 + 8 15π 2 (7 ln 2 − 1)(kF a)2. 11.15. In the ground state of a Fermi system, the chemical potential is identical to the Fermi energy: (µ)T =0 = ε(pF ). Making use of the energy spectrum ε(p) of the previous problem, we obtain (µ)T =0 ≃ p2 F 2m [1 + 4 3π (kF a) + 4 15π 2 (11 − 2 ln 2)(kF a)2] . Integrating this result, rederive equation (11.7.31) for the ground-state energy of the system. 11.16. The energy levels of an imperfect Fermi gas in the presence of an external magnetic ﬁeld B, to ﬁrst order in a, may be written as En = ∑ p (n + p + n − p ) p2 2m + 4πaℏ2 mV N +N − − µ ∗B(N + − N −); see equations (8.2.8) and (11.7.12). Using this expression for En and following the procedure adopted in Section 8.2.A, study the magnetic behavior of this gas — in particular, the zero-ﬁeld susceptibility χ(T ). Also examine the possibility of spontaneous magnetization arising from the interaction term with a > 0. 11.17. Rewrite the Gross–Pitaevskii equation and the mean ﬁeld energy, see equations (11.2.21) and (11.2.23), for an isotropic harmonic oscillator trap with frequency ω0 in a dimensionless form by deﬁning a dimensionless wavefunction ψ = a3/2 osc/9N, a dimensionless length s = r/aosc, and a dimensionless energy E/Nℏω0. Show that the dimensionless parameter that controls the mean ﬁeld energy is Na/aosc, where N is the number of particles in the condensate, a is the scattering length, and aosc = √ ℏ/mω0. Next, show that the dimensionless versions of the Gross–Pitaevskii equation and the mean ﬁeld energy are − 1 2 ˜∇2ψ + 1 2 s2ψ + 4π Na aosc |ψ|2 ψ = ˜µψ , 400 Chapter 11. Statistical Mechanics of Interacting Systems and E[ψ] Nℏω0 = ∫ ( 1 2 ∣ ∣ ∣ ˜∇ψ∣ ∣ ∣ 2 + 1 2 s2 |ψ|2 + 2π Na aosc |ψ|4) ds . 11.18. Solve the Gross–Pitaevskii equation and evaluate the mean ﬁeld energy, see equations (11.2.21) and (11.2.23), for a uniform Bose gas to show that this method yields precisely equation (11.2.6). 11.19. Solve the Gross–Pitaevskii equation (11.2.23) in a harmonic trap for the case when the scattering length a is zero. Show that this reproduces the properties of the ground state of the noninteracting Bose gas. 11.20. Solve the Gross–Pitaevskii equation and evaluate the mean ﬁeld energy, see equations (11.2.21) and (11.2.23), for an isotropic harmonic oscillator trap with frequency ω0 for the case Na/aosc ≫ 1 by ignoring the kinetic energy term. Reproduce the results (11.2.25) through (11.2.28). 12 Phase Transitions: Criticality, Universality, and Scaling Various physical phenomena to which the formalism of statistical mechanics has been applied may, in general, be divided into two categories. In the ﬁrst category, the micro- scopic constituents of the given system are, or can be regarded as, practically noninteract- ing; as a result, the thermodynamic functions of the system follow straightforwardly from a knowledge of the energy levels of the individual constituents. Notable examples of phe- nomena belonging to this category are the speciﬁc heats of gases (Sections 1.4 and 6.5), the speciﬁc heats of solids (Section 7.4), chemical reactions and equilibrium constants (Section 6.6), the condensation of an ideal Bose gas (Sections 7.1 and 7.2), the spectral distribution of the blackbody radiation (Section 7.3), the elementary electron theory of metals (Section 8.3), the phenomenon of paramagnetism (Sections 3.9 and 8.2), and so on. In the case of solids, the interatomic interaction does, in fact, play an important physical role; however, since the actual positions of the atoms, over a substantial range of temper- atures, do not depart signiﬁcantly from their mean values, we can rewrite our problem in terms of the so-called normal coordinates and treat the given solid as an “assembly of practically noninteracting harmonic oscillators.” We note that the most signiﬁcant feature of the phenomena falling in the ﬁrst category is that, with the sole exception of Bose– Einstein condensation, the thermodynamic functions of the systems involved are smooth and continuous! Phenomena belonging to the second category, however, present a very different sit- uation. In most cases, one encounters analytic discontinuities or singularities in the thermodynamic functions of the given system which, in turn, correspond to the occur- rence of various kinds of phase transitions. Notable examples of phenomena belonging to this category are the condensation of gases, the melting of solids, phenomena associ- ated with the coexistence of phases (especially in the neighborhood of a critical point), the behavior of mixtures and solutions (including the onset of phase separation), phenom- ena of ferromagnetism and antiferromagnetism, the order–disorder transitions in alloys, the superﬂuid transition from liquid He I to liquid He II, the transition from a normal to a superconducting material, and so on. The characteristic feature of the interparticle inter- actions in these systems is that they cannot be “removed” by means of a transformation of the coordinates of the problem; accordingly, the energy levels of the total system can- not, in any simple manner, be related to the energy levels of the individual constituents. One ﬁnds instead that, under favorable circumstances, a large number of microscopic Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00012-8 © 2011 Elsevier Ltd. All rights reserved. 401 402 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling constituents of the system may exhibit a tendency of interacting with one another in a rather strong, cooperative fashion. This cooperative behavior assumes macroscopic signiﬁ- cance at a particular temperature Tc, known as the critical temperature of the system, and gives rise to the kind of phenomena listed previously. Mathematical problems associated with the study of cooperative phenomena are quite formidable. 1 To facilitate calculations, one is forced to introduce models in which the interparticle interactions are considerably simpliﬁed, yet retain characteristics that are essential to the cooperative aspect of the problem. One then hopes that a theoretical study of these simpliﬁed models, which still involves serious difﬁculties of analysis, will repro- duce the most basic features of the phenomena exhibited by actual physical systems. For instance, in the case of a magnetic transition, one may consider a lattice structure in which all interactions other than the ones among nearest-neighbor spins are neglected. It turns out that a model as simpliﬁed as that captures practically all the essential features of the phenomenon — especially in the close neighborhood of the critical point. The inclusion of interactions among spins farther out than the nearest neighbors does not change these features in any signiﬁcant manner, nor are they affected by the replacement of one lattice structure by another so long as the dimensionality of the lattice is the same. Not only this, these features may also be shared, with little modiﬁcation, by many other physical sys- tems undergoing very different kinds of phase transitions, for example, gas–liquid instead of paramagnetic–ferromagnetic. This “unity in diversity” turns out to be a hallmark of the phenomena associated with phase transitions — a subject we propose to explore in considerable detail in this and the following two chapters, but ﬁrst a few preliminaries. 12.1 General remarks on the problem of condensation We consider an N-particle system, obeying classical or quantum statistics, with the proviso that the total potential energy of the system can be written as a sum of two-particle terms u(rij), with i < j. The function u(r) is supposed to satisfy the conditions u(r) = +∞ for r ≤ σ , 0 > u(r) > −ε for σ < r < r∗ u(r) = 0 for r ≥ r∗    ; (1) see Figure 12.1. Thus, each particle may be looked upon as a hard sphere of diameter σ , surrounded by an attractive potential of range r∗ and of (maximum) depth ε. From a prac- tical point of view, conditions (1) do not entail any “serious restriction” on the two-body potential, for the interparticle potentials ordinarily met with in nature are not materially 1In this connection, one should note that the mathematical schemes developed in Chapters 10 and 11 give reliable results only if the interactions among the microscopic constituents of the given system are sufﬁciently weak — in fact, too weak to bring about cooperative transitions. 12.1 General remarks on the problem of condensation 403 σ 0 2\u0002 ru(r)r ∗ FIGURE 12.1 A sketch of the interparticle potential u(r), as given by equation (1). different from the one satisfying these conditions. We, therefore, expect that the conclu- sions drawn from the use of this potential will not be very far from the realities of the actual physical phenomena. Suppose that we are able to evaluate the exact partition function, QN (V , T ), of the given system. This function will possess certain properties that have been recognized and accepted for quite some time, though a rigorous proof of these was ﬁrst attempted by van Hove as late as in 1949.2 These properties can be expressed as follows: (i) In the thermodynamic limit (i.e., when N and V → ∞ while the ratio N/V stays constant), the quantity N −1 ln Q tends to be a function only of the speciﬁc volume v (= V /N) and the temperature T ; this limiting form may be denoted by the symbol f (v, T ). It is natural to identify f (v, T ) with the intensive variable −A/NkT , where A is the Helmholtz free energy of the system. The thermodynamic pressure P is then given by P(v, T ) = − ( ∂A ∂V ) N,T = kT ( ∂f ∂v ) T , (2) which turns out to be a strictly nonnegative quantity. (ii) The function f (v, T ) is everywhere concave, so the slope (∂P/∂v)T of the (P, v)-curve is never positive. While at high temperatures the slope is negative for all v, at lower temperatures there can exist a region (or regions) in which the slope is zero and, consequently, the system is inﬁnitely compressible! The existence of such regions, in the (P, v)-diagram, corresponds to the coexistence of two or more phases of different density in the given system; in other words, it constitutes direct evidence of the onset of a phase transition in the system. In this connection it is important to note that, so long as one uses the exact partition function of the system, isotherms of the van der Waals type, which possess unphysical regions of positive slope, never appear. On the 2For historical details, see Grifﬁths (1972, p. 12). 404 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling A v3 v2 v1 v 2 1 P˜(T ) B 2 3 P FIGURE 12.2 An unphysical isotherm corrected with the help of the Maxwell construction; the horizontal line is such that the areas A and B are equal. The “corrected” isotherm corresponds to a phase transition, taking place at pressure ˜P(T ), with densities v−1 1 and v−1 3 of the respective phases. other hand, if the partition function is evaluated under approximations, as we did in the derivation of the van der Waals equation of state in Section 10.3, isotherms with unphysical regions may indeed appear. In that case the isotherms in question have got to be “corrected,” by introducing a region of “ﬂatness” (∂P/∂v = 0), with the help of the Maxwell construction of equal areas; see Figure 12.2.3 The real reason for the appearance of unphysical regions in the isotherms is that the approximate evalua- tions of the partition function introduce, almost invariably (though implicitly), the restraint of a uniform density throughout the system. This restraint eliminates the very possibility of the system passing through states in which there exist, side by side, two phases of different densities; in other words, the existence of a region of “ﬂatness” in the (P, v)-diagram is automatically ruled out. On the other hand, an exact evaluation of the partition function must allow for all possible conﬁgurations of the system, including the ones characterized by a simultaneous existence of two or more phases of different densities. Under suitable conditions (for instance, when the temperature is sufﬁciently low), such a conﬁguration might turn out to be the equilibrium conﬁguration of the system, with the result that the system shows up in a multiphase, rather than a single-phase, state. We should, in this context, mention that if in the evaluation of the partition function one introduces no other approximation except the assumption of a uniform density in the system, then the resulting isotherms, corrected with the help of the Maxwell construction, would be the exact isotherms of the problem. 3The physical basis of the Maxwell construction can be seen with the help of the Gibbs free energy density g(T , P). Since dg = −sdT + vdP and along the “corrected” isotherm dP = dT = 0, it follows that g1 = g3; see Figure 12.2. To achieve the same result from the theoretical isotherm (along which dT = 0 but dP ̸= 0), we clearly require that the quantity vdP, integrated along the isotherm from state 1 to state 3, must vanish; this leads to the “theorem of equal areas.” 12.1 General remarks on the problem of condensation 405 (iii) The presence of an absolutely ﬂat portion in an isotherm, with mathematical singularities at its ends, is, strictly speaking, a consequence of the limiting process N → ∞. If N were ﬁnite, and if the exact partition function were used, then the quantity P′, deﬁned by the relation P′ = kT ( ∂ ln Q ∂V ) N,T , (3) would be free from mathematical singularities. The ordinarily sharp corners in an isotherm would be rounded off; at the same time, the ordinarily ﬂat portion of the isotherm would not be strictly ﬂat — it would have for large N a small, negative slope. In fact, the quantity P′ in this case would not be a function of v and T alone; it would depend on the number N as well, though in a thermodynamically negligible manner. If we employ the grand partition function Q, as obtained from the exact partition functions QN , namely Q(z, V , T ) = ∑ N≥0 QN (V , T )zN , (4) a similar picture results. To see this, we note that for real molecules, with a given V , the variable N will be bounded by an upper limit, say Nm, which is the number of molecules that ﬁll the volume V “tight-packed”; obviously, Nm ∼ V /σ 3. For N > Nm, the potential energy of the system will be inﬁnite; accordingly, QN (N > Nm) ≡ 0. (5) Hence, for all practical purposes, our power series in (4) is a polynomial in z (which is ≥ 0) and is of degree Nm. Since the coefﬁcients QN are all positive and Q0 ≡ 1, the sum Q ≥ 1. The thermodynamic potential ln Q is, therefore, a well-behaved function of the parameters z, V , and T . Consequently, so long as V (and hence Nm) remains ﬁnite, we do not expect any singularities or discontinuities in any of the functions derived from this potential. A nonanalytic behavior could appear only in the limit (V , Nm) → ∞. We now deﬁne P′ by the relation P′ = kT V ln Q (V ﬁnite); (6) since Q ≥ 1, P′ ≥ 0. The mean number of particles and the mean square deviation in this number are given by the formulae N = ( ∂ ln Q ∂ ln z ) V ,T (7) 406 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling and N 2 − N 2 ≡ ( N − N)2 = ( ∂N ∂ ln z ) V ,T , (8) respectively; see Sections 4.2 and 4.5. Accordingly, ( ∂ ln Q ∂ N ) V ,T = ( ∂ ln Q ∂ ln z ) V ,T ∕ ( ∂N ∂ ln z ) V ,T = N N 2 − N 2 . (9) At the same time, writing v for V /N and using (6), we have ( ∂ ln Q ∂N ) V ,T = V kT ( ∂P′ ∂N ) V ,T = − v2 kT ( ∂P′ ∂v ) V ,T . (10) Comparing (9) and (10), we obtain ( ∂P′ ∂v ) V ,T = − kT V 2 N 3 N 2 − N 2 , (11) which is clearly nonpositive. 4 For ﬁnite V , expression (11) will never vanish; accordingly, P′ will never be strictly constant. Nevertheless, the slope (∂P′/∂v) can, in a certain region, be extremely small — in fact, as small as O(1/N); such a region would hardly be distin- guishable from a phase transition because, on a macroscopic scale, the value of P′ in such a region would be as good as a constant.5 If we now deﬁne the pressure of the system by the limiting relationship P( v, T ) = Lim V →∞ P′ (v, T ; V ) = kT Lim V →∞ ( 1 V ln Q(z, V , T )) , (12) then we can expect, in a set of isotherms, an absolutely ﬂat portion (∂P/∂v ≡ 0), with sharp corners implying mathematical singularities. The mean particle density n would now be given by n = Lim V →∞ [ 1 V ∂ ln Q(z, V , T ) ∂ ln z ] ; (13) it seems important to mention here that the operation V → ∞ and the operation ∂/∂ ln z cannot be interchanged freely. In passing, we note that the picture emerging from the grand partition function Q, which has been obtained from the exact partition functions QN , remains practically 4Compare equation (11), which has been derived here nonthermodynamically, with equation (4.5.7) derived earlier. 5The presence of such a region entails that (N 2 − N 2) be O(N 2). This implies that the ﬂuctuations in the variable N be macroscopically large, which in turn implies equally large ﬂuctuations in the variable v within the system and hence the coexistence of two or more phases with different values of v. In a single-phase state, (N 2 − N 2) is O(N); the slope (∂P′/∂v) is then O(N 0), as an intensive quantity should be. 12.2 Condensation of a van der Waals gas 407 unchanged even if one had employed a set of approximate QN . This is so because the argument developed in the preceding paragraphs makes no use whatsoever of the actual form of the functions QN . Thus, if an approximate QN leads to the van der Waals type of loop in the canonical ensemble, as shown in Figure 12.2, the corresponding set of QN , when employed in a grand canonical ensemble, would lead to isotherms free from such loops (Hill, 1953). Subsequent to van Hove, Yang and Lee (1952) suggested an altemative approach that enables one to carry out a rigorous mathematical discussion of the phenomenon of con- densation and of other similar transitions. In their approach, one is primarily concerned with the analytic behavior of the quantities P and n, of equations (12) and (13), as func- tions of z at different values of T . The problem is examined in terms of the “zeros of the grand partition function Q in the complex z-plane,” with attention focused on the way these zeros are distributed in the plane and the manner in which they evolve as the vol- ume of the system is increased. For real, positive z, Q ≥ 1, therefore none of the zeros will lie on the real, positive axis in the z-plane. However, as V → ∞ (and hence the degree of the polynomial (4) and, with it, the number of zeros itself grows to inﬁnity), the distribu- tion of zeros is expected to become continuous and, depending on T , may in fact converge on the real, positive axis at one or more points zc. If so, our functions P(z) and n(z), even with z varied along the real axis only, may, by virtue of their relationship to the function ln Q, turn out to be singular at the points z = zc. The presence of such a singularity would imply the onset of a phase transition in the system. For further details of this approach, see Sections 12.3 and 12.4 of the ﬁrst edition of this book; see also Grifﬁths (1972, pp. 50–58). 12.2 Condensation of a van der Waals gas We start with the simplest, and historically the ﬁrst, theoretical model that undergoes a gas–liquid phase transition. This model is generally referred to as the van der Waals gas and obeys the equation of state, see equation (10.3.9), P = RT v − b − a v2 , (1) v being the molar volume of the gas; the parameters a and b then also pertain to one mole of the gas. We recall that, while a is a measure of the attractive forces among the molecules of the system, b is a measure of the repulsive forces that come into play when two molecules come too close to one another; accordingly, b is also a measure of the “effective space” occupied by the molecules (by virtue of a ﬁnite volume that may be asso- ciated with each one of them). In Section 10.3, the equation of state (1) was derived under the express assumption that v ≫ b; here, we shall pretend, with van der Waals, that this equation holds even when v is comparable to b. The isotherms following from equation (1) are shown in Figure 12.3. We note that, for temperatures above a critical temperature Tc, P decreases monotonically with v. For 408 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling 12 Coexistence curve T \u0002 Tc T \u0003Tc Critical point T \u0004 Tc 3P(T ) Pc vI vg\u0002c v P FIGURE 12.3 The isotherms of a van der Waals system; those for T < Tc are “corrected” with the help of the Maxwell construction, thus leading to the coexistence curve at the top of which sits the critical point. T < Tc, however, the relationship is nonmonotonic, so that over a certain range of v we encounter a region where (∂P/∂v) > 0; such a region is unphysical and must be “corrected” with the help of the Maxwell construction,6 leading to an isotherm with a ﬂat portion sig- naling transition from the gaseous state with molar volume vg (T ) to the liquid state with molar volume vl(T ) at a constant pressure P(T ). For vl < v < vg , the system resides in a state of mixed phases — partly liquid, partly gaseous — and, since the passage from one end of the ﬂat portion to the other takes place with 1v ̸= 0 but 1P = 0, the system is all along in a state of inﬁnite compressibility; clearly, we are encountering here a brand of behavior that is patently singular. As T increases toward Tc, the transition takes place at a comparatively higher value of P, with vg less than and vl more than before — so that, as T → Tc, both vg and vl approach a common value vc that may be referred to as the critical volume; the corresponding value of P may then be designated by Pc, and we ﬁnd ourselves located at the critical point of the system. The locus of all such points as vl(T ) and vg (T ) is generally referred to as the coexistence curve, for the simple reason that in the region enclosed by this curve the gaseous and the liquid phases mutually coexist; the top of this curve, where vl = vg , coincides with the critical point itself. Finally, the isotherm 6A more precise formulation of the van der Waals theory, as the limit of a theory with an inﬁnite range potential, has been formulated by Kac, Uhlenbeck and Hemmer (1963). They considered the potential u(r) = { +∞ for r ≤ σ −κe−κr for r > σ , so that the integral ∫ ∞ σ u(r)dr is simply − exp(−κσ ); when κ → 0 the potential becomes inﬁnite in range but inﬁnitesi- mally weak. Kac et al. showed that, in this limit, the model becomes essentially the same as van der Waals’ — with one noteworthy improvement, that is, no unphysical regions in the (P, v)–diagram appear and hence no need for the Maxwell construction arises. 12.2 Condensation of a van der Waals gas 409 pertaining to T = Tc, which, of course, passes through the critical point is referred to as the critical isotherm of the system; it is straightforward to see that the critical point is a point of inﬂection of this isotherm, so that both (∂P/∂v)T and (∂ 2P/∂v2)T vanish at this point. Using (1), we obtain for the coordinates of the critical point Pc = a 27b2 , vc = 3b, Tc = 8a 27bR , (2) so that the number K ≡ RTc/Pcvc = 8/3 = 2.666 . . . . (3) We thus ﬁnd that, while Pc, vc, and Tc vary from system to system (through the interaction parameters a and b), the quantity K has a common, universal value for all of them — so long as they all obey the same (i.e., van der Waals) equation of state. The experimental results for K indeed show that it is nearly the same over a large group of substances; for instance, its value for carbon tetrachloride, ethyl ether, and ethyl formate is 3.677, 3.814, and 3.895, respectively — close, though not exactly the same, and also a long way from the van der Waals value. The concept of universality is, nonetheless, there (even though the van der Waals equation of state may not truly apply). It is now tempting to see if the equation of state itself can be written in a universal form. We ﬁnd that this indeed can be done by introducing reduced variables Pr = P Pc , vr = v vc , Tr = T Tc . (4) Using (1) and (2), we readily obtain the reduced equation of state ( Pr + 3 v2 r ) (3vr − 1) = 8Tr, (5) which is clearly universal for all systems obeying van der Waals’ original equation of state (1); all we have done here is to rescale the observable quantities P, v, and T in terms of their critical values and thereby “push the interaction parameters a and b into the back- ground.” Now, if two different systems happen to be in states characterized by the same values of vr and Tr, then their Pr would also be the same; the systems are then said to be in “corresponding states” and, for that reason, the statement just made is referred to as the “law of corresponding states.” Clearly, the passage from equation (1) to equation (5) takes us from an expression of diversity to a statement of unity! We shall now examine the behavior of the van der Waals system in the close neighbor- hood of the critical point. For this, we write Pr = 1 + π, vr = 1 + ψ, Tr = 1 + t. (6) 410 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling Equation (5) then takes the form π (2 + 7ψ + 8ψ 2 + 3ψ 3) + 3ψ 3 = 8t (1 + 2ψ + ψ 2). (7) First of all, along the critical isotherm (t = 0) and in the close vicinity of the critical point (|π |, |ψ| ≪ 1), we obtain the simple, asymptotic result π ≈ − 3 2 ψ 3, (8) which is indicative of the “degree of ﬂatness” of the critical isotherm at the critical point. Next, we examine the dependence of ψ on t as we approach the critical point from below. For this, we write (7) in the form 3ψ 3 + 8 (π − t) ψ 2 + (7π − 16t) ψ + 2 (π − 4t) ≃ 0. (9) Now, a close look at the (symmetric) shape of the coexistence curve near its top (where |t| ≪ 1) shows that the three roots ψ1, ψ2, and ψ3 of equation (9), which arise from the limiting behavior of the roots v1, v2, and v3 of the original equation of state (1) as T → Tc−, are such that |ψ2| ≪ |ψ1,3| and |ψ1| ≃ |ψ3|. This means that, in the region of interest, π ≈ 4t, (10) so that one of the roots, ψ2, of equation (9) essentially vanishes while the other two are given by ψ 2 + 8tψ + 4t ≃ 0. (9a) We expect the middle term here to be negligible (as will be conﬁrmed by the end result), yielding ψ1,3 ≈ ±2|t| 1/2; (11) note that the upper sign here pertains to the gaseous phase and the lower sign to the liquid phase. Finally, we consider the isothermal compressibility of the system which, in terms of reduced variables, is determined essentially by the quantity −(∂ψ/∂π)t. Retaining only the dominant terms, we obtain from (7) − ( ∂ψ ∂π ) t ≈ 2 7π + 9ψ 2 − 16t . (12) For t > 0, we approach the critical point along the critical isochore (ψ = 0); equation (12), with the help of equation (10), then gives − ( ∂ψ ∂π ) t→0+ ≈ 1 6t . (13) 12.3 A dynamical model of phase transitions 411 For t < 0, we approach the critical point along the coexistence curve (on which ψ 2 ≈ −4t); we now obtain − ( ∂ψ ∂π ) t→0− ≈ 1 12|t| . (14) For the record, we quote here results for the speciﬁc heat, CV , of the van der Waals gas (Uhlenbeck, 1966; Thompson, 1988) CV ≈    (CV )ideal + 9 2 Nk ( 1 + 28 25 t) (t ≤ 0) (15a) (CV )ideal (t > 0), (15b) which imply a ﬁnite jump at the critical point. Equations (8), (11), (13), (14), and (15) illustrate the nature of the critical behavior dis- played by a van der Waals system undergoing the gas–liquid transition. While it differs in several important respects from the critical behavior of real physical systems, it shows up again and again in studies pertaining to other critical phenomena that have apparently nothing to do with the gas–liquid phase transition. In fact, this particular brand of behav- ior turns out to be a benchmark against which the results of more sophisticated theories are automatically compared. 12.3 A dynamical model of phase transitions A number of physico-chemical systems that undergo phase transitions can be represented, to varying degrees of accuracy, by an “array of lattice sites, with only nearest-neighbor interaction that depends on the manner of occupation of the neighboring sites.” This simple-minded model turns out to be good enough to provide a uniﬁed, theoretical basis for understanding a variety of phenomena such as ferromagnetism and antiferromag- netism, gas–liquid and liquid–solid transitions, order–disorder transitions in alloys, phase separation in binary solutions, and so on. There is no doubt that this model considerably oversimpliﬁes the actual physical systems it is supposed to represent; nevertheless, it does retain the essential physical features of the problem — features that account for the prop- agation of long-range order in the system. Accordingly, it does lead to the onset of a phase transition in the given system, which arises in the nature of a cooperative phenomenon. We ﬁnd it convenient to formulate our problem in the language of ferromagnetism; later on, we shall establish correspondence between this language and the languages appropriate to other physical phenomena. We thus regard each of the N lattice sites to be occupied by an atom possessing a magnetic moment µ, of magnitude gµB√ [ J( J + 1)], which is capable of (2J + 1) discrete orientations in space. These orientations deﬁne “dif- ferent possible manners of occupation” of a given lattice site; accordingly, the whole lattice is capable of (2J + 1)N different conﬁgurations. Associated with each conﬁguration is an energy E that arises from mutual interactions among the neighboring atoms of the 412 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling lattice and from the interaction of the whole lattice with an external ﬁeld B. A statistical analysis in the canonical ensemble should then enable us to determine the expectation value, M(B, T ), of the net magnetization M. The presence of a spontaneous magnetization M(0, T ) at temperatures below a certain (critical) temperature Tc and its absence above that temperature will then be interpreted as a ferromagnetic phase transition in the system at T = Tc. Detailed studies, both theoretical and experimental, have shown that, for all ferromag- netic materials, data on the temperature dependence of the spontaneous magnetization, M(0, T ), ﬁt best with the value J = 1 2 ; see Figure 12.4. One is, therefore, tempted to infer that the phenomenon of ferromagnetism is associated only with the spins of the electrons and not with their orbital motions. This is further conﬁrmed by gyromagnetic experiments (Barnett, 1944; Scott, 1951, 1952), in which one either reverses the magnetization of a freely suspended specimen and observes the resulting rotation or imparts a rotation to the spec- imen and observes the resulting magnetization; the former is known as the Einstein–de Haas method, the latter the Barnett method. From these experiments one can derive the relevant g-value of the specimen which, in each case, turns out to be very close to 2; this, as we know, pertains to the electron spin. Therefore, in discussing the problem of ferro- magnetism, we may speciﬁcally take: µ = 2µB√ [s(s + 1)], where s is the quantum number associated with the electron spin. With s = 1 2 , only two orientations are possible for each lattice site, namely sz = + 1 2 (with µz = +µB) and sz = − 1 2 (with µz = −µB). The whole lattice is then capable of 2N conﬁgurations; one such conﬁguration is shown in Figure 12.5. We now consider the nature of the interaction energy between two neighboring spins si and sj. According to quantum mechanics, this energy is of the form Kij ± Jij, where the upper sign applies to “antiparallel” spins (S = 0) and the lower sign to “parallel” spins (S = 1). Here, Kij is the direct or Coulomb energy between the two spins, while Jij is the 0 0.2 0.4 0.6 0.8 1.0 0.2 0.4 0.6 0.8 1.0 Fe J 5` J 5 1 J 5 1/2 Co Ni T TcM (0, T)M (0, 0) FIGURE 12.4 Spontaneous magnetization of iron, nickel, and cobalt as a function of temperature. Theoretical curves are based on the Weiss theory of ferromagnetism. 12.3 A dynamical model of phase transitions 413 FIGURE 12.5 One of the 2N possible conﬁgurations of a system composed of N spins; here, N = 25. exchange energy between them: Kij = ∫ ψ ∗ i (1)ψ ∗ j (2)uijψj(2)ψi(1)dτ1dτ2, (1) while Jij = ∫ ψ ∗ j (1)ψ ∗ i (2)uijψj(2)ψi(1)dτ1dτ2, (2) uij being the relevant interaction potential. The energy difference between a state of “parallel” spins and one of “antiparallel” spins is given by ε↑↑ − ε↑↓ = −2Jij. (3) If Jij > 0, the state ↑↑ is energetically favored against the state ↑↓; we then look for the possibility of ferromagnetism. If, on the other hand, Jij < 0, the situation is reversed and we see the possibility of antiferromagnetism. It seems useful to express the interaction energy of the two states, ↑↑ and ↓↓, by a single expression; for this, we consider the eigenvalues of the scalar product si · sj = 1 2 { (si + sj)2 − s2 i − s2 j } = 1 2 S(S + 1) − s(s + 1), (4) which equals + 1 4 if S = 1 and − 3 4 if S = 0. We may, therefore, write for the interaction energy of the spins i and j εij = const. − 2Jij(si · sj), (5) which is consistent with the energy difference (3). The precise value of the constant here is immaterial because the potential energy is arbitrary to the extent of an additive constant anyway. Typically, the exchange interaction Jij falls off rapidly as the separation of the two 414 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling spins is increased. To a ﬁrst approximation, therefore, we may regard Jij as negligible for all but nearest-neighbor pairs (for which its value may be denoted by a common symbol J). The interaction energy of the whole lattice is then given by E = const. − 2J ∑ n.n. ( si · sj), (6) where the summation goes over all nearest-neighbor pairs in the lattice. The model based on expression (6) for the interaction energy of the lattice is known as the Heisenberg model (1928). A simpler model results if we use, instead of (6), a truncated expression in which the product (si · sj), which is equal to the sum (sixsjx + siysjy + sizsjz), is replaced by a single term sizsjz; one reason for adopting this simpler model is that it does not necessarily require a quantum-mechanical treatment (because all the variables in the truncated expression for E commute). Expression (6) may now be written as E = const. − J ∑ n.n. σiσj, (7) where the new symbol σi (or σj) = +1 for an “up” spin and −1 for a “down” spin; note that, with the introduction of the new symbol, we still have: ε↑↑ − ε↑↓ = −2J. The model based on expression (7) is known as the Ising model; it originated with Lenz (1920) and was subsequently investigated by his student Ising (1925).7 A different model results if we suppress the z-components of the spins and retain the x- and y-components instead. This model was originally introduced by Matsubara and Matsuda (1956) as a model of a quantum lattice gas, with possible relevance to the super- ﬂuid transition in liquid He4. The critical behavior of this so-called XY model has been investigated in detail by Betts and coworkers, who have also emphasized the relevance of this model to the study of insulating ferromagnets (see Betts et al., 1968 – 1974). It seems appropriate to regard the Ising and the XY models as special cases of an anisotropic Heisenberg model with interaction parameters Jx, Jy, and Jz; while the Ising model represents the situation Jx, Jy ≪ Jz, the XY model represents just the opposite. Intro- ducing a parameter n, which denotes the number of spin components entering into the Hamiltonian of the system, we may regard the Ising, the XY , and the Heisenberg models as pertaining to the n-values 1, 2, and 3, respectively. As will be seen later, the parameter n, along with the dimensionality d of the lattice, constitutes the basic set of elements that determine the qualitative nature of the critical behavior of a given system. For the time being, though, we conﬁne our attention to the Ising model, which is not only the sim- plest one to analyze but also uniﬁes the study of phase transitions in systems as diverse as ferromagnets, gas–liquids, liquid mixtures, binary alloys, and so on. 7For an historical account of the origin and development of the Lenz–Ising model, see the review article by Brush (1967). This review gives a large number of other references as well. 12.3 A dynamical model of phase transitions 415 To study the statistical mechanics of the Ising model, we disregard the kinetic energy of the atoms occupying the various lattice sites, for the phenomenon of phase transitions is essentially a consequence of the interaction energy among the atoms; in the interac- tion energy again, we include only the nearest-neighbor contributions, in the hope that the farther-neighbor contributions would not affect the results qualitatively. To ﬁx the z-direction, and to be able to study properties such as magnetic susceptibility, we subject the lattice to an external magnetic ﬁeld B, directed “upward”; the spin σi then possesses an additional potential energy −µBσi. 8 The Hamiltonian of the system in conﬁguration {σ1, σ2, . . . , σN } is then given by H{σi} = −J ∑ n.n. σiσj − µB ∑ i σi, (8) and the partition function by QN (B, T ) = ∑ σ1 ∑ σ2 . . . ∑ σN exp[−βH{σi}] = ∑ σ1 ∑ σ2 . . . ∑ σN exp [ βJ ∑ n.n. σiσj + βµB ∑ i σi ] . (9) The Helmholtz free energy, the internal energy, the speciﬁc heat, and the net magnetiza- tion of the system then follow from the formulae A(B, T ) = −kT ln QN (B, T ), (10) U(B, T ) = −T 2 ∂ ∂T ( A T ) = kT 2 ∂ ∂T ln QN , (11) C(B, T ) = ∂U ∂T = −T ∂ 2A ∂T 2 , (12) and M(B, T ) = µ ( ∑ i σi ) = ( − ∂H ∂B ) = 1 β ( ∂ ln QN ∂B ) T = − ( ∂A ∂B ) T . (13) Obviously, the quantity M(0, T ) gives the spontaneous magnetization of the system; if it is nonzero at temperatures below a certain critical temperature Tc, the system would be ferromagnetic for T < Tc and paramagnetic for T > Tc. At the transition temperature itself, the system is expected to show some sort of a singular behavior. It is obvious that the energy levels of the system as a whole will be degenerate, in the sense that the various conﬁgurations {σi} will not all possess distinct energy values. In fact, the energy of a given conﬁguration does not depend on the detailed values of all 8Henceforth, we use the symbol µ instead of µB. 416 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling the variables σi; it depends only on a few numbers such as the total number N+ of “up” spins, the total number N++ of “up–up” nearest-neighbor pairs, and so on. To see this, we deﬁne certain other numbers as well: N− as the total number of “down” spins, N−− as the total number of “down–down” nearest-neighbor pairs, and N+− as the total number of nearest-neighbor pairs with opposite spins. The numbers N+ and N− must satisfy the relation N+ + N− = N. (14) And if q denotes the coordination number of the lattice, that is, the number of nearest neighbors for each lattice site, 9 then we also have the relations qN+ = 2N++ + N+−, (15) qN− = 2N−− + N+−. (16) With the help of these relations, we can express all our numbers in terms of any two of them, say N+ and N++. Thus N− = N − N+, N+− = qN+ − 2N++, N−− = 1 2 qN − qN+ + N++; (17) it will be noted that the total number of nearest-neighbor pairs of all types is given, quite expectedly, by the expression N++ + N−− + N+− = 1 2 qN. (18) Naturally, the Hamiltonian of the system can also be expressed in terms of N+ and N++; we have from (8), with the help of the relations established above, HN (N+, N++) = −J(N++ + N−− − N+−) − µB(N+ − N−) = −J( 1 2 qN − 2qN+ + 4N++ ) − µB(2N+ − N). (19) Now, let gN (N+, N++) be “the number of distinct ways in which the N spins of the lattice can be so arranged as to yield certain preassigned values of the numbers N+ and N++.” The partition function of the system can then be written as QN (B, T ) = ∑′ N+,N++gN (N+, N++) exp{−βHN (N+, N++)} , (20) 9The coordination number q for a linear chain is obviously 2; for two-dimensional lattices, namely honeycomb, square, and triangular, it is 3, 4, and 6, respectively; for three-dimensional lattices, namely simple cubic, body-centered cubic, and face-centered cubic, it is 6, 8, and 12, respectively. 12.4 The lattice gas and the binary alloy 417 that is, e−βA = eβN( 1 2 qJ−µB) N∑ N+=0 e−2β(qJ−µB)N+ ∑ N++ ′gN (N+, N++)e4βJN++ , (21) where the primed summation in (21) goes over all values of N++ that are consistent with a ﬁxed value of N+ and is followed by a summation over all possible values of N+, that is, from N+ = 0 to N+ = N. The central problem thus consists in determining the combinatorial function gN (N+, N++) for the various lattices of interest. 12.4 The lattice gas and the binary alloy Apart from ferromagnets, the Ising model can be readily adapted to simulate the behavior of certain other systems as well. More common among these are the lattice gas and the binary alloy. The lattice gas Although it had already been recognized that the results derived for the Ising model would apply equally well to a system of “occupied” and “unoccupied” lattice sites (i.e., to a system of “atoms” and “holes” in a lattice), it was Yang and Lee (1952) who ﬁrst used the term “lattice gas” to describe such a system. By deﬁnition, a lattice gas is a collection of atoms, Na in number, that can occupy only discrete positions in space — positions that constitute a lattice structure with coordination number q. Each lattice site can be occupied by at most one atom, and the interaction energy between two occupied sites is nonzero, say −ε0, only if the sites involved constitute a nearest-neighbor pair. The conﬁgurational energy of the gas is then given by E = −ε0Naa, (1) where Naa is the total number of nearest-neighbor pairs (of occupied sites) in a given con- ﬁguration of the system. Let gN (Na, Naa) denote “the number of distinct ways in which the Na atoms of the gas, assumed indistinguishable, can be distributed among the N sites of the lattice so as to yield a certain preassigned value of the number Naa.” The partition function of the system, neglecting the kinetic energy of the atoms, is then given by QNa (N, T ) = ∑′ Naa gN (Na, Naa) eβε0Naa , (2) where the primed summation goes over all values of Naa that are consistent with the given values of Na and N; clearly, the number N here plays the role of the “total volume” available to the gas. 418 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling Going over to the grand canonical ensemble, we write for the grand partition function of the system Q(z, N, T ) = N∑ Na=0 zNa QNa (N, T ). (3) The pressure P and the mean number N a of the atoms in the gas are then given by eβPN = N∑ Na=0 zNa ∑′ Naa gN (Na, Naa) eβε0Naa (4) and N a N = 1 v = z kT ( ∂P ∂z ) T ; (5) here, v denotes the average volume per particle of the gas (measured in terms of the “volume of a primitive cell of the lattice”). To establish a formal correspondence between the lattice gas and the ferromagnet, we compare the present formulae with the ones established in the preceding section — in par- ticular, formula (4) with formula (12.3.21). The ﬁrst thing to note here is that the canonical ensemble of the ferromagnet corresponds to the grand canonical ensemble of the lattice gas! The rest of the correspondence is summarized in the following chart: The lattice gas The ferromagnet Na, N − Na ↔ N+, N − N+(= N−) ε0 ↔ 4J z ↔ exp{−2β(qJ − µB)} P ↔ − ( A N + 1 2 qJ − µB) N a N ( = 1 v ) ↔ N + N ( = 1 2 { M Nµ + 1 }) , where M = µ ( N + − N −) = µ(2N + − N) . (6) We also note that the ferromagnetic analogue of formula (5) would be N + N = 1 kT    ∂ (A/N + 1 2 qJ − µB) 2β∂ ( qJ − µB)    T = 1 2 [− 1 Nµ ( ∂A ∂B ) T + 1] (7) 12.4 The lattice gas and the binary alloy 419 which, by equation (12.3.13), assumes the expected form N + N = 1 2 ( M Nµ + 1 ) . (8) It is quite natural to ask: does lattice gas correspond to any real physical system in nature? The immediate answer is that if we let the lattice constant tend to zero (thus going from a discrete structure to a continuous one) and also add, to the lattice-gas formulae, terms corresponding to an ideal gas (namely, the kinetic energy terms), then the model might simulate the behavior of a gas of real atoms interacting through a delta function potential. A study of the possibility of a phase transition in such a system may, therefore, be of some value in understanding phase transitions in real gases. The case ε0 > 0, which implies an attractive interaction among the nearest neighbors, has been frequently cited as a possible model for a gas–liquid transition. On the other hand, if the interaction is repulsive (ε0 < 0), so that conﬁgurations with alternating sites being “occupied” and “unoccupied” are the more favored ones, then we obtain a model that arouses interest in connection with the theory of solidiﬁcation; in such a study, however, the lattice constant has to stay ﬁnite. Thus, several authors have pursued the study of the antiferromagnetic version of this model, hoping that this might throw some light on the liquid–solid transition. For a bibliography of these pursuits, see the review article by Brush (1967). The binary alloy Much of the early activity in the theoretical analysis of the Ising model was related to the study of order–disorder transitions in alloys. In an alloy — to be speciﬁc, a binary alloy — we have a lattice structure consisting of two types of atoms, say 1 and 2, numbering N1 and N2, respectively. In a conﬁguration characterized by the numbers N11, N22, and N12 of the three types of nearest-neighbor pairs, the conﬁgurational energy of the alloy may be written as E = ε11N11 + ε22N22 + ε12N12, (9) where ε11, ε22, and ε12 have obvious meanings. As in the case of a ferromagnet, the various numbers appearing in the expression for E may be expressed in terms of the numbers N, N1, and N11 (of which only N11 is variable here). Equation (9) then takes the form E = ε11N11 + ε22 ( 1 2 qN − qN1 + N11 ) + ε12 ( qN1 − 2N11) = 1 2 qε22N + q(ε12 − ε22)N1 + (ε11 + ε22 − 2ε12)N11. (10) 420 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling The correspondence between this system and the lattice gas is now straightforward: The lattice gas The binary alloy Na, N − Na ↔ N1, N − N1(= N2) −ε0 ↔ (ε11 + ε22 − 2ε12) A ↔ A − 1 2 qε22N − q(ε12 − ε22)N1 The correspondence with a ferromagnet can be established likewise; in particular, this requires that ε11 = ε22 = −J and ε12 = +J. At absolute zero, our alloy will be in the state of minimum conﬁgurational energy, which would also be the state of maximum conﬁgurational order. We expect that the two types of atoms would then occupy mutually exclusive sites, so that one might speak of atoms 1 being only at sites a and atoms 2 being only at sites b. As tempera- ture rises, an exchange of sites results and, in the face of thermal agitation, the order in the system starts giving way. Ultimately, the two types of atoms get so “mixed up” that the very notion of the sites a being the “right” ones for atoms 1 and the sites b being the “right” ones for atoms 2 break down; the system then behaves, from the conﬁgurational point of view, as an assembly of N1 + N2 atoms of essentially the same species. 12.5 Ising model in the zeroth approximation In 1928 Gorsky attempted a statistical study of order–disorder transitions in binary alloys on the basis of the assumption that the work expended in transferring an atom from an “ordered” position to a “disordered” one (or, in other words, from a “right” site to a “wrong” one) is directly proportional to the degree of order prevailing in the system. This idea was further developed by Bragg and Williams (1934, 1935) who, for the ﬁrst time, introduced the concept of long-range order in the sense we understand it now and, with relatively simple mathematics, obtained results that could explain the main qualitative features of the relevant experimental data. The basic assumption in the Bragg– Williams approximation was that the energy of an individual atom in the given system is determined by the (average) degree of order prevailing in the entire system rather than by the ( ﬂuctuating) conﬁgurations of the neighboring atoms. In this sense, the approximation is equivalent to the mean molecular ﬁeld (or the internal ﬁeld) theory of Weiss, which was put forward in 1907 to explain the magnetic behavior of ferromagnetic materials. It seems natural to call this approximation the zeroth approximation, for its features are totally insensitive to the detailed structure, or even to the dimensionality, of the lattice. We expect that the results following from this approximation will become more reliable 12.5 Ising model in the zeroth approximation 421 as the number of neighbors interacting with a given atom increases (i.e., as q → ∞), thus diminishing the importance of local, ﬂuctuating inﬂuences.10 We now deﬁne a long-range order parameter L in a given conﬁguration by the very suggestive relationship L = 1 N ∑ i σi = N+ − N− N = 2 N+ N − 1 (−1 ≤ L ≤ +1), (1) which gives N+ = N 2 (1 + L) and N− = N 2 (1 − L). (2) The magnetization M is then given by M = (N+ − N−)µ = NµL (−Nµ ≤ M ≤ +Nµ); (3) the parameter L is, therefore, a direct measure of the net magnetization in the system. For a completely random conﬁguration, N + = N − = 1 2 N; the expectation values of both L and M are then identically zero. Now, in the spirit of the present approximation, we replace the ﬁrst part of the Hamilto- nian (12.3.8) by the expression −J( 1 2 qσ ) ∑ i σi, that is, for a given σi, we replace each of the qσj by σ while the factor 1 2 is included to avoid duplication in the counting of the nearest- neighbor pairs. Making use of equation (1), and noting that σ ≡ L, we obtain for the total conﬁgurational energy of the system E = − 1 2 ( qJL) NL − (µB)NL. (4) The expectation value of E is then given by U = − 1 2 qJNL2 − µBNL. (5) In the same approximation, the difference 1ε between the overall conﬁgurational energy of an “up” spin and the overall conﬁgurational energy of a “down” spin — speciﬁcally, the energy expended in changing an “up” spin into a “down” spin — is given by, see equation (12.3.8), 1ε = −J(qσ )1σ − µB1σ = 2µ ( qJ µ σ + B) , (6) 10In connection with the present approximation, we may as well mention that early attempts to construct a theory of binary solutions were based on the assumption that the atoms in the solution mix randomly. One ﬁnds that the results following from this assumption of random mixing are mathematically equivalent to the ones following from the mean ﬁeld approximation; see Problems 12.12 and 12.13. 422 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling for here 1σ = −2. The quantity qJσ /µ thus plays the role of the internal (molecular) ﬁeld of Weiss; it is determined by (i) the mean value of the long-range order prevailing in the system and by (ii) the strength of the coupling, qJ, between a given spin i and its q nearest neighbors. The relative values of the equilibrium numbers N + and N − then follow from the Boltzmann principle, namely N −/N + = exp( −1ε/kT ) = exp{ −2µ(B′ + B)/kT } , (7) where B′ denotes the internal molecular ﬁeld: B′ = qJσ /µ = qJ (M/Nµ2). (8) Substituting (2) into (7), and keeping in mind equation (8), we obtain for L 1 − L 1 + L = exp{ −2(qJL + µB)/kT } (9) or, equivalently, qJL + µB kT = 1 2 ln 1 + L 1 − L = tanh−1 L. (10) To investigate the possibility of spontaneous magnetization, we let B → 0, which leads to the relationship L0 = tanh ( qJL0 kT ) . (11) Equation (11) may be solved graphically; see Figure 12.6. For any temperature T , the appropriate value of L0(T ) is determined by the point of intersection of (i) the straight line y = L0 and (ii) the curve y = tanh(qJL0/kT ). Clearly, the solution L0 = 0 is always there; however, we are interested in nonzero solutions, if any. For those, we note that, since the slope of the curve (ii) varies from the initial value qJ/kT to the ﬁnal value zero while the slope of the line (i) is unity throughout, an intersection other than the one at the origin is possible if, and only if, qJ/kT > 1, (12) that is, T < qJ/k = Tc, say. (13) We thus obtain a critical temperature Tc, below which the system can acquire a nonzero spontaneous magnetization and above which it cannot. It is natural to identify Tc with the Curie temperature of the system — the temperature that marks a transition from the ferromagnetic to the paramagnetic behavior of the system or vice versa. It is clear from Figure 12.6, as well as from equation (11), that if L0 is a solution of the problem, then −L0 is also a solution. The reason for this duplicity of solutions is that, in 12.5 Ising model in the zeroth approximation 423 0 L0 tanh(L0Tc /T ), L0 T \u0002T c T \u0003T c L0 1 –1 1 –L0–1 FIGURE 12.6 The graphical solution of equation (11), with Tc = qJ/k. the absence of an external ﬁeld, there is no way of assigning a “positive,” as opposed to a “negative,” direction to the alignment of spins. In fact, if B were zero right from the begin- ning, then the positive solution of equation (11) would be as likely to occur as the negative one — with the result that the true expectation value of L0(T ) would be zero. If, on the other hand, B were nonzero to begin with (to be deﬁnite, say B > 0), then equation (10) for L(B, T ) would admit only positive solutions and, in the limit B → 0+, we would obtain a positive L0(T ). The “up–down symmetry” will then be broken and we will see a net alignment of spins in the “up” direction. 11 The precise variation of L0(T ) with T can be obtained by solving equation (11) numeri- cally; the general trend, however, can be seen from Figure 12.6. We note that, at T = qJ/k (= Tc), the straight line y = L0 is tangential to the curve y = tanh(qJL0/kT ) at the ori- gin; the relevant solution then is L0(Tc) = 0. As T decreases, the initial slope of the curve becomes larger and the relevant point of intersection moves rapidly away from the origin; accordingly, L0(T ) rises rapidly as T decreases below Tc. To obtain an approximate depen- dence of L0(T ) on T near T = Tc, we write (11) in the form L0 = tanh(L0Tc/T ) and use the approximation tanh x ≃ x − x3/3, to obtain L0(T ) ≈ {3(1 − T /Tc)} 1/2 (T ≲ Tc, B → 0). (14) On the other hand, as T → 0, L0 → 1, in accordance with the asymptotic relationship L0(T ) ≈ 1 − 2 exp(−2Tc/T ) {(T /Tc) ≪ 1}. (15) Figure 12.7 shows a plot of L0(T ) versus T , along with the relevant experimental results for iron, nickel, cobalt, and magnetite; we ﬁnd the agreement not too bad. 11The concept of “broken symmetry” plays a vital role in this and many other phenomena in physics; for details, see Fisher (1972) and Anderson (1984). 424 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling (T/Tc) 0.50 0 0.5 1.0 1.0L0(T) FIGURE 12.7 The spontaneous magnetization of a Weiss ferromagnet as a function of temperature. The experimental points (after Becker) are for iron (×), nickel (o), cobalt (1), and magnetite (+). The ﬁeld-free conﬁgurational energy and the ﬁeld-free speciﬁc heat of the system are given by, see equation (5), U0(T ) = − 1 2 qJNL2 0 (16) and C0(T ) = −qJNL0 dL0 dT = NkL2 0 (T /Tc)2/(1 − L2 0) − T /Tc , (17) where the last step has been carried out with the help of equation (11). Thus, for all T > Tc, both U0(T ) and C0(T ) are identically zero. However, the value of the speciﬁc heat at the transition temperature Tc, as approached from below, turns out to be, see equations (14) and (17), C0(Tc−) = Lim x→0    Nk · 3x (1−x)2 1−3x − (1 − x)    = 3 2 Nk. (18) The speciﬁc heat, therefore, displays a discontinuity at the transition point. On the other hand, as T → 0, the speciﬁc heat vanishes, in accordance with the formula, see equations (15) and (17), C0(T ) ≈ 4Nk ( Tc T )2 exp(−2Tc/T ). (19) The full trend of the function C0(T ) is shown in Figure 12.8. It is important to note that the vanishing of the conﬁgurational energy and the spe- ciﬁc heat of the system at temperatures above Tc is directly related to the fact that, in the present approximation, the conﬁgurational order prevailing in the system at lower temper- atures is completely wiped out as T → Tc. Consequently, the conﬁgurational entropy and 12.5 Ising model in the zeroth approximation 425 (T/Tc)C0(T)/Nk 0 0 0.5 1.0 2.0 1.5 12 FIGURE 12.8 The ﬁeld-free speciﬁc heat of a Weiss ferromagnet as a function of temperature. the conﬁgurational energy of the system attain their maximum values at T = Tc; beyond that, the system remains thermodynamically “inert.” As a check, we evaluate the con- ﬁgurational entropy of the system at T = Tc; with the help of equations (11) and (17), we get S0(Tc) = Tc∫ 0 C0(T )dT T = −qJN 0∫ 1 L0 T dL0 = Nk 1∫ 0 (tanh−1 L0)dL0 = Nk ln 2, (20) precisely the result we expect for a system capable of 2N equally likely microstates.12 The fact that all these microstates are equally likely to occur is again related to the fact that for T ≥ Tc there is no (conﬁgurational) order in the system. We now proceed to study the magnetic susceptibility of the system. Using equa- tion (10), we get χ(B, T ) = ( ∂M ∂B ) T = Nµ ( ∂L ∂B ) T = Nµ2 k 1 − L2(B, T ) T − Tc{1 − L2(B, T )} . (21) For L ≪ 1 (which is true at high temperatures for a wide range of B but is also true near Tc if B is small), we obtain the Curie–Weiss law χ0(T ) ≈ (Nµ2/k)(T − Tc)−1 (T ≳ Tc, B → 0), (22a) 12Recall equation (3.3.14), whereby S = k ln \u0000. 426 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling which may be compared with the Curie law derived earlier for a paramagnetic system; see equation (3.9.12). For T less than, but close to, Tc we utilize equation (14) as well and get χ0(T ) ≈ (Nµ2/2k)(Tc − T )−1 (T ≲ Tc, B → 0). (22b) Experimentally, one ﬁnds that the Curie–Weiss law is satisﬁed with considerable accuracy, except that the empirical value of Tc thus obtained is always somewhat larger than the true transition temperature of the material; for instance, in the case of nickel, the empirical value of Tc obtained in this manner turns out to be about 650 K while the actual transition takes place at about 631 K. In passing, we add that, as T → 0, the low-ﬁeld susceptibility vanishes, in accordance with the formula χ0(T ) ≈ 4Nµ2 kT exp(−2Tc/T ). (23) Finally, we examine the relationship between L and B at T = Tc. Using, once again, equation (10) and employing the approximation tanh−1 x ≃ x + x3/3, we get L ≈ (3µB/kTc)1/3 (T = Tc, B → 0). (24) At this point we wish to emphasize the remarkable similarity that exists between the critical behavior of a gas–liquid system obeying van der Waals equation of state and that of a magnetic system treated in the Bragg–Williams approximation. Even though the two systems are physically very different, the level of approximation is such that the exponents governing power-law behavior of the various physical quantities in the critical region turn out to be the same; compare, for instance, equation (14) with (12.2.11), equations (22a) and (22b) with (12.2.13) and (12.2.14), equation (24) with (12.2.8) — along with the behavior of the speciﬁc heat as well. This sort of similarity will be seen again and again whenever we employ an approach similar in spirit to the mean ﬁeld approach of this section. Before we close our discussion of the so-called zeroth approximation, we would like to demonstrate that it corresponds exactly to the random mixing approximation (which was employed originally in the theory of binary solutions). According to equation (12.3.19), the mean conﬁgurational energy in the absence of the external ﬁeld is given by U0 = −J ( 1 2 qN − 2qN + + 4N ++ ). (25) At the same time, equations (2) and (16) of the present approach give N + = 1 2 N(1 + L0) and U0 = − 1 2 qJNL2 0. (26) Combining (25) and (26), we obtain N ++ = 1 8 qN( 1 + L0)2 , (27) 12.6 Ising model in the ﬁrst approximation 427 so that N ++ 1 2 qN = ( N + N )2 . (28) Thus, the probability of having an “up–up” nearest-neighbor pair of spins in the lat- tice is precisely equal to the square of the probability of having an “up” spin; in other words, there does not exist, in spite of the presence of a nearest-neighbor interaction (characterized by the coupling constant J), any speciﬁc correlation between the neigh- boring spins of the lattice. Put differently, there does not exist any short-range order in the system, apart from what follows statistically from the long-range order (charac- terized by the parameter L). It follows that, in the present approximation, our system consists of a speciﬁc number of “up” spins, namely N(1 + L)/2, and a corresponding number of “down” spins, namely N(1 − L)/2, distributed over the N lattice sites in a completely random manner — similar to the mixing of N(1 + L)/2 atoms of one kind with N(1 − L)/2 atoms of another kind in a completely random manner to obtain a binary solution of N atoms; see also Problem 12.4. For this sort of mixing, we obviously have N ++ = 1 2 qN ( 1 + L 2 )2 , N −− = 1 2 qN ( 1 − L 2 )2 , (29a) N +− = 2 · 1 2 qN ( 1 + L 2 ) ( 1 − L 2 ) , (29b) with the result that N ++N −− (N +−)2 = 1 4 . (30) 12.6 Ising model in the ﬁrst approximation The approaches considered in the preceding section have a natural generalization toward an improved approximation. The mean ﬁeld approach leads naturally to the Bethe approximation (Bethe, 1935; Rushbrooke, 1938), which treats the interaction of a given spin with its nearest neighbors somewhat more accurately. The random mixing approach, on the other hand, leads to the quasichemical approximation (Guggenheim, 1935; Fowler and Guggenheim, 1940), which takes into account the speciﬁc short-range order of the lat- tice — over and above the one that follows statistically from the long-range order. As shown by Guggenheim (1938) and by Chang (1939), the two methods yield identical results for the Ising model. It seems worthwhile to mention here that the extension of these approxima- tions to higher orders, or their application to the Heisenberg model, does not produce identical results. 428 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling In the Bethe approximation, a given spin σ0 is regarded as the central member of a group, which consists of this spin and its q nearest neighbors, and in writing down the Hamiltonian of this group the interaction between the central spin and its q neighbors is taken into account exactly while the interaction of these neighbors with other spins in the lattice is taken into account through a mean molecular ﬁeld B′. Thus Hq+1 = −µBσ0 − µ(B + B′) q∑ j=1 σj − J q∑ j=1 σ0σj, (1) B being the external magnetic ﬁeld acting on the lattice. The internal ﬁeld B′ is determined by the condition of self-consistency, which requires that the mean value, σ 0, of the central spin be the same as the mean value, σ j, of any of the q neighbors. The partition function Z of this group of spins as a whole is given by Z = ∑ σ0,σj=±1 exp   1 kT   µBσ0 + µ (B + B′) q∑ j=1 σj + J q∑ j=1 σ0σj      = ∑ σ0,σj=±1 exp  ασ0 + (α + α′) q∑ j=1 σj + γ q∑ j=1 σ0σj   , (2) where α = µB kT , α′ = µB′ kT and γ = J kT . (3) Now, the right side of (2) can be written as a sum of two terms, one pertaining to σ0 = +1 and the other to σ0 = −1, that is, Z = Z+ + Z−, where Z± = ∑ σj=±1 exp  ±α + (α + α′ ± γ ) q∑ j=1 σj   = e±α [2 cosh (α + α′ ± γ )]q . (4) The mean value of the central spin is then given by σ 0 = Z+ − Z− Z , (5) 12.6 Ising model in the ﬁrst approximation 429 while the mean value of any one of its q neighbors is given by, see (2) and (4), σ j = 1 q   q∑ j=1 σj   = 1 q ( 1 Z ∂Z ∂α′ ) = 1 Z { Z+ tanh ( α + α′ + γ ) + Z− tanh ( α + α′ − γ )}. (6) Equating (5) and (6), we get Z+ { 1 − tanh (α + α′ + γ )} = Z− { 1 + tanh ( α + α′ − γ )} . (7) Substituting for Z+ and Z− from (4), we ﬁnally obtain e2α′ = { cosh ( α + α′ + γ ) cosh (α + α′ − γ ) }q−1 . (8) Equation (8) determines α′ which, in turn, determines the magnetic behavior of the lattice. To study the possibility of spontaneous magnetization, we set α(= µB/kT ) = 0. Equa- tion (8) then reduces to α′ = q − 1 2 ln { cosh ( α′ + γ ) cosh (α′ − γ ) } . (9) In the absence of interactions (γ = 0), α′ is clearly zero. In the presence of interactions (γ ̸= 0), α′ may still be zero unless γ exceeds a certain critical value, γc say. To determine this value, we expand the right side of (9) as a Taylor series around α′ = 0, with the result α′ = (q − 1) tanh γ { α′ − sech 2γ α′3 3 + · · · } . (10) We note that, for all γ , α′ = 0 is one possible solution of the problem; this, however, does not interest us. A nonzero solution requires that (q − 1) tanh γ > 1, that is, γ > γc = tanh−1 ( 1 q − 1 ) = 1 2 ln ( q q − 2 ) . (11) In terms of temperature, this means that T < Tc = 2J k ∕ ln ( q q − 2 ) , (12) 430 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling which determines the Curie temperature of the lattice. From (10), we also infer that for temperatures less than, but close to, the Curie temperature α′ ≃ { 3 cosh2 γc [(q − 1) tanh γ − 1 ]}1/2 ≃ {3(q − 1)(γ − γc)}1/2 ≃ { 3(q − 1) J kTc ( 1 − T Tc )}1/2 . (13) The parameter L, which is a measure of the long-range order in the system, is, by deﬁnition, equal to σ . From equations (5) and (7), we get L = (Z+/Z−) − 1 (Z+/Z−) + 1 = sinh(2α + 2α′) cosh(2α + 2α′) + exp(−2γ ) . (14) In the limit B → 0 (which means α → 0) and at temperatures less than, but close to, the Curie temperature (γ ≳ γc; α′ ≃ 0), we obtain L0 = sinh(2α′) cosh(2α′) + exp(−2γ ) ≃ 2α′ 1 + (q − 2)/q = q q − 1 α′. (15) Substituting from (12) and (13), we get L0 ≃ [3 q q − 1 { q 2 ln ( q q − 2 )} (1 − T Tc )]1/2 . (16) We note that, for q ≫ 1, equations (12) and (16) reduce to their zeroth-order counter parts (12.5.13) and (12.5.14), respectively; in either case, as T → Tc from below, L0 vanishes as (Tc − T )1/2. We also note that the spontaneous magnetization curve in the present approxi- mation has the same general shape as in the zeroth approximation; see Figure 12.7. Of course, in the present case the curve depends explicitly on the coordination number q, being steepest for small q and becoming less steep as q increases — tending ultimately to the limiting form given by the zeroth approximation. We shall now study correlations that might exist among neighboring spins in the lattice. For this, we evaluate the numbers N ++, N −−, and N +− in terms of the parameters α, α′, and γ , and compare the resulting expressions with the ones obtained under the mean ﬁeld approximation. Carrying out summations in (2) over all the spins (of the group) except σ0 and σ1, we obtain Z = ∑ σ0,σ1=±1 [ exp{ ασ0 + (α + α′)σ1 + γ σ0σ1} {2 cosh(α + α′ + γ σ0) }q−1]. (17) Writing this as a sum of three parts pertaining, respectively, to the cases (i) σ0 = σ1 = +1, (ii) σ0 = σ1 = −1, and (iii) σ0 = −σ1 = ±1, we have Z = Z++ + Z−− + Z+−, (18) 12.6 Ising model in the ﬁrst approximation 431 where, naturally enough, N ++ : N −− : N +− :: Z++ : Z−− : Z+−. (19) We thus obtain, using (8) as well, N ++ ∝ e(2α+α′+γ ) { 2 cosh(α + α′ + γ )}q−1 , N −− ∝ e(−2α−α′+γ ) { 2 cosh(α + α′ − γ ) }q−1 = e(−2α−3α′+γ ){2 cosh(α + α′ + γ )}q−1, and N +− ∝ e(−α′−γ ) { 2 cosh(α + α′ + γ )}q−1 + e(α′−γ ) { 2 cosh(α + α′ − γ )}q−1 = 2e(−α′−γ ){2 cosh(α + α′ + γ )}q−1. Normalizing these expressions with the help of the relationship N ++ + N −− + N +− = 1 2 qN, (20) we obtain the desired results ( N ++, N −−, N +−) = 1 2 qN ( e2α+2α′+γ , e−2α−2α′+γ , 2e−γ ) 2 { eγ cosh (2α + 2α′) + e−γ } , (21) whereby N ++N −− (N +−)2 = 1 4 e4γ = 1 4 e4J/kT . (22) The last result differs signiﬁcantly from the one that followed from the random mixing approximation, namely (12.5.30). The difference lies in the extra factor exp(4J/kT ) which, for J > 0, favors the formation of parallel-spin pairs ↑↑ and ↓↓, as opposed to antiparallel- spin pairs ↑↓ and ↓↑. In fact, one may regard the elementary process ↑↑ + ↓↓ ⇔ 2 ↑↓, (23) which leaves the total numbers of “up” spins and “down” spins unaltered, as a kind of a “chemical reaction” which, proceeding from left to right, is endothermic (requiring an amount of energy 4J to get through) and, proceeding from right to left, is exothermic (releasing an amount of energy 4J). Equation (22) then constitutes the law of mass action for this reaction, the expression on the right side being the equilibrium constant of the reaction. Historically, equation (22) was adopted by Guggenheim as the starting point of his “quasichemical” treatment of the Ising model; only later on did he show that his treatment was equivalent to the Bethe approximation expounded here. 432 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling Equation (22) tells us that, for J > 0, there exists among like neighbors (↑ and ↑ or ↓ and ↓) a positive correlation and among unlike neighbors (↑ and ↓) a negative correlation, and that these correlations are a direct consequence of the nearest-neighbor interaction. Accordingly, there must exist a speciﬁc short-range order in the system, over and above the one that follows statistically from the long-range order. To see this explicitly, we note that even when long-range order disappears (α + α′ = 0), some short-range order still persists. For instance, from equation (21) we obtain (N ++, N −−, N +−) L=0 = 1 2 qN ( eγ , eγ , 2e−γ ) 4 cosh γ (24) which, only in the limit γ → 0, goes over to the random-mixing result, see equa- tion (12.5.29) with L = 0, ( N ++, N −−, N +−) L=0 = 1 2 qN (1, 1, 2) 4 . (25) In the zeroth approximation, equation (25) is supposed to hold at all temperatures above Tc; we now ﬁnd that a better approximation at these temperatures is provided by (24). Next, we evaluate the conﬁgurational energy U0 and the speciﬁc heat C0 of the lattice in the absence of the external ﬁeld (α = 0). In view of equation (12.5.25), U0 = −J( 1 2 qN − 2qN + + 4N ++ ) α=0 . (26) The expression for N ++ is given by equation (21) while that for N + can be obtained from (14): (N +)α=0 = 1 2 N(1 + L0) = 1 2 N exp(2α′) + exp(−2γ ) cosh(2α′) + exp(−2γ ) . (27) Equation (26) then gives U0 = − 1 2 qJN cosh(2α′) − exp(−2γ ) cosh(2α′) + exp(−2γ ) , (28) where α′ is determined by equation (9). For T > Tc, α′ = 0, so U0 = − 1 2 qJN 1 − exp(−2γ ) 1 + exp(−2γ ) = − 1 2 qJN tanh γ . (29) Obviously, this result arises solely from the short-range order that persists in the system even above Tc. As for the speciﬁc heat, we get C0/Nk = 1 2 qγ 2sech 2γ (T > Tc). (30) As T → ∞, C0 vanishes like T −2. We note that a nonzero speciﬁc heat above the transition temperature is a welcome feature of the present approximation, for it brings our model 12.6 Ising model in the ﬁrst approximation 433 0 0 1 1 2 2 2 2.88 4 6 (kT/J )C0(T)/Nk FIGURE 12.9 The ﬁeld-free speciﬁc heat of an Ising lattice with coordination number 4. Curve 1 obtains in the Bethe approximation, curve 2 in the Bragg–Williams approximation. somewhat closer to real physical systems. In this connection, we recall that in the previous approximation the speciﬁc heat was zero for all T > Tc. Figure 12.9 shows the speciﬁc heat of an Ising lattice, with coordination number 4, as given by the Bethe approximation; for comparison, the result of the previous approximation is also included. We are now in a position to study the speciﬁc heat discontinuity at T = Tc. The limiting value of C0, as T approaches Tc from above, can be obtained from equation (30) by letting γ → γc. One obtains, with the help of equation (11), 1 Nk C0 (Tc+) = 1 2 qγ 2 c sech 2γc = 1 8 q2(q − 2) (q − 1)2 { ln ( q q − 2 )}2 . (31) To obtain the corresponding result as T approaches Tc from below, we must use the general expression (28) for U0, with α′ → 0 as γ → γc. Expanding (28) in powers of the quantities (γ − γc) and α′, and making use of equation (13), we obtain for (1 − T /Tc) ≪ 1 U0 = − 1 2 qJN [ 1 (q − 1) + q(q − 2) (q − 1)2 (γ − γc) + q(q − 2) (q − 1)2 α′2 + · · · ] = − 1 2 qJN [ 1 (q − 1) + q(q − 2)(3q − 2) (q − 1)2 J kTc (1 − T Tc ) + · · · ] . (32) Differentiating with respect to T and substituting for Tc, we obtain 1 Nk C0(Tc−) = 1 8 q2(q − 2)(3q − 2) (q − 1)2 { ln ( q q − 2 )}2 , (33) which is (3q − 2) times larger than the corresponding result for T = Tc+; compare with equation (31). The speciﬁc-heat discontinuity at the transition point is, therefore, 434 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling given by 1 Nk 1C0 = 3 8 q2(q − 2) (q − 1) {ln ( q q − 2 )}2 . (34) One may check that, for q ≫ 1, the foregoing results go over to the ones following from the zeroth approximation. Finally, we examine the relationship between L and B at T = Tc. Using equations (8) and (14), with both α and α′ ≪ 1 while γ = γc, we get L ≈ { 3q2µB/(q − 1)(q − 2)kTc}1/3 (T = Tc, B → 0); (35) compare with equation (12.5.24). For the behavior of χ0, see Problem 12.16. In passing, we note that, according to equation (12), the transition temperature for a lattice with q = 2 is zero, which essentially means that a one-dimensional Ising chain does not undergo a phase transition. This result is in complete agreement with the one follow- ing from an exact treatment of the one-dimensional lattice; see Section 13.2. In fact, for a lattice with q = 2, any results following from the Bethe approximation are completely identical with the corresponding exact results (see Problem 13.3); on the other hand, the Bragg–Williams approximation is least reliable when q = 2. That Tc for q = 2 is zero (rather than 2J/k) is in line with the fact that, for all q, the ﬁrst approximation yields a transition temperature closer to the correct value of Tc than does the zeroth approximation. The same is true of the amplitudes that determine the quan- titative behavior of the various physical quantities near T = Tc, though the exponents in the various power laws governing this behavior remain the same; compare, for instance, equation (16) with (12.5.14), equation (35) with (24) as well as the behavior of the spe- ciﬁc heat. In fact, one ﬁnds that successive approximations of the mean ﬁeld approach, while continuing to improve the theoretical value of Tc and the quantitative behavior of the various physical quantities (as given by the amplitudes), do not modify their quali- tative behavior (as determined by the exponents). For an account of the higher-order approximations, see Domb (1960). One important virtue of the Bethe approximation is that it brings out the role of the dimensionality of the lattice in bringing about a phase transition in the system. The fact that Tc = 0 for q = 2 and thereon it increases steadily with q leads one to infer that, while a linear Ising chain does not undergo phase transition at any ﬁnite T , higher dimensionality does promote the phenomenon. One may, in fact, argue that the absence of a phase tran- sition in a one-dimensional chain is essentially due to the fact that, the interactions being severely short-ranged, “communication” between any two parts of the chain can be com- pletely disrupted by a single defect in-between. The situation remains virtually unaltered even if the range of interactions is allowed to increase — so long as it remains ﬁnite. Only when interactions become truly long-ranged, with Jij ∼ |i − j|−(1+σ )(σ > 0), does a phase transition at a ﬁnite T become possible — but only if σ < 1; for σ > 1, we are back to the 12.7 The critical exponents 435 case of no phase transition, while the borderline case σ = 1 remains in doubt. For more details, see Grifﬁths (1972, pp. 89–94). Peierls (1936) was the ﬁrst to demonstrate that at sufﬁciently low temperatures the Ising model in two or three dimensions must exhibit a phase transition. He considered the lat- tice as made up of two kinds of domains, one consisting of “up” spins and the other of “down” spins, separated by a set of boundaries between the neighboring domains, and argued on energy considerations that in a two- or three-dimensional lattice the long-range order that exists at 0 K would persist at ﬁnite temperatures. Again, for details, see Grifﬁths (1972, pp. 59–66). 12.7 The critical exponents A basic problem in the theory of phase transitions is to study the behavior of a given system in the neighborhood of its critical point. We know that this behavior is marked by the fact that the various physical quantities pertaining to the system possess singularities at the critical point. It is customary to express these singularities in terms of power laws char- acterized by a set of critical exponents that determine the qualitative nature of the critical behavior of the given system. To begin with, we identify an order parameter m, and the cor- responding ordering ﬁeld h, such that, in the limit h → 0, m tends to a limiting value m0, with the property that m0 = 0 for T ≥ Tc and ̸= 0 for T < Tc. For a magnetic system, the nat- ural candidate for m is the parameter L(= σ ) of Sections 12.5 and 12.6, while h is identiﬁed with the quantity µB/kTc; for a gas–liquid system, one may adopt the density differential (ρl − ρc) or |ρg − ρc| for m and the pressure differential (P − Pc) for h. The various critical exponents are then deﬁned as follows. The manner in which m0 → 0, as T → Tc from below, deﬁnes the exponent β: m0 ∼ (Tc − T )β (h → 0, T ≲ Tc). (1) The manner in which the low-ﬁeld susceptibility χ0 diverges, as T → Tc from above (or from below), deﬁnes the exponent γ (or γ ′): χ0 ∼ ( ∂m ∂h ) T ,h→0 ∼ { (T − Tc) −γ (h → 0, T ≳ Tc) (2a) (Tc − T ) −γ ′ (h → 0, T ≲ Tc); (2b) in the gas–liquid transition, the role of χ0 is played by the isothermal compressibility, κT = ρ−1(∂ρ/∂P)T , of the system. Next, we deﬁne an exponent δ by the relation m|T =Tc ∼ h1/δ (T = Tc, h → 0); (3) in the case of a gas–liquid system, δ is a measure of the “degree of ﬂatness” of the critical isotherm at the critical point, for then |P − Pc| ∣ ∣ ∣ T =Tc ∼ |ρ − ρc|δ (T = Tc, P → Pc). (4) 436 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling Finally, we deﬁne exponents α and α′ on the basis of the speciﬁc heat, CV , of the gas–liquid system: CV ∼ { (T − Tc) −α (T ≳ Tc) (5a) (Tc − T ) −α′ (T ≲ Tc). (5b) In connection with the foregoing relations, especially equations (5), we wish to empha- size that in certain cases the exponent in question is rather small in value; it is then more appropriate to write f (t) ∼ |t|−λ − 1 λ (|t| ≪ 1). (6) Now, if λ > 0, the function f (t) would have a power-law divergence at t = 0; in case λ → 0, the function f (t) would have a logarithmic divergence instead: f (t) ∼ ln(1/|t|) (|t| ≪ 1). (7) In either case, the derivative f ′(t) ∼ |t|−(1+λ). A survey of the results derived in Sections 12.2 through 12.6 shows that for a gas–liquid system obeying van der Waals equation of state or for a magnetic system treated in the mean ﬁeld approximation (it does not matter what order of approximation one is talking about), the various critical exponents are the same: β = 1 2 , γ = γ ′ = 1, δ = 3, α = α′ = 0. (8) In Table 12.1 we have compiled experimental data on critical exponents pertaining to a variety of systems including the ones mentioned above; for completeness, we have included here data on another two exponents, ν and η, which will be deﬁned in Section 12.12. We ﬁnd that, while the observed values of an exponent, say β, differ very little as one goes from system to system within a given category (or even from category to category), these values are considerably different from the ones following from the mean ﬁeld approximation. Clearly, we need a theory of phase transitions that is basically different from the mean ﬁeld theory. To begin with, some questions arise: (i) Are these exponents completely independent of one another or are they mutually related? In the latter case, how many of them are truly independent? (ii) On what characteristics of the given system do they depend? This includes the question why, for systems differing so much from one another, they differ so little. (iii) How can they be evaluated from ﬁrst principles? The answer to question (i) is simple: yes, the various exponents do obey certain rela- tions and hence are not completely independent. These relations appear in the form of inequalities, dictated by the principles of thermodynamics, which will be explored 12.7 The critical exponents 437 Table 12.1 Experimental Data on Critical Exponents Critical Magnetic Gas–liquid Binary Fluid Binary Ferroelectric Superﬂuid Mean Field Exponents Systems(a) Systems(b) Mixtures(c) Alloys(d) Systems(e) He4(f) Results α, α′ 0.0–0.2 0.1–0.2 0.05–0.15 −−− −−− −0.026 0 β 0.30–0.36 0.32–0.35 0.30–0.34 0.305 ± 0.005 0.33–0.34 −−− 1/2 γ 1.2–1.4 1.2–1.3 1.2–1.4 1.24 ± 0.015 1.0 ± 0.2 inaccessible 1 γ ′ 1.0–1.2 1.1–1.2 −−− 1.23 ± 0.025 1.23 ± 0.02 inaccessible 1 δ 4.2–4.8 4.6–5.0 4.0–5.0 −−− −−− inaccessible 3 ν 0.62–0.68 −−− −−− 0.65 ± 0.02 0.5–0.8 0.675 1/2 η 0.03–0.15 −−− −−− 0.03–0.06 −−− −−− 0 (a)Stierstadt et al. (1990). (b)Voronel (1976); Rowlinson and Swinton (1982). (c)Rowlinson and Swinton (1982). (d)Als-Nielsen (1976); data pertain to beta-brass only. (e)Kadanoff et al. (1967); Lines and Glass (1977). (f)Ahlers (1980). in Section 12.8; in the modern theory of phase transitions, see Sections 12.10 through 12.12 and Chapter 14, the same relations turn up as equalities, and the number of these (restrictive) relations is such that, in most cases only two of the exponents are truly independent. As regards question (ii), it turns out that our exponents depend on a very small number of characteristics, or parameters, of the problem, which explains why they differ so little from one system to another in a given category of systems (and also from one category to another, even though systems in those categories are so different from one another). The characteristics that seem to matter are (a) the dimensionality, d, of the space in which the system is embedded, (b) the number of components, n, of the order parameter of the problem, and (c) the range of microscopic interactions in the system. Insofar as interactions are concerned, all that matters is whether they are short-ranged (which includes the special case of nearest-neighbor interactions) or long-ranged. In the former case, the values of the critical exponents resulting from nearest-neighbor interac- tions remain unaltered — regardless of whether further-neighbor interactions are included or not; in the latter case, assuming Jij ∼ |i − j|−(d+σ ) with σ > 0, the critical exponents depend on σ . Unless a statement is made to the contrary, the microscopic interactions operating in the given system will be assumed to be short-ranged; the critical exponents then depend only on d and n — both of which, for instructional purposes, may be treated as continuous variables. Insofar as d is concerned, we recall the Bethe approximation that highlighted the special role played by the dimensionality of the lattice through, and only through, the coor- dination number q. We also recall that, while the theoretical value of Tc and the various amplitudes of the problem were inﬂuenced by q, the critical exponents were not. In more accurate theories we ﬁnd that the critical exponents depend more directly on d and only 438 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling indirectly on q; however, for a given d, they do not depend on the structural details of the lattice (including the number q). Insofar as n is concerned, the major difference lies between the Ising model (n = 1) with discrete symmetry (σi = +1 or −1) and other models (n ≥ 2) with continuous symme- try (−1 ≤ σiα ≤ +1 for α = 1, . . . , n, with |σi| = 1). In the former case, Tc is zero for d ≤ 1 and nonzero for d > 1; in the latter, Tc is zero for d ≤ 2 and nonzero for d > 2. 13 In either case, the critical exponents depend on both d and n, except that for d > 4 they become indepen- dent of d and n, and assume values identical to the ones given by the mean ﬁeld theory; the physical reason behind this overwhelming generality is examined in Section 12.13. In passing, we note that, for given d and n, the critical exponents do not depend on whether the spins constituting the system are treated classically or quantum-mechanically. As regards question (iii), the obvious procedure for evaluating the critical exponents is to carry out exact (or almost exact) analysis of the various models — a task to which the whole of Chapter 13 is devoted. An alternative approach is provided by the renormal- ization group theory, which is discussed in Chapter 14. A modest attempt to evaluate the critical exponents is made in Section 12.9, which yields results that are inconsistent with the experiment but teaches us quite a few lessons about the shortcomings of the so-called classical approaches. 12.8 Thermodynamic inequalities The ﬁrst rigorous relation linking critical exponents was derived by Rushbrooke (1963) who, on thermodynamic grounds, showed that for any physical system undergoing a phase transition ( α′ + 2β + γ ′) ≥ 2. (1) The proof of inequality (1) is straightforward if one adopts a magnetic system as an exam- ple. We start with the thermodynamic formula for the difference between the speciﬁc heat at constant ﬁeld CH and the speciﬁc heat at constant magnetization CM (see Problem 3.40) CH − CM = −T ( ∂H ∂T ) M ( ∂M ∂T ) H = T χ −1 {( ∂M ∂T ) H }2 . (2) Since CM ≥ 0, it follows that CH ≥ T χ −1 {( ∂M ∂T ) H }2 . (3) Now, letting H → 0 and T → Tc from below, we get D1(Tc − T )−α′ ≥ D2Tc(Tc − T )γ ′+2(β−1), (4) 13The special case n = 2 with d = 2 is qualitatively different from others; for details, see Section 13.7. 12.8 Thermodynamic inequalities 439 where D1 and D2 are positive constants; here, use has been made of power laws (12.7.1, 2b, and 5b). 14 Inequality (4) may as well be written as (Tc − T ) 2−(α′+2β+γ ′) ≥ D2Tc/D1. (5) Since (Tc − T ) can be made as small as we like, (5) will not hold if (α′ + 2β + γ ′) < 2. The Rushbrooke inequality (1) is thus established. To establish further inequalities, one utilizes the convexity properties of the Helmholtz free energy A(T , M). Since dA = −SdT + HdM, ( ∂A ∂T ) M = −S, ( ∂ 2A ∂T 2 ) M = − ( ∂S ∂T ) M = − CM T ≤ 0 (6a, b) and ( ∂A ∂M ) T = H, ( ∂ 2A ∂M 2 ) T = ( ∂H ∂M ) T = 1 χ ≥ 0. (7a, b) It follows that A(T , M) is concave in T and convex in M. We now proceed to establish the Grifﬁths inequality (1965a, b) α′ + β(δ + 1) ≥ 2. (8) Consider a magnetic system in zero ﬁeld and at a temperature T1 < Tc. Then, by (7a), A(T , M) is a function of T only, so we can write A(T1, M) = A(T1, 0) (−M1 ≤ M ≤ M1), (9) where M1 is the spontaneous magnetization at temperature T1; see Figure 12.10. Applying (6a) to (9), we get S(T1, M) = S(T1, 0) (−M1 ≤ M ≤ M1). (10) We now deﬁne two new functions A ∗(T , M) = {A(T , M) − Ac} + (T − Tc)Sc (11) and S∗(T , M) = S(T , M) − Sc, (12) 14Recalling the correspondence between a gas–liquid system and a magnet, one might wonder why we have employed CH , rather than CM , in place of CV . The reason is that, since we are letting H → 0 and T → Tc−, M → 0 as well. So, as argued by Fisher (1967), in the limit considered here, CH and CM display the same singular behavior. In fact, it can be shown that if the ratio CM /CH → 1 as T → Tc, then (α′ + 2β + γ ′) must be greater than 2; on the other hand, if this ratio tends to a value less than 1, then (α′ + 2β + γ ′) = 2. For details, see Stanley (1971), Section 4.1. 440 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling M 0 T (T1, M1) (T1, 2M1) (H , 0) (H . 0) (H 02) (H 01) FIGURE 12.10 Magnetization, M(T , H), of a magnetic system for H > 0, H < 0, and H → 0. Here, M1 denotes the spontaneous magnetization of the system at a temperature T1 < Tc. where Ac = A(Tc, 0) and Sc = S(Tc, 0). It follows that ( ∂A∗ ∂T ) M = −S∗, ( ∂ 2A∗ ∂T 2 ) M = − ( ∂S∗ ∂T ) M = − CM T ≤ 0. (13a, b) Thus, A∗ is also concave in T . Geometrically, this means that, for any choice of T1, the curve A∗(T ), with M ﬁxed at M1, lies below the tangent line at T = T1, that is, A ∗(T , M1) ≤ A ∗(T1, M1) + ( ∂A∗ ∂T ) M1,T =T1 (T − T1); (14) see Figure 12.11. Letting T = Tc in (14), we get A ∗(Tc, M1) ≤ A ∗(T1, M1) − S∗(T1, M1)(Tc − T1) (15) which, in view of equations (9) through (12), may be written as A ∗(Tc, M1) ≤ A ∗(T1, 0) − S∗(T1, 0)(Tc − T1). (16) Utilizing, once again, the concavity of the function A∗(T ) but this time at T = Tc (with M ﬁxed at zero and the slope (∂A∗/∂T ) vanishing), we get, see (14), A ∗(T , 0) ≤ A ∗(Tc, 0). (17) Now, letting T = T1 in (17) and noting that A∗(Tc, 0) = 0 by deﬁnition, we get A ∗(T1, 0) ≤ 0. (18) 12.8 Thermodynamic inequalities 441 TcT1 T M \u0002 M1 FIGURE 12.11 The function A∗(T , M) of a magnetic system, with magnetization M ﬁxed at M1. The slope of this curve is S(Tc, 0) − S(T , M1), which is positive for all T ≤ Tc. Combining (16) and (18), we ﬁnally get A ∗(Tc, M1) ≤ −(Tc − T1)S∗(T1, 0), (19) valid for all T1 < Tc. The next step is straightforward. We let T1 → Tc−, so that M1 → 0 and along with it A ∗(Tc, M1) =    M1∫ 0 HdM    T =Tc ≈ DM δ+1 1 ≈ D′(Tc − T1) β(δ+1), (20) while S∗(T1, 0) = T1∫ Tc C(T , 0) T dT ≈ − D′′ Tc (Tc − T1) 1−α′ , (21) where D, D′, and D′′ are positive constants; here, use has been made of power laws (12.7.1, 3, and 5b). Substituting (20) and (21) into (19), we get (Tc − T1)2−α′−β(δ+1) ≥ D′Tc/D′′. (22) Again, since (Tc − T1) can be made as small as we like, (22) will not hold if α′ + β(δ + 1) < 2. The Grifﬁths inequality (8) is thus established. It will be noted that unlike the Rushbrooke inequality, which related critical exponents pertaining only to T < Tc, the present inequal- ity relates two such exponents, α′ and β, with one, namely δ, that pertains to the critical isotherm (T = Tc). While inequalities (1) and (8) are thermodynamically exact, Grifﬁths has derived several others that require certain plausible assumptions on the system in question. We quote two 442 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling of them here, without proof: γ ′ ≥ β(δ − 1) (23) γ ≥ (2 − α)(δ − 1)/(δ + 1). (24) For a complete list of such inequalities, see Grifﬁths (1972), p. 102, where references to original papers are also given. Before proceeding further, the reader may like to verify that the experimental data on critical exponents, as given earlier in Table 12.1, do indeed conform to the inequalities proved or quoted in this section. It is important in this connection to note that the mean ﬁeld exponents (α = α′ = 0, β = 1/2, γ = γ ′ = 1, and δ = 3) satisfy all these relations as equalities. 12.9 Landau’s phenomenological theory As early as 1937 Landau attempted a uniﬁed description of all second-order phase transi- tions — second-order in the sense that the second derivatives of the free energy, namely the speciﬁc heat and the magnetic susceptibility (or isothermal compressibility, in the case of ﬂuids), show a divergence while the ﬁrst derivatives, namely the entropy and the magnetization (or density, in the case of ﬂuids), are continuous at the critical point. He emphasized the importance of an order parameter m0 (which would be zero on the high-temperature side of the transition and nonzero on the low-temperature side) and suggested that the basic features of the critical behavior of a given system may be deter- mined by expanding its free energy in powers of m0 (for we know that, in the close vicinity of the critical point, m0 ≪ 1). He also argued that in the absence of the ordering ﬁeld (h = 0) the up–down symmetry of the system would require that the proposed expansion contain only even powers of m0. Thus, the zero-ﬁeld free energy ψ0(= A0/NkT ) of the system may be written as ψ0(t, m0) = q(t) + r(t)m 2 0 + s(t)m 4 0 + · · · (t = T − Tc Tc , |t| ≪ 1 ) ; (1) at the same time, the coefﬁcients q(t), r(t), s(t) . . . may be written as q(t) = ∑ k≥0 qktk, r(t) = ∑ k≥0 rktk, s(t) = ∑ k≥0 sktk, . . . . (2) The equilibrium value of the order parameter is then determined by minimizing ψ0 with respect to m0; retaining terms only up to the order displayed in (1), which for thermodynamic stability requires that s(t) > 0, we obtain r(t)m0 + 2s(t)m3 0 = 0. (3) 12.9 Landau’s phenomenological theory 443 The equilibrium value of m0 is thus either 0 or ± √[−r(t)/2s(t)]. The ﬁrst solution is of lesser interest, though this is the only one we will have for t > 0; it is the other solutions that lead to the possibility of spontaneous magnetization in the system. To obtain physically sensible results, see equations (9) through (11), we must have in equation (2): r0 = 0, r1 > 0, and s0 > 0, with the result |m0| ≈ [(r1/2s0)|t|]1/2 (t ≲ 0), (4) giving β = 1/2. The asymptotic expression for the free energy, namely ψ0(t, m0) ≈ q0 + r1tm2 0 + s0m 4 0 (r1, s0 > 0), (5) is plotted in Figure 12.12. We see that, for t ≥ 0, there is only one minimum, which is located at m0 = 0; for t = 0, the minimum is rather ﬂat. For t < 0, on the other hand, we have two minima, located at m0 = ±ms, as given by expression (4), with a maximum at m0 = 0. Now, since ψ0 has to be convex in m0, so that the susceptibility of the system be nonnegative, see equation (12.8.7b), we must replace the nonconvex portion of the curve, which lies between the points m0 = −ms and m0 = +ms, by a straight line (along which the suscep- tibility would be inﬁnite). This replacement is reminiscent of the Maxwell construction employed in Sections 12.1 and 12.2. We now subject the system to an ordering ﬁeld h, assumed positive. If the ﬁeld is weak, the only change in the expression for the free energy would be the addition of a term −hm. Disregarding the appearance of any higher powers of (hm) as well as any modiﬁcations of \u00020(t, m0) m0 1m s2ms t . 0 t , 0 t 5 0 FIGURE 12.12 The free energy ψ0(t, m0) of the Landau theory, shown as a function of m0, for three different values of t. The dashed curve depicts spontaneous magnetization ms(t), while the horizontal line for t < 0 provides the Maxwell construction. 444 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling the coefﬁcients already present, we may now write ψh(t, m) = −hm + q(t) + r(t)m2 + s(t)m4. (6) The equilibrium value of m is now given by15 −h + 2r(t)m + 4s(t)m 3 = 0. (7) The low-ﬁeld susceptibility of the system, in units of Nµ2/kT , thus turns out to be χ = ( ∂h ∂m )−1 t = 1 2r(t) + 12s(t)m2 , (8) valid in the limit h → 0. Now, for t > 0, m → 0 and we get χ ≈ 1/2r1t (t ≳ 0), (9) giving γ = 1. On the other hand, for t < 0, m → √ [(r1/2s0)|t|], see (4); we then get χ ≈ 1/4r1|t| (t ≲ 0), (10) giving γ ′ = 1. Finally, if we set t = 0 in (7), we obtain the following relation between h and m: h ≈ 4s0m 3 (h → 0), (11) giving δ = 3. We shall now look at the speciﬁc heats Ch and Cm. If t > 0, then h → 0 implies m → 0, so in this limit there is no difference between Ch and Cm. Equation (1) then gives, in units of Nk, Ch = Cm = − ( ∂ 2ψ0 ∂t2 ) m→0 = −(2q2 + 6q3t + · · · ) (t ≳ 0). (12) For t < 0, we have Cm = − [ (2q2 + 6q3t + · · · ) + (2r2 + · · · )m 2 s + · · · ] = − [ 2q2 + {6q3 − (r1r2/s0)}t + . . .] (t ≲ 0). (13) Next, using equation (12.8.2) along with (4) and (10), we have Ch − Cm = ( ∂h ∂m ) t {( ∂m ∂t ) h }2 ≈ r2 1 2s0 (t ≲ 0). (14) 15It may be mentioned here that the passage from equation (1) to (6) is equivalent to effecting a Legendre transfor- mation from the Helmholtz free energy A to the Gibbs free energy G (= A − HM), and equation (7) is analogous to the relation (∂A/∂M)T = H. 12.9 Landau’s phenomenological theory 445 It follows that, while Cm possesses a cusp-like singularity at t = 0, Ch undergoes a jump discontinuity of magnitude (Ch)t→0− − (Ch)t→0+ ≈ r2 1 /2s0. (15) It follows that α = α′ = 0. The most striking feature of the Landau theory is that it gives exactly the same critical exponents as the mean ﬁeld theory of Sections 12.5 and 12.6 (or the van der Waals theory of Section 12.2). Actually it goes much further, for it starts with an expression for the free energy of the system containing parameters qk, rk, sk, . . ., which represent the structure of the given system and the interactions operating in it, and goes on to show that, while the amplitudes of the various physical quantities near the critical point do depend on these parameters, the critical exponents do not! This universality (of critical exponents) suggests that we are dealing here with a class of systems which, despite their structural differences, display a critical behavior that is qualitatively the same for all members of the class. This leads to the concept of a universality class which, if Landau were right, would be a rather large one. The fact of the matter is that the concept of universality is very much overstated in Landau’s theory; in reality, there are many different universality classes — each deﬁned by the parameters d and n of Section 12.7 and by the range of the microscopic interac- tions — such that the critical exponents within a class are the same while they vary from one class to another. The way Landau’s theory is set up, the parameter n is essentially equal to 1 (because the order parameter m0 is treated as a scalar), the parameter d plays no role at all (though later on we shall see that the mean ﬁeld exponents are, in fact, valid for all n if d > 4), while the microscopic interactions are implicitly long-ranged.16 An objection commonly raised against the Landau theory is that, knowing fully well that the thermodynamic functions of the given system are going to be singular at t = 0, a Taylor-type expansion of the free energy around m = 0 is patently a wrong start. While the objection is valid, it is worth noting how a regular function, (1) or (6), leads to an equation of state, (3) or (7), which yields different results for t → 0− from the ones for t → 0+, the same being true of whether h → 0+ or 0−. The trick lies in the fact that we are not using equation (1) or (6) as such for all t; for t < 0, we use instead a modiﬁed form, as “corrected” by the Maxwell construction (see Figure 12.12). The spirit of the singularity is thereby cap- tured, though the nature of the singularity, being closely tied with the nature of the original expansion, could not be any different from the mean-ﬁeld type. The question now arises: how can the Landau theory be improved so that it may provide a more satisfactory picture of the critical phenomena? Pending exact analyses, one wonders if some generalization of the Landau approach, admitting more than one universality class, would provide a bet- ter picture than the one presented so far. It turns out that the scaling approach, initiated by Widom (1965), by Domb and Hunter (1965), and by Patashinskii and Pokrovskii (1966), provided the next step in the right direction. 16In certain systems such as superconductors, the effective interactions (which, for instance, lead to the formation of Cooper pairs of electrons) are, in fact, long-ranged. The critical exponents pertaining to such systems turn out to be the same as one gets from the mean ﬁeld theory. For details, see Tilley and Tilley (1990). 446 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling 12.10 Scaling hypothesis for thermodynamic functions The scaling approach, which took the subject of phase transitions far beyond the mean ﬁeld theory, emerged independently from three different sources — from Widom (1965), who searched for a generalization of the van der Waals equation of state that could accommodate nonclassical exponents; from Domb and Hunter (1965), who analyzed the behavior of the series expansions of higher derivatives of the free energy with respect to the magnetic ﬁeld at the critical point of a magnetic system; and from Patashinskii and Pokrovskii (1966), who studied the behavior of multipoint correlation functions for the spins constituting a system. All three were led to the same form of a thermodynamic equa- tion of state. Subsequently, Kadanoff (1966a) suggested a scaling hypothesis from which not only could this equation of state be derived but one could also obtain a number of rela- tions among the critical exponents, which turned out to be equalities consistent with the ﬁndings of Section 12.8. This approach also made it clear why one needed only two inde- pendent numbers to describe the nature of the singularity in question; all other relevant numbers followed as consequences. To set the stage for this development, we go back to the equation of state following from the Landau theory, namely (12.9.7), and write it in the asymptotic form h(t, m) ≈ 2r1tm + 4s0m 3. (1) In view of the relationship (12.9.4), we rewrite (1) in the form h(t, m) ≈ r3/2 1 s1/2 0 |t| 3/2  2 sgn(t) ( s1/2 0 r1/2 1 m |t|1/2 ) + 4 ( s1/2 0 r1/2 1 m |t|1/2 )3 . (2) It follows that m(t, h) ≈ r1/2 1 s1/2 0 |t| 1/2 × a function of ( s1/2 0 r3/2 1 h |t|3/2 ) (3) and, within the context of the Landau theory, the function appearing here is universal for all systems conforming to this theory. In the same spirit, the relevant part of the free energy ψh(t, m) — the part that determines the nature of the singularity — may be written in the form ψ (s) h (t, m) ≈ −hm + r1tm2 + s0m 4 (4) = r2 1 s0 t2  − ( s1/2 0 r3/2 1 h |t|3/2 ) ( s1/2 0 r1/2 1 m |t|1/2 ) + sgn (t) ( s1/2 0 r1/2 1 m |t|1/2 )2 + ( s1/2 0 r1/2 1 m |t|1/2 )4 . (5) 12.10 Scaling hypothesis for thermodynamic functions 447 Substituting (3) into (5), one gets ψ (s)(t, h) ≈ r2 1 s0 t2 × a function of ( s1/2 0 r3/2 1 h |t|3/2 ) , (6) where, again, the function appearing here is universal. As a check, we see that differentiat- ing (6) with respect to h we readily obtain (3). The most notable feature of the equation of state, as expressed in (3), is that, instead of being the usual relationship among three variables m, h, and t, it is now a relationship among only two variables, namely m/|t|1/2 and h/|t|3/2. Thus, by scaling m with |t|1/2 and h with |t|3/2, we have effectively reduced the total number of variables by one. Similarly, we have replaced equation (4) by (6), which expresses the singular part of the free energy ψ scaled with t2 as a function of the single variable h scaled with |t|3/2. This reduction in the total number of effective variables may be regarded as the ﬁrst important achievement of the scaling approach. The next step consists of generalizing (6), to write ψ (s)(t, h) ≈ F|t| 2−αf (Gh/|t| 1), (7) where α and 1 are universal numbers common to all systems in the given universality class, f (x) is a universal function which is expected to have two different branches, f+ for t > 0 and f− for t < 0, while F and G (like r1 and s0) are nonuniversal parameters char- acteristic of the particular system under consideration. We expect α and 1 to determine all the critical exponents of the problem, while the amplitudes appearing in the various power laws will be determined by F, G, and the limiting values of the function f (x) and its derivatives (as x tends to zero). Equation (7) constitutes the so-called scaling hypothesis, whose status will become much more respectable when it acquires legitimacy from the renormalization group theory; see Sections 14.1 and 14.3. First of all it should be noted that the exponent of |t|, outside the function f (x) in equation (7), has been chosen to be (2 − α), rather than 2 of the corresponding mean ﬁeld expression (6), so as to ensure that the speciﬁc heat singularity is correctly repro- duced. Secondly, the fact that one must not encounter any singularities as one crosses the critical isotherm (t = 0) at nonzero values of h or m requires that the exponents on the high-temperature side of the critical point be the same as on the low-temperature side, that is, α′ = α and γ ′ = γ . (8) From equation (7) it readily follows that m(t, h) = − ( ∂ψ (s) ∂h ) t ≈ −FG|t| 2−α−1f ′(Gh/|t|1) (9) 448 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling and χ(t, h) = − ( ∂ 2ψ (s) ∂h2 ) t ≈ −FG2|t| 2−α−21f ′′(Gh/|t| 1). (10) Letting h → 0, we obtain for the spontaneous magnetization m(t, 0) ≈ B|t| β (t ≲ 0), (11) where B = −FGf ′ −(0), β = 2 − α − 1, (12a, b) and for the low-ﬁeld susceptibility χ(t, 0) ≈ |t| −γ { C+ (t ≳ 0) (13a) C− (t ≲ 0), (13b) where C± = −FG2f ′′ ±(0), γ = α + 21 − 2. (14a, b) Combining (12b) and (14b), we get 1 = β + γ = 2 − α − β, (15) so that α + 2β + γ = 2. (16) To recover δ, we write the function f ′(x) of equation (9) as xβ/1g(x), so that m(t, h) ≈ −FG(1+β/1)hβ/1g(Gh/|t| 1). (17) Inverting (17), we can write |t| ≈ G1/1h1/1 × a function of (FG(1+β/1)h β/1/m). (18) It follows that, along the critical isotherm (t = 0), the argument of the function appearing in (18) would have a universal value (which makes the function vanish), with the result that m ∼ FG(1+β/1)h β/1 (t = 0). (19) Comparing (19) with (12.7.3), we infer that δ = 1/β. (20) 12.11 The role of correlations and ﬂuctuations 449 Combining (20) with the previous relations, namely (12b) and (15), we get α + β(δ + 1) = 2 (21) and γ = β(δ − 1). (22) Finally, combining (21) and (22), we have γ = (2 − α)(δ − 1)/(δ + 1). (23) For completeness, we write down for the speciﬁc heat Ch at h = 0 C(s) h (t, 0) = − ∂ 2ψ (s) ∂t2 ∣ ∣ ∣ ∣ ∣ h→0 ≈ −(2 − α)(1 − α)F|t| −α { f+(0) (t ≳ 0) (24a) f−(0) (t ≲ 0). (24b) We thus see that the scaling hypothesis (7) leads to a number of relations among the critical exponents of the system, emphasizing the fact that only two of them are truly independent. Comparing these relations with the corresponding ones appearing in Section 12.8 — namely, (16), (21), (22), and (23) with (12.8.1), (12.8.8), (12.8.23), and (12.8.24) — we feel satisﬁed that they are mutually consistent, though the present ones are far more restrictive than the ones there. Besides exponent relations, we also obtain here relations among the various amplitudes of the problem; though individually these amplitudes are nonuniversal, certain combinations thereof turn out to be universal. For instance, the combination (FC±/B2), which consists of coefﬁcients appearing in equa- tions (7), (11), and (13), is universal; see equations (12a) and (14a). The same is true of the ratio C+/C−. For further information on this question, see the original papers by Watson (1969) and a review by Privman, Hohenberg, and Aharony (1991). We now pose the question: why do “universality classes” exist in the ﬁrst place? In other words, what is the reason that a large variety of systems differing widely in their structures should belong to a single universality class and hence have common critical exponents and common scaling functions? The answer lies in the role played by the corre- lations among the microscopic constituents of the system which, as T → Tc, become large enough to prevail over macroscopic distances in the system and in turn make structural details at the local level irrelevant. We now turn our attention to this important aspect of the problem. 12.11 The role of correlations and ﬂuctuations Much can be learned about criticality by scattering radiation — light, x-rays, neutrons, and so on — off the system of interest; see Section 10.7.A. In a standard scattering experiment, a well-collimated beam of light, or other radiation, with known wavelength λ is directed at the sample and one measures the intensity, I(θ), of the light scattered at an angle θ from 450 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling the “forward” direction of the beam. The radiation undergoes a shift in the wavevector, k, which is related to the parameters θ and λ by |k| = 4π λ sin 1 2 θ . (1) Now, the scattered intensity I(θ) is determined by the ﬂuctuations in the medium. If the medium were perfectly uniform (i.e., spatially homogenous), there would be no scattering at all! If one has in mind light scattering from a ﬂuid, then the relevant ﬂuctuations corre- spond to regions of different refractive index and, hence, of different particle density n(r). For neutron scattering from a magnet, ﬂuctuations in the spin or magnetization density are the relevant quantities, and so on. We need to study here the normalized scattering intensity I(θ; T , H)/I idea1(θ), where I(θ ; T , H) is the actual scattering intensity observed at angle θ , which will normally depend on such factors as temperature, magnetic ﬁeld, and so on, while I idea1(θ) is the scattering that would take place if the individual parti- cles (or spins) that cause the scattering could somehow be taken far apart so that they no longer interact and hence are quite uncorrelated with one another. Now, this normalized scattering intensity turns out to be essentially proportional to the quantity ˜g(k) = ∫ g(r)eik·rdr, (2) which represents the Fourier transform of the appropriate real-space correlation function g(r), which will be deﬁned shortly. As the critical point of the system (say, a ﬂuid) is approached, one observes an enor- mously enhanced level of scattering, especially at low angles which corresponds, via equations (1) and (2), to long wavelength density ﬂuctuations in the ﬂuid. In the criti- cal region, the scattering is so large that it can be visible to the unaided eye, particularly through the phenomenon of critical opalescence. This behavior is, by no means, limited to ﬂuids. Thus if, for example, one scatters neutrons from iron in the vicinity of the Curie point, one likewise sees a dramatic growth in the low-angle neutron scattering intensity, as sketched in Figure 12.13. One sees that for small-angle scattering there is a pronounced peak in I(θ ; T ) as a function of temperature, and this peak approaches closer and closer to Tc as the angle is decreased. Of course, one could never actually observe zero-angle scat- tering directly, since that would mean picking up the oncoming beam itself, but one can extrapolate to zero angle. When this is done, one ﬁnds that the zero-angle scattering I(0; T ) actually diverges at Tc. This is the most dramatic manifestation of the phenomenon of criti- cal opalescence and is quite general, in that it is observed whenever appropriate scattering experiments can be performed. Empirically, one may write for small-angle scattering Imax(θ) ∼ k−λ1 , {Tmax(θ) − Tc} ∼ kλ2 , (3) so that Imax(θ){Tmax(θ) − Tc}λ1/λ2 = const. (4) 12.11 The role of correlations and ﬂuctuations 451 T0 Tc I(\u0002;T ) Small \u0002 0\u0002 FIGURE 12.13 Schematic plot of the elastic scattering intensity of neutrons scattered at an angle θ from a magnetic system, such as iron, in the vicinity of the critical point Tc. The small arrows mark the smoothly rounded maxima (at ﬁxed θ ) which occur at a temperature Tmax(θ) that approaches Tc as θ → 0. Here, λ1 and λ2 are positive exponents (which, as will be seen later, are determined by the universality class to which the system belongs), while k, for a given θ , is determined by equation (1); note that, for small θ , k is essentially proportional to θ . The ﬁrst real insight into the problem of critical scattering in ﬂuids was provided by Ornstein and Zernike (1914) and Zernike (1916) who emphasized the difference between the direct inﬂuence of the microscopic interactions among the atoms of the ﬂuid, which are necessarily short-ranged, and the indirect (but more crucial) inﬂuence of the density– density correlations that become long-ranged as the critical temperature is approached; it is the latter that are truly responsible for the propagation of long-range order in the sys- tem and for practically everything else that goes with it. Unfortunately, the original work of Ornstein and Zernike makes difﬁcult reading; moreover, it is based on the classical theory of van der Waals. Nevertheless, the subject has been neatly clariﬁed in the review arti- cles by Fisher (1964, 1983) and Domb (1985), to which the reader may turn for further details. Here, we shall stick to the language of the magnetic systems and work out the most essential parts of the theory in somewhat general terms. We deﬁne the spin–spin correlation function g(i, j), for the pair of spins at sites i and j, by the standard deﬁnition g(i, j) = σiσj − σ iσ j. (5) For i = j, expression (5) denotes the “mean-square ﬂuctuation in the value of the variable σ at site i”; on the other hand, as the separation between the sites i and j increases indeﬁ- nitely, the spins σi and σj get uncorrelated, so that σiσj → σ iσ j and the function g(i, j) → 0. 452 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling In view of the fact that expression (5) can also be written as g(i, j) = (σi − σ i)(σj − σ j), (6) the function g(i, j) may also be looked upon as a measure of the “correlation among the ﬂuctuations in the order parameter of the system at sites i and j.” This makes sense because σi may, quite appropriately, be regarded as the locally ﬂuctuating order parameter linked to site i, just as σ is the order parameter for the whole system. We shall now establish connections between the function g(i, j) and some important thermodynamic properties of the system. We start with the partition function of the system, see equation (12.3.9), QN (H, T ) = ∑ {σi} exp [ βJ ∑ n.n. σiσj + βµH ∑ i σi ] , (7) where the various symbols have their usual meanings. It follows that ∂ ∂H (ln QN ) = βµ ( ∑ i σi ) = βM, (8) where M(= µ ∑i σi) denotes the net magnetization of the system. Next, since ∂ 2 ∂H 2 (ln QN ) = ∂ ∂H ( 1 QN ∂QN ∂H ) = 1 QN ∂ 2QN ∂H 2 − 1 Q2 N ( ∂QN ∂H )2 = β2(M 2 − M 2), (9) we obtain for the magnetic susceptibility of the system χ ≡ ∂M ∂H = β(M 2 − M 2) (10a) = βµ2    (∑ i σi )2 − (∑ i σi )2   = βµ2 ∑ i ∑ j g(i, j). (10b) Equation (10a) is generally referred to as the ﬂuctuation–susceptibility relation; it may be compared with the corresponding relation for ﬂuids, namely (4.5.7), which connects isothermal compressibility κT with the density ﬂuctuations in the system. Equations (10) and (4.5.7) represent the equilibrium limit of the ﬂuctuation–dissipation theorem dis- cussed later in Section 15.6. Equation (10b), on the other hand, relates χ to a summation of the correlation function g(i, j) over all i and j; assuming homogeneity, this may be written as χ = Nβµ 2 ∑ r g(r) (r = rj − ri). (11) 12.11 The role of correlations and ﬂuctuations 453 Treating r as a continuous variable, equation (11) may be written as χ = Nβµ2 ad ∫ g(r)dr, (12) where a is a microscopic length, such as the lattice constant, so deﬁned that Nad = V , the volume of the system; for a similar result appropriate to ﬂuids, see equation (10.7.14). Finally, introducing the Fourier transform of the function g(r), through equation (2), we observe that χ = Nβµ2 ad ˜g(0); (13) compare this result to equation (10.7.21) for ﬂuids. Our next task consists in determining the mathematical form of the functions g(r) and ˜g(k). Pending exact calculations, let us see what the mean ﬁeld theory has to offer in this regard. Following Kadanoff (1976b), we consider a magnetic system subject to an exter- nal ﬁeld H which is nonuniform, that is, H = {Hi}, where Hi denotes the ﬁeld at site i. Using mean ﬁeld approximation, the thermal average of the variable σi is given by, see equation (12.5.10), σ i = tanh(βµHeff), (14) where Heff = Hi + ( J/µ) ∑ n.n. σ j; (15) note that, in view of the nonuniformity of H, the product (qσ ) of equation (12.5.10) has been replaced by a sum of σ j over all the nearest neighbors of spin i. If σ varies slowly in space, which means that the applied ﬁeld is not too nonuniform, then (15) may be approximated as Heff ≃ Hi + (qJ/µ)σ i + (cJa2/µ)∇2σ i, (16) where c is a number of order unity whose actual value depends on the structure of the lattice, while a is an effective lattice constant; note that the term involving ∇σ i cancels on summation over the q nearest neighbors that are supposed to be positioned in some symmetrical fashion around the site i. At the same time, the function tanh x, for small x, may be approximated by x − x3/3. Retaining only essential terms, we get from (14) and (16) βµHi = (1 − qβJ)σ i + 1 3 (qβJ) 3σ 3 i − cβJa2∇2σ i. (17) 454 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling Now, the conditions for criticality are {Hi} = 0 and qβcJ = 1; see equation (12.5.13). So, near criticality, we may introduce our familiar variables hi = βµHi, t = (T − Tc)/Tc ≃ (βc − β)/βc; (18) equation (17) then reduces to ( t + 1 3 σ 2 i − c′a2∇2) σ i = hi, (19) where c′ is another number of order unity. Equation (19) generalizes equation (12.10.1) of Landau’s theory by taking into account the nonuniformity of σ . Differentiating (19) with respect to hj, we get (t + σ 2 i − c′a2∇2) ∂σ i ∂hj = δi,j. (20) The “response function” ∂σ i/∂hj is identical with the correlation function g(i, j); 17 equa- tion (20) may, therefore, be written as ( t + σ 2 i − c′a2∇2) g(i, j) = δi,j. (21) For t > 0 and {hi} → 0, σ i → 0; equation (21) then becomes (t − c′a2∇2) g(i, j) = δi,j. (22) Assuming homogeneity, so that g(i, j) = g(r) where r = rj − ri, and introducing Fourier transforms, equation (22) gives the form ( t + c′a2k2) ˜g(k) = const. (23) It follows that ˜g(k) is a function of the magnitude k only (which is not surprising in view of the assumed symmetry of the lattice). Thus ˜g(k) ∼ 1 t + c′a2k2 , (24) 17Remembering that M = µ6iσ i, we change the ﬁeld {Hi} to {Hi + δHi}, with the result that δM = µ ∑ ˙i   ∑ j (∂σ i/∂Hj)δHj  . Now, for simplicity, we let all δHj be the same; then (δM/δH) = µ ∑ i ∑ j (∂σ i/∂Hj). Comparing this with (10b), we infer that (∂σ i/∂Hj) = βµg(i, j) and hence (∂σ i/∂hj) = g(i, j). 12.11 The role of correlations and ﬂuctuations 455 which is the famous Ornstein–Zernike result derived originally for ﬂuids. Now, taking the inverse Fourier transform of ˜g(k), we obtain (disregarding numerical factors that are not so essential for the present argument) g(r) ∼ ∫ e−ik·r t + c′a2k2 dd(ka) (25a) ∼ ∞∫ 0 ad t + c′a2k2 ( 1 kr )(d−2)/2 J(d−2)/2(kr)kd−1dk; (25b) see equations (8) and (11) of Appendix C. The integral in (25b) is tabulated; see Gradshteyn and Ryzhik (1965, p. 686). We get g(r) ∼ ( a2 ξ r )(d−2)/2 K(d−2)/2 ( r ξ ) {ξ = a(c′/t) 1/2}, (26) Kµ(x) being a modiﬁed Bessel function. For x ≫ 1, Kµ(x) ∼ x−1/2e−x; equation (26) then gives g(r) ∼ ad−2 ξ (d−3)/2r(d−1)/2 e−r/ξ (r ≫ ξ ). (27) On the other hand, for x ≪ 1, Kµ(x), for µ > 0, ∼ x−µ ; equation (26) then gives g(r) ∼ ad−2 rd−2 (r ≪ ξ ; d > 2 ). (28) In the special case d = 2, we obtain instead g(r) ∼ ln(ξ/r) (r ≪ ξ ; d = 2). (29) It is worth noting that equation (26) simpliﬁes considerably when d = 3. Since K1/2(x) is exactly equal to (π/2x)1/2e−x for all x, g(r)|d=3 ∼ a r e−r/ξ (30) for all r. Equation (30) is another important result of Ornstein and Zernike. Clearly, the quantity ξ appearing here is a measure of the “distances over which the spin–spin (or density–density) correlations in the system extend” — hence the name correlation length. So long as T is signiﬁcantly above Tc, ξ = O(a); see (26). However, as T approaches Tc, ξ increases indeﬁnitely — ultimately diverging at T = Tc. The resulting singularity is also of the power-law type: ξ ∼ at−1/2 (t ≳ 0). (31) 456 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling The divergence of ξ at T = Tc is perhaps the most important clue we have for our general understanding of the critical phenomena. As ξ → ∞, correlations extend over the entire system, paving the way for the propagation of long-range order (even though the microscopic interactions, which are at the root of the phenomenon, are themselves short- ranged). Moreover, since correlations extend over macroscopic distances in the system, any structural details that differentiate one system from another at the microscopic level lose signiﬁcance, leading thereby to universal behavior! Going back to equations (13) and (24), we see that the singularity in χ is indeed of the type expected in a mean ﬁeld theory, namely χ ∼ ˜g(0) ∼ t−1 (t ≳ 0). (32) In view of the foregoing results, one may write 1 ˜g(k) ∼ 1 χ (1 + ξ 2k2). (33) In a so-called Ornstein–Zernike analysis, one plots 1/ ˜g(k) (or 1/I(k), where I(k) is the intensity of the light scattered at angle θ , see equation (1)) in the critical region versus k2. The data for small k (ka ≲ 0.1), for which the above treatment holds, fall close to a straight line whose intercept with the vertical axis determines χ(t). As t → 0, this intercept tends to zero but the successive isotherms remain more or less parallel to one another; the reduced slope evidently serves to determine ξ(t). For t ≃ 0, these plots show a slight downward cur- vature, indicating departure from the k2-law to one in which the power of k is somewhat less than 2. Finally, as regards the plot I(θ ; T ) of Figure 12.13 earlier in this section, the max- imum in the curve, according to equation (24), should lie at t = 0 for all θ and the height of the maximum should be ∼ k−2 (i.e., essentially ∼ θ −2); thus, according to the mean ﬁeld expression for ˜g(k), the exponent λ1 in equation (3) should be 2 while λ2 should be 0. 12.12 The critical exponents ν and η According to the mean ﬁeld theory, the divergence of ξ at T = Tc is governed by the power law (12.11.31), with a critical exponent 1 2 . We anticipate that the experimental data on actual systems may not conform to this law. We, therefore, introduce a new critical exponent, ν, such that ξ ∼ t−ν (h → 0, t ≳ 0). (1) In the spirit of the scaling hypothesis, see Section 12.10, the corresponding exponent ν′ appropriate to t ≲ 0 would be the same as ν. 18 Table 12.1 in Section 12.7 shows 18It turns out that the exponent ν′ is relevant only for scalar models, for which n = 1; for vector models (n ≥ 2), ξ is inﬁnite at all T ≤ Tc and hence ν′ is irrelevant. 12.12 The critical exponents ν and η 457 experimental results for ν obtained from a variety of systems; we see that the observed values of ν, while varying very little from system to system, differ considerably from the mean ﬁeld value. As regards the correlation function, the situation for t ≳ 0 is described very well by a law of the type (12.11.27), namely g(r) ∼ e−r/ξ(t) × some power of r (t ≳ 0), (2) where ξ(t) is given by (1). The variation of g(r) with r in this regime is governed primarily by the exponential, so g(r) falls rapidly as r exceeds ξ (which is typically of the order of the lattice constant a). As t → 0 and hence ξ → ∞, the behavior of g(r) would be expected to be like equation (12.11.28) or (12.11.29). A problem now arises: we have an exact expression for g(r) at T = Tc for a two-dimensional Ising model (see Section 13.4), according to which g(r) ∼ r−1/4 (d = 2, n = 1, t = 0), (3) which is quite different from the mean ﬁeld expression (12.11.29). We, therefore, generalize our classical result to g(r) ∼ r−(d−2+η) (t = 0), (4) which introduces another critical exponent, η. Clearly, η for the two-dimensional Ising model is 1 4 , which can even be conﬁrmed by experiments on certain systems that are effectively two-dimensional. Table 12.1 shows experimental values of η for some systems in three dimensions; typically, η turns out to be a small number, which makes it rather difﬁcult to measure reliably. We shall now derive some scaling relations involving the exponents ν and η. First of all we write down the correlation function g(r; t, h) and its Fourier transform ˜g(k; t, h) in a scaled form. For this, we note that, while h scales with t1, the only natural variable with which r will scale is ξ ; accordingly, r will scale with t−ν. We may, therefore, write g(r; t, h) ≈ G(rtν , h/t1) rd−2+η , ˜g(k; t, h) ≈ ˜G(k/tν , h/t1) k2−η , (5a, b) where the functions G(x, y) and ˜G(z, y), like the exponents 1, ν, and η, are universal for a given universality class; in expressions (5), for simplicity, we have suppressed nonuniversal parameters that vary from system to system within a class. In the absence of the ﬁeld (h = 0), expressions (5) reduce to g(r; t, 0) ≈ G0(rtν ) rd−2+η , ˜g(k; t, 0) ≈ ˜G0(k/tν ) k2−η , (6a, b) 458 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling where G0(x) and ˜G0(z) are again universal. At the critical point (h = 0, t = 0), we have simply gc(r) ∼ 1 rd−2+η , ˜gc(k) ∼ 1 k2−η . (7a, b) We now recall equation (12.11.12), which relates χ to an integral of g(r) over dr, and substitute expression (6a) into it. We get, ignoring nonuniversal parameters as well as numerical factors, χ ∼ ∫ G0(rtν ) rd−2+η rd−1 dr. (8) By a change of variables, this gives χ ∼ t−(2−η)ν . (9) Invoking the standard behavior of χ, we obtain γ = (2 − η)ν. (10) Note that the same scaling relation can also be obtained by appealing to equa- tions (12.11.13) and (6b); the argument is that, in the limit k → 0, the function ˜G0(z) must be ∼ z2−η (so that k is eliminated), leaving behind a result identical to (9). In passing, we note that in the critical region χ ∼ ξ 2−η. (11) Relation (10) is consistent with the Fisher inequality (1969) γ ≤ (2 − η)ν, and is obviously satisﬁed by the mean ﬁeld exponents (γ = 1, ν = 1 2 , η = 0); it also checks well with the experimental data given earlier in Table 12.1. In fact, this relation provides a much better method of extracting the elusive exponent η, from a knowledge of γ and ν, than determining it directly from experiment. Incidentally, the presence of η explains the slight downward curvature of the Ornstein–Zernike plot, 1/ ˜g(k) versus k2, as k → 0, for the appropriate expression for 1/ ˜g(k) now is 1 ˜g(k) ∼ 1 χ (1 + ξ 2−ηk2−η), (12) rather than (12.11.33). We shall now derive another exponent relation involving ν, but ﬁrst notice that all expo- nent relations derived so far have no explicit dependence on the dimensionality d of the system (though the actual values of the exponents do depend on d). There is, however, one important relationship that does involve d explicitly. For this, let us visualize what 12.12 The critical exponents ν and η 459 happens inside the system (say, a magnetic one) as t → 0 from above. At some stage the correlation length ξ becomes signiﬁcantly larger than the atomic spacings, with the result that magnetic domains, of alternating magnetization, begin to appear. The closer we get to the critical point, the larger the size of these domains; one may, in fact, say that the vol- ume \u0000 of any such domain is ∼ ξ d. Now, the singular part of the free energy density of the system — or, for that matter, of any one of these domains — is given by, see equa- tion (12.10.7) with h = 0, f (s)(t) ∼ t2−α, (13) which vanishes as t → 0. At the same time, the domain volume \u0000 diverges. It seems natural to expect that f (s), being a density, would vanish as 1/\u0000, that is, f (s)(t) ∼ \u0000−1 ∼ ξ −d ∼ tdν . (14) Comparing (13) and (14), we obtain the desired relationship dν = 2 − α, (15) which is generally referred to as a hyperscaling relation — to emphasize the fact that it goes beyond, and cannot be derived from, the ordinary scaling formulation of Section 12.10 without invoking something else, such as the domain volume \u0000. The relation in equation (15) is consistent with the Josephson inequalities (1967): dν ≥ 2 − α, dν′ ≥ 2 − α′, (16a, b) proved rigorously by Sokal (1981); of course, the scaling theory does not distinguish between exponents pertaining to t > 0 and their counterparts pertaining to t < 0. It is important to note that the classical exponents (ν = 1 2 , α = 0) satisfy (15) only for d = 4, which shows that the hyperscaling relations, (15) and any others that follow from it, have a rather different status than the other scaling relations (that do not involve d explicitly). The renormalization group theory, to be discussed in Chapter 14, shows why the hyperscaling relations are to be expected fairly generally, why typically they hold for d < 4 but break down for d > 4; see also Section 12.13. The reader may check that relation (15) is satisﬁed reasonably well by the experimental data of Table 12.1, with d = 3; it is also satisﬁed by the exponents derived theoretically by solving different models exactly, or almost exactly, as in Chapter 13. Combining (15) with other scaling relations, see Section 12.10, we may write dν = 2 − α = 2β + γ = β(δ + 1) = γ (δ + 1)/(δ − 1). (17) It follows that 2 − η = γ /ν = d(δ − 1)/(δ + 1), (18) 460 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling which is consistent with the Buckingham–Gunton inequality (1969) 2 − η ≤ d(δ − 1)/(δ + 1). (19) Notice that the experimental observation that, for magnetic systems in three dimensions, δ < 4.8, implies that η ≥ 0.034. 12.13 A ﬁnal look at the mean ﬁeld theory We now return to the question: why does the mean ﬁeld theory fail to represent the true nature of the critical phenomena in real systems? The short answer is — because it neglects ﬂuctuations! As emphasized in Section 12.11, correlations among the microscopic con- stituents of a given system are at the very heart of the phenomenon of phase transitions, for it is through them that the system acquires a long-range order (even when the micro- scopic interactions are themselves short-ranged). At the same time, there is so direct a relationship between correlations and ﬂuctuations, see equation (12.11.6), that they grow together and, as the critical point is approached, become a dominant feature of the system. Neglecting ﬂuctuations is, therefore, a serious drawback of the mean ﬁeld theory. The question now arises: is mean ﬁeld theory ever valid? In other words, can ﬂuctua- tions ever be neglected? To answer this question, we recall the ﬂuctuation–susceptibility relation (12.11.10a), namely χ = (M 2 − M 2)/kT = (1M)2/kT (1) and write it in the form (1M)2/M 2 = kT χ/M 2. (2) Now, in order that the neglect of ﬂuctuations be justiﬁed, we must have: kT χ ≪ M 2. (3) Requirement (3) is generally referred to as the Ginzburg criterion (1960); for a more detailed discussion of this criterion, along with physical illustrations, see Als-Nielsen and Birgeneau (1977). We apply condition (3) to a domain, of volume \u0000 ∼ ξ d, close to but below the critical point; we are assuming here a system of the Ising type (n = 1), so that ξ is ﬁnite for t < 0. Invoking the power-law behavior of χ and M, we have kTc(Aξ d|t| −γ ) ≪ (Bξ d|t| β ) 2 (t ≲ 0), (4) where A and B are positive constants. Since ξ ∼ a|t|−ν, we get |t| dν−2β−γ ≪ B2ad/AkTc. (5) 12.13 A ﬁnal look at the mean ﬁeld theory 461 In view of the scaling relation α + 2β + γ = 2, we may as well write |t| dν−(2−α) ≪ D, (6) where D is a positive number of order unity.19 For the mean ﬁeld theory (with ν = 1 2 , α = 0) to be valid, condition (6) assumes the form |t| (d−4)/2 ≪ D. (7) Now, since |t| can be made as small as we like, condition (7) will be violated unless d > 4. We, therefore, conclude that the mean ﬁeld theory is valid for d > 4; by implication, it is inadequate for d ≤ 4. The preceding result has been established for scalar models (n = 1) only. In Section 13.5, we shall see that in the case of the spherical model, which pertains to the limit n → ∞, the mean ﬁeld results do apply when d > 4. This means that, once again, ﬂuctua- tions can be neglected if d > 4. Now ﬂuctuations are supposed to decrease with decreasing n; the validity of the mean ﬁeld theory for d > 4 should, therefore, hold for all n. Ordinarily, when a system is undergoing a phase transition, expression (2), which is a measure of the relative ﬂuctuations in the system, is expected to be of order unity. Condition (6) then suggests that the exponents ν and α obey the hyperscaling relation dν = 2 − α. (8) Experience shows that this relation is indeed obeyed when d < 4. At d = 4, the mean ﬁeld theory begins to take over and thereafter, for all d > 4, the critical exponents are stuck at the mean ﬁeld values (which are independent of both d and n). The dimensionality d = 4 is often referred to as the upper critical dimension for the kind of systems under study. An alternative way of looking into the question posed at the beginning of this section is to examine the speciﬁc heat of the system which, according to the mean ﬁeld theory, undergoes a jump discontinuity at the critical point whereas in real systems it shows a weak divergence. The question now arises: what is the source of this divergence that is missed by the mean ﬁeld theory? The answer again lies in the “neglect of ﬂuctuations.” To see it more explicitly, we look at the internal energy of the system which, in the absence of the ﬁeld, is given by U = −J (∑ n.n. σiσj ) = −J ∑ n.n. σiσj. (9) In the mean ﬁeld theory, one replaces σiσj by σi σj(= σ 2), see equation (12.5.5), which leads to the jump discontinuity in the speciﬁc heat of magnitude 3 2 /Nk; see equation (12.5.18). 19To see this, we note that A ∼ Nµ2/\u0000kTc while B ∼ Nµ/\u0000, with the result that D ∼ Nad/\u0000 = O(1). 462 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling The ﬂuctuational part of U, which is neglected in the mean ﬁeld theory, may be written as Uf = −J ∑ n.n.(σiσj − σ iσ j) = −J ∑ n.n. g(rij), (10) where g(r) is the spin–spin correlation function, for which we may use the mean ﬁeld expression (12.11.26); thus, we will be using the mean ﬁeld theory itself to predict its own shortcomings! Since the nearest-neighbor distances rij in (10) are all much smaller than ξ , one may be tempted to use for g(rij) the zeroth-order approximation (12.11.28). This, however, produces a temperature-independent term, which does not contribute to the speciﬁc heat of the system. We must, therefore, go to the next approximation, which can be obtained by using the asymptotic formulae Kµ(x)∣ ∣ x≪1 ≈    1 2 0(µ) ( 1 2 x)−µ + 1 2 0(−µ) ( 1 2 x)µ for 0 < µ < 1 (11a) x−1 + ( 1 2 x) ln( 1 2 x) for µ = 1 (11b) 1 2 0(µ) ( 1 2 x)−µ − 1 2 0(µ − 1) ( 1 2 x)2−µ for µ > 1, (11c) with µ = (d − 2)/2 and x = rij/ξ . The temperature-dependent part of Uf comes from the second term(s) in (11); remembering that ξ here is ∼ at−1/2, we get 20 (Uf /NJ)thermal ∼    t(d−2)/2 for 2 < d < 4 (12a) t ln(1/t) for d = 4 (12b) t for d > 4. (12c) The ﬂuctuational part of the speciﬁc heat then turns out to be Cf /Nk ∼    t(d−4)/2 for 2 < d < 4 (13a) ln(1/t) for d = 4 (13b) const. for d > 4. (13c) It follows that the speciﬁc-heat singularity for d > 4 is indeed a “jump discontinuity,” and hence the mean ﬁeld theory remains applicable in this case. For d = 4, Cf shows a logarithmic divergence and for d < 4 a power-law divergence, making mean ﬁeld theory invalid for d ≤ 4. It is rather instructive to see what part of the ﬂuctuation–correlation spectrum, ˜g(k), contributes signiﬁcantly to the divergence of the speciﬁc heat at t = 0. For this, we examine 20Note that the negative sign in (10) cancels the implicit negative sign of 0(−µ) in (11a), that of ln( 1 2 x) in (11b), and the explicit negative sign in (11c). Problems 463 the quantity −∂g(rij)/∂t, which essentially determines the behavior of Cf near the critical point; see equation (10). Using equation (12.11.25a), we have − ∂g(rij) ∂t ∼ ad ∫ e−ik·rij t2(1 + ξ 2k2)2 kd−1dk. (14) Now, the values of k that are much larger than ξ −1 contribute little to this integral; the only signiﬁcant contributions come from the range (0, kmax), where kmax = O(ξ −1); moreover, since rij ≪ ξ , the exponential for these values of k is essentially equal to 1. Expression (14) may, therefore, be written as − ∂g(rij) ∂t ∼ ad ∫ kd−1dk t2(1 + ξ 2k2)2 (15) which, for d < 4, scales as (a/ξ )dt−2 ∼ t(d−4)/2; compare with (13a). We thus see that the most signiﬁcant contribution to the criticality of the problem arises from ﬂuctuations whose length scale, k−1, is of order ξ or longer and hardly any contribution comes from ﬂuctuations whose length scale is shorter. Now, it is only the latter that are likely to pick up the structural details of the system at the atomic level; since they do not play any sig- niﬁcant role in bringing about the phenomenon, the precise nature of criticality remains independent of the structural details. This explains why a large variety of systems, differ- ing so much in their structure at the macroscopic level, may, insofar as critical behavior is concerned, fall into a single universality class. Problems 12.1. Assume that in the virial expansion Pv kT = 1 − ∞∑ j=1 j j + 1 βj ( λ3 v )j , (10.4.22) where βj are the irreducible cluster integrals of the system, only terms with j = 1 and j = 2 are appreciable in the critical region. Determine the relationship between β1 and β2 at the critical point, and show that kTc/Pcvc = 3. 12.2. Assuming the Dietrici equation of state, P(v − b) = kT exp(−a/kTv), evaluate the critical constants Pc, vc, and Tc of the given system in terms of the parameters a and b, and show that the quantity kTc/Pcvc = e2/2 ≃ 3.695. Further show that the following statements hold in regard to the Dietrici equation of state: (a) It yields the same expression for the second virial coefﬁcient B2 as the van der Waals equation does. (b) For all values of P and for T ≥ Tc, it yields a unique value of v. (c) For T < Tc, there are three possible values of v for certain values of P and the critical volume vc is always intermediate between the largest and the smallest of the three volumes. (d) The Dietrici equation of state yields the same critical exponents as the van der Waals equation does. 464 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling 12.3. Consider a nonideal gas obeying a modiﬁed van der Waals equation of state (P + a/vn)(v − b) = RT (n > 1). Examine how the critical constants Pc, vc, and Tc, and the critical exponents β, γ , γ ′, and δ, of this system depend on the number n. 12.4. Following expressions (12.5.2), deﬁne p = (1 + L)/2 and q = (1 − L)/2 (−1 ≤ L ≤ 1) (1) as the probabilities that a spin chosen at random in a lattice composed of N spins is either “up” or “down.” The partition function of the system may then be written as Q(B, T ) = ∑ L g(L)eβN( 1 2 qJL2+µBL), (2) where g(L) is the multiplicity factor associated with a particular value of L, that is, g(L) = N! /(Np)! (Nq)! ; (3) note that in writing the Hamiltonian here we have made the assumption of random mixing, according to which (N++ + N−− − N+−) = 1 2 qN(p 2 + q2 − 2pq) = 1 2 qNL2. (a) Determine the value, L∗, of L that maximizes the summand in (2). Check that L∗ is identical to the mean value, L, as given by equation (12.5.10). (b) Write down the free energy A and the internal energy U of the system, and show that the entropy S conforms to the relation S(B, T ) = −Nk(p∗ ln p ∗ + q∗ ln q∗), where p∗ = p(L∗) and q∗ = q(L∗). 12.5. Using the correspondence established in Section 12.4, apply the results of the preceding problem to the case of a lattice gas. Show, in particular, that the pressure, P, and the volume per particle, v, are given by P = µB − 1 8 qε0 (1 + L2) − 1 2 kT ln ( 1 − L2 4 ) and v−1 = 1 2 (1 ± L). Check that the critical constants of this system are: Tc = qε0/4k, Pc = kTc(ln 2 − 1 2 ), and vc = 2, so that the quantity kTc/Pcvc = 1/(ln 4 − 1) ≃ 2.589. 12.6. Consider an Ising model with an inﬁnite-range interaction such that each spin interacts equally strongly with all other spins: H = −c ∑ i<j σiσj − µB ∑ i σi. Express this Hamiltonian in terms of the parameter L(= N −16iσi) and show that, in the limit N → ∞ and c → 0, the mean ﬁeld theory, with J = Nc/q, is exact for this model. 12.7. Study the Heisenberg model of a ferromagnet, based on the interaction (12.3.6), in the mean ﬁeld approximation and show that this also leads to a phase transition of the kind met with in the Ising Problems 465 model. Show, in particular, that the transition temperature Tc and the Curie–Weiss constant C are given by Tc = qJ k 2s(s + 1) 3 and C = N(gµB)2 Vk s(s + 1) 3 . Note that the ratio Tc/CV = 2qJ/N(gµB)2 is the molecular ﬁeld constant of the problem; compare to equation (12.5.8). 12.8. Study the spontaneous magnetization of the Heisenberg model in the mean ﬁeld approximation and examine the dependence of L0 on T (i) in the neighborhood of the critical temperature where (1 − T /Tc) ≪ 1, and (ii) at sufﬁciently low temperatures where T /Tc ≪ 1. Compare these results with the corresponding ones, namely (12.5.14) and (12.5.15) for the Ising model. [In this connection, it may be pointed out that, at very low temperatures, the experimental data do not agree with the theoretical formula derived here. We ﬁnd instead a much better agreement with the formula L0 = {1 − A(kT /J)3/2}, where A is a numerical constant (equal to 0.1174 in the case of a simple cubic lattice). This formula is known as Bloch’s T 3/2-law and is derivable from the spin-wave theory of ferromagnetism; see Wannier (1966), Section 15.5.] 12.9. An antiferromagnet is characterized by the fact that the exchange integral J is negative, which tends to align neighboring spins antiparallel to one another. Assume that a given lattice structure is such that the whole lattice can be divided into two interpenetrating sublattices, a and b say, so that the spins belonging to each sublattice, a as well as b, tend to align themselves in the same direction, while the directions of alignment in the two sublattices are opposite to one another. Using the Ising as well as Heisenberg type of interaction, and working in the mean ﬁeld approximation, evaluate the paramagnetic susceptibility of such a lattice at high temperatures. 12.10. The N´eel temperature TN of an antiferromagnet is deﬁned as that temperature below which the sublattices a and b possess nonzero spontaneous magnetizations Ma and Mb, respectively. Determine TN for the model described in the preceding problem. 12.11. Suppose that each atom of a crystal lattice can be in one of several internal states (which may be denoted by the symbol σ ) and the interaction energy between an atom in state σ ′ and its nearest neighbor in state σ ′′ is denoted by u(σ ′, σ ′′){= u(σ ′′, σ ′)}. Let f (σ ) be the probability of an atom being in a particular state σ , independently of the states in which its nearest neighbors are. The interaction energy and the entropy of the lattice may then be written as E = 1 2 qN ∑ σ ′, σ ′′ u(σ ′, σ ′′)f (σ ′)f (σ ′′) and S/Nk = − ∑ σ f (σ ) ln f (σ ), respectively. Minimizing the free energy (E − TS), show that the equilibrium value of the function f (σ ) is determined by the equation f (σ ) = C exp{−(q/kT )6σ ′ u(σ , σ ′)f (σ ′)}, where C is the constant of normalization. Further show that, for the special case u(σ ′, σ ′′) = −Jσ ′σ ′′, where the σ can be either +1 or −1, this equation reduces to the Weiss equation (12.5.11), with f (σ ) = 1 2 (1 + L0σ ). 12.12. Consider a binary alloy containing NA atoms of type A and NB atoms of type B, so that the relative concentrations of the two components are: xA = NA/(NA + NB) ≤ 1 2 and xB = NB/(NA + NB) ≥ 1 2 . The degree of long-range order, X , is such that [ A a ] = 1 2 NxA(1 + X ), [ A b ] = 1 2 NxA(1 − X ), [ B a ] = 1 2 N(xB − xAX ), [ B b ] = 1 2 N(xB + xAX ), 466 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling where N = NA + NB, while the symbol [ A a ] denotes the number of atoms of type A occupying sites of the sublattice a, and so on. In the Bragg–Williams approximation, the number of nearest-neighbor pairs of different kinds can be written down straightaway; for instance, [ AA ab ] = 1 2 qN · xA(1 + X ) · xA(1 − X ), and so on. The conﬁgurational energy of the lattice then follows from equation (12.4.9). In the same approximation, the entropy of the lattice is given by S = k ln W , where W = ( 1 2 N)! [ A a ] ! [ B a ] ! · ( 1 2 N)! [ A b ] ! [ B b ] ! . Minimizing the free energy of the lattice, show that the equilibrium value of X is determined by the equation X xB + xAX 2 = tanh( 2qxAε kT X ) ; ε = 1 2 (ε11 + ε22) − ε12 > 0. Note that, in the special case of equal concentrations (xA = xB = 1 2 ), this equation assumes the more familiar form X = tanh( qε 2kT X ). Further show that the transition temperature of the system is given by Tc = 4xA(1 − xA)T 0 c , where T 0 c (= qε/2k) is the transition temperature in the case of equal concentrations. [Note: In the Kirkwood approximation (see Kubo (1965), problem 5.19), T 0 c turns out to be (ε/k){1 − √ [1 − (4/q)]}−1, which may be written as (qε/2k)(1 − 1/q + · · · ). To this order, the Bethe approximation also yields the same result.] 12.13. Consider a two-component solution of NA atoms of type A and NB atoms of type B, which are supposed to be randomly distributed over N(= NA + NB) sites of a single lattice. Denoting the energies of the nearest-neighbor pairs AA, BB, and AB by ε11, ε22, and ε12, respectively, write down the free energy of the system in the Bragg–Williams approximation and evaluate the chemical potentials µA and µB of the two components. Next, show that if ε = (ε11 + ε22 − 2ε12) < 0, that is, if the atoms of the same species display greater afﬁnity to be neighborly, then for temperatures below a critical temperature Tc, which is given by the expression q|ε|/2k, the solution separates out into two phases of unequal relative concentrations. [Note: For a study of phase separation in an isotopic mixture of hard-sphere bosons and fermions, and for the relevance of this study to the actual behavior of He3−He4 solutions, see Cohen and van Leeuwen (1960, 1961).] 12.14. Modify the Bragg–Williams approximation (12.5.29) to include a short-range order parameter s, such that N ++ = 1 2 qNγ ( 1 + L 2 )2 (1 + s), N −− = 1 2 qNγ ( 1 − L 2 )2 (1 + s), N +− = 2 · 1 2 qNγ ( 1 + L 2 ) ( 1 − L 2 ) (1 − s). (a) Evaluate γ from the condition that the total number of nearest-neighbor pairs is 1 2 qN. (b) Show that the critical temperature Tc of this model is (1 − s2)qJ/k. Problems 467 (c) Determine the nature of the speciﬁc-heat singularity at T = Tc, and compare your result with both the Bragg–Williams approximation of Section 12.5 and the Bethe approximation of Section 12.6. 12.15. Show that in the Bethe approximation the entropy of the Ising lattice at T = Tc is given by the expression Sc Nk = ln 2 + q 2 ln ( 1 − 1 q ) − q(q − 2) 4(q − 1) ln ( 1 − 2 q ) . Compare this result with the one following from the Bragg–Williams approximation, namely (12.5.20). 12.16. Examine the critical behavior of the low-ﬁeld susceptibility, χ0, of an Ising model in the Bethe approximation of Section 12.6, and compare your results with equations (12.5.22) of the Bragg–Williams approximation. 12.17. A function f (x) is said to be concave over an interval (a, b) if it satisﬁes the property f {λx1 + (1 − λ)x2} ≥ λf (x1) + (1 − λ)f (x2), where x1 and x2 are two arbitrary points in the interval (a, b) while λ is a positive number in the interval (0, 1). This means that the chord joining the points x1 and x2 lies below the curve f (x). Show that this also means that the tangent to the curve f (x) at any point x in the interval (a, b) lies above the curve f (x) or, equivalently, that the second derivative ∂ 2f /∂x2 throughout this interval ≤ 0. 12.18. In view of the thermodynamic relationship CV = TV (∂ 2P/∂T 2)V − TN(∂ 2µ/∂T 2)V for a ﬂuid, µ being the chemical potential of the system, Yang and Yang (1964) pointed out that, if CV is singular at T = Tc, then either (∂ 2P/∂T 2)V or (∂ 2µ/∂T 2)V or both will be singular. Deﬁne an exponent 2 by writing (∂ 2P/∂T 2)V ∼ (Tc − T ) −2 (T ≲ Tc), and show that (Grifﬁths, 1965b) 2 ≤ α′ + β and 2 ≤ (2 + α′δ)/(δ + 1). 12.19. Determine the numerical values of the coefﬁcients r1 and s0 of equation (12.9.5) in (i) the Bragg–Williams approximation of Section 12.5 and (ii) the Bethe approximation of Section 12.6. Using these values of r1 and s0, verify that equations (12.9.4), (12.9.9), (12.9.10), (12.9.11), and (12.9.15) reproduce correctly the results obtained in the zeroth and the ﬁrst approximation, respectively. 12.20. Consider a system with a modiﬁed expression for the Landau free energy, namely ψh(t, m) = −hm + q(t) + r(t)m2 + s(t)m4 + u(t)m6, with u(t) a ﬁxed positive constant. Minimize ψ with respect to the variable m and examine the spontaneous magnetization m0 as a function of the parameters r and s. In particular, show the following:21 (a) For r > 0 and s > −(3ur)1/2, m0 = 0 is the only real solution. (b) For r > 0 and −(4ur)1/2 < s ≤ −(3ur)1/2, m0 = 0 or ±m1, where m2 1 = √(s2−3ur)−s 3u . However, the minimum of ψ at m0 = 0 is lower than the minima at m0 = ±m1, so the ultimate equilibrium value of m0 is 0. (c) For r > 0 and s = −(4ur)1/2, m0 = 0 or ±(r/u)1/4. Now, the minimum of ψ at m0 = 0 is of the same height as the ones at m0 = ±(r/u)1/4, so a nonzero spontaneous magnetization is as likely to occur as the zero one. 21To ﬁx ideas, it is helpful to use (r, s)-plane as our “parameter space.” 468 Chapter 12. Phase Transitions: Criticality, Universality, and Scaling (d) For r > 0 and s < −(4ur)1/2, m0 = ±m1 — which implies a ﬁrst-order phase transition (because the two possible states available here differ by a ﬁnite amount in m). The line s = −(4ur)1/2, with r positive, is generally referred to as a “line of ﬁrst-order phase transitions.” (e) For r = 0 and s < 0, m0 = ±(2|s|/3u)1/2. (f ) For r < 0, m0 = ±m1 for all s. As r → 0, m1 → 0 if s is positive. (g) For r = 0 and s > 0, m0 = 0 is only solution. Combining this result with (f), we conclude that the line r = 0, with s positive, is a “line of second-order phase transitions,” for the two states available here differ by a vanishing amount in m. The lines of ﬁrst-order phase transitions and second-order phase transitions meet at the point (r = 0, s = 0), which is commonly referred to as a tricritical point (Grifﬁths, 1970). 12.21. In the preceding problem, put s = 0 and approach the tricritical point along the r-axis, setting r ≈ r1t. Show that the critical exponents pertaining to the tricritical point in this model are α = 1 2 , β = 1 4 , γ = 1, and δ = 5. 12.22. Consider a ﬂuid near its critical point, with isotherms as sketched in Figure 12.3. Assume that the singular part of the Gibbs free energy of the ﬂuid is of the form G(s)(T , P) ∼ |t|2−αg(π/|t|1), where π = (P − Pc)/Pc, t = (T − Tc)/Tc while g(x) is a universal function, with branches g+ for t > 0 and g− for t < 0; in the latter case, the function g− has a point of inﬁnite curvature at a value of π that varies smoothly with t, such that π(0) = 0 and (∂π/∂t)t→0 = const. (a) Using the above expression for G(s), determine the manner in which the densities, ρl and ρg , of the two phases approach one another as t → 0 from below. (b) Also determine how (P − Pc) varies with (ρ − ρc) as the critical point is approached along the critical isotherm (t = 0). (c) Examine as well the critical behavior of the isothermal compressibility κT , the adiabatic compressibility κS, the speciﬁc heats CP and CV , the coefﬁcient of volume expansion αP, and the latent heat of vaporization l. 12.23. Consider a model equation of state which, near the critical point, can be written as h ≈ am(t + bm2)2 (1 < 2 < 2; a, b > 0). Determine the critical exponents β, γ , and δ of this model, and check that they obey the scaling relation (12.10.22). 12.24. Assuming that the correlation function g(ri, rj) is a function only of the distance r = |rj − ri|, show that g(r) for r ̸= 0 satisﬁes the differential equation d2g dr2 + d − 1 r dg dr − 1 ξ 2 g = 0. Check that expression (12.11.27) for g(r) satisﬁes this equation in the regime r ≫ ξ , while expression (12.11.28) does so in the regime r ≪ ξ . 12.25. Consider the correlation function g(r; t, h) of Section 12.11 with h > 0.22 Assume that this function has the following behavior: g(r) ∼ e−r/ξ(t,h) × some power of r (t ≳ 0), such that ξ(0, h) ∼ h−νc . Show that νc = ν/1. Next, assume that the susceptibility χ(0, h) ∼ h−γ c . Show that γ c = γ /1 = (δ − 1)/δ. 22For more details, see Tarko and Fisher (1975). Problems 469 12.26. Liquid He4 undergoes a superﬂuid transition at T ≃ 2.17 K. The order parameter in this case is a complex number 9, which is related to the Bose condensate density ρ0 as ρ0 ∼ |9|2 ∼ |t|2β (t ≲ 0). The superﬂuid density ρs, on the other hand, behaves as ρs ∼ |t|ν (t ≲ 0). Show that the ratio23 (ρ0/ρs) ∼ |t|ην (t ≲ 0). 12.27. The surface tension, σ , of a liquid approaches zero as T → Tc from below. Deﬁne an exponent µ by writing σ ∼ |t| µ (t ≲ 0). Identifying σ with the “free energy associated with a unit area of the liquid–vapor interface,” argue that µ = (d − 1)ν = (2 − α)(d − 1)/d. [Note: Analysis of the experimental data on surface tension yields: µ = 1.27 ± 0.02, which agrees with the fact that for most ﬂuids α ≃ 0.1.] 23The corresponding ratio for a magnetic system is M 2 0 / 0, where M0 is the spontaneous magnetization and 0 the helicity modulus of the system; for details, see Fisher, Barber, and Jasnow (1973). 13 Phase Transitions: Exact (or Almost Exact) Results for Various Models In the preceding chapter we saw that the onset of a phase transition in a given physico- chemical system is characterized by (singular) features whose qualitative nature is deter- mined by the universality class to which the system belongs. In this chapter we propose to consider a variety of model systems belonging to different universality classes and ana- lyze them theoretically to ﬁnd out how these features arise and how they vary from class to class. In this context, we recall that the parameters distinguishing one universality class from another are: (i) the space dimensionality d, (ii) the dimensionality of the order parameter, often referred to as the spin dimensionality, n, and (iii) the range of the microscopic inter- actions. As regards the latter, unless a statement is made to the contrary, we shall assume a short-range interaction which, in most cases, will be of the nearest-neighbor type; the only parameters open for selection will then be d and n. We start our analysis with the properties of one-dimensional ﬂuids, the one- dimensional Ising (n = 1) model, and the general n-vector models (again in one dimen- sion). We then return to the Ising model — this time in two dimensions — and follow it with a study of two models in general d but with n → ∞. These studies will give us a fairly good idea as to what to expect in the most practical, three-dimensional situations for which, unfortunately, we have no exact solutions — though a variety of mathematical techniques have been developed to obtain almost exact results in many cases of interest. For completeness, these and other results of physical importance will be revisited in the last section of this chapter. 13.1 One-dimensional ﬂuid models A system of interacting particles in one dimension can be solved analytically for sev- eral cases. In particular, a system of hard spheres in one dimension can be solved in the canonical ensemble (Tonks, 1936) while the one-dimensional isobaric ensemble allows the solution of a more general set of nearest-neighbor interactions. None of these mod- els exhibits a transition to an ordered phase but they do display many of the short-range correlation properties characteristic of ﬂuids. Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00013-X © 2011 Elsevier Ltd. All rights reserved. 471 472 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models 13.1.A Hard spheres on a ring The partition function of a one-dimensional system of hard spheres was ﬁrst evaluated by Tonks (1936). For this we consider the case of N hard spheres with diameter D on a ring of circumference L, obeying periodic boundary conditions. The free energy, the pressure, and the pair correlation function of this system can be determined exactly both for ﬁnite N and in the thermodynamic limit. The hard sphere pair interaction is given by u(r) = {∞ for r ≤ D 0 for r > D. (1) The conﬁgurational partition function can be written as an integral over the spatially ordered positions of the N spheres, with particle 1 set at x1 = 0, while the other particles labeled j = 2, 3, . . . , N are restricted by the conditions xj−1 + D < xj < L − (N − j + 1)D: ZN (L) = L N L−(N−1)D∫ D dx2 L−(N−2)D∫ x2+D dx3 · · · L−D∫ xN−1+D dxN = L(L − ND)N−1 N! ; (2) the prefactor L here comes from integrating x1 over the circumference of the ring, while the factor 1/N delabels that ﬁnal integral. The Helmholtz free energy in the thermodynamic limit turns out to be A(N, L, T ) = −NkT ln ( L − ND Nλ ) − NkT , (3) where λ is the thermal deBroglie wavelength. The pressure is then given by P = − ( ∂A ∂L ) T ,N = nkT 1 − nD , (4) where n (= N/L) is the one-dimensional number density. This is equivalent to the pressure of an ideal gas of N particles in a free volume L − ND. The isothermal compressibility is κT = 1 n ( ∂n ∂p ) T = (1 − nD)2 nkT = κ ideal T (1 − nD) 2 . (5) The pair correlation function for the particles on the ring can also be determined exactly (M. Foss-Feig, unpublished). This is accomplished by integrating over all conﬁgurations in which particle 1 is ﬁxed at the origin and, in succession, each of the other particles is ﬁxed at position x (if possible). This gives g(x) = N−1∑ j=1 gj(x). (6) 13.1 One-dimensional ﬂuid models 473 0 0 1 2 3 4g(x) 510 X 15 FIGURE 13.1 The pair correlation function for a system of 12 hard disks on a ring. The scaled number density nD = 0.75. The solid line represents the exact solution from equations (6) and (7), as compared to a Monte Carlo simulation. where gj(x) is deﬁned on the range jD ≤ x ≤ L − (N − j)D by gj(x) = ( L(N − 1)! N(L − ND)N−1 ) ( (x − jD)j−1(L − x − (N − j)D)N−1−j (j − 1)! (N − 1 − j)! ) ; (7) see Figure 13.1. In the thermodynamic limit, the correlation function becomes g(x) = ∞∑ j=1 gj(x) , (8) where gj(x) is deﬁned on the range jD ≤ x < ∞ by gj(x) = (βP(x − jD))j−1 exp ( −βP(x − jD) ) (1 − nD)(j − 1)! , (9) where βP = n/(1 − nD); see Sells, Harris, and Guth (1953). Using equation (10.7.12) gives the correct virial equation of state pressure P nkT = 1 + nDg(D+) = 1 1 − nD ; (10) where g(D+) is the pair correlation function at contact; see Problem 13.28. 13.1.B Isobaric ensemble of a one-dimensional ﬂuid Takahashi (1942) has shown that a one-dimensional system of particles that interact with nearest neighbors via pair potential u(r) can be analyzed analytically using an isobaric 474 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models ensemble. The potential energy of the system can be written as U = N+1∑ j=1 u(xj − xj−1), (11) where the left and right walls are treated as particles ﬁxed at x0 = 0 and xN+1 = L. The isobaric partition function is given by YN (P, T ) = 1 λ ∞∫ 0 exp(−βPL)QN (L, T )dL, (12) where λ is the thermal deBroglie wavelength. Equation (12) can be factorized in terms of integrals over the distances between nearest neighbors yi (= xi − xi−1): YN (P, T ) =   1 λ ∞∫ 0 exp(−βPy − βu(y))dy   N+1 = Y1(p, T )N+1. (13) The bulk Gibbs free energy is then given by G(N, P, T ) = −NkT ln (Y1(P, T )), (14) and the average system size at pressure P by ( ∂G ∂P ) T ,N = L = N⟨y⟩, (15) where ⟨y⟩ = ∫ ∞ 0 y exp[−βPy − βu(y)]dy ∫ ∞ 0 exp[−βPy − βu(y)]dy (16) is the average nearest-neighbor distance between the particles. The isothermal compress- ibility, κT = −1 L ( ∂L ∂P ) T ,N = N kTL (⟨y2⟩ − ⟨y⟩2) , (17) is proportional to the variance of the nearest-neighbor distances. It is now easy to show that one-dimensional models cannot form a long-range ordered lattice. The average dis- tance between two particles labeled by i and j is ⟨xi − xj⟩ = (i − j)⟨y⟩ but the variance is given by ⟨(xi − xj)2⟩ = |i − j|(⟨y2⟩ − ⟨y⟩2). Therefore, if a chosen particle is located on a particular lattice site, then a particle m sites away will on average be separated from it by m lattice spacings, but the variance of this particle’s position from that site location grows linearly with m. 13.1 One-dimensional ﬂuid models 475 In the thermodynamic limit, the structure factor S(k), equation (10.7.18), can be written in the form S(k) = 〈 ∞∑ j=−∞ eik(xj−x0)〉 . (18) Since (xj − x0) = ∑j i=1 yi, the structure factor can be summed exactly to give S(k) = −1 + ∞∑ j=0 zj + ∞∑ j=0 (z∗) j = 1 − |z|2 1 + |z|2 − z − z∗ , (19) where z = 〈eiky〉 = ∫ ∞ 0 exp [−βPy − βu(y) + iky] dy ∫ ∞ 0 exp [ −βPy − βu(y) ] dy , (20) and z∗ is the complex conjugate of z. The ﬂuctuation-compressibility relation now gives: S(k → 0) = κT /κ ideal T = (⟨y2⟩ − ⟨y⟩2) /⟨y⟩2. For the particular case of hard spheres, the pres- sure is given by equation (4) and the structure factor is given by S(k) = (kD)2 (kD)2 + 2(βPD)2(1 − cos(kD)) + 2(βPD)(kD) sin(kD) ; (21) see Figure 13.2. Equation (10.7.20a), applied to the hard sphere pair correlation function in equation (9), also gives equation (21). 0 0 1 2 3S(k) 20 40 60 80 kD 100 FIGURE 13.2 The structure factor S(k) for a system of hard spheres on a line at density nD = 0.75. The structure factor at k = 0 is S(0) = (1 − nD)2 = κT /κ ideal T . 476 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models 13.2 The Ising model in one dimension In this section we present an exact treatment of the Ising model in one dimension. This is important for several reasons. First of all, there do exist phenomena, such as adsorption on a linear polymer or on a protein chain, the elastic properties of ﬁbrous proteins, and so on, that can be looked upon as one-dimensional nearest-neighbor problems. Secondly, it helps us evolve mathematical techniques for treating lattices in higher dimensions, which is essential for understanding the critical behavior of a variety of physical systems met with in nature. Thirdly, it enables us to estimate the status of the Bethe approximation as a “possible” theory of the Ising model, for it demonstrates mathematically that, at least in one dimension, this approximation leads to exact results. In a short paper published in 1925, Ising himself gave an exact solution to this prob- lem in one dimension. He employed a combinatorial approach that has by now been superseded by other approaches. Here we shall follow the transfer matrix method, ﬁrst introduced by Kramers and Wannier (1941). In the one-dimensional case, this method worked with immediate success. Three years later, in 1944, it became, through Onsager’s ingenuity, the ﬁrst method to treat successfully the ﬁeld-free Ising model in two dimen- sions. To apply this method, we replace the actual lattice by one having the topology of a closed, endless structure; thus, in the one-dimensional case we replace the straight, open chain by a curved one such that the Nth spin becomes a neighbor of the ﬁrst (see Figure 13.3). This replacement eliminates the inconvenient end effects; it does not, however, alter the thermodynamic properties of the (inﬁnitely long) chain. The impor- tant advantage of this replacement is that it enables us to write the Hamiltonian of the system, HN {σi} = −J ∑ n.n. σiσj − µB N∑ i=1 σi, (1) in a symmetrical form, namely HN {σi} = −J N∑ i=1 σiσi+1 − 1 2 µB N∑ i=1(σi + σi+1), (2) N 2 3 N 2 2 N 2 1 N 1 2 3 4 5 FIGURE 13.3 An Ising chain with a closed, endless structure. 13.2 The Ising model in one dimension 477 because σN+1 ≡ σ1. The partition function of the system is then given by QN (B, T ) = ∑ σ1=±1 · · · ∑ σN =±1 exp [ β N∑ i=1{Jσiσi+1 + 1 2 µB(σi + σi+1)} ] (3a) = ∑ σ1=±1 · · · ∑ σN =±1 ⟨σ1|P|σ2⟩⟨σ2|P|σ3⟩ · · · ⟨σN−1|P|σN ⟩⟨σN |P|σ1⟩, (3b) where P denotes an operator with matrix elements ⟨σi|P|σi+1⟩ = exp [β { Jσiσi+1 + 1 2 µB(σi + σi+1) }] , that is, (P) = ( eβ(J+µB) e−βJ e−βJ eβ(J−µB) ) . (4) According to the rules of matrix algebra, the summations over the various σi in equa- tion (3b) lead to the simple result QN (B, T ) = ∑ σ1=±1 ⟨σ1|PN |σ1⟩ = Trace (PN ) = λN 1 + λN 2 , (5) where λ1 and λ2 are the eigenvalues of the matrix P. These eigenvalues are given by the equation ∣ ∣ ∣ ∣ ∣ eβ(J+µB) − λ e−βJ e−βJ eβ(J−µB) − λ ∣ ∣ ∣ ∣ ∣ = 0, (6) that is, by λ 2 − 2λeβJ cosh(βµB) + 2 sinh(2βJ) = 0. (7) One readily obtains ( λ1 λ2 ) = eβJ cosh(βµB) ± {e−2βJ + e2βJ sinh2(βµB)}1/2. (8) Quite generally, λ2 < λ1; so, (λ2/λ1)N → 0 as N → ∞. Thus, it is only the larger eigenvalue, λ1, that determines the major physical properties of the system in the thermodynamic limit; see equation (5). It follows that 1 N ln QN (B, T ) ≈ ln λ1 (9) = ln[eβJ cosh(βµB) + {e−2βJ + e2βJ sinh 2(βµB)} 1/2]. (10) 478 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models The Helmholtz free energy then turns out to be A(B, T ) = −NJ − NkT ln[cosh(βµB) + {e−4βJ + sinh 2(βµB)}1/2]. (11) The various other properties of the system follow readily from equation (11). Thus, U(B, T ) ≡ −T 2 ∂ ∂T ( A T ) = −NJ − NµB sinh(βµB) {e−4βJ + sinh 2(βµB)}1/2 + 2NJe−4βJ [cosh(βµB) + {e−4βJ + sinh 2(βµB)}1/2]{e−4βJ + sinh2(βµB)}1/2 , (12) from which the speciﬁc heat can be derived, and M(B, T ) ≡ − ( ∂A ∂B ) T = Nµ sinh(βµB) {e−4βJ + sinh 2(βµB)}1/2 , (13) from which the susceptibility can be derived. Right away we note that, as B → 0, M (for all ﬁnite β) → 0. This rules out the possibility of spontaneous magnetization, and hence of a phase transition, at any ﬁnite temperature T . Of course, at T = 0, M (for any value of B) is equal to the saturation value Nµ, which implies perfect order in the system. This means that there is, after all, a phase transition at a critical temperature Tc, which coincides with absolute zero! Figure 13.4 shows the degree of magnetization, M, of the lattice as a function of the parameter (βµB) for different values of (βJ). For J = 0, we have the paramagnetic result M = Nµ tanh(βµB); compare to equation (3.9.27). A positive J enhances magnetization and, in turn, leads to a faster approach toward saturation. As βJ → ∞, the magnetiza- tion curve becomes a step function — indicative of a singularity at T = 0. The low-ﬁeld susceptibility of the system is given by the initial slope of the magnetization curve; one obtains χ0(T ) = Nµ2 kT e2J/kT , (14) \u00022 \u00021 \u00021 1 01 2 (\u0002\u0003B) M(B, T )/N\u0003 \u0002J \u0003 0 \u0002J \u0004 0FIGURE 13.4 The degree of magnetization of an Ising chain as a function of the parameter (βµB). 13.2 The Ising model in one dimension 479 which diverges as T → 0. It should be noted that the singularity here is not of the power-law type; it is exponential instead. The zero-ﬁeld energy and the zero-ﬁeld speciﬁc heat of the system follow from equa- tion (12); one gets U0(T ) = −NJ tanh(βJ) (15) and C0(T ) = Nk(βJ) 2sech 2(βJ). (16) Figure 13.5 shows the variation of the speciﬁc heat C0 as a function of temperature. Although it passes through a maximum, C0 is a smooth function of T , vanishing as T → 0. Note that equations (15) and (16) are identical to the corresponding equations, (12.6.29) and (12.6.30), of the Bethe approximation, with coordination number 2, for which Tc = 0. It turns out that for a one-dimensional chain the Bethe approximation, in fact, yields exact results; for a fuller demonstration of this, see Problem 13.3. At this stage it seems instructive to express the free energy of the system, near its crit- ical point, in a scaled form, as in Section 12.10. Unfortunately, there is a problem here. Since Tc = 0, the conventional deﬁnition, t = (T − Tc)/Tc, does not work. A closer look at equations (11) and (14), however, suggests that we may adopt instead the deﬁnition t = e−pJ/kT (p > 0) (17) so that, as T → Tc, t → 0 as desired while for temperatures close to Tc, t is much less than unity. The deﬁnition of h remains the same, namely µB/kT . The free energy function (A + NJ)/NkT then takes the form ψ (s)(t, h) = − ln[cosh h + (t4/p + sinh 2 h)1/2] (18a) ≈ −(t4/p + h 2) 1/2 (t, h ≪ 1), (18b) which may be written in the scaled form ψ (s)(t, h) ≈ t2/pf (h/t2/p). (19) 0 0 0.5 12 kT/JC0(T)/NkFIGURE 13.5 The zero-ﬁeld speciﬁc heat of an Ising chain as a function of temperature. 480 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models At the same time, equation (14) becomes χ0(T ) (Nµ2/kT ) ≈ t−2/p. (20) Comparing these results with the scaling formulation of Section 12.10, we infer that for this model α = 2 − 2/p, 1 = 2/p, and γ = 2/p, (21) in conformity with the exponent relation (12.10.14b). Note that the exponents β and δ for this model cannot be deﬁned in the normal, conventional sense. One may, however, write equation (13) in the form m = sinh h/(t4/p + sinh2 h) 1/2 (22a) ≈ h/(t4/p + h 2) 1/2 (t, h ≪ 1) (22b) = −t0f ′(h/t2/p), (22c) suggesting that β may formally be taken as zero. At the same time, since m|t=0 = 1, (23) which is ∼ h0, the exponent δ may formally be taken as inﬁnite. We now study spin–spin correlations in the Ising chain. For this, we set B = 0 but at the same time generalize the interaction parameter J to become site-dependent (the reason for which will become clear soon). The partition function of the system is then given by QN (T ) = ∑ σ1=±1 · · · ∑ σN =±1 ∏ i eβJiσiσi+1 ; (24) compare to equation (3a). With B = 0, it is simpler to work with an open chain, which has only (N − 1) nearest-neighbor pairs; the advantage of this choice is that in the summand of (24) the variables σ1 and σN appear only once! A summation over either of these can be carried out easily; doing this over σN , we have ∑ σN =±1 eβJN−1σN−1σN = 2 cosh(βJN−1σN−1) = 2 cosh(βJN−1), (25) regardless of the sign of σN−1. We thus obtain the recurrence relation QN (T ; J1, . . . , JN−1) = 2 cosh(βJN−1)QN−1(T ; J1, . . . , JN−2). (26) 13.2 The Ising model in one dimension 481 By iteration, we get QN (T ) = N−1∏ i=1 {2 cosh(βJi)} ∑ σ1=±1 1 = 2N N−1∏ i=1 cosh(βJi), (27) so that 1 N ln QN (T ) = ln 2 + 1 N N−1∑ i=1 ln cosh(βJi), (28) which may be compared with equation (9) — remembering that, in the absence of the ﬁeld, λ1 = 2 cosh(βJ). We are now ready to calculate the correlation function, g(r), of the Ising chain. It is straightforward to see from equation (24) that σkσk+1 = 1 QN ( 1 β ∂ ∂Jk ) QN = ( 1 β ∂ ∂Jk ) ln QN . (29) Substituting from equation (28), and remembering that σ k = 0 at all ﬁnite temperatures, we obtain for the nearest-neighbor correlation function gk(n.n.) = σkσk+1 = tanh(βJk). (30) For a pair of spins separated by r lattice constants, we get gk(r) = σkσk+r = (σkσk+1)(σk+1σk+2) . . . (σk+r−1σk+r) (since all σ 2 i = 1) = 1 QN ( 1 β ∂ ∂Jk ) ( 1 β ∂ ∂Jk+1 ) · · · ( 1 β ∂ ∂Jk+r−1 ) QN = k+r−1∏ i=k tanh(βJi). (31) Reverting to a common J, we obtain the desired result g(r) = tanh r(βJ), (32) which may be written in the standard form g(r) = e−r/ξ , with ξ = [ln coth(βJ)]−1 . (33a, b) For βJ ≫ 1, ξ ≈ 1 2 e2βJ , (34) 482 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models which diverges as T → 0. In terms of the variable t, as deﬁned in equation (17), ξ ∼ t−2/p (t ≪ 1), (35) giving ν = 2/p. And since our g(r) does not contain any power of r, we infer that (d − 2 + η) = 0 — giving η = 1; one may check that the same result follows from equation (12.12.10) or (12.12.11). In passing, we note that, regardless of the choice of the number p in deﬁning t, we have for this model γ = ν = 2 − α. (36) We further note that, since d = 1 here, the hyperscaling relation, dν = 2 − α, is also obeyed. Finally, we observe that expression (33b) for ξ is in conformity with the general result ξ −1 = ln(λ1/λ2), (37) where λ1 is the largest eigenvalue of the transfer matrix P of the problem and λ2 the next largest; for a derivation of this result, see Section 5.3 of Yeomans (1992). In our case, λ1 = 2 cosh(βJ) and λ2 = 2 sinh(βJ), see equation (8) with B = 0, and hence expression (33b) for ξ . 13.3 The n-vector models in one dimension We now consider a generalization of the Ising chain in which the spin variable σ i is an n-dimensional vector of magnitude unity, whose components can vary continuously over the range −1 to +1; in contrast, the Ising spin σi could have only a discrete value, +1 or −1. We shall see that the vector models (with n ≥ 2), while differing quantitatively from one another, differ rather qualitatively from the scalar models (for which n = 1). While some of these qualitative differences will show up in the present study, more will become evident in higher dimensions. Here we follow a treatment due to Stanley (1969a,b) who ﬁrst solved this problem for general n. Once again we employ an open chain composed of N spins constituting (N − 1) nearest-neighbor pairs. The Hamiltonian of the system, in zero ﬁeld, is given by HN {σ i} = − N−1∑ i=1 Jiσ i · σ i+1. (1) We assume our spins to be classical, so we do not have to worry about the commutation properties of their components. And since the components σiα(α = 1, . . . , n) of each spin vector σ i are now continuous variables, the partition function of the system will involve integrations, rather than summations, over these variables. Associating equal a priori 13.3 The n-vector models in one dimension 483 probabilities with solid angles of equal magnitude in the n-dimensional spin-vector space, we may write QN = ∫ d\u00001 \u0000(n) · · · d\u0000N \u0000(n) N−1∏ i=1 eβJiσ i·σ i+1, (2) where \u0000(n) is the total solid angle in an n-dimensional space; see equation (7b) of Appendix C, which gives \u0000(n) = 2π n/2/ 0(n/2). (3) We ﬁrst carry out integration over σ N , keeping the other σ i ﬁxed. The relevant integral to do is 1 \u0000(n) ∫ eβJN−1σ N−1·σ N d\u0000N . (4) For σ N we employ spherical polar coordinates, with polar axis in the direction of σ N−1, while for d\u0000N we use expression (9) of Appendix C. Integration over angles other than the polar angle θ yields a factor of 2π (n−1)/2/ 0{(n − 1)/2}. (5) The integral over the polar angle is π∫ 0 eβJN−1 cos θ sin n−2 θ dθ = π 1/20{(n − 1)/2} ( 1 2 βJN−1)(n−2)/2 I(n−2)/2(βJN−1), (6) where Iµ(x) is a modiﬁed Bessel function; see Abramowitz and Stegun (1964), formula 9.6.18. Combining (3), (5), and (6), we obtain for (4) the expression 0(n/2) ( 1 2 βJN−1)(n−2)/2 I(n−2)/2(βJN−1), (7) regardless of the direction of σ N−1. By iteration, we get QN = N−1∏ i=1 0(n/2) ( 1 2 βJi)(n−2)/2 I(n−2)/2)(βJi); (8) the last integration, over d\u00001, gave simply a factor of unity. Expression (8) is valid for all n — including n = 1, for which it gives: QN = ∏i cosh(βJi). This last result differs from expression (13.2.27) by a factor of 2N ; the reason for this dif- ference lies in the fact that the QN of the present study is normalized to go to unity as the βJi go to zero [see equation (2)] whereas the QN of the preceding section, being a sum over 2N discrete states [see equation (13.2.24)] goes to 2N instead. This difference is important 484 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models in the evaluation of the entropy of the system; it is of no consequence for the calculations that follow. First of all we observe that the partition function QN is analytic at all β — except possibly at β = ∞ where the singularity of the problem is expected to lie. Thus, no long- range order is expected to appear at any ﬁnite temperature T — except at T = 0 where, of course, perfect order is supposed to prevail. In view of this, the correlation function for the nearest-neighbor pair (σ k, σ k+1) is simply σ k · σ k+1 and is given by, see equations (2) and (8), gk(n.n.) = 1 QN ( 1 β ∂ ∂Jk ) QN = In/2(βJk) I(n−2)/2(βJk) . (9) The internal energy of the system turns out to be U0 ≡ − ∂ ∂β (ln QN ) = − N−1∑ i=1 Ji In/2(βJi) I(n−2)/2(βJi) ; (10) not surprisingly, U0 is simply a sum of the expectation values of the nearest-neighbor interaction terms −Jiσ i · σ i+1, which is identical to a sum of the quantities −Jigi(n.n.) over all nearest-neighbor pairs in the system. The calculation of gk(r) is somewhat tricky because of the vector character of the spins, but things are simpliﬁed by the fact that we are dealing with a one-dimensional system only. Let us consider the trio of spins σ k, σ k+1 and σ k+2, and suppose for a moment that our spins are three-dimensional vectors; our aim is to evaluate σ k · σ k+2. We choose spherical polar coordinates with polar axis in the direction of σ k+1; let the direction of σ k be deﬁned by the angles (θ0, φ0) and that of σ k+2 by (θ2, φ2). Then σ k · σ k+2 = cos θ(k, k + 2) = cos θ0 cos θ2 + sin θ0 sin θ2 cos(φ0 − φ2). (11) Now, with σ k+1 ﬁxed, spins σ k and σ k+2 will orient themselves independently of one another because, apart from σ k+1, there is no other channel of interaction between them. Thus, the pairs of angles (θ0, φ0) and (θ2, φ2) vary independently of one another; this makes cos(φ0 − φ2) = 0 and cos θ0 cos θ2 = cos(θ0) cos(θ2). It follows that σ k · σ k+2 = σ k · σ k+1 σ k+1 · σ k+2. (12) Extending this argument to general n and to a segment of length r, we get gk(r) = k+r−1∏ i=k gi(n.n.) = k+r−1∏ i=k In/2(βJi)/I(n−2)/2(βJi). (13) 13.3 The n-vector models in one dimension 485 With a common J, equations (9), (10), and (13) take the form g(n.n.) = In/2(βJ)/I(n−2)/2(βJ), (14) U0 = −(N − 1)J In/2(βJ)/I(n−2)/2(βJ) (15) and g(r) = {In/2(βJ)/I(n−2)/2(βJ)}r. (16) The last result here may be written in the standard form e−r/ξ , with ξ = [ln{I(n−2)/2(βJ)/In/2(βJ)}]−1. (17) For n = 1, we have: I1/2(x)/I−1/2(x) = tanh x; the results of the preceding section are then correctly recovered. For a study of the low-temperature behavior, where βJ ≫ 1, we invoke the asymptotic expansion Iµ(x) = ex √(2πx) [ 1 − 4µ2 − 1 8x + · · · ] (x ≫ 1), (18) with the result that g(n.n.) ≈ 1 − n − 1 2βJ , (14a) U0 ≈ −(N − 1)J [ 1 − n − 1 2βJ ] (15a) and ξ ≈ 2βJ n − 1 ∼ T −1. (17a) Clearly, the foregoing results hold only for n ≥ 2; for n = 1, the asymptotic expansion (18) is no good because it yields the same result for µ = 1 2 as for µ = − 1 2 . In that case one is obliged to use the closed form result, g(n.n.) = tanh(βJ), which for βJ ≫ 1 gives g(n.n.) ≈ 1 − 2e−2βJ (14b) U0 ≈ −(N − 1)J[1 − 2e−2βJ ] (15b) and ξ ≈ 1 2 e2βJ , (17b) 486 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models in complete agreement with the results of the preceding section. For completeness, we have for the low-temperature speciﬁc heat of the system C0 ≈ (N − 1)    1 2 (n − 1)k for n ≥ 2 (19a) 4k(βJ) 2e−2βJ for n = 1. (19b) The most obvious distinction between one-dimensional models with continuous sym- metry (n ≥ 2) and those with discrete symmetry (n = 1) is in relation to the nature of the singularity at T = 0. While in the case of the former it is a power-law singularity, with critical exponents1 α = 1, ν = 1, η = 1, and hence γ = 1, (20) in the case of the latter it is an exponential singularity. Nevertheless, by introducing the temperature parameter t = e−pβJ , see equation (13.2.17), we converted this exponential singularity in T into a power-law singularity in t, with α = 2 − 2/p, γ = ν = 2/p, η = 1. (21) However, the inherent arbitrariness in the choice of the number p left an ambiguity in the values of these exponents; we now see that by choosing p = 2 we can bring exponents (21) in line with (20). Next we observe that the critical exponents (20) for n ≥ 2 turn out to be independent of n — a feature that seems peculiar to situations where Tc = 0. In higher dimensions, where Tc is ﬁnite, the critical exponents do vary with n; for details, see Section 13.7. In any case, the amplitudes always depend on n. In this connection we note that, since each of the N spins comprising the system has n components, the total number of degrees of free- dom in this problem is Nn. It seems appropriate that the extensive quantities, such as U0 and C0, be divided by Nn, so that they are expressed as per degree of freedom. A look at equation (15a) then tells us that our parameter J must be of the form nJ ′, so that in the thermodynamic limit U0 Nn ≈ −J ′ + n − 1 2n kT (22) and, accordingly, C0 Nn ≈ n − 1 2n k. (23) 1Note that, since Tc = 0 here, the assertion that the free energy function ψ ≡ (A/NkT ) ∼ (T − Tc)2−α implies that, near T = Tc in the present case, A ∼ T 3−α; accordingly, the speciﬁc heat C0 ∼ T 2−α. Comparison with expression (19a) would be inappropriate because C0, in the limit T → 0, cannot be nonzero; the result quoted in (19a) is an artiﬁce of the model considered, which must somehow be “subtracted away.” The next approximation yields a result proportional to the ﬁrst power in T , giving α = 1. For a parallel situation, see equation (13.5.35) for the spherical model (which pertains to the case n = ∞). 13.3 The n-vector models in one dimension 487 Equation (17a) then becomes ξ ≈ 2n n − 1 J ′ kT . (24) Note that the amplitudes appearing in equations (22) through (24) are such that the limit n → ∞ exists; this limit pertains to the so-called spherical model, which will be studied in Section 13.5. Figure 13.6 shows the normalized energy u0(= U0/NnJ ′) as a function of temperature for several values of n, including the limiting case n = 1. We note that u0 (which, in the thermodynamic limit, is equal and opposite to the nearest-neighbor correlation function g(n.n.)) increases monotonically with n — implying that g(n.n.), and hence g(r), decrease monotonically as n increases. This is consistent with the fact that the correlation length ξ also decreases as n increases; see equation (24). The physical reason for this behavior is that an increase in the number of degrees of freedom available to each spin in the system effectively diminishes the degree of correlation among any two of them. Another feature emerges here that distinguishes vector models (n ≥ 2) from the scalar model (n = 1); this is related to the manner in which the quantity u0 approaches its ground-state value −1. While for n = 1, the approach is quite slow — leading to a vanishing 0.0 20.2 20.4 n 51 2 3 4 6 820.6 20.8 21.0 0.0 0.5 1.0 1.5 2.0 2.5 u0 kT/J9 FIGURE 13.6 The normalized energy u0( = U0/NnJ ′) of a one-dimensional chain as a function of the temperature parameter kT /J ′ for several values of n (after Stanley, 1969a,b). Note that for this classical model, the slopes as T → 0 are given by the equipartition theorem for n − 1 degrees of freedom per spin. 488 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models speciﬁc heat, see equations (15b) and (19b) — for n ≥ 2, the approach is essentially linear in T , leading to a ﬁnite speciﬁc heat; see equations (15a) and (19a). This last result violates the third law of thermodynamics, according to which the speciﬁc heat of a real system must go to zero as T → 0. The resolution of this dilemma lies in the fact that the low-lying states of a system with continuous symmetry (n ≥ 2) are dominated by long-wavelength excitations, known as Goldstone modes, which in the case of a magnetic system assume the form of “spin waves,” characterized by a particle-like spectrum: ω(k) ∼ k2. The very low-temperature behavior of the system is primarily governed by these modes, and the thermal energy associated with them is given by Utherma1 ∼ ∫ ℏω exp(ℏω/kBT ) − 1 kd−1dk ∼ T (d+2)/2; (25) this results in a speciﬁc heat ∼ T d/2, which indeed is consistent with the third law. For a general account of the Goldstone excitations, see Huang (1987); for their role as “spin waves” in a magnetic system, see Plischke and Bergersen (1989). For further information on one-dimensional models, see Lieb and Mattis (1966) and Thompson (1972a,b). 13.4 The Ising model in two dimensions As stated earlier, Ising (1925) himself carried out a combinatorial analysis of the one- dimensional model and found that there was no phase transition at a ﬁnite temperature T . This led him to conclude, erroneously though, that his model would not exhibit a phase transition in higher dimensions either. In fact, it was this “supposed failure” of the Ising model that motivated Heisenberg to develop, in 1928, the theory of ferromagnetism based on a more sophisticated interaction among the spins; compare the Heisenberg interac- tion (12.3.6) with the Ising interaction (12.3.7). It was only after some exploitation of the Heisenberg model that people returned to investigate the properties of the Ising model. The ﬁrst exact, quantitative result for the two-dimensional Ising model was obtained by Kramers and Wannier (1941) who successfully located the critical temperature of the system. They were followed by Onsager (1944) who derived an explicit expression for the free energy in zero ﬁeld and thereby established the precise nature of the speciﬁc-heat singularity. These authors employed the transfer matrix method that was introduced in Section 13.2 to solve the corresponding one-dimensional problem; its application to the two-dimensional model, even in the absence of the ﬁeld, turned out to be an extremely difﬁcult task. Although some of these difﬁculties were softened by subsequent treatments due to Kaufman (1949) and to Kaufman and Onsager (1949), it seemed very natural to look for other simpler approaches. One such approach was developed by Kac and Ward (1952), later reﬁned by Potts and Ward (1955), in which combinatorial arguments were used to express the partition func- tion of the system as the determinant of a certain matrix A. This method throws special 13.4 The Ising model in two dimensions 489 light on the “topological conditions” that give rise to an exact solution in two dimensions but are clearly absent in three dimensions; a particularly lucid account of this method has been given by Baker (1990). In 1960 Hurst and Green introduced yet another approach to investigate the Ising problem; this involved the use of “triangular arrays of quantities closely related to antisymmetric determinants” and became rightly known as the method of Pfafﬁans. This method applies rather naturally to the study of “conﬁgurations of dimer molecules on a given lattice” which, in turn, is closely related to the Ising problem; for details, see Kasteleyn (1963), Montroll (1964), and Green and Hurst (1964). A pedagog- ical account of the approach through Pfafﬁans is given in Thompson (1972b), where a comprehensive treatment of the original, algebraic approach can also be found. Another combinatorial solution, which is generally regarded as the simplest, was obtained by Vdovichenko (1965) and by Glasser (1970), and is readily accessible in Stanley (1971). For an exhaustive account of the two-dimensional Ising model, see McCoy and Wu (1973). We analyze this problem with the help of a combinatorial approach assisted, from time to time, by a graphical representation. The zero-ﬁeld partition function of the system is given by the familiar expression Q(N, T ) = ∑ {σi} ∏ n.n. eK σiσj (K = J/kT ). (1) Our ﬁrst step consists of carrying out a high-temperature and a low-temperature expan- sion of the partition function and establishing an intimate relation between the two. High-temperature expansion Since the product (σiσj) can only be +1 or −1, we may write eK σiσj = cosh K + σiσj sinh K = cosh K (1 + σiσjv), v = tanh K . (2) The product over all nearest-neighbor pairs then takes the form ∏ n.n. eK σiσj = (cosh K )N ∏ n.n.(1 + σiσjv), (3) N being the total number of nearest-neighbor pairs on the lattice; for a lattice with peri- odic boundary conditions, N = 1 2 qN where q is the coordination number. The partition function may then be written as Q(N, T ) = (cosh K ) N ∑ σ1=±1 · · · ∑ σN =±1 [1 + v ∑ (i,j) σiσj + v2 ∑ (i,j) (i,j)̸=(k,l) ∑ (k,l) σiσjσkσl + . . . ] . (4) Now we represent each product (σiσj) appearing in (4) by a “bond connecting sites i and j on the given lattice”; then, each coefﬁcient of vr in the expansion would be represented by a “graph consisting of r different bonds on the lattice.” Figure 13.7 shows all possible graphs, with r = 1 and 2, on a square lattice. Notice that in each case we have some of 490 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models (i) (ii)a (ii)b FIGURE 13.7 Graphs with r = 1 and r = 2 on a square lattice. Graph (i) is for r = 1. The r = 2 graphs are of two types, ones that do not include a common site as in (ii)a and ones that do include a common site as in (ii)b. r 5 4 r 5 6 r 5 8 FIGURE 13.8 Examples of closed graphs with r bonds on a square lattice. the σi appearing only once in the term, which makes all these terms vanish on summation over {σi}. The same is true for r = 3. Only when we reach r = 4 do we receive a nonvanish- ing contribution from terms of the type (σiσjσjσkσkσlσlσi) ≡ 1 which, on summation over {σi}, yield a contribution of 2N each. It is obvious that a nonvanishing term corresponds to a graph in which each vertex is met by an even number of bonds — making the graph necessarily a closed one; see Figure 13.8, where some other closed graphs are also shown. In view of these observations, expression (4) may be written as Q(N, T ) = 2 N (cosh K ) N ∑ r n(r)vr [n(0) = 1], (5) where n(r) is the number of graphs that can be drawn on the given lattice using r bonds such that each vertex of the graph is met by an even number of bonds. For simplic- ity, we shall refer to these graphs as closed graphs. Our problem thus reduces to one of enumerating such graphs on the given lattice. Since v = tanh( J/kT ), the higher the temperature the smaller the v. Expansion (5) is, therefore, particularly useful at higher temperatures (even though it is exact for all T ). As an illustration, we apply this result to a one-dimensional Ising chain. In the case of an open chain, no closed graphs are possible, so all we get from (5) is the term with r = 0; with N = N − 1, this gives Q(N, T ) = 2 N (cosh K ) N−1, (6) 13.4 The Ising model in two dimensions 491 which agrees with our previous result (13.2.27). In the case of a closed chain, we do have a closed graph — the one with r = N; we now get (with N = N) Q(N, T ) = 2 N (cosh K )N [1 + vN ] = 2 N [(cosh K ) N + (sinh K ) N ], (7) which agrees with expression (13.2.5), with (λ1)B=0 = 2 cosh K and (λ2)B=0 = 2 sinh K . Low-temperature expansion We start with the observation that the ground state of the system consists of all spins aligned in the same direction, with the total energy E0 = −JN . As one spin is ﬂipped, q unlike nearest-neighbor pairs are created at the expense of like ones, and the energy of the system increases by an amount 2qJ. It seems appropriate, therefore, that the Hamiltonian of the system be written in terms of the number, N+−, of unlike nearest-neighbor pairs in the lattice, that is, H(N+−) = −J(N++ + N−− − N+−) = −J(N − 2N+−). (8) The partition function of the system may then be written as Q(N, T ) = eK N ∑ r m(r)e−2Kr [m(0) = 1], (9) where m(r) denotes the “number of distinct ways in which the N spins of the lattice can be so arranged as to yield r unlike nearest-neighbor pairs.” It is obvious that the ﬁrst nonzero term in (9), after the one with r = 0, would be the one with r = q. A graphical representation of the number m(r) is straightforward. Referring to Figure 13.9, which pertains to a square lattice, we see that each term in expansion (9) can be associated with a closed graph that cordons off region(s) of “up” spins from those of “down” spins, the perimeter of the graph being precisely the number of unlike nearest- neighbor pairs in the lattice for that particular conﬁguration. Our problem then reduces to one of enumerating closed graphs, of appropriate perimeters, that can be drawn on the given lattice. r 5 4 1111 1 1111 1 1211 1 1111 1 1111 1 r 5 6 1111 1 11 1 1 1 1 2 21 1 1111 1 1111 1 r 5 8 1111 1 11 1 1 12 2 21 1 1111 1 1111 1 FIGURE 13.9 Graphs cordoning off regions of “up” spins from those of “down” spins, with r unlike nearest-neighbor pairs. 492 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models Now, since expansion (9) is a power series in the variable e−2K that increases as T increases, this expansion is particularly useful at lower temperatures (even though it is exact for all T ). We shall now establish an important relation between the coefﬁcients appearing in expansion (5) and the ones appearing in (9). The duality transformation To establish the desired relation we construct a lattice dual to the one given. By deﬁnition, we draw right bisectors of all the bonds in the lattice, so that the points of intersection of these bisectors become the sites of the new lattice. The resulting lattice may not be similar in structure to the one we started with; for instance, while the dual of a square lattice is itself a square lattice, the dual of a triangular lattice (q = 6) is, in fact, a honeycomb lattice (q = 3), and vice versa; see Figures 13.10 and 13.11. The argument now runs as follows: We start with the given lattice on which one of the n(r) closed graphs, with r bonds, is drawn and construct the lattice dual to this one, placing spins of one sign on the sites inside this graph and spins of opposite sign on the sites outside. Then this graph represents precisely a conﬁguration with r unlike nearest-neighbor pairs in the dual lattice and hence qualiﬁes to be counted as one of the m(r) graphs on the dual lattice. Conversely, if we start with one of the m(r) graphs, of perimeter r, representing a conﬁguration with r unlike nearest-neighbor pairs in the original lattice and go through the process of constructing the dual lattice, then this graph will qualify to be one of the n(r) closed graphs, with r bonds, on the dual lattice. In fact, there is a one-to-one correspondence between graphs of one kind on the given lattice and graphs of the other kind on the dual lattice; compare Figure 13.8 with Figure 13.9. It follows that n(r) = mD(r) and m(r) = nD(r), (10a, b) FIGURE 13.10 A square lattice and its dual (which is also square). 13.4 The Ising model in two dimensions 493 FIGURE 13.11 A honeycomb lattice (q = 3) and its dual, which is triangular (q = 6). where the sufﬁx D refers to the dual lattice. With relations (10) established, we go back to equation (9) and introduce another temperature variable K ∗(= J/kT ∗) such that tanh K ∗ = e−2K ; (11) note that equation (11) can also be written in the symmetrical form sinh(2K ) sinh(2K ∗) = 1. (12) Substituting (10b) and (11) into (9), we get Q(N, T ) = eK N ∑ r nD(r)v∗r, v∗ = tanh K ∗. (13) At the same time we apply equation (5) to the dual lattice at temperature T ∗, to get QD(ND, T ∗) = 2 ND (cosh K ∗)N ∑ r nD(r)v∗r, (14) where ND = qN/qD; see again Figure 13.11. Comparing (13) and (14), we arrive at the desired relation Q(N, T ) = 2 −ND (sinh K ∗ cosh K ∗)−N /2QD(ND, T ∗), (15) 494 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models which relates the partition function of the given lattice at temperature T to that of the dual lattice at temperature T ∗. Equation (15) constitutes the so-called duality transformation. Location of the critical point For a square lattice, which is self-dual, there should be no distinction between Q and QD. With q = 4, and hence N = 2N, equation (15) becomes Q(N, T ) = [sinh(2K ∗)]−N Q(N, T ∗), (16) which may also be written as [sinh(2K )]−N/2Q(N, T ) = [sinh(2K ∗)]−N/2Q(N, T ∗). (17) It will be noted from equation (11) or (12) that as T → ∞, T ∗ → 0 and as T → 0, T ∗ → ∞; equation (17), therefore, establishes a one-to-one correspondence between the high- temperature and the low-temperature values of the partition function of the lattice. It then follows that if there exists a singularity in the partition function at a particular temperature Tc, there must exist an equivalent singularity at the corresponding temperature T ∗ c . And in case we have only one singularity, as indeed follows from one of the theorems of Yang and Lee (1952), it must exist at a temperature Tc such that T ∗ c = Tc. The critical temperature of the square lattice is, therefore, given by the equation, see formula (12), sinh(2Kc) = 1, (18) which gives Kc = 1 2 sinh −1 1 = 1 2 ln( √2 + 1) = 1 2 ln cot(π/8) ≃ 0.4407. (19) For comparison, we note that for the same lattice the Bragg–Williams approximation gave Kc = 0.25 while the Bethe approximation gave Kc = 1 2 ln 2 ≃ 0.3466. The situation for other lattices such as the triangular or the honeycomb, which are not self-dual, is complicated by the fact that the functions Q and QD in equation (15) are not the same. One then needs another trick — the so-called star–triangle transformation — which was ﬁrst alluded to by Onsager (1944) in his famous paper on the solution of the square lattice problem but was written down explicitly by Wannier (1945); for details, see Baxter (1982). Unlike the duality transformation, this one establishes a relation between a high-temperature model on the triangular lattice and again a high-temperature model on the honeycomb lattice, and so on. Combining the two transformations, one can elim- inate the dual lattice altogether and obtain a relation between a high-temperature and a low-temperature model on the same lattice. The location of the critical point is then straightforward; one obtains for the triangular lattice (q = 6) Kc = 1 2 sinh −1 1 √3 ≃ 0.2747, (20) 13.4 The Ising model in two dimensions 495 and for the honeycomb lattice (q = 3) Kc = 1 2 sinh −1 √3 ≃ 0.6585. (21) The numerical values of Kc, given by equations (19) through (21), reinforce the fact that higher coordination numbers help propagate long-range order in the system more effec- tively and hence raise the critical temperature Tc. The partition function and the speciﬁc-heat singularity The partition function of the Ising model on a square lattice is given by, see references cited at the beginning of this section, 1 N ln Q(T ) = ln{21/2 cosh(2K )} + 1 π π/2∫ 0 dφ ln{1 + √(1 − κ 2 sin2 φ)}, (22) where κ = 2 sinh(2K )/ cosh2(2K ). (23) Differentiating (22) with respect to − β, one obtains for the internal energy per spin 1 N U0(T ) = − 2J tanh(2K ) + 1 π ( κ dκ dβ ) × π/2∫ 0 dφ sin 2 φ {1 + √ (1 − κ 2 sin2 φ)}√(1 − κ 2 sin2 φ) . (24) Rationalizing the integrand, the integral in (24) can be written as 1 κ 2 {− π 2 + K1(κ) } , (25) where K1(κ) is the complete elliptic integral of the ﬁrst kind, κ being the modulus of the integral: K1(κ) = π/2∫ 0 dφ √ (1 − κ 2 sin 2 φ) . (26) Now, a logarithmic differentiation of (23) with respect to β gives 1 κ dκ dβ = 2J{coth(2K ) − 2 tanh(2K )}. (27) 496 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models Substituting these results into (24), we obtain 1 N U0(T ) = −J coth(2K ) { 1 + 2κ ′ π K1(κ)} , (28) where κ ′ is the complementary modulus: κ ′ = 2 tanh2(2K ) − 1 (κ 2 + κ ′2 = 1). (29) Figure 13.12 shows the variation of the moduli κ and κ ′ with the temperature parame- ter (kT /J) = K −1. We note that, while κ is always positive, κ ′ can be positive or negative; actually, κ lies between 0 and 1 while κ ′ lies between −1 and 1. At the critical point, where sinh(2Kc) = 1 and hence K −1 c ≃ 2.269, the moduli κ and κ ′ are equal to 1 and 0, respectively. To determine the speciﬁc heat of the lattice, we differentiate (28) with respect to temperature. In doing so, we make use of the following results: dκ dβ = − κ ′ κ dκ ′ dβ , dκ ′ dβ = 8J tanh(2K ){1 − tanh 2(2K )} (30) and dK1(κ) dκ = 1 κ ′2κ {E1(κ) − κ ′2K1(κ)}, (31) where E1(κ) is the complete elliptic integral of the second kind: E1(κ) = π/2∫ 0 √ (1 − κ 2 sin2 φ)dφ. (32) 1 \u0002, \u00029 kT /J \u0002 0 24 21 \u00029 FIGURE 13.12 Variation of the moduli κ and κ ′ with (kT /J). 13.4 The Ising model in two dimensions 497 We ﬁnally obtain 1 Nk C0(T ) = 2 π {K coth(2K )} 2 [ 2{K1(κ) − E1(κ)} − (1 − κ ′) { π 2 + κ ′K1(κ)}] . (33) Now, the elliptic integral K1(κ) has a singularity at κ = 1 (i.e., at κ ′ = 0), in the neighbor- hood of which K1(κ) ≈ ln{4/|κ ′|} and E1(κ) ≈ 1. (34) Accordingly, the speciﬁc heat of the lattice displays a logarithmic singularity at a tempera- ture Tc, given by the condition: κc = 1 (or κ ′ c = 0), which is identical to (18). In the vicinity of the critical point, equation (33) reduces to 1 Nk C0(T ) ≃ 8 π K 2 c [ ln{4/|κ ′|} − (1 + π 4 )] ; (35) at the same time, the parameter κ ′ reduces to, see equation (30), κ ′ ≃ 2 √ 2Kc ( 1 − T Tc ) . (36) The speciﬁc heat singularity is, therefore, given by 1 Nk C0(T ) ≃ 8 π K 2 c [ − ln ∣ ∣ ∣ ∣1 − T Tc ∣ ∣ ∣ ∣ + { ln ( √ 2 Kc ) − ( 1 + π 4 )}] ≃ −0.4945 ln ∣ ∣ ∣ ∣1 − T Tc ∣ ∣ ∣ ∣ + const., (37) signaling a logarithmic divergence at T = Tc. Figures 13.13 and 13.14 show the temperature dependence of the internal energy and the speciﬁc heat of the square lattice, as given by the Onsager expressions (28) and (33); for comparison, the results of the Bragg–Williams approximation and of the Bethe approx- imation (with q = 4) are also included. The speciﬁc-heat singularity, given correctly by the Onsager expression (37), is seen as a (logarithmic) peak in Figure 13.14, which differs markedly from the jump discontinuity predicted by the mean ﬁeld theory. We conclude that the critical exponent α = α′ = 0(log). In passing, we note that the internal energy of the lattice is continuous at the critical point, having a value of −√ 2J per spin and an inﬁnite, positive slope; needless to say, the continuity of the internal energy implies that the transition takes place without any latent heat. Other properties We now consider the temperature dependence of the order parameter (i.e., the sponta- neous magnetization), of the lattice. An exact expression for this quantity was ﬁrst derived 498 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models 0 0 1 2 3 46 \u00021 \u00022U0(T )/NJ kT/J 2 2.27 2.88 FIGURE 13.13 The internal energy of a square lattice (q = 4) according to (1) the Onsager solution, (2) the Bethe approximation, and (3) the Bragg–Williams approximation. 00 2.27 2.88 4 6 3 2 1 1 2C0(T )/Nk kT/J 2 FIGURE 13.14 The speciﬁc heat of a square lattice (q = 4) according to (1) the Onsager solution, (2) the Bethe approximation, and (3) the Bragg–Williams approximation. by Onsager (1949), though he never published the details of his derivation. The ﬁrst published derivation is due to Yang (1952), who showed that L0(T ) ≡ 1 Nµ M(0, T ) = {[1 − {sinh(2K )}−4]1/8 for T ≤ Tc (38a) 0 for T ≥ Tc, (38b) where K , as usual, is J/kT . In the limit T → 0, L0(T ) ≃ 1 − 2 exp(−8J/kT ), (39) which implies a very slow variation with T . On the other hand, in the limit T → Tc−, L0(T ) ≈ { 8 √2Kc (1 − T Tc )}1/8 ≃ 1.2224 ( 1 − T Tc )1/8 , (40) 13.4 The Ising model in two dimensions 499 00 0.5 1.0 0.5 1.0 1 2 3 (T/Tc)L0(T ) FIGURE 13.15 The spontaneous magnetization of a square lattice (q = 4) according to (1) the Onsager solution, (2) the Bethe approximation, and (3) the Bragg–Williams approximation. which indicates a very fast variation with T . The detailed dependence of L0 on T is shown in Figure 13.15; for comparison, the results of the Bragg–Williams approximation and the Bethe approximation are also included. We infer that the critical exponent β for this model is 1 8 , which is very different from the mean ﬁeld value of 1 2 . Onsager also calculated the correlation length ξ of the lattice, which showed that the critical exponent ν = ν′ = 1 — in sharp contrast to the classical value of 1 2 . Finally, he set up calculations for the correlation function g(r) from which one could infer that the exponent η = 1 4 , again in disagreement with the classical value of zero. Precise asymptotic expres- sions for the correlation function in different regimes of temperature were derived by later authors (Fisher, 1959; Kadanoff, 1966a; Au-Yang and Perk, 1984): g(r) ≈ {4(Kc − K )}1/4 23/8(π r/ξ )1/2 e−r/ξ , ξ = {4(Kc − K )}−1 (41) for T > Tc, g(r) ≈ {4(K − Kc)}1/4 221/8π(r/ξ )2 e−2r/ξ , ξ = {4(K − Kc)} −1 (42) for T < Tc, and g(r) ≈ 21/12 exp{3ζ ′(−1)} r1/4 (43) at T = Tc; in the last expression, ζ ′(x) denotes the derivative of the Riemann zeta function. We note from expressions (41) and (42) that the correlation length ξ , while diverging at T = Tc, is ﬁnite on both sides of the critical point. This feature is peculiar to the scalar model (n = 1) only, for in the case of vector models (n ≥ 2), ξ turns out to be inﬁnite at all T ≤ Tc. 500 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models The zero-ﬁeld susceptibility of this system has also been worked out (see Barouch et al., 1973; Tracy and McCoy, 1973; Wu et al., 1976); asymptotically, one ﬁnds that χ0 ≈ Nµ2 kTc × {C+t−7/4 for t ≳ 0 (44a) C−|t| −7/4 for t ≲ 0, (44b) where t, as usual, is (T − Tc)/Tc while the constants C+ and C− are about 0.96258 and 0.02554, respectively. We see that the critical exponent γ = γ ′ = 7 4 , as opposed to the mean ﬁeld value of 1, and the ratio C+/C− ≃ 37.69, as opposed to the mean ﬁeld value of 2. Assembling all the exponents in one place, we have for the two-dimensional Ising model α = α′ = 0(log), β = 1 8 , γ = γ ′ = 7 4 , ν = ν′ = 1, η = 1 4 . (45) Since this model has not yet been solved in the presence of a ﬁeld, a direct evaluation of the exponent δ has not been possible. Assuming the validity of the scaling relations, however, we can safely conclude that δ = 15 — again very different from the classical value of 3. All in all, the results of this section tell us very clearly, and loudly, how inadequate the mean ﬁeld theory can be. Before we close this section, a few remarks seem to be in order. First of all, it may be mentioned that for the model under consideration one can also calculate the interfacial tension s, which may be deﬁned as the “free energy associated, per unit area, with the interfaces between the domains of up spins and those of down spins”; in our analogy with the gas–liquid systems, this corresponds to the conventional surface tension σ . The corre- sponding exponent µ, that determines the manner in which s → 0 as T → Tc−, turns out to be 1 for this model; see Baxter (1982). This indeed obeys the scaling relation µ = (d − 1)ν, as stated in Problem 12.26. Second, we would like to point out that, while the solution of the two-dimensional Ising model was the ﬁrst exact treatment that exposed the inade- quacy of the mean ﬁeld theory, it was also the ﬁrst to disclose the underlying universality of the problem. As discovered by Onsager himself, if the spin–spin interactions were allowed to have different strengths, J and J ′, in the horizontal and vertical directions of the lattice, the speciﬁc-heat divergence at T = Tc continued to be logarithmic — independently of the ratio J ′/J — even though the value of Tc itself and of the various amplitudes appearing in the ﬁnal expressions were modiﬁed. A similar result for the spontaneous magnetization was obtained by Chang (1952) who showed that, regardless of the value of J ′/J, the expo- nent β continued to be 1 8 . Further corroborative evidence for universality came from the analysis of two-dimensional lattices other than the square one which, despite structural differences, led to the same critical exponents as the ones listed in equation (45). 13.4.A The two-dimensional Ising model on a ﬁnite lattice Phase transitions, viewed as critical phenomena, cannot occur in a ﬁnite system since a statistical mechanical model with a ﬁnite number of degrees of freedom cannot have 13.4 The Ising model in two dimensions 501 a nonanalytic partition function or free energy. Criticality occurs only in the thermody- namic limit. Since real physical systems are of ﬁnite size, the manner in which ﬁnite- size effects manifest themselves as the correlation length ξ approaches the system size is of considerable importance in understanding how critical singularities get rounded off in real systems. In this regard, the two-dimensional nearest-neighbor Ising model on a square lattice in zero ﬁeld can be solved on a ﬁnite square lattice with periodic boundary conditions (Kaufman, 1949), which allows for a detailed exploration of ﬁnite- size effects, especially near the bulk critical point; see Ferdinand and Fisher (1969). Kaufman’s solution is based on a determination of all the eigenvalues of the transfer matrix. Onsager (1944) only required the largest eigenvalue since his solution was based on a strip geometry with the length of one side taken to inﬁnity. We here consider the Ising model on a lattice with n rows and m columns with periodic boundary conditions; see Figure 13.16. Each column of n spins has 2n possible conﬁgurations, so the transfer matrix P that couples nearest-neighbor columns is a 2n × 2n matrix of Boltzmann factors with eigenvalues λα, with α = 1, 2, . . . , 2n. Just as in the case of the one-dimensional Ising model studied in Section 13.2, the partition function of a system with n rows and m columns can be written as the trace of a transfer matrix P: Qn,m(K ) = Trace(Pm) = 2n ∑ α=1 λ m α , (46) where the eigenvalues of the transfer matrix fall into two classes: λα =    (2 sinh(2K ) )n/2 ∑ exp ( 1 2 ( ±γ0 ± γ2 ± ... ± γ2n−2)), (2 sinh(2K ) )n/2 ∑ exp ( 1 2 ( ±γ1 ± γ3 ± ... ± γ2n−1)). (47) FIGURE 13.16 A ﬁnite square lattice with n = 4 rows and m = 6 columns. In view of the periodic boundary conditions, sites on the leftmost column interact with sites on the rightmost column and the bottom row interacts with the top row. 502 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models The quantity γq for 0 < q < 2n is the positive root of the equation cosh(γq) = cosh2(2K ) sinh(2K ) − cos ( π q n ), (48) while the q = 0 case is given by eγ0 = e2K tanh(K ). (49) Only terms with an even number of minus signs inside the exponentials appear in the sums in equation (47), so the partition function can be written as Qn,m(K ) = 1 2 (2 sinh(2K ))nm/2 (Y1 + Y2 + Y3 + Y4), (50) where Y1 = n−1∏ q=0 (2 cosh ( m 2 γ2q+1)) , (51a) Y2 = n−1∏ q=0 (2 sinh ( m 2 γ2q+1)) , (51b) Y3 = n−1∏ q=0 (2 cosh ( m 2 γ2q)) , (51c) Y4 = n−1∏ q=0 (2 sinh ( m 2 γ2q)) ; (51d) see Kaufman (1949). This form of the partition function allows for an exact calculation of the free energy, internal energy, and speciﬁc heat on ﬁnite lattices; see Figure 13.17. The logarithmic singularity in the speciﬁc heat at the bulk critical point evolves from a speciﬁc heat peak that grows logarithmically with the system size, that is Cnm(Kc)/nmk ≈ (8K 2 c /π) ln(n) ≃ 0.4945 ln(n); see Ferdinand and Fisher (1969). Note also that the coefﬁ- cient of ln(n) here is the same as the coefﬁcient of the ln(|1 − T /Tc|) term in the bulk speciﬁc heat, as given in equation (37). The low-temperature series expansion for the partition function can be written as Qn,m(K ) = e2nmK ˜Qn,m(K ), where ˜Qn,m(K ) = nm∑ q=0 gqx2q, (52) x = e−2K is the Boltzmann factor for a single excitation, and the coefﬁcients gq denote the number of conﬁgurations with energy 4qJ above the ground state. The sum of the 13.4 The Ising model in two dimensions 503 64 \u0002 64 32 \u0002 32 16 \u0002 16 8 \u0002 8 4 \u0002 4 2 \u0002 2 2.5 2 1.5 1 0.5 0 1 2 3 4 kT / J C Nk FIGURE 13.17 Speciﬁc heat of the two-dimensional Ising model for ﬁnite 2 × 2, 4 × 4, . . . , 64 × 64 lattices. The speciﬁc heat is analytic for all ﬁnite lattices. The maximum value of the speciﬁc heat grows proportional to the logarithm of the linear dimension of the lattice and the location of the maximum approaches the bulk critical temperature (denoted by the vertical line) proportional to the inverse of the linear dimension of the lattice. From Ferdinand and Fisher (1969). Reprinted with permission; copyright © 1969, American Physical Society. coefﬁcients counts all the microstates in the system; therefore lim K →0 ˜Qn,m(K ) = nm∑ q=0 gq = 2 nm . The coefﬁcients gq represent the number of microstates pertaining to energy (−2nmJ + 4qJ), with the corresponding entropy being k ln gq. The ﬁrst term in the series is g0 = 2 since there are two degenerate ground states, namely all spins up or all spins down. It is straightforward to see that only even orders in x appear in this expansion. Examples of the low-order graphs that contribute to the series 504 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models \u0002\u0002\u0002\u0002 \u0002\u0002\u0002\u0002 \u0002\u0002\u0003\u0002 \u0002\u0002\u0002\u0002 \u0002 \u0002 \u0002 \u0002 \u0002 \u0002\u0002\u0002\u0002 \u0002\u0002\u0002\u0002 \u0002\u0002\u0002 \u0002 \u0003 \u0003\u0002\u0002 \u0002\u0002\u0002\u0002 \u0002 \u0002 \u0002 \u0002 \u0002 \u0002\u0002\u0002\u0002 \u0002\u0002\u0002\u0002 \u0002\u0003\u0002\u0002 \u0002\u0002\u0002\u0002 \u0002\u0002\u0003\u0002 \u0002 \u0002 \u0002 \u0002 \u0002 \u0002\u0002\u0002\u0002 \u0002\u0002\u0002\u0002 \u0002\u0002\u0002 \u0002 \u0003 \u0003\u0003\u0002 \u0002\u0002\u0002\u0002 \u0002 \u0002 \u0002 \u0002 \u0002 \u0002\u0002\u0002\u0002 (a) (b) (c) (d) FIGURE 13.18 The lowest few excited states of the lattice. The q = 2 states (a), have a single down spin in a sea of up spins or a single up spin in a sea of down spins; these states have energy 8J above the ground state and there are g2 = 2nm conﬁgurations. The q = 3 states (b), have a pair of down spins in a sea of up spins, or vice versa; these states have energy 12J above the ground state and g3 = 4nm conﬁgurations. The q = 4 states (c) and (d), can have a single grouping of opposite spins, or a pair of isolated ﬂipped spins; these states have energy 16J above the ground state and the total number of conﬁgurations g4 = (nm)2 + 9nm. are shown in Figure 13.18. The ﬁrst few terms in the series are ˜Qn,m(K ) = 2 + (2nm)x4 + (4nm)x6 + ((nm) 2 + 9nm) x8 + (4(nm)2 + 24nm ) x10 + . . . . (53) If both n and m are even, the model’s ferromagnetic/antiferromagnetic symmetry ( J → −J and si → −si on one sublattice) gives: gq = gnm−q. Due to the self-duality of the two-dimensional square lattice, exactly the same coefﬁcients gq also appear in the high-temperature series expansion where the expansion variable is tanh K . The probability Pq of ﬁnding an equilibrium state with energy 4qJ above the ground state is given by Pq = gqx2q ˜Qn,m(K ) , (54) and the internal energy and the heat capacity per spin are given by U NJ = −2 + 4 N N∑ q=0 qPq (N = nm), (55a) C Nk = 16 N ( J kT )2    N∑ q=0 q2Pq −   N∑ q=0 qPq   2   . (55b) One can cast Kaufman’s solution, equation (50) and equation (51), in the form of a low-temperature expansion of the form shown in (52), thereby giving an exact determi- nation of the partition function and the equilibrium energy distribution; see Beale (1996). 13.4 The Ising model in two dimensions 505 The low-temperature series (52) can be written as ˜Qn,m(K ) = nm∑ q=0 gqx2q = (Z1 + Z2 + Z3 + Z4), (56) where if n is even, then Z1 = 1 2 n/2−1∏ q=0 c2 2q+1, (57a) Z2 = 1 2 n/2−1∏ q=0 s2 2q+1, (57b) Z3 = 1 2 c0cn n/2−1∏ q=1 c2 2q, (57c) Z4 = 1 2 s0sn n/2−1∏ q=1 s2 2q; (57d) while if n is odd, then Z1 = 1 2 cn (n−3)/2∏ q=0 c2 2q+1, (58a) Z2 = 1 2 sn (n−3)/2∏ q=0 s2 2q+1, (58b) Z3 = 1 2 c0 (n−1)/2∏ q=1 c2 2q, (58c) Z4 = 1 2 s0 (n−1)/2∏ q=1 s2 2q. (58d) The factors in equations (57) and (58) are c0 = (1 − x)m + (x(1 + x))m , (59a) s0 = (1 − x) m − (x(1 + x))m , (59b) cn = (1 + x) m + (x(1 − x))m , (59c) sn = (1 + x) m − (x(1 − x))m , (59d) c2 q = 1 2m−1       ⌊ m 2 ⌋ ∑ j=0 m! (α2 q − β2)j αm−2j q (2j)! (m − 2j)!    + βm   , (59e) 506 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models s2 q = 1 2m−1       ⌊ m 2 ⌋ ∑ j=0 m! ( α2 q − β2)j αm−2j q (2j)! (m − 2j)!    − βm   , (59f) β = 2x(1 − x2), (59g) αq = (1 + x2) 2 − β cos ( πq n ) . (59h) The function ⌊z⌋ denotes the largest integer less than or equal to z. The quantities c2 q and s2 q were expanded using the binomial series in order to explicitly remove all square roots that would hide the polynomial nature of the ﬁnal result. A symbolic programming language can be used to numerically expand the partition function as a polynomial in the variable x in the form (52). One must set the numerical precision in the calculation to somewhat more than nm ln 2/ ln 10 decimal digits in order to determine the exact values of the integer coefﬁcients {gq}. The numerical calculation can be checked against the low-order result (53) or with an exact enumeration of energies on small lattices. The low-temperature series for the Ising model on a 32 × 32 lattice is ˜Q32,32(K ) = 2 + 2048x4 + 4096x6 + 1057792x8 + 4218880x10 + 371621888x12 + 2191790080x14 + 100903637504x16 + 768629792768x18 + 22748079183872x20 + · · · + 4096x2042 + 2048x2044 + 2x2048, (60) where the largest coefﬁcient is g512 = 6,342, 873, 169, 001, 916, 568, 766, 443, 273, 025, 000, 331, 593, 063, 924, 436, 135, 196, 680, 443, 689, 656, 478, 072, 741, 300, 511, 612, 123, 900, 652, 711, 596, 311, 283, 701, 724, 071, 226, 144, 241, 851, 411, 641, 714, 893, 727, 789, 741, 510, 169, 213, 344, 005, 116, 385, 197, 594, 692, 089, 556, 614, 547, 788, 150, 860, 200, 720, 413, 211, 442, 412, 355, 672, 291, 841, 364, 265, 145, 274, 980, 444, 405, 423, 129, 672, 679, 584, 959, 498, 234, 944, 801, 613, 246, 300, 853, 599, 317, 229, 362, 316 , (61) that is, there are about 6.342 × 10306 conﬁgurations with energy halfway between the ferromagnetic and antiferromagnetic ordered states. This single microstate comprises 3.5 percent of the 21024 total conﬁgurations of the model. The exact results for the micro- canonical entropy and the energy distribution for the 128 × 128 lattice are shown in Figures 13.19 and 13.20. These results provide excellent tests of Monte Carlo simulation 13.4 The Ising model in two dimensions 507 methods, including broad histogram methods; see Beale (1996), Wang and Landau (2001), and Landau and Binder (2009).2 0.8 0.6 0.4 0.2 0.0 0.0 0.2 0.4 0.6 0.8 1.0 q/nm In(gq) nm FIGURE 13.19 Microcanonical entropy per spin S/Nk = ln(gq)/nm for the two dimensional Ising model on a 128 × 128 lattice as calculated from equations (56), (57), and (59). The slope of the curve is proportional to the inverse temperature, so the state with q/nm = 1/2 represents the inﬁnite temperature state with energy halfway between the ordered ferromagnetic and antiferromagnetic states; the largest coefﬁcient g8192 ≃ 1.049 × 104930 is the number of conﬁgurations with q = nm/2 = 8192. Likewise, the states at q = 0 and q = nm represent the ferromagnetic and antiferromagnetic ground states, so the slopes of the curve diverge logarithmically in the thermodynamic limit. 0.008 0.006 0.004 0.002 0.000 0.00 0.05 0.10 0.15 0.20 0.25 q/nm Pq K \u0002 0.4 K \u0002 0.5 K \u0002 Kc FIGURE 13.20 The exact energy distribution Pq for the two-dimensional Ising model on a 128 × 128 lattice for K = 0.4, K = Kc ≃ 0.4407, and K = 0.5. The variance of the energy distribution is proportional to the speciﬁc heat, so is largest near K = Kc. Refer to Figure 13.17. 2Mathematica code for calculating the low-temperature series coefﬁcients for a two-dimensional Ising model, as well as the microcanonical entropies, internal energies, and speciﬁc heats for several lattice sizes can be found at www.elsevierdirect.com. 508 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models 13.5 The spherical model in arbitrary dimensions In the wake of Onsager’s solution to the two-dimensional Ising problem in zero ﬁeld, sev- eral attempts were made to go beyond Onsager — by solving either the three-dimensional problem in zero ﬁeld or the two-dimensional problem with ﬁeld. None of these attempts succeeded; the best one could accomplish was to rederive the Onsager solution by newer means. This led to the suggestion that one may instead consider certain “adaptations” of the Ising model, which may turn out to be mathematically tractable in more than two dimensions and hopefully throw some light on the problem of phase transitions in more realistic situations (where d is usually 3). One such adaptation was devised by Kac who, in 1947, considered a model in which the spin variable σi, instead of being restricted to the discrete choices −1 or +1, could vary continuously, from −∞ to +∞, subject to a Gaussian probability distribution law, p(σi)dσi = (A/π) 1/2e−Aσ 2 i dσi (i = 1, . . . , N), (1) so that σ 2 i , on an average, = 1/(2A). Clearly, for conformity with the standard practice, namely σ 2 i = 1, the constant A here should be equal to 1 2 ; we may, however, leave it arbi- trary for the time being. The resulting model is generally referred to as the Gaussian model, and its partition function in the presence of the ﬁeld is given by the multiple integral QN = +∞∫ −∞ · · · +∞∫ −∞ ( A π )N/2 e−A ∑ i σ 2 i +K ∑ n.n. σiσj+h ∑ i σi ∏ i dσi (K = βJ, h = βµB). (2) The exponent in the integrand is a symmetric, quadratic function in the σi; using standard techniques, it can be diagonalized. Integrations over the (transformed) σj can then be car- ried out straightforwardly — and in any number of dimensions; for details, see Berlin and Kac (1952) or Baker (1990). One ﬁnds that for d > 2 the Gaussian model undergoes a phase transition at a ﬁnite temperature Tc which, for a simple hypercubic lattice, is determined by the condition Kc = A/d; note that, with A = 1 2 , this result is precisely the one predicted by the mean ﬁeld theory (with q = 2d). There are differences, though. First of all, the present model does not exhibit a phase transition at a ﬁnite temperature for d ≤ 2. Secondly, the critical exponents for 2 < d < 4 are nonclassical, in the sense that some of them are d-dependent, though for d > 4 they do become classical. More importantly, at temperatures below Tc, where K exceeds A/d, the integral in (2) diverges and the model breaks down! This led Kac to aban- don this model and invent a new one in which the spins were again continuous variables but subject to an overall constraint, ∑ i σ 2 i = N, (3) 13.5 The spherical model in arbitrary dimensions 509 rather than to individual constraints, σ 2 i = 1 for each i, or to an arbitrary probability distribution law. Constraint (3) allows individual spins to vary over a rather wide range, −N 1/2 to +N 1/2, but restricts the super spin vector {σi} to the “surface of an N-dimensional hypersphere of radius N 1/2”; in the Ising model, the same vector is restricted to the “cor- ners of a hypercube inscribed within the above hypersphere.” The resulting model is generally referred to as the spherical model. Constraint (3) can be taken care of by inserting an appropriate delta function in the integrand of the partition function. Using the representation δ ( N − ∑ i σ 2 i ) = 1 2πi x+i∞∫ x−i∞ ez(N−∑ i σ 2 i )dz, (4) the partition function of the spherical model is given by QN = 1 2πi x+i∞∫ x−i∞ dz e zN +∞∫ −∞ · · · +∞∫ −∞ e−z ∑ i σ 2 i +K ∑ n.n. σiσj+h ∑ i σi ∏ i dσi. (5) For a ﬁxed z, the integral over the σi can be carried out in the same manner as in the Gaus- sian model; see equation (2). Let the result of that calculation be denoted by the symbol ZN (K , h; z). The partition function QN of the spherical model is then given by the complex integral QN = 1 2πi x+i∞∫ x−i∞ dz e zN ZN (K , h; z), (6) which can be evaluated by the saddle-point method — also known as the method of steep- est descent; see Section 3.2. One ﬁnds that the saddle point of the integrand in (6) lies at the point z = x0, where x0 is determined by the condition ∂ ∂z {zN + ln ZN (K , h; z)}∣ ∣ ∣ ∣ z=x0 = 0, (7) with the result that, asymptotically, 1 N ln QN ≈ x0 + 1 N ln ZN (K , h; x0). (8) The thermodynamic properties of the system can then be worked out in detail. It turned out that many physicists felt uncomfortable at the necessity of using the method of steepest descent, so a search for an alternative approach seemed desirable. In this connection Lewis and Wannier (1952) pointed out that while the ensemble underlying the model of Berlin and Kac was canonical in the variable E it was microcanonical in the variable ∑i σ 2 i . They proposed that one consider instead an ensemble that is canonical in 510 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models both E and ∑i σ 2 i ; the method of steepest descent could then be avoided. All one requires now is that the constraint (3) be obeyed only in the sense of an ensemble average, 〈 ∑ i σ 2 i 〉 = N, (9) rather than in the original sense that was comparatively more rigid. The resulting model is referred to as the mean spherical model. Constraint (9) can easily be taken care of by modifying the Hamiltonian of the system by including a term proportional to ∑i σ 2 i , that is, by writing H = −J ∑ n.n. σiσj − µB ∑ i σi + λ ∑ i σ 2 i , (10) where λ is the so-called spherical ﬁeld, and requiring that ⟨(∂H/∂λ)⟩ = N. (11) The partition function of the revised model is thus given by QN = +∞∫ −∞ · · · +∞∫ −∞ e−βλ ∑ i σ 2 i +K ∑ n.n. σiσj+h ∑ i σi ∏ i dσi (12a) = ZN (K , h; βλ), (12b) with the constraint 1 β ∂ ln ZN (K , h; βλ) ∂λ = −N. (13) Comparing (13) with (7), we readily see that the parameter x0 of the spherical model is precisely equal to the parameter βλ of the mean spherical model. The free energy result- ing from (12), however, differs a little from the one given by equation (8), which is not surprising because the transition from a model that was microcanonical in the variable S 2(≡ ∑i σ 2 i ) to one that is canonical modiﬁes the nature of the free energy — it goes from “being at constant S ” to “being at constant λ.” The two free energies are connected by the Legendre transformation Aλ = A S + λ⟨S 2⟩ = A S + λN, (14) so that 1 N A S = 1 N Aλ − λ. (15) This is precisely the difference that arises from the use of expression (8) or expression (12). 13.5 The spherical model in arbitrary dimensions 511 We now proceed to examine the thermodynamic properties of the mean spherical model, especially the nature of its critical behavior in arbitrary dimensions. The impor- tance of these results will be discussed toward the end of this section. The thermodynamic functions We consider a simple hypercubic lattice, of dimensions L1 × · · · × Ld, subject to periodic boundary conditions. The partition function of the system, as given by equation (12a), then turns out to be (see Joyce, 1972; Barber and Fisher, 1973) ZN (K , h; βλ) = ∏ k [ π β(λ − µk) ]1/2 eNh2/4β(λ−µ0), (16) where µk are the eigenvalues of the problem, µk = J d∑ j=1 cos(kja), kj = 2πnj Lj {nj = 0, 1, . . . , (Nj − 1)}, (17a) Nj = Lj/a, N = ∏ j Nj, (17b) and a the lattice constant of the system. The free energy Aλ is then given by Aλ = 1 2β ∑ k ln β(λ − µk) π − Nµ2B2 4(λ − µ0) , (18) while the parameter λ is determined by the constraint equation, see equation (13), 1 2β ∑ k 1 (λ − µk) + Nµ2B2 4(λ − µ0)2 = N. (19) The magnetization M and the low-ﬁeld susceptibility χ0 follow readily from equa- tion (18): 3 M = Nµ2B 2(λ − µ0) , χ0 = Nµ2 2(λ − µ0) . (20a, b) Introducing the variable m(≡ M/Nµ), the constraint equation (19) may be written in the form ∑ k 1 (λ − µk) = 2Nβ(1 − m 2). (21) 3Note, however, that to calculate the ﬁeld-dependent susceptibility, (∂M/∂B)T ,S , subject to the spherical constraint (19), one must keep in mind the ﬁeld dependence of λ while differentiating (20a). 512 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models Next, the entropy of the system in zero ﬁeld is given by4 S0 = −(∂A/∂T )µk ,B=0 = 1 2 kB ∑ k [1 − ln{β(λ − µk)}] (22) and the corresponding speciﬁc heat by C0 = T ( ∂S0 ∂T ) = 1 2 kB ∑ k [ 1 − T (∂λ/∂T )0 (λ − µk) ] = N [ 1 2 kB − ( ∂λ ∂T ) 0 ] ; (23) here, use has been made of equation (19), with B = 0. To make further progress we need to determine λ, as a function of B and T , from the constraint equation (19). But ﬁrst note, from equation (18), that for the free energy of the system to be well-behaved, λ must be larger than the largest eigenvalue µ0 — which, by (17a), is equal to Jd. At the same time, equation (20b) tells us that the singularity of the problem presumably lies at λ = µ0. We may thus infer that, as T decreases from higher values downward, λ also decreases and eventually reaches its lowest possible value, µ0, at some critical temperature, Tc, where the system undergoes a phase transition. The condition for criticality, therefore, is λc = µ0 = Jd, (24) which suggests that we may introduce a “reduced ﬁeld,” φ, by the deﬁnition φ = (λ − λc)/J = (λ/J) − d; (25) the condition for criticality then becomes φc = 0. (26) It follows that, as we approach the critical point from above, the parameter φ becomes much smaller than unity; ultimately, it becomes zero as Tc is reached and stays so for all T < Tc. Now, substituting for the eigenvalues µk into the sum appearing in equations (19) and (21), and making use of the representation 1 z = ∞∫ 0 e−zxdx, (27) 4We denote Boltzmann’s constant by the symbol kB here so as to avoid confusion with the wavenumber k. 13.5 The spherical model in arbitrary dimensions 513 we have ∑ k 1 (λ − µk) = 1 J ∑ {nj} ∞∫ 0 exp    −  φ + d∑ j=1 { 1 − cos ( 2π nj Nj )}  x    dx = 1 J ∞∫ 0 e−φx ∏ j   Nj−1 ∑ nj=0 exp { −x + x cos ( 2π nj Nj )}  dx. (28) For Nj ≫ 1, the summation over nj may be replaced by integration; writing θj = 2π nj/Nj, one gets ∑ nj exp{· · · } ≈ 2π∫ 0 e−x+x cos θj Nj 2π dθj = Nje−xI0(x), (29) where I0(x) is a modiﬁed Bessel function. Multiplying over j, one ﬁnally gets ∑ k 1 λ − µk = N J Wd(φ), (30) where Wd(φ) is the so-called Watson function, deﬁned by5 Wd(φ) = ∞∫ 0 e−φx[e−xI0(x)]ddx. (31) Equations (19) and (21) now take the form Wd(φ) = 2K − (βµB)2 2K φ2 (32a) = 2K (1 − m 2). (32b) The asymptotic behavior of the functions Wd(φ), for φ ≪ 1, is examined in Appendix G. The critical behavior We now analyze the various physical properties of the mean spherical model in different regimes of d. (a) d < 2. For this regime we take expression (7a) of Appendix G and substitute it into equation (32a), with B = 0. We obtain φ|B=0 ≈ [ 0{(2 − d)/2} 2(2π)d/2K ]2/(2−d) ∼ ( kBT J )2/(2−d) . (33) 5Note that our deﬁnition of the function Wd(φ) differs slightly from the one adopted by Barber and Fisher (1973); this difference arises from the fact that our J is twice, and our φ is one-half, of theirs. 514 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models We see that φ in this case goes to zero only as T → 0. The phase transition, therefore, takes place at Tc = 0. Equations (20b), (23), (24), and (25) then give the following for the low-temperature susceptibility χ0 = Nµ2 2Jφ ∼ Nµ2 J ( kBT J )−2/(2−d) (34) and for the low-temperature speciﬁc heat C0 − 1 2 NkB = −NJ ( ∂φ ∂T ) 0 ∼ −NkB ( kBT J )d/(2−d) . (35) (b) d = 2. We now use expression (7b) of Appendix G and obtain φ|B=0 ∼ exp(−4πJ/kBT ), (36) so that once again Tc = 0 but now, at low temperatures, χ0 ∼ (Nµ2/J) exp(4π J/kBT ) (37) and C0 − 1 2 NkB ∼ −NkB( J/kBT )2 exp(−4π J/kBT ). (38) (c) 2 < d < 4. We now substitute expression (7c) of Appendix G into equation (32a), with the result Wd(0) − |0{(2 − d)/2}| (2π)d/2 φ(d−2)/2 = 2K − (βµB)2 2K φ2 . (39) The critical point is now determined by setting B = 0 and letting φ → 0; the condition for criticality then turns out to be Kc = 1 2 Wd(0). (40) The variation of φ with T as one approaches the critical point is given by φ|B=0 ≈ [ 2(2π)d/2(Kc − K ) |0{(2 − d)/2}| ]2/(d−2) (K ≲ Kc). (41a) We also note that once φ becomes zero it stays so for all temperatures below, that is, φ|B=0 = 0 (K ≥ Kc). (41b) It then follows that χ0 ∼ (Kc − K )−2/(d−2) ∼ (T − Tc)−2/(d−2) (T ≳ Tc) (42) 13.5 The spherical model in arbitrary dimensions 515 and is inﬁnite for T ≤ Tc. At the same time C0 − 1 2 NkB ∼ (T − Tc) (4−d)/(d−2) (T ≳ Tc) (43) and it vanishes for T ≤ Tc. The spontaneous magnetization is determined by equations (32b), (40), and (41b); we obtain a remarkably simple result m0 = (1 − Kc/K )1/2 = (1 − T /Tc) 1/2 (T ≤ Tc). (44) Finally, if in equation (39) we retain B but set T = Tc, we get φc ∼ B4/(d+2) (T = Tc); (45) equation (20a) then gives mc = µB 2Jφc ∼ B(d−2)/(d+2) (T = Tc). (46) The foregoing results give, for the critical exponents of the system, α = d − 4 d − 2 , β = 1 2 , γ = 2 d − 2 , δ = d + 2 d − 2 (2 < d < 4). (47) (d) d > 4. In this regime we employ expression (8) of Appendix G. The condition for criticality remains the same as in (40); the variation of φ with T as we approach the critical point is, however, different. We now have, for all d > 4, φ|B=0 ∼ (Kc − K )1 (K ≲ Kc). (48) The subsequent results are modiﬁed accordingly: χ0 ∼ (T − Tc) −1, C0 − 1 2 NkB ∼ (T − Tc) 0 (T ≳ Tc) (49) φc ∼ B2/3, mc ∼ B1/3 (T = Tc). (50) Equations (41b) and (44) continue to apply as such. We, therefore, conclude that α = 0, β = 1 2 , γ = 1, δ = 3 (d > 4). (51) (e) d = 4. For this borderline case, we use expression (12) of Appendix G. Once again, the condition for criticality remains the same; however, the variation of φ with T as one approaches the critical point is now determined by the implicit relation φ ln(1/φ) ≈ 8π 2(Kc − K ) (K ≲ Kc). (52) 516 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models Introducing the conventional parameter t = (T − Tc)/Tc = (Kc − K )/K , (53) we get, to leading order in t, φ|B=0 ∼ t/ ln(1/t) (0 < t ≪ 1). (54) It follows that χ0 ∼ t−1 ln(1/t), C0 ∼ 1/ ln(1/t) (0 < t ≪ 1) (55) φc ∼ B2/3/{ln(1/B)} 1/3, mc ∼ {B ln(1/B)}1/3 (t = 0). (56) Spin–spin correlations Following the procedure that led to equations (16) through (19), we obtain in the absence of the ﬁeld G(r, r′) ≡ σ (r)σ (r′) = 1 2Nβ ∑ k exp{i(k · R)} λ − µk (R = r − r′); (57) compare to equation (19), with B = 0. The summation over k in (57) can be handled in the same manner as was done in (28); however, the resulting summation over nj now turns out to be ∑ nj {· · · } ≈ 2π∫ 0 exp{iRjθj/a}e−x+x cos θj Nj 2π dθj = Nje−xIRj/a(x); (58) compare to (29). This leads to the result G(R) = 1 2K ∞∫ 0 e−φx ∏ j [e−xIRj/a(x)]dx; (59) compare to equation (32a), with B = 0. For the functions In(x) we may use the asymptotic expression (see Singh and Pathria, 1985a) In(x) ≈ ex−n2/2x √(2π x) (x ≫ 1), (60) 13.5 The spherical model in arbitrary dimensions 517 so that, for φ ≪ 1, G(R) ≈ 1 2(2π)d/2K ∞∫ 0 e−φx−R2/(2a2x)x−d/2dx = 1 (2π)d/2K ( a2 ξ R )(d−2)/2 K(d−2)/2 ( R ξ ) , (61) where Kµ(x) is the other modiﬁed Bessel function while ξ = a/(2φ)1/2. (62) For R ≫ ξ , we may use the asymptotic result Kµ(x) ≈ (π/2x)1/2e−x; equation (61) then becomes G(R) ≈ ad−2 2K ξ (d−3)/2(2π R)(d−1)/2 e−R/ξ , (63) which identiﬁes ξ as the correlation length of the system. Now, comparing equation (62) with equation (20b), we ﬁnd that χ0 = Nµ2 2Jφ = Nµ2 Ja2 ξ 2. (64) In view of the fact that ξ ∼ χ 1/2 0 , we infer that, in all regimes of d, the exponent ν = 1 2 γ and hence, by relations (12.12.10) and (12.12.11), the exponent η = 0. To obtain this last result directly from equation (61), we observe that, as T → Tc from above, the parameter φ → 0 and hence ξ → ∞. We may then use the approximation R/ξ ≪ 1 and employ the formula Kµ(x) ≈ 1 2 0(µ) ( 1 2 x)−µ (µ > 0), (65) to obtain G(R)|T =Tc ≈ 0{(d − 2)/2} 4π d/2Kc ad−2 Rd−2 (d > 2). (66) The power of R appearing here clearly shows that η = 0. Finally, substituting equation (41a) into equation (62), we get ξ ≈ 1 2 a [ |0{(2 − d)/2}| 4π d/2(Kc − K ) ]1/(d−2) (K ≲ Kc), (67) which shows that for 2 < d < 4 the critical exponent ν = 1/(d − 2). For T < Tc we expect the function G(R) to afﬁrm the presence of long-range order in the system, that is, in the limit R → ∞, it should tend to a limit, σ 2, that is nonzero. To 518 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models demonstrate this property of G(R), we need to take a closer look at the derivations of this subsection that were carried out with the express purpose of obtaining results valid in the thermodynamic limit (N → ∞). This resulted in “errors” that were negligible in the region T ≳ Tc but are not so when T < Tc. The ﬁrst such error crept in when we replaced the sum- mations over {nj} in equation (28) by integrations; that suppressed contribution from the term with n = 0. Equation (30), therefore, accounts for only the (k ̸= 0)-terms of the orig- inal sum in (28), and the missing term, 1/Jφ, may be added to it ad hoc. 6 Equation (19), with B = 0, then becomes 1 2β [ 1 Jφ + N J Wd(φ) ] = N. (68) Now, when φ becomes very very small, Wd(φ) may be approximated by Wd(0), which is precisely equal to 2Kc; equation (68) then gives φ ≈ [2N(K − Kc)]−1 (K > Kc), (69) rather than zero! The correlation length then turns out to be ξ = a/(2φ) 1/2 ≈ a[N(K − Kc)] 1/2 (K > Kc), (70) rather than inﬁnite! Now, the same error was committed once again in going from equation (57) to (59); so, the primary result for G(R), as given in equation (61), may be similarly amended by adding the missing term 1/(2NβJφ) which, by (69), is exactly equal to (1 − Kc/K ). Thus, for R ≪ ξ , we obtain, instead of (66), G(R) ≈ (1 − Kc K ) + 0{(d − 2)/2} 4π d/2K ad−2 Rd−2 (K > Kc). (71) Now if we let R → ∞, G(R) does approach a nonzero value σ 2, which is precisely the same as m2 0 given by equation (44). It is remarkable, though, that in the present derivation the magnetic ﬁeld B has not been introduced at any stage of the calculation, which under- scores the fundamental role played by correlations in bringing about long-range order in the system. In the preceding paragraph we outlined the essential argument that led to the desired expression, (71), for G(R). For a more rigorous analysis of this problem, see Singh and Pathria (1985b, 1987a). Physical signiﬁcance of the spherical model With a constraint as relaxed as in equation (3), or even more so in (9), one wonders how meaningful the spherical model is from a physical point of view. Relief comes from the fact, ﬁrst established by Stanley (1968, 1969a,b), that the spherical model provides a correct 6This is reminiscent of a similar problem, and a similar ad hoc solution, encountered in the study of Bose–Einstein condensation in Section 7.1; see also Section 13.6. 13.6 The ideal Bose gas in arbitrary dimensions 519 representation of the (n → ∞)-limit of an n-vector model with nearest-neighbor interac- tions; see also Kac and Thompson (1971). This connection arises from the very nature of the constraint imposed on the model, which introduces a super spin vector S with N degrees of freedom; it is not surprising that, in the limit N → ∞, the model in some sense acquires the same sort of freedom that an n-vector model has in the limit n → ∞. In any case, this connection brings the spherical model in line with, and actually makes it a good guide for, all models with continuous symmetry, namely the ones with n ≥ 2. And since it can be solved exactly in arbitrary dimensions, this model gives us some idea as to what to expect of models for which n is ﬁnite. For instance, we have seen that, for d > 4, the critical exponents of the spherical model are the same as the ones obtained from the mean ﬁeld theory. Now, ﬂuctuations are neglected in the mean ﬁeld theory but, among the variety of models we are considering, ﬂuctuations should be largest in the spherical model, for it has the largest number of degrees of freedom. If, for d > 4, ﬂuctuations turn out to be negligible in the spherical model, they would be even more so in models with ﬁnite n. It thus follows that, regardless of the actual value of n, mean ﬁeld theory should be valid for all these models when d > 4. See, in this connection, Section 14.4 as well. For d < 4, the ﬁnal results depend signiﬁcantly on n. The spherical model now provides a starting point from which one may carry out the so-called (1/n)-expansions to determine how models with ﬁnite n might behave in this regime. Such an approach was initiated by Abe and collaborators (1972, 1973) and independently by Ma (1973); for a detailed account of this approach, along with the results following from it, see Ma (1976c). Finally, for a comprehensive discussion of the spherical model, including the one with long-range interactions, see the review article by Joyce (1972). 13.6 The ideal Bose gas in arbitrary dimensions In this section we propose to examine the problem of Bose–Einstein condensation in an ideal Bose gas in arbitrary dimensions. As was ﬁrst shown by Gunton and Buckingham (1968), the phenomenon of Bose–Einstein condensation falls in the same universality class as the phase transition in the spherical model; accordingly, the ideal Bose gas too corre- sponds to the (n → ∞)-limit of an n-vector model. It must, however, be borne in mind that liquid He 4, whose transition from a normal to a superﬂuid state is often regarded as a manifestation of the “Bose–Einstein condensation in an interacting Bose liquid,” actually pertains to the case n = 2. Now, just as the spherical model turns out to be a good guide for all models with continuous symmetry including the X Y model (for which n = 2), in the same way the ideal Bose gas has also been a good guide for liquid He4. We consider a Bose gas composed of N noninteracting particles conﬁned to a box of volume V (= L1 × · · · × Ld) at temperature T . Following the procedure of Section 7.1, we obtain for the pressure P of the gas P = − kBT V ∑ ε ln(1 − ze−βε) = kBT λd g(d+2)/2(z), (1) 520 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models where λ[= h/ √(2π mkBT )] is the mean thermal wavelength of the particles, z is the fugacity of the gas, which is related to the chemical potential µ through the formula z = exp(βµ) < 1 (β = 1/kBT ), (2) while gν(z) are Bose–Einstein functions whose main properties are discussed in Appen- dix D. The quantity z is determined by the equation N = ∑ ε (z−1eβε − 1) −1 = N0 + Ne, (3) where N0 is the mean number of particles in the ground state (ε = 0), N0 = z/(1 − z), (4) while Ne is the mean number of particles in the excited states (ε > 0): Ne = V λd gd/2(z). (5) At high temperatures, where z is signiﬁcantly below the limiting value 1, N0 is negligible in comparison with N; the quantity z is then determined by the simpliﬁed equation N = V λd gd/2(z), (6) and the pressure P in turn is given by the expression P = NkBT V g(d+2)/2(z) gd/2(z) . (7) The internal energy of the gas may be obtained from the relationship U = 1 2 d(PV ); (8) see the corresponding derivation of equation (7.1.12) as well as of equation (6.4.4). Now, making use of the recurrence relation (D.10) and remembering that the mean thermal wavelength λ ∝ T −1/2, we get from equation (6) 1 z ( ∂z ∂T ) v = − d 2T gd/2(z) g(d−2)/2(z) (v = V N ) , (9) and from equation (1) 1 z ( ∂z ∂T ) P = − d + 2 2T g(d+2)/2(z) gd/2(z) . (10) 13.6 The ideal Bose gas in arbitrary dimensions 521 It is now straightforward to show that the speciﬁc heats CV and CP of the gas are given by the formulae CV NkB = d(d + 2) 4 g(d+2)/2(z) gd/2(z) − d2 4 gd/2(z) g(d−2)/2(z) (11) and CP NkB = (d + 2)2 4 {g(d+2)/2(z)}2g(d−2)/2(z) {gd/2(z)}3 − d(d + 2) 4 g(d+2)/2(z) gd/2(z) , (12) respectively; it follows that the ratio CP CV = (d + 2) d g(d+2)/2(z)g(d−2)/2(z) {gd/2(z)}2 . (13) The isothermal compressibility κT and the adiabatic compressibility κS turn out to be κT = − 1 v ( ∂v ∂P ) T = − 1 v (∂v/∂z)T (∂P/∂z)T = g(d+2)/2(z)g(d−2)/2(z) {gd/2(z)}2 1 P (14) and κS = − 1 v ( ∂v ∂P ) S = − 1 v (∂v/∂T )z (∂P/∂T )z = d d + 2 1 P , (15) respectively; note that the ratio κT /κS is precisely equal to the ratio CP/CV , as is expected thermodynamically. As the temperature of the gas is reduced, keeping v constant, the fugacity z increases and ultimately approaches its limiting value 1 — marking the end of the regime where N0 was negligible in comparison with N. Whether this limit is reached at a ﬁnite T or at T = 0 depends entirely on the value of d; see equation (6), which tells us that if the function gd/2(z), as z → 1−, is bounded then the limit in question will be reached at a ﬁnite T . On the other hand, if gd/2(z), as z → 1−, is unbounded then the desired limit will be reached at T = 0 instead. To settle this question, we refer to equations (D.9) and (D.11), which summarize the behavior of the function gν(z) as z → 1− (or as α → 0+, where α = − ln z); we thus have gd/2(e−α) ≈    0( 2 − d 2 ) α−(2−d)/2 + const. for d < 2 (16a) ln(1/α) + 1 2 α for d = 2 (16b) ζ ( d 2 ) − ∣ ∣ ∣ ∣0 ( 2 − d 2 )∣ ∣ ∣ ∣ α(d−2)/2 for 2 < d < 4 (16c) ζ (2) − {ln(1/α) + 1}α for d = 4 (16d) ζ ( d 2 ) − ζ ( d − 2 2 ) α for d > 4, (16e) 522 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models ζ (ν) being the Riemann zeta function. Similarity of this system with the spherical model is quite transparent. We readily see from equation (6) that, for d > 2, α → 0 at a ﬁnite temperature Tc, given by λd c = vζ (d/2), (17) with the result that Tc = h2 2π mkB [ 1 vζ (d/2) ]2/d ; (18) for d ≤ 2, α → 0 only as λ → ∞, so Tc = 0. For brevity, we conﬁne our further discussion only to d > 2. The critical behavior As T approaches Tc from above, the manner in which α → 0 is determined by substitut- ing the appropriate expression (16) into (6) and utilizing the criticality condition (17). For 2 < d < 4, one gets asymptotically ∣ ∣ ∣ ∣0 ( 2 − d 2 )∣ ∣ ∣ ∣ α(d−2)/2 ≈ 1 v (λ d c − λ d) ≃ d 2 ζ ( d 2 ) [ T Tc − 1 ] . (19) For T ≳ Tc, this gives α ∼ t2/(d−2) [t = (T − Tc)/Tc, 0 < t ≪ 1]. (20) As T → Tc, the speciﬁc heat CP and the isothermal compressibility κT diverge because the function g(d−2)/2(z) appearing in equations (12) and (14), being ∼ α−(4−d)/2 [see equation (D.9)], becomes divergent; for small t, CP ∼ κT ∼ t−(4−d)/(d−2). (21) The speciﬁc heat CV , on the other hand, approaches a ﬁnite value, ( CV NkB ) T →TC + = d(d + 2) 4 ζ {(d + 2)/2} ζ (d/2) , (22) with a derivative that, depending on the actual value of d, might diverge: 1 NkB ( ∂CV ∂T ) V = 1 T [ d2(d + 2) 8 g(d+2)/2(z) gd/2(z) − d2 4 gd/2(z) g(d−2)/2(z) − d3 8 {gd/2(z)}2g(d−4)/2(z) {g(d−2)/2(z)}3 ] (23a) ∼ −α−(d−3) ∼ −t−2(d−3)/(d−2) (3 < d < 4). (23b) 13.6 The ideal Bose gas in arbitrary dimensions 523 Equating the exponent appearing here with (1 + α), we conclude7 that the critical expo- nent α for this system is (d − 4)/(d − 2); compare to equation (13.5.47). For a proper appreciation of the critical behavior of CV , we must as well examine the region T < Tc, along with the limit T → Tc−. For T < Tc, the fugacity z is essentially equal to 1; equations (5) and (17) then give Ne = V λd ζ ( d 2 ) = N ( λc λ )d = N ( T Tc )d/2 . (24) It follows that N0 = N − Ne = N [ 1 − ( T Tc )d/2] . (25) Equation (4) then tells us that the precise value of z in this region is given by z = N0/(N0 + 1) ≃ 1 − 1/N0, (26) which gives α = − ln z ≃ 1/N0, (27) rather than zero. Disregarding this subtlety, equation (1) gives P = kBT λd ζ ( d + 2 2 ) ∝ T (d+2)/2. (28) Since P here is a function of T only, the quantities κT and CP in this region are inﬁnite; see, however, Problem 13.26. From equations (8) and (28), we get U = 1 2 d kBTV λd ζ ( d + 2 2 ) , (29) which gives CV NkB = d(d + 2) 4 v λd ζ ( d + 2 2 ) = d(d + 2) 4 ζ {(d + 2)/2} ζ (d/2) ( T Tc )d/2 . (30) As T → Tc−, we obtain precisely the same limit as in (22) — showing that CV is continuous at the critical point. Its derivative, however, turns out to be different from the one given in 7We equate this exponent with (1 + α) because if CV ∼ t−α, then ∂CV /∂t ∼ t−α−1. We hasten to add that the critical exponent α should not be confused with the physical quantity denoted by the same symbol, namely α(= − ln z), which was introduced just before equations (16) and has been used throughout this section. 524 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models (23), for now 1 NkB ( ∂CV ∂T ) V = 1 Tc d2(d + 2) 8 ζ {(d + 2)/2} ζ (d/2) ( T Tc )(d−2)/2 (31a) → 1 Tc d2(d + 2) 8 ζ {(d + 2)/2} ζ (d/2) (31b) as T → Tc−. As for the condensate fraction, N0/N, equation (25) gives N0 N = 1 − ( T Tc )d/2 ≈ d 2 |t| [t < 0, |t| ≪ 1]. (32) Now, the order parameter in the present problem is a complex number, 90, such that |90|2 = N0/V , the condensate particle density in the system; see Gunton and Buckingham (1968). We therefore, expect that, for |t| ≪ 1, N0 would be ∼ t2β ; equation (32) then tells us that the critical exponent β in this case has the classical value 1 2 for all d > 2. To determine the exponents γ and δ, we must introduce a “complex Bose ﬁeld, conjugate to the order parameter 90” and examine quantities such as the “Bose susceptibility” χ as well as the variation of 90 with the Bose ﬁeld at T = Tc. Proceeding that way, one obtains: γ = 2/(d − 2) and δ = (d + 2)/(d − 2), just as for the spherical model. The pair correlations We now examine the pair correlation function of the ideal Bose gas G(R) = 1 V ∑ k eik·R eα+βε(k) − 1 . (33) As usual, we replace the summation over k by integration (mindful of the fact that this replacement suppresses the (k = 0)-term which may, therefore, be kept aside). Making use of equation (C.11) in Appendix C, we get G(R) = N0 V + 1 (2π)d ∫ eik·R eα+βℏ2k2/2m − 1 ddk = N0 V + 1 (2π)d/2R(d−2)/2 ∞∫ 0   ∞∑ j=1 e−jα−jβℏ2k2/2m   J(d−2)/2(kR)kd/2dk = N0 V + 1 λd ∞∑ j=1 e−jα−π R2/jλ2 j−d/2 [ λ = ℏ ( 2πβ m )1/2] ; (34) compare to equations (3) through (5), which pertain to the case R = 0. For R > 0, one may extend the summation over j from j = 0 to j = ∞, for the term so added is identically zero. 13.6 The ideal Bose gas in arbitrary dimensions 525 At the same time, the summation over j may be replaced by integration — committing errors O(e−R/λ), which are negligible so long as R ≫ λ; for details, see Zasada and Pathria (1976). We thus obtain G(R) = N0 V + 1 λd ∞∫ 0 e−jα−π R2/jλ2 j−d/2dj = N0 V + 2 λ2(2πξ R)(d−2)/2 K(d−2)/2 ( R ξ ) , (35) where Kµ(x) is a modiﬁed Bessel function while ξ = λ/(2π 1/2α1/2). (36) For T ≳ Tc, we may use expression (20) for α; equation (36) then gives ξ ∼ λt−1/(d−2) (0 < t ≪ 1), (37) which means that ξ ≫ λ. Now, if R ≫ ξ , equation (35) reduces to G(R) ≈ 1 λ2(2πξ )(d−3)/2R(d−1)/2 e−R/ξ , (38) which identiﬁes ξ as the correlation length of the system. Equation (37) then tells us that for, 2 < d < 4, the critical exponent ν of the ideal Bose gas is 1/(d − 2). At T = Tc, ξ is inﬁnite; equation (35) now gives G(R) ≈ 0{(d − 2)/2} π (d−2)/2λ2 c Rd−2 , (39) which shows that the critical exponent η = 0. For T < Tc, ξ continues to be inﬁnite but now the condensate fraction, which is a measure of the long-range order in the system, is nonzero. The correlation function then assumes the form G(R) = |90| 2 + A(T ) Rd−2 , (40) where A(T ) = 0{(d − 2)/2} π (d−2)/2λ2 ∝ T ; (41) compare this result to the corresponding equation (13.5.7) of the spherical model. In the paper quoted earlier, Gunton and Buckingham also generalized the study of Bose–Einstein condensation to the single-particle energy spectrum ε ∼ kσ , where σ is a 526 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models positive number not necessarily equal to 2. They found that the phase transition, at a ﬁnite temperature Tc, now took place for all d > σ , and the critical exponents in the regime σ < d < 2σ turned out to be α = d − 2σ d − σ , β = 1 2 , γ = σ d − σ , δ = d + σ d − σ , ν = 1 d − σ , η = 2 − σ . (42) While mathematically correct, these results left one with the awkward conclusion that the Bose gas in its extreme relativistic state (σ = 1) was in a different universality class than the one in the nonrelativistic state (σ = 2). It was shown later by Singh and Pandita (1983) that, if one employs the appropriate energy spectrum ε = c√(m2 0c2 + ℏ2k2) and, at the same time, allows for the possibility of particle–antiparticle pair production in the system, as had been suggested earlier by Haber and Weldon (1981, 1982), then the relativistic Bose gas falls in the same universality class as the nonrelativistic one; see Problem (13.27). 13.7 Other models In Section 13.4 we saw that a two-dimensional lattice model characterized by a discrete order parameter (n = 1) underwent a phase transition, accompanied by a spontaneous magnetization m0, at a ﬁnite temperature Tc; naturally, one would expect the same if d were greater than 2. On the other hand, the spherical model, which is characterized by a continuous order parameter (with n = ∞), undergoes such a transition only if d > 2. The question then arises whether intermediate models, with n = 2, 3, . . ., would undergo a phase transition at a ﬁnite Tc if d were equal to 2. The answer to this important question was provided by Mermin and Wagner (1966) who, making use of a well-known inequality due to Bogoliubov (1962), established the following theorem:8 Systems composed of spins with continuous symmetry (n ≥ 2) and short-range inter- actions do not acquire spontaneous magnetization at any ﬁnite temperature T if the space dimensionality d ≤ 2. In this sense, systems with n ≥ 2 behave in a manner similar to the spherical model — and quite unlike the Ising model! The marginal case (n = 2, d = 2), however, deserves a special mention. Clearly, this refers to an XY model in two dimensions, which has a direct relevance to superﬂuid He4 adsorbed on a substrate. As shown by Kosterlitz and Thouless (1972, 1973), this model exhibits a curious phase transition in that, while no long-range order develops at any ﬁnite temperature T , various physical quantities such as the susceptibility, the correla- tion length, the speciﬁc heat, and the superﬂuid density do become singular at a ﬁnite temperature Tc, whose precise value is determined by point defects, such as vortices or 8For a review of this theorem and other allied questions, see (Grifﬁths, 1972, pp. 84–89). 13.7 Other models 527 dislocations, in the system. The correlation length ξ , as T → Tc+, displays an essential singularity, ξ ∼ eb′/(T −Tc)1/2 , (1) where b′ is a nonuniversal constant; of course, the critical temperature itself is nonuni- versal and, for a square lattice, is given by Kc = J/kTc ≃ 1.12 ; (2) see Hasenbusch and Pinn (1997) and Dukovski, Machta, and Chayes (2002). The singular part of the speciﬁc heat shows a somewhat similar behavior, namely c(s) ∼ ξ −2 (3) which, measured against a regular background, is rather indetectable since every deriva- tive of the speciﬁc heat is ﬁnite at the critical point, yet the function is nonanalytic. The superﬂuid density behaves rather strangely; it approaches a ﬁnite value, as T → Tc−, pre- ceded by a square-root cusp. The correlation function is no different; at T = Tc, Kosterlitz (1974) found a logarithmic factor along with a power law, namely g(r) ∼ [ln(r/a)]1/8 r1/4 , (4) while for T < Tc we encounter a temperature-dependent exponent η such that g(r) ∼ 1 rη(T ) , (5) where η(T ) ≈ kT /2π J, for kT ≪ J, as shown by Berezinskii (1970) and η(Tc) = 1/4, as shown by Kosterlitz (1974); see Berche, Sanchez, and Paredes (2002) for a numerical determi- nation of η(T ). This phase, with a power-law decay of correlations, is said to display quasi-long-range order. For further details of this transition, see Kosterlitz and Thouless (1978) and Nelson (1983); for a pedagogical account, see Plischke and Bergersen (1989), Section 5.E. For other exactly soluble models in two dimensions, see Baxter (1982), Wu (1982), Nienhuis (1987), and Cardy (1987), where references to other relevant literature on the subject can also be found. We now proceed to consider the situation in three dimensions. Here, no exact solutions exist except for the extreme case n = ∞, which has been discussed in Section 13.5. However, an enormous amount of effort has been spent in obtaining approximate solutions which, over the years, have become accurate enough to be regarded as “almost exact.” Irrespective of the model under study, the problem has generally been attacked along three different lines which, after some reﬁnements, have led to almost identical results. In summary, these approaches may be described as follows. 528 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models The method of series expansions In this approach, the partition function or other relevant properties of the system are expanded as a high-temperature series such as (13.4.5), with expansion parameter v = tanh(βJ), or as a low-temperature series such as (13.4.9), with expansion parameter w = exp(−2βJ); in the presence of an external ﬁeld, one would have series with two expan- sion parameters instead of one. In either case, the ﬁrst major task involves the numerical computation of coefﬁcients, such as n(r) and m(r), on the basis of graph theory and other allied techniques, while the second major task involves analysis of these coefﬁcients with a view to determining the location and the nature of the singularity governing the prop- erty in question. The latter task is generally accomplished by employing the ratio method, which examines the trend of the ratio of two consecutive coefﬁcients, such as n(r) and n(r − 1), as r → ∞, or by constructing Pad´e approximants which, in a sense, provide a con- tinuation of the known (ﬁnite) series beyond its normal range of validity up to its radius of convergence — thus locating and examining the nature of the relevant singularity. Since their inception (in the mid-1950s for the ratio method and the early 1960s for the Pad´e approximants), these techniques have been expanded, reﬁned, and enriched in so many ways that it would be hopeless to attempt a proper review of them here. Sufﬁce it to say that the reader may refer to Volume 3 of the Domb–Green series, which is devoted solely to the method of series expansions — in particular, to the articles by Gaunt and Guttmann (1974) on the asymptotic analysis of the various coefﬁcients, by Domb (1974) on the Ising model, by Rushbrooke, Baker, and Wood (1974) on the Heisenberg model, by Stanley (1974) on the n-vector models, and by Betts (1974) on the X Y model. For more recent reviews, see Guttmann (1989) and Baker (1990), where references to other relevant work on the subject are also available. The renormalization group method This method is based on the crucial observation (Wilson, 1971) that, as the critical point is approached, the correlation length of the system becomes exceedingly large — with the result that the sensitivity of the system to a length transformation (or renormalization) gets exceedingly diminished. At the critical point itself, the correlation length becomes inﬁnite and, with it, the system becomes totally insensitive to such a transformation! The ﬁxed point of the transformation is then identiﬁed with the critical point of the system, and the behavior of the system parameters such as K and h, see equation (13.5.2), in the neighborhood of the ﬁxed point determines the critical exponents, and so on. Since very few systems could be solved exactly, approximation procedures had to be developed to handle most of the cases under study. One such procedure starts with known results for the upper critical dimension d = 4 and carries out expansions in terms of the (small) parameter ε = 4 − d, while the other starts with known results for the spherical model (n = ∞) and carries out expan- sions in terms of the (small) parameter 1/n; in the former case, the coefﬁcients of the expansion would be n-dependent, while in the latter case they would be d-dependent. 13.7 Other models 529 Highly sophisticated manipulations enable one to obtain reliable results for ε that are as large as 1 (which corresponds to the most practical dimension d = 3) and for n as small as 1 (which corresponds to a large variety of systems that can be described through an order parameter that is scalar). We propose to discuss this method at length in Chapter 14; for the present, sufﬁce it to say that the reader interested in further details may refer to Volume 6 of the Domb–Green series, which is devoted entirely to this topic. Monte Carlo methods As the name implies, these methods employ pseudorandom numbers to simulate statis- tical ﬂuctuations for carrying out numerical integrations and computer simulations of systems with large numbers of degrees of freedom. Such methods have been in vogue for quite some time and, fortunately, have kept pace with developments along other lines of approach — so much so that they have adapted themselves to the ideas of the renormaliza- tion group as well (see Ma, 1976b). The interested reader may refer to Binder (1986, 1987, 1992), Frenkel and Smit (2002), Binder and Heermann (2002), and Landau and Binder (2009). We propose to discuss computer simulation methods further in Chapter 16. As mentioned earlier, the aforementioned methods lead to results that are mutually compatible and, within the stated margins of error, essentially identical. Table 13.1 lists the generally accepted values of the critical exponents of a three-dimensional system with n = 0, 1, 2, 3, and ∞. It includes all the major exponents except α, which can be deter- mined by using the scaling relation α + 2β + γ = 2 (or the hyperscaling relation dν = 2 − α); we thus obtain, for n = 0, 1, 2, 3, and ∞, α = 0.235, 0.111, −0.008, −0.114, and −1, respec- tively — of course, with appropriate margins of error. The theoretical results assem- bled here may be compared with the corresponding experimental ones listed earlier in Table 12.1, remembering that, while all other entries there are Ising-like (n = 1), the case of superﬂuid He 4 pertains to n = 2. Table 13.1 includes exponents for the case n = 0 as well. This relates to the fact that if the spin dimensionality n is treated as a continuously varying parameter then the limit n → 0 corresponds to the statistical behavior of self-avoiding random walks and hence of polymers (de Gennes, 1972; des Cloizeaux, 1974). The role of t in that case is played by the parameter 1/N, where N is the number of steps constituting the walk or the number of Table 13.1 Theoretical Values of the Critical Exponents in Three Dimensions n = 0 n = 1 n = 2 n = 3 n = ∞ β 0.302 ± 0.004 0.324 ± 0.006 0.346 ± 0.009 0.362 ± 0.012 0.5 γ 1.161 ± 0.003 1.241 ± 0.004 1.316 ± 0.009 1.39 ± 0.01 2.0 δ 4.85 ± 0.08 4.82 ± 0.06 4.81 ± 0.08 4.82 ± 0.12 5.0 ν 0.588 ± 0.001 0.630 ± 0.002 0.669 ± 0.003 0.705 ± 0.005 1.0 η 0.026 ± 0.014 0.031 ± 0.011 0.032 ± 0.015 0.031 ± 0.022 0.0 Source: After Baker (1990). 530 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models monomers constituting the polymer chain; thus, the limit N → ∞ corresponds to t → 0, whereby one approaches the critical point of the system. Concepts such as the correlation function, the correlation length, the susceptibility, the free energy, and so on, can all be introduced systematically into the problem and one obtains a well-deﬁned model that ﬁts neatly with the rest of the family. For details, see de Gennes (1979) and des Cloizeaux (1982). 9 Finally, we look at the situation with d ≥ 4. As mentioned earlier, especially toward the end of Section 13.5, critical exponents for d > 4 are independent of n and have values as predicted by the mean ﬁeld theory. To recapitulate, they are: α = 0, β = 1 2 , γ = 1, δ = 3, ν = 1 2 , η = 0. (6) At the borderline dimensionality d = 4, two nonclassical features appear. First, the nature of the singularity is such that it cannot be represented by a power law alone; logarithmic factors are also present. Second, the dependence on n shows up in a striking fashion. In this context, we simply quote the results; for details, see Br´ezin et al. (1976): c(s) ∼ | ln t|(4−n)/(n+8) (h = 0, t ≳ 0) (7) m0 ∼ |t| 1/2| ln |t||3/(n+8) (h = 0, t ≲ 0) (8) χ ∼ t−1| ln t| (n+2)/(n+8) (h = 0, t ≳ 0) (9) h ∼ m3| ln m| −1 (t = 0, h ≳ 0), (10) along with the fact that η = 0 and hence ξ ∼ χ 1/2. In the limit n → ∞, these results go over to the ones pertaining to the spherical model; see Section 13.5. Problems 13.1. Making use of expressions (12.3.17) through (12.3.19), (13.2.12), and (13.2.13), show that the expectation values of the numbers N+, N−, N++, N−−, and N+− in the case of an Ising chain are N ± = N P(β, B) ± sinh(βµB) 2P(β, B) , N ++ = N 2D(β, B) eβµB[P(β, B) + sinh(βµB)], N −− = N 2D(β, B) e−βµB[P(β, B) − sinh(βµB)] 9Values of n other than the ones appearing in Table 13.1 are sometimes encountered. For instance, certain antiferro- magnetic order–disorder transitions require for their description an order parameter with n = 4, 6, 8, or 12; see Mukamel (1975), and Bak, Krinsky, and Mukamel (1976). Another example of this is provided by the superﬂuidity of liquid He3, which seems to require an order parameter with n = 18; see, for instance, Anderson (1984), and Vollhardt and W¨olﬂe (1990). Even negative values of n have been investigated; see Balian and Toulouse (1973) and Fisher (1973). Problems 531 and N +− = N D(β, B) e−4βJ , where P(β, B) = {e−4βJ + sinh2(βµB)} 1/2 and D(β, B) = P(β, B)[P(β, B) + cosh(βµB)]. Check that (i) the preceding expressions satisfy the requirement that N ++ + N −− + N +− = N and (ii) they agree with the quasichemical approximation (12.6.22), regardless of the value of B. 13.2. (a) Show that the partition function of an Ising lattice can be written as QN (B, T ) = ∑′ N+,N+−gN (N+, N+−) exp{−βHN (N+, N+−)}, where HN (N+, N+−) = −J ( 1 2 qN − 2N+− ) − µB(2N+ − N), while other symbols have their usual meanings; compare these results to equations (12.3.19) and (12.3.20). (b) Next, determine the combinatorial factor gN (N+, N+−) for an Ising chain (q = 2) and show that, asymptotically, ln gN (N+, N+−) ≈ N+ ln N+ + (N − N+) ln(N − N+) − ( N+ − 1 2 N+− ) ln ( N+ − 1 2 N+− ) − ( N − N+ − 1 2 N+− ) ln ( N − N+ − 1 2 N+− ) − 2 ( 1 2 N+− ) ln ( 1 2 N+− ) . Now, assuming that ln QN ≈ (the logarithm of the largest term in the sum ∑′), evaluate the Helmholtz free energy A(B, T ) of the system and show that this leads to precisely the same results as the ones quoted in the preceding problem as well as the ones obtained in Section 13.2. 13.3. Using the approximate expression, see Fowler and Guggenheim (1940), gN (N1, N12) ≃ ( 1 2 qN) ! N11! N22! [( 1 2 N12) ! ]2 ( N1! N2! N! )q−1 , for evaluating the partition function of an Ising lattice, show that one is led to the same results as the ones following from the Bethe approximation. [Note that, for q = 2, the quantity ln g here is asymptotically exact; see Problem 13.2(b). No wonder that the Bethe approximation gives exact results in the case of an Ising chain.] 13.4. Making use of relation (13.2.37), along with expressions (13.2.8) for the eigenvalues λ1 and λ2 of the transfer matrix P, determine the correlation length ξ(B, T ) of the Ising chain in the presence of a magnetic ﬁeld. Evaluate the critical exponent νc, as deﬁned in Problem 12.25, and check that νc = ν/1, where ν and 1 are standard exponents deﬁned in Sections 12.10 and 12.12. 532 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models 13.5. Consider a one-dimensional Ising system in a ﬂuctuating magnetic ﬁeld B, so that QN (s, T ) ∼ ∞∫ −∞ dB ∑ {σi} exp { − βNB2 2s + N∑ i=1[βµBσi + βJσiσi+1] } , with σN+1 = σ1. Note that when the system is very large (i.e., N ≫ 1) the typical value of B is very small; nevertheless, the presence of this small ﬂuctuating ﬁeld leads to an order–disorder transition in this one-dimensional system! Determine the critical temperature of this transition. 13.6. Solve exactly the problem of a ﬁeld-free Ising chain with nearest-neighbor and next-nearest-neighbor interactions, so that H{σi} = −J1 ∑ i σiσi+1 − J2 ∑ i σiσi+2, and examine the various properties of interest of this model. [Hint: Introduce a new variable τi = σiσi+1 = ±1, with the result that H{τi} = −J1 ∑ i τi − J2 ∑ i τiτi+1, which is formally similar to expression (13.2.1)]. 13.7. Consider a double Ising chain such that the nearest-neighbor coupling constant along either chain is J1 while the one linking adjacent spins in the two chains is J2. Then, in the absence of the ﬁeld, H{σi, σ ′ i } = −J1 ∑ i (σiσi+1 + σ ′ i σ ′ i+1) − J2 ∑ i σiσ ′ i . Show that the partition function of this system is given by 1 2N ln Q ≈ 1 2 ln[2 cosh K2{cosh 2K1 + √ (1 + sinh 2 2K1 tanh2 K2)}], where K1 = βJ1 and K2 = βJ2. Examine the various thermodynamic properties of this system. [Hint: Express the Hamiltonian H in a symmetric form by writing the last term as − 1 2 J26i(σiσ ′ i + σi+1σ ′ i+1) and use the transfer matrix method.] 13.8. Write down the transfer matrix P for a one-dimensional spin-1 Ising model in zero ﬁeld, described by the Hamiltonian HN {σi} = −J ∑ i σiσi+1 σi = −1, 0, +1. Show that the free energy of this model is given by 1 N A(T ) = −kT ln { 1 2 [ (1 + 2 cosh βJ) + √ {8 + (2 cosh βJ − 1)2} ]} . Examine the limiting behavior of this quantity in the limits T → 0 and T → ∞. 13.9. (a) Apply the theory of Section 13.2 to a one-dimensional lattice gas and show that the pressure P and the volume per particle v are given by P kT = ln [ 1 2 {(y + 1) + √ [(y − 1)2 + 4yη2]}] and 1 v = 1 2 [ 1 + y − 1 √ [(y − 1)2 + 4yη2] ] , Problems 533 where y = z exp(4βJ) and η = exp(−2βJ), z being the fugacity of the gas. Examine the high and the low temperature limits of these expressions. (b) A hard-core lattice gas pertains to the limit J → −∞; this makes y → 0 and η → ∞ such that the quantity yη2, which is equal to z, stays ﬁnite. Show that this leads to the equation of state P kT = ln ( 1 − ρ 1 − 2ρ ) (ρ = 1 v ) . 13.10. For a one-dimensional system, such as the ones discussed in Sections 13.2 and 13.3, the correlation function g(r) at all temperatures is of the form exp(−ra/ξ ), where a is the lattice constant of the system. Using the ﬂuctuation-susceptibility relation (12.11.11), show that the low-ﬁeld susceptibility of such a system is given by χ0 = Nβµ 2 coth(a/2ξ ). Note that as T → 0 and, along with it, ξ → ∞, χ0 becomes directly proportional to ξ — consistent with the fact that the critical exponent η = 1. For an n-vector model (including the scalar case n = 1), ξ is given by equation (13.3.17), which leads to the result χ0 = Nβµ 2 I(n−2)/2(βJ) + In/2(βJ) I(n−2)/2(βJ) − In/2(βJ) . Check that for the special case n = 1 this result reduces to equation (13.2.14). 13.11. Show that for a one-dimensional, ﬁeld-free Ising model σkσlσmσn = {tanh βJ} n−m+l−k, where k ≤ l ≤ m ≤ n. 13.12. Recall the symbol n(r), of equation (13.4.5), which denotes the number of closed graphs that can be drawn on a given lattice using exactly r bonds. Show that for a square lattice wrapped on a torus (which is equivalent to imposing periodic boundary conditions) n(4) = N, n(6) = 2N, n(8) = 1 2 N 2 + 9 2 N, . . . . Substituting these numbers into equation (13.4.5) and taking logs, one gets ln Q(N, T ) = N {ln(2 cosh2 K ) + v4 + 2v6 + 9 2 v8 + · · · } , v = tanh K . Note that the term in N 2 has disappeared — in fact, all higher powers of N do the same. Why? 13.13. According to Onsager, the ﬁeld-free partition function of a rectangular lattice (with interaction parameters J and J ′ in the two perpendicular directions) is given by 1 N ln Q(T ) = ln 2 + 1 2π 2 π∫ 0 π∫ 0 ln{cosh(2γ ) cosh(2γ ′) − sinh(2γ ) cos ω − sinh(2γ ′) cos ω′}dωdω′, where γ = J/kT and γ ′ = J ′/kT . Show that if J ′ = 0, this leads to expression (13.2.9) for the linear chain with B = 0 while if J ′ = J, one is led to expression (13.4.22) for the square net. Locate the critical point of the rectangular lattice and study its thermodynamic behavior in the neighborhood of that point. 13.14. Write the elliptic integral K1(κ) in the form K1(κ) = π/2∫ 0 1 − κ sin φ √ (1 − κ 2 sin 2 φ) dφ + π/2∫ 0 κ sin φ √ (1 − κ 2 sin 2 φ) dφ, 534 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models and show that, as κ → 1−, the ﬁrst integral → ln 2 while the second ≈ ln[2/(1 − κ 2)1/2]. Hence K1(κ) ≈ ln(4/|κ ′|), as in equation (13.4.34). [Hint: In the second integral, substitute cos φ = x.] 13.15. Using equations (13.4.22) and (13.4.28) at T = Tc, show that the entropy of the two-dimensional Ising model on a square lattice at its critical point is given by Sc Nk = 2G π + 1 2 ln 2 − √ 2Kc ≃ 0.3065; here, G is Catalan’s constant, which is approximately equal to 0.915966. Compare this result with the ones following from the Bragg–Williams approximation and from the Bethe approximation; see Problem 12.15. 13.16. The spontaneous magnetization of a two-dimensional Ising model on a square lattice at T < Tc is given by equation (13.4.38a). Express this result in the form B|t|β {1 + b|t| + · · · }, where B and β are stated in equation (13.4.40) while b = (1 − 9Kc/ √ 2)/8. As usual, t = (T − Tc)/Tc < 0 and |t| ≪ 1. 13.17. Apply the theory of Section 13.4 to a two-dimensional lattice gas and show that, at T = Tc, the quantity kTc/Pcvc ≃ 10.35. 13.18. Show that for the spherical model in one dimension the free energy at constant λ is given by βAλ N = 1 2 ln [ β{λ + √ (λ2 − J 2)} 2π ] − βµ2B2 4(λ − J) , while λ is determined by the constraint equation 1 2β√ (λ2 − J 2) + µ2B2 4(λ − J)2 = 1. In the absence of the ﬁeld (B = 0), λ = √ 1 + 4β2J 2/2β; the free energy at constant S is then given by βA S N = 1 2 ln [ √ (1 + 4β2J 2) + 1 4π ] − 1 2 √ (1 + 4β2J 2). 13.19. Starting with expression (13.3.8) for the partition function of a one-dimensional n-vector model, with Ji = nJ ′, show that Lim n,N→∞ 1 nN ln QN (nK ) = 1 2 [ √(4K 2 + 1) − 1 − ln { √ (4K 2 + 1) + 1 2 }] , where K = βJ ′. Note that, apart from a constant term, this result is exactly the same as for the spherical model; the difference arises from the fact that the present result is normalized to give QN = 1 when K = 0. [Hint: Use the asymptotic formulae (for ν ≫ 1) 0(ν) ≈ (2π/ν) 1/2(ν/e) ν and Iν (νz) ≈ (2πν)−1/2(z2 + 1)−1/4eνη, where η = √ (z2 + 1) − ln[{√ (z2 + 1) + 1}/z].] 13.20. Show that the low-ﬁeld susceptibility, χ0, of the spherical model at T < Tc is given by the asymptotic expression χ0 ≈ (Nµ 2/kBT ) · Nm 2 0(T ), where m0(T ) is the spontaneous magnetization of the system; note that in the thermodynamic limit the reduced susceptibility, kBT χ0/Nµ2, is inﬁnite at all T < Tc. Compare to Problem 13.26. Problems 535 13.21. In view of the fact that only those ﬂuctuations whose length scale is large play a dominant role in determining the nature of a phase transition, the quantity (λ − µk) in the expression for the correlation function of the spherical model, see equation (13.5.57), may be replaced by λ − µk = λ − J d∑ j=1 cos(kja) ≃ J [ φ + k2a2 2 ] , where φ = (λ/J) − d. Show that this approximation leads to the same result for G(R) as we have in equation (13.5.61), with the same ξ as in equation (13.5.62). For a similar reason, the quantity [exp(α + βε) − 1] in the correlation function (13.6.33) of the ideal Bose gas may be replaced by eα+βε − 1 ≃ α + βε = α + (βℏ2/2m)k2, leading to the same G(R) as in equation (13.6.35), with the same ξ as in equation (13.6.36).10 13.22. Consider a spherical model whose spins interact through a long-range potential varying as (a/r)d+σ (σ > 0), r being the distance between two spins. This replaces the quantity (λ − µk) of equations (13.5.16) and (13.5.57) by an expression approximating J[φ + 1 2 (ka)σ ] for σ < 2 and J[φ + 1 2 (ka)2] for σ > 2; note that the nearest-neighbor interaction corresponds to the limit σ → ∞ and hence to the latter case. Assuming σ to be less than 2, show that the above system undergoes a phase transition at a ﬁnite temperature Tc for all d > σ . Further show that the critical exponents for this model are α = d − 2σ d − σ , β = 1 2 , γ = σ d − σ , δ = d + σ d − σ , ν = 1 d − σ , η = 2 − σ for σ < d < 2σ , and α = 0, β = 1 2 , γ = 1, δ = 3, ν = 1 σ , η = 2 − σ for d > 2σ . 13.23. Refer to Section 13.6 on the ideal Bose gas in d dimensions, and complete the steps leading to equations (13.6.9) through (13.6.15) and (13.6.23). 13.24. Show that for an ideal Bose gas in d dimensions and at T > Tc V ( ∂ 2P ∂T 2 ) v = NkB T [ d(d + 2) 4 g(d+2)/2(z) gd/2(z) − d 2 gd/2(z) g(d−2)/2(z) − d2 4 {gd/2(z)}2g(d−4)/2(z) {g(d−2)/2(z)}3 ] and ( ∂ 2µ ∂T 2 ) v = kB T [ d(d − 2) 4 gd/2(z) g(d−2)/2(z) − d2 4 {gd/2(z)}2g(d−4)/2(z) {g(d−2)/2(z)}3 ] , where µ(= kT ln z) is the chemical potential of the gas while other symbols have the same meanings as in Section 13.6. Note that these quantities satisfy the thermodynamic relationship VT ( ∂ 2P ∂T 2 ) v − NT ( ∂ 2µ ∂T 2 ) v = CV . 10A comparison with the mean ﬁeld results (12.11.25) and (12.11.26) brings out a close similarity that exists between these models and the mean ﬁeld picture of a phase transition; for instance, they all share a common critical exponent η, which is zero. There are, however, signiﬁcant differences; for one, the correlation length ξ for these models is character- ized by a critical exponent ν which is nonclassical — in the sense that it is d-dependent whereas in the mean ﬁeld case it is independent of d. 536 Chapter 13. Phase Transitions: Exact (or Almost Exact) Results for Various Models Also note that, since P here equals (2U/dV ), the quantities (∂P/∂T )v and (∂ 2P/∂T 2)v are directly proportional to CV and (∂CV /∂T )V , respectively. Finally, examine the singular behavior of these quantities as T → Tc from above. 13.25. Show that for any given ﬂuid CP = VT (∂P/∂T )S(∂P/∂T )V κT and CV = VT (∂P/∂T )S(∂P/∂T )V κS, where the various symbols have their usual meanings. In the two-phase region, these formulae take the form CP = VT (dP/dT )2κT and CV = VT (dP/dT )2κS, respectively. Using the last of these results, rederive equation (13.6.30) for CV at T < Tc. 13.26. Show that for any given ﬂuid κT = ρ−2(∂ρ/∂µ)T , where ρ(= N/V ) is the particle density and µ the chemical potential of the ﬂuid. For the ideal Bose gas at T < Tc, ρ = ρ0 + ρe ≈ − kBT V µ + ζ (d/2) λd . Using these results, show that11 κT ≈ (V /kBT )(ρ0/ρ)2 (T < Tc); note that in the thermodynamic limit the reduced compressibility, kBT κT /v, is inﬁnite at all T < Tc. Compare Problem 13.20. 13.27. Consider an ideal relativistic Bose gas composed of N1 particles and N2 antiparticles, each of rest mass m0, with occupation numbers 1 exp[β(ε − µ1)] − 1 and 1 exp[β(ε − µ2)] − 1 , respectively, and the energy spectrum ε = c√ (p2 + m2 0c2). Since particles and antiparticles are supposed to be created in pairs, the system is constrained by the conservation of the number Q (= N1 − N2), rather than of N1 and N2 separately; accordingly, µ1 = −µ2 = µ, say. Set up the thermodynamic functions of this system in three dimensions and examine the onset of Bose–Einstein condensation as T approaches a critical value, Tc, determined by the “number density” Q/V . Show that the nature of the singularity at T = Tc is such that, regardless of the severity of the relativistic effects, this system falls in the same universality class as the nonrelativistic one. 13.28. Derive equation (13.1.9) for hard spheres in one dimension from equation (13.1.7). Plot the pair correlation function for nD = 0.25, 0.50, 0.75, and 0.90. Determine the structure factor S(k) numerically and plot it for the same densities. Compare your results with equation (13.1.21). 13.29. Use the pair correlation function (13.1.8) and (13.1.9) to determine analytically the structure factor for hard spheres in one dimension. Show that S(k) is given by equation (13.1.21). Plot g(x) and S(k) for nD = 0.25, 0.50, 0.75, and 0.90. 13.30. Use the Takahashi method of Section 13.1 for a system of point masses and harmonic springs of length a. Allow the particles to pass through each other, so that the partition function can be evaluated in a closed form. Show that the system is stable at zero pressure. Determine the average 11This remarkable relationship between the isothermal compressibility of a ﬁnite-sized Bose gas and the condensate density in the corresponding bulk system was ﬁrst noticed by Singh and Pathria (1987b). Problems 537 distance between particles that are far apart on the chain and the variance of that distance. Determine the structure factor and plot it for several values of the parameter mω2a2/kT , where m is the mass and mω2 is the spring constant. Show that the speciﬁc heat of this system is independent of temperature, as given by the equipartition theorem. 13.31. Conﬁrm the ﬁrst few coefﬁcients in the low-temperature series for the two-dimensional Ising model in equation (13.4.53). Write a program to calculate the energies of all 216 states for a 4 × 4 periodic lattice. Show that the coefﬁcients here are gq = {2, 0, 32, 64, 424, 1728, 6688, 13568, 20524, 13568, 6688, 1728, 424, 64, 32, 0, 2}. Extend your code to calculate the partition function for a 6 × 6 lattice, which has 236 states. 13.32. Calculate the exact zero ﬁeld partition function of the one-dimensional Ising model on a periodic chain of n spins using equation (13.2.5) and write QN (0, T ) in the form of equation (13.4.52). Show that for x → 1, the partition function → 2n. Evaluate the microcanonical entropy S(q)/k = ln gq and plot it for the case n = 16. 13.33. Use the code posted at www.elsevierdirect.com to evaluate equations (13.4.56) through (13.4.59) to determine the low-temperature series coefﬁcients for the two-dimensional Ising model for an 8 × 8 lattice. Plot the internal energy and the speciﬁc heat as a function of temperature. Repeat your calculation for 16 × 16 and 32 × 32 lattices. 13.34. Use the data posted at www.elsevierdirect.com to evaluate equations (13.4.56) through (13.4.59) to plot the two-dimensional Ising model internal energy and speciﬁc heat as a function of temperature for an L × L lattice, where L = 64. Compare your results with the ones displayed in Figure 13.17. 14 Phase Transitions: The Renormalization Group Approach In this chapter we propose to discuss what has turned out to be the most successful approach to the problem of phase transitions. This approach is based on ideas ﬁrst pro- pounded by Kadanoff (1966b) and subsequently developed by Wilson (1971) and others into a powerful calculational tool. The main point of Kadanoff’s argument is that, as the critical point of a system is approached, its correlation length becomes exceedingly large — with the result that the sensitivity of the system to a length transformation (or a change of scale, as one may call it) gets exceedingly diminished. At the critical point itself, the correlation length becomes inﬁnitely large and with it the system becomes totally insensitive to such a transformation. It is then conceivable that, if one is not too far from the critical point (i.e., |t|, h ≪ 1), the given system (with lattice constant a) may bear a close resemblance to a transformed system (with lattice constant a′ = la, where l > 1, and presumably modiﬁed parameters t′ and h′), renormalized so that all distances in it are measured in terms of the new lattice constant a′; clearly, the rescaled correlation length ξ ′ (in units of a′) would be one-lth of the original correlation length ξ (in units of a). This resemblance in respect of critical behavior is expected only if ξ ′ is also much larger than a′, just as ξ was in comparison with a, which in turn requires that l ≪ (ξ/a); by implication, |t′| and h′ would also be ≪ 1. These considerations lead to a formulation similar to the one presented in Section 12.10, with the difference that, while there we had to rely on a scaling hypothe- sis, here we have a convincing argument based on the role played by correlations among the microscopic constituents of the system which, in the vicinity of the critical point, are so large-scale that they make all other length scales, including the one that determines the structure of the lattice, essentially irrelevant. Unfortunately, Kadanoff’s approach did not provide a systematic means of deriving the critical exponents or of constructing the scal- ing functions that appear in the formulation. Those deﬁciencies were remedied by Wilson by introducing the concept of a renormalization group (RG) into the theory. We propose to discuss Wilson’s approach in Sections 14.3 and 14.4, but ﬁrst we present a formulation of scaling along the lines indicated above and follow it with an exploration of simple examples of renormalization that pave way for establishing Wilson’s theory. Finally, in Section 14.5, we outline the theory of ﬁnite-sizing scaling that too has beneﬁted greatly from the RG approach. Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00014-1 © 2011 Elsevier Ltd. All rights reserved. 539 540 Chapter 14. Phase Transitions: The Renormalization Group Approach 14.1 The conceptual basis of scaling The scale change in a given system can be effected in several different ways, the earliest one being due to Kadanoff who suggested that, when large-scale correlations prevail, the individual spins in the system may be grouped into “blocks of spins,” each block consisting of ld original spins, and let each block play the role of a “single spin” in the transformed system; see Figure 14.1, where a block–spin transformation with l = 2 and d = 2 is shown. The spin variable of a block may be denoted by the symbol σ ′, which arises from the values of the individual spins in the block, but a rule has to be established so that σ ′ too is either +1 or −1, just as the original σi were. 1 The transformed system then consists of N ′ “spins,” where N ′ = l−dN, (1) occupying a lattice structure with lattice constant a′ = la. To preserve the spatial density of the degrees of freedom in the system, all spatial distances must be rescaled by the factor l, so that for any two “spins” in the transformed system r′ = l−1r. (2) A second way of effecting a scale change is to write down the partition function of the system, Q = ∑ {σi} exp[−βHN {σi}], (3) (a) (b) FIGURE 14.1 A block–spin transformation, with l = 2 and d = 2. The original lattice (a) has N (= 36) spins, the transformed one (b) has N ′ (= 9); after rescaling, the latter looks very much the same as the former, especially in the limit N, N ′ → ∞. 1For simplicity, we employ the language of the scalar model here. 14.1 The conceptual basis of scaling 541 and carry out summation over a subset of (N − N ′) spins, such that one is left with a summation, over the remaining N ′ spins, which can (hopefully) be expressed in a form similar to (3), namely Q = ∑ {σ ′ i } exp[−βHN ′ {σ ′ i }]. (4) If the desired passage, from expression (3) to (4), can be accomplished with some degree of accuracy, we should expect a close resemblance between the critical behavior of the original system represented by equation (3) and the transformed one represented by (4); see Figure 14.2, where an example of this procedure with l = √ 2 and d = 2 is shown. We note that this procedure forms the very backbone of the Wilson approach and is generally referred to as “decimation,” although the fraction of the spins removed, (N − N ′)/N, is rarely equal to 1/10. Other ways of effecting a scale change will be mentioned later. It is quite natural to expect that the free energy of the transformed system (or, at least, that part of it that determines the critical behavior) is the same as that of the original sys- tem. The singular parts of the free energy per spin of the two systems should, therefore, be related as N ′ψ (s)(t′, h ′) = Nψ (s)(t, h), (5) so that ψ (s)(t, h) = l−dψ (s)(t′, h′). (6) (a) (b) Spins summed over Spins that remain FIGURE 14.2 A scale transformation by “decimation,” with l = √ 2 and d = 2. The original lattice (a) has N (= 36) spins, the transformed one (b) has N ′ (= 18); the latter is yet to be rescaled (and rotated through an angle π/4) so that it looks very much the same as the former, especially in the limit N, N ′ → ∞. 542 Chapter 14. Phase Transitions: The Renormalization Group Approach Now, since both t and t′ are small in magnitude, one may assume that they are linearly related, that is, t′ = l yt t, (7) where yt, as yet, is an unknown number. Similarly, one may assume that h′ = l yh h, (8) with the result that ψ (s)(t, h) = l−dψ (s)(l yt t, l yh h); (9) like yt, the number yh is also unknown at this stage of the game. We now assert that the function ψ (s), which governs much of the critical behavior of the system, is essentially insensitive to a change of scale; we should, therefore, be able to eliminate the scale factor l from expression (9). This essentially forces us to replace the variables t′ and h′ by a single, l-independent variable, namely h′ |t′|yh/yt = h |t|yh/yt = h |t|1 , say ( 1 = yh yt ) ; (10) at the same time, it requires us to write ψ (s)(t′, h′) = |t′| d/yt ˜ψ(h′/|t′|1), (11) leading to the identical result ψ (s)(t, h) = |t|d/yt ˜ψ(h/|t| 1); (12) note that, as of now, the function ˜ψ is also unknown. 2 Comparing (12) with equation (12.10.7), we readily identify the critical exponent α as α = 2 − (d/yt ); (13) more importantly, the present considerations have led to the same scaled form for the free energy density of the system as was hypothesized in Section 12.10. We have thus raised the status of expression (12.10.7) from being a mere hypothesis to being a well-founded result whose conceptual basis lies in the prevalence of large-scale correlations in the system. As in Section 12.10, we infer that the exponents β, γ , and δ are now given by β = 2 − α − 1 = (d − yh)/yt , (14) γ = −(2 − α − 21) = (2yh − d)/yt , (15) 2Some authors derive equation (12) from (9) by choosing l to be t−1/yt . As will be seen shortly, see equation (19), this amounts to letting l be O(ξ/a), which violates the requirement, l ≪ ξ/a, mentioned earlier. 14.2 Some simple examples of renormalization 543 and δ = 1/β = yh/(d − yh). (16) As remarked earlier, the rescaled correlation length ξ ′ of the transformed system and the original correlation length ξ of the given system are related as ξ ′ = l−1ξ . (17) At the same time, we expect ξ ′ to be ∼ |t′|−ν, just as ξ ∼ |t|−ν. It follows that ( ξ ′ ξ ) = ( t′ t )−ν = l−νyt . (18) Comparing (17) and (18), we conclude that ν = 1/yt (19) and hence, by (13), dν = 2 − α. (20) We thus obtain not only a useful expression for the critical exponent ν but also the hyper- scaling relation (12.12.15) on a basis far sounder than the one employed in Section 12.12. Finally we look at the correlation functions of the two systems. At the critical point we expect that for the transformed system g(r′ 1, r′ 2) = ⟨σ ′(r′ 1)σ ′(r′ 2)⟩ ∼ (r′)−(d−2+η), (21) just as for the original system g(r1, r2) = ⟨σ (r1)σ (r2)⟩ ∼ r−(d−2+η). (22) In order that equations (21) and (22) be mutually compatible, we must rescale the spin variables such that σ ′(r′) = l(d−2+η)/2σ (r). (23) As for η, we may use the scaling relation γ = (2 − η)ν, to get η = d + 2 − 2yh. (24) 14.2 Some simple examples of renormalization 14.2.A The Ising model in one dimension We start with the partition function (13.2.3a) of a closed Ising chain consisting of N spins, namely QN (B, T ) = ∑ {σi} exp [ N∑ i=1 {K0 + K1σiσi+1 + 1 2 K2(σi + σi+1) }] (K0 = 0, K1 = βJ, K2 = βµB); (1) 544 Chapter 14. Phase Transitions: The Renormalization Group Approach N 2 3 N 2 2 N 2 1 N 1 2 3 4 5 FIGURE 14.3 A closed Ising chain to be “decimated” by carrying out summations over σ2, σ4, . . .. the parameter K0 has been introduced here for reasons that will become clear in the sequel. For simplicity, we assume N to be even and carry out summation in (1) over all σi for which i is even, that is, over σ2, σ4, . . .; see Figure 14.3. Writing the summand in (1) as N∏ i=1 exp{K0 + K1σiσi+1 + 1 2 K2(σi + σi+1)} = 1 2 N ∏ j=1 exp{2K0 + K1(σ2j−1σ2j + σ2jσ2j+1) + 1 2 K2(σ2j−1 + 2σ2j + σ2j+1) }, (2) the summations over σ2j (= +1 or −1) can be carried out straightforwardly, with the result 1 2 N ∏ j=1 exp(2K0) · 2 cosh{K1(σ2j−1 + σ2j+1) + K2} · exp { 1 2 K2(σ2j−1 + σ2j+1) }. (3) Denoting σ2j−1 by σ ′ j , the partition function QN assumes the form QN (B, T ) = ∑ {σ ′ j } 1 2 N ∏ j=1 exp(2K0) · 2 cosh{K1(σ ′ j + σ ′ j+1) + K2} · exp{ 1 2 K2(σ ′ j + σ ′ j+1) }. (4) The crucial step now consists in expressing (4) in a form similar to (1), namely QN (B, T ) = ∑ {σ ′ j } exp   N ′ ∑ j=1 { K ′ 0 + K ′ 1σ ′ j σ ′ j+1 + 1 2 K ′ 2(σ ′ j + σ ′ j+1) } . (5) 14.2 Some simple examples of renormalization 545 This requires that, for all choices of the variables σ ′ j and σ ′ j+1, exp{K ′ 0 + K ′ 1σ ′ j σ ′ j+1 + 1 2 K ′ 2(σ ′ j + σ ′ j+1)} = exp(2K0) · 2 cosh{K1(σ ′ j + σ ′ j+1) + K2} · exp{ 1 2 K2(σ ′ j + σ ′ j+1) } . (6) The various choices being σ ′ j = σ ′ j+1 = +1, σ ′ j = σ ′ j+1 = −1 and σ ′ j = −σ ′ j+1 = ±1, we obtain from (6) exp(K ′ 0 + K ′ 1 + K ′ 2) = exp(2K0 + K2) · 2 cosh(2K1 + K2), (7a) exp(K ′ 0 + K ′ 1 − K ′ 2) = exp(2K0 − K2) · 2 cosh(2K1 − K2), (7b) and exp(K ′ 0 − K ′ 1) = exp(2K0) · 2 cosh K2. (7c) Solving for K ′ 0, K ′ 1, and K ′ 2, we get e K ′ 0 = 2e2K0 {cosh(2K1 + K2) cosh(2K1 − K2) cosh2 K2}1/4, (8a) e K ′ 1 = {cosh(2K1 + K2) cosh(2K1 − K2)/ cosh2 K2} 1/4, (8b) and e K ′ 2 = eK2 {cosh(2K1 + K2)/ cosh(2K1 − K2)}1/2. (8c) We may now remark on the need to have the parameter K0 included in expression (1) and, accordingly, K ′ 0 in (5). Since we end up having three equations (7a), (7b), and (7c), to determine the parameters appropriate to the transformed system, the problem could not be solved with K1 and K2 only; thus, even if K0 were set equal to zero, a K ′ 0 ̸= 0 is essential for a proper representation of the transformed system. To highlight the role played by this parameter in determining the free energy of the given system, we observe on the basis of equations (1) and (5) that, with K0 = 0, QN (K1, K2) = eN ′K ′ 0 QN ′ (K ′ 1, K ′ 2) (9) and hence for the free energy we have (in units of kT ) AN (K1, K2) = −N ′K ′ 0 + AN ′ (K ′ 1, K ′ 2). (10) Since N ′ = 1 2 N, we obtain for the free energy per spin the recurrence relation f (K1, K2) = − 1 2 K ′ 0 + 1 2 f (K ′ 1, K ′ 2), (11) 546 Chapter 14. Phase Transitions: The Renormalization Group Approach which relates the free energy per spin of the given system with that of the transformed system; the role played by K ′ 0 is clearly signiﬁcant. For example, in the limit T → ∞, when (K1, K2) and along with them (K ′ 1, K ′ 2) tend to zero, equations (8a) and (11) give f (0, 0) = −K ′ 0 = − ln 2, (12) which is indeed the correct result (arising from the limiting value of the entropy, Nk ln 2, of the system). We note that the parameter K0 does not appear in equations (8b) and (8c), which deter- mine K ′ 1 and K ′ 2 in terms of K1 and K2. As will be seen in Sections 14.3 and 14.4, it is these two relations that determine the singular part of the free energy of the system and hence its critical behavior; the parameters K0 and K ′ 0 affect only the regular part of the free energy and hence play no direct role in determining the critical behavior of the system. We might hasten to add that, while renormalization is generally used as a technique for studying the properties of a given system in the vicinity of its critical point, it can be useful over a much broader range of the variables K1 and K2. For instance, in the absence of the ﬁeld (K2 = 0), equations (8) and (11) give K ′ 0 = ln{2√[cosh(2K1)]}, K ′ 1 = ln √[cosh(2K1)], K ′ 2 = 0 (13) and hence f (K1, 0) = − 1 2 ln{2√[cosh(2K1)]} + 1 2 f (ln √[cosh(2K1)], 0); (14) the functional equation (14) has the solution f (K1, 0) = − ln(2 cosh K1), (15) valid at all K1. On the other hand, in the paramagnetic case (K1 = 0), we get K ′ 0 = ln(2 cosh K2), K ′ 1 = 0, K ′ 2 = K2 (16) and hence f (0, K2) = − 1 2 ln(2 cosh K2) + 1 2 f (0, K2), (17) with the solution f (0, K2) = − ln(2 cosh K2), (18) valid at all K2. The case when both K1 and K2 are present is left as an exercise for the reader; see Problem 14.2. The critical behavior of this system will be studied in Section 14.4. 14.2 Some simple examples of renormalization 547 14.2.B The spherical model in one dimension We adopt the same topology as in Figure 14.3 and write down the partition function of the one-dimensional spherical model consisting of N spins, see equation (13.5.12a), QN = ∞∫ −∞ . . . ∞∫ −∞ exp [ N∑ i=1 {K0 + K1σiσi+1 + K2σi − 3σ 2 i }] dσ1 . . . dσN (K0 = 0, K1 = βJ, K2 = βµB, 3 = βλ), (19) where 3 is chosen so that 〈 N∑ i=1 σ 2 i 〉 = − ∂ ∂3 ln QN = N; (20) see equations (13.5.9) and (13.5.13). Assuming N to be even, we carry out integrations over σ2, σ4, . . .. For this, we write our integrand as N∏ i=1 exp{ K0 + K1σiσi+1 + K2σi − 3σ 2 i } = 1 2 N ∏ j=1 exp { 2K0 + K1(σ2j−1σ2j + σ2jσ2j+1) + K2(σ2j−1 + σ2j) − 3 (σ 2 2j−1 + σ 2 2j)} (21) and integrate over σ2j, using the formula ∞∫ −∞ e−px2+qxdx = ( π p )1/2 e q2/4p (p > 0). (22) After simpliﬁcation, we get 1 2 N ∏ j=1 ( π 3 )1/2 exp {( 2K0 + K 2 2 43 ) + K 2 1 23 σ2j−1σ2j+1 + (K2 + K1K2 3 ) σ2j−1 − ( 3 − K 2 1 23 ) σ 2 2j−1 } . (23) Denoting σ2j−1 by σ ′ j , expression (19) may now be written in the renormalized form QN = ∞∫ −∞ . . . ∞∫ −∞ exp   N ′ ∑ j=1 { K ′ 0 + K ′ 1σ ′ j σ ′ j+1 + K ′ 2σ ′ j − 3′σ ′2 j }  dσ ′ 1 . . . dσ ′ N ′ , (24) 548 Chapter 14. Phase Transitions: The Renormalization Group Approach where K ′ 0 = 1 2 ln ( π 3 ) + 2K0 + K 2 2 43 , K ′ 1 = K 2 1 23 , (25a, b) K ′ 2 = K2 ( 1 + K1 3 ) , 3′ = 3 − K 2 1 23 (25c, d) and, of course, N ′ = 1 2 N. It follows that, with K0 = 0, QN (K1, K2, 3) = eN ′K ′ 0 QN ′ (K ′ 1, K ′ 2, 3′) (26) and hence for the free energy per spin (in units of kT ) we have the recurrence relation f (K1, K2, 3) = − 1 2 K ′ 0 + 1 2 f (K ′ 1, K ′ 2, 3′). (27) The critical behavior of this system will be studied in Section 14.4. Presently we would like to demonstrate how the free energy of the system, over a broad range of the vari- ables K1 and K2, can be determined by using the recurrence relation (27) along with the transformation equations (25). First of all we identify two invariants of the transformation, namely 3′2 − K ′2 1 = 32 − K 2 1 (28a) and (3 ′ − K ′ 1)/K ′ 2 = (3 − K1)/K2. (28b) It turns out that it is precisely these combinations that appear in the constraint equation of the system as well; see Problem 13.18. It follows that the constraint equation (20) is RG- invariant, that is, once it is satisﬁed in the original system, its counterpart 〈 N ′ ∑ j=1 σ ′2 j 〉 = N ′ (29) is automatically satisﬁed in the transformed system — without any need to rescale the spin variables. 3 Now, in the absence of the ﬁeld (K2 = 0), equations (25) and (27) give K ′ 0 = 1 2 ln ( π 3 ) , K ′ 1 = K 2 1 23 , K ′ 2 = 0, 3′ = 3 − K 2 1 23 (30) and hence f (K1, 3) = − 1 4 ln ( π 3 ) + 1 2 f ( K 2 1 23 , 3 − K 2 1 23 ) . (31) 3This is further related to the fact that the critical exponent η in this case is equal to 1; see equation (14.1.23) which, with d = 1, gives: σ ′(r′) = σ (r). 14.2 Some simple examples of renormalization 549 The functional equation (31) has the solution f (K1, 3) = 1 2 ln [ 3 + √(32 − K 2 1) 2π ] , (32) valid at all K1; the appropriate value of 3 is given by the constraint equation ∂f ∂3 = 1 2√(32 − K 2 1) = 1, that is 3 = 1 2 √(1 + 4K 2 1). (33) Note that the invariant (28a) in this case is equal to 1 4 . On the other hand, in the paramagnetic case (K1 = 0), we get K ′ 0 = 1 2 ln ( π 3 ) + K 2 2 43 , K ′ 1 = 0, K ′ 2 = K2, 3′ = 3 (34) and hence f (K2, 3) = − 1 4 ln ( π 3 ) − K 2 2 83 + 1 2 f(K2, 3), (35) with the solution f (K2, 3) = − 1 2 ln ( π 3 ) − K 2 2 43 , (36) valid at all K2; the appropriate value of 3 is now given by ∂f ∂3 = 1 23 + K 2 2 432 = 1, that is 3 = √(1 + 4K 2 2) + 1 4 . (37) The case when both K1 and K2 are present is left as an exercise for the reader; see Problem 14.3. 14.2.C The Ising model in two dimensions As our third example of renormalization, we consider an Ising model on a square lattice in two dimensions. In the ﬁeld-free case, the partition function of this system is given by QN (T ) = ∑ {σi} exp { ∑ n.n. K σiσj } (K = βJ), (38) where the summation in the exponent goes over all nearest-neighbor pairs of spins in the lattice. Writing the summand in (38) as a product of factors pertaining to different pairs of 550 Chapter 14. Phase Transitions: The Renormalization Group Approach 789 456 123 FIGURE 14.4 A section of the two-dimensional Ising lattice. The summed-over spins are denoted by open circles, the remaining ones by solid dots. To begin with, we concentrate on the summation over σ5. spins, we may highlight those factors that contain a particular spin, say σ5, and carry out summation over this spin (see Figure 14.4): ∑ σ5=±1 ∏ n.n. . . . eK σ2σ5 · eK σ4σ5 · eK σ5σ6 · eK σ5σ8 . . . (39) = ∏ n.n. ′ . . . [2 cosh K (σ2 + σ4 + σ6 + σ8)] . . . , (40) where the primed product goes over the remaining nearest-neighbor pairs in the lattice. This procedure of summation is supposed to be continued until one-half of the spins, shown as open circles in Figure 14.4, are all summed over. Clearly, this will generate a host of factors of the type shown in expression (40) but the real task now is to express these fac- tors in a form similar, or at least as close as possible, to the factors appearing in the original expression (38); moreover, this mode of expression should be valid for all possible values of the remaining spins, namely σ2, σ4, . . . = ±1. For the factor explicitly displayed in (40), there are 16 possible values for the spins involved, of which only four turn out to be nonequivalent; they are (i) σ2 = σ4 = σ6 = σ8, (41a) (ii) σ2 = σ4 = σ6 = −σ8, (41b) (iii) σ2 = σ4 = −σ6 = −σ8, (41c) (iv) σ2 = −σ4 = −σ6 = σ8. (41d) However, even four values are too many to accommodate by a factor of the form exp{A + B(σ2σ4 + σ2σ6 + σ4σ8 + σ6σ8)}, 14.2 Some simple examples of renormalization 551 which contains only nearest-neighbor interactions in the transformed lattice and hence only two parameters to choose. Clearly, we need two more degrees of freedom, and it turns out that these are provided by the next-nearest-neighbor interactions and by interactions among a quartet of spins sitting on the corners of an elementary square in the new lattice. Thus, we are obliged to set 2 cosh K (σ2 + σ4 + σ6 + σ8) = exp{K ′ 0 + 1 2 K ′(σ2σ4 + σ2σ6 + σ4σ8 + σ6σ8) + L′(σ2σ8 + σ4σ6) + M ′σ2σ4σ6σ8}; (42) the reason why we have written 1 2 K ′, rather than K ′, will become clear shortly. Now, the four possibilities listed above require that 2 cosh 4K = exp(K ′ 0 + 2K ′ + 2L′ + M ′), (43a) 2 cosh 2K = exp(K ′ 0 − M ′), (43b) 2 = exp(K ′ 0 − 2L′ + M ′), (43c) 2 = exp(K ′ 0 − 2K ′ + 2L′ + M ′), (43d) with the result that K ′ 0 = ln 2 + 1 2 ln cosh 2K + 1 8 ln cosh 4K , (44) K ′ = 1 4 ln cosh 4K , (45) L′ = 1 8 ln cosh 4K , (46) M ′ = 1 8 ln cosh 4K − 1 2 ln cosh 2K . (47) Continuing this process, we ﬁnd that the factor exp ( 1 2 K ′σ2σ4) appears once again when summation over σ1 is carried out, the factor exp ( 1 2 K ′σ2σ6) appears once again when sum- mation over σ3 is carried out, and so on; no further factors involving the products σ2σ8, σ4σ6 and σ2σ4σ6σ8 appear. The net result is that the partition function (38) assumes the form QN = eN ′K ′ 0 ∑ {σ ′ j } exp    K ′ ∑ n.n. σ ′ j σ ′ k + L′ ∑ n.n.n. σ ′ j σ ′ k + M ′ ∑ sq. σ ′ j σ ′ kσ ′ l σ ′ m    , (48) where N ′ = 1 2 N. Clearly, we have not been able to establish an exact correspondence between the transformed system and the original one (in which no interactions other than the nearest- neighbor ones were present). It seems more reasonable now that we redeﬁne the original system as one having all the interactions appearing in expression (48), but with L = M = 0. We may then write QN (K , 0, 0) = eN ′K ′ 0 QN ′ (K ′, L′, M ′) (49) 552 Chapter 14. Phase Transitions: The Renormalization Group Approach and hence for the free energy per spin (in units of kT ) f (K , 0, 0) = − 1 2 K ′ 0 + 1 2 f (K ′, L′, M ′), (50) where K ′ 0, K ′, L′, and M ′ are given by equations (44) through (47). In view of the appear- ance of new parameters, L′ and M ′, in the recurrence relation (50), no further progress can be made without introducing some sort of an approximation, for which see Section 14.4. But one thing is clear: when renormalization is carried out in two dimensions or more, the connectivity of the lattice requires that the Hamiltonian of the decimated system contain some higher-order interactions not present in the original system, in order that the lat- ter be represented correctly on transformation. It is obvious that further renormalizations would require more and more such interactions, and hence the need for more and more parameters would grow without limit. It may then be advisable that the Hamiltonian of the given system be regarded as a function of an “inﬁnitely large number of parameters” (all but a few of which are zero to begin with), such that the number of parameters with a nonzero value grows indeﬁnitely as renormalization transformations are carried out in succession and the number of degrees of freedom of the system steadily reduced. We now present a formulation of the renormalization group approach to the study of critical phenomena. 14.3 The renormalization group: general formulation We start with a system whose Hamiltonian depends on a large number of parameters K1, K2, . . . (all but a few of which are zero to begin with) and on the spin conﬁguration {σi} of the lattice. The free energy of the system is then given by exp(−βA) = ∑ {σi} exp[−βH{σi}({Kα})] α = 1, 2, . . . . (1) We now effect a “decimation” of the system, which reduces the number of degrees of freedom from N to N ′ and the correlation length from ξ to ξ ′, such that N ′ = l−dN, ξ ′ = l−1ξ (l > 1). (2a, b) Expressing the Hamiltonian of the transformed system in a form similar to the one for the original system, except that we now have new parameters K ′ α, along with the additional K ′ 0, and new spins σ ′ j , equation (1) takes the form exp(−βA) = exp(N ′K ′ 0) ∑ {σ ′ j } exp [−βH{σ ′ j }({K ′ α})], (3) so that the free energy per spin (in units of β−1) is given by f ({Kα}) = l−d[−K ′ 0 + f ({K ′ α})]. (4) 14.3 The renormalization group: general formulation 553 We now look closely at the transformation {Kα} → {K ′ α} by introducing a vector space K in which the set of parameters Kα is represented by the tip of a position vector K ; on trans- formation, K changes to K ′, which may be looked upon as a kind of “ﬂow from one position in the vector space to another.” This ﬂow may be represented by the transformation equation K ′ = Rl(K ) (5) where Rl is the renormalization-group operator appropriate to the case under considera- tion. A repeated application of this process leads to a sequence of vectors K ′, K ′′, . . ., such that K (n) = Rl(K (n−1)) = . . . = Rn l (K (0)) n = 0, 1, 2, . . . , (6) where K (0) denotes the original K . At the end of this sequence, the correlation length ξ and the singular part of the free energy fs are given by ξ (n) = l−nξ (0), f (n) s = lnd f (0) s ; (7a, b) see equations (2b) and (4). Now, the transformation (5) may have a ﬁxed point, K ∗, so that Rl(K ∗) = K ∗. (8) Equation (2b) then tells us that ξ(K ∗) = l−1ξ(K ∗), which means that ξ(K ∗) is either zero or inﬁnite! The former possibility is of little interest to us, so let us dwell only on the latter (which makes the system with parameters K = K ∗ critical); in simple situations, the ﬁxed point, K ∗, will correspond to the critical point, K c, of the given system. Conceivably, an arbitrary point K , on successive transformations such as (6), may end up at the ﬁxed point K ∗. Since the correlation length ξ can only decrease on transformation, see equation (7a), and is inﬁnite at the end of this sequence of transformations, it must be inﬁnite at K as well (the same being true for all points intermediate between K and K ∗). The collection of all those points which, on successive transformations, ﬂow into the ﬁxed point, constitutes a surface over which ξ is inﬁnite; this surface is generally referred to as the critical surface. All ﬂow lines in this surface are directed toward, and terminate at, the ﬁxed point, while points off this surface may initially move toward the ﬁxed point but eventually their ﬂow lines will veer away from it; see Figure 14.5. Reasons behind this pattern of ﬂow will become clear soon. For the analysis of the critical behavior we examine the pattern of ﬂow in the neighbor- hood of the ﬁxed point K ∗. 4 Setting K = K ∗ + k, (9) 4In general, the vector K ∗ will contain components not present in the original problem. In such a case, one has to locate, on the critical surface, a point K c that is free of these “unnecessary” components; since ξ is inﬁnite at K = K c as well, the latter may be identiﬁed as the critical point of the given system. As will be seen in the sequel, the critical behavior of the system is still determined by the ﬂow pattern in the neighborhood of the ﬁxed point. 554 Chapter 14. Phase Transitions: The Renormalization Group Approach Fixed point Critical trajectories Physical critical point Renormalized critical point h h9 t t 9 FIGURE 14.5 The parameter space of a physical system, showing critical trajectories (solid lines) ﬂowing into the ﬁxed point. The subspace of the relevant variables, t and h, is everywhere “orthogonal” to these trajectories (on all of which t = h = 0); the critical trajectories differ from one another only in respect of irrelevant variables that vanish as the ﬁxed point is approached. The dashed lines depict that part of the ﬂow in which the relevant variables play a decisive role. we have by equations (5) and (8) K ′ = K ∗ + k′ = Rl(K ∗ + k) (10) so that k′ = Rl ( K ∗ + k) − K ∗ (11) Assuming {kα}, and hence {k′ α}, to be small, we may linearize equation (11) to write k′ ≈ dRl dK ∣ ∣ ∣ ∣K =K ∗ k = A∗ l k (12) where A∗ l is a matrix arising from the linearization of the operator Rl around the ﬁxed point K ∗. The eigenvalues λi and the eigenvectors φi of the matrix A∗ l play a vital role in determining the critical behavior of the system. If the vectors φi form a complete set, we may expand k and k′ in terms of φi, k = ∑ i uiφi, k′ = ∑ i u′ iφi, (13a, b) with the result that u′ i = λiui i = 1, 2, . . . ; (14) 14.3 The renormalization group: general formulation 555 the coefﬁcients ui appearing here are generally referred to as the scaling ﬁelds of the prob- lem. Under successive transformations (all in the neighborhood of the ﬁxed point), these ﬁelds are given by u(n) i = λn i u(0) i . (15) It is obvious that the ﬁelds ui are certain linear combinations of the original parameters kα; they may, therefore, be looked upon as the “generalized coordinates” of the problem. The relative inﬂuence of these coordinates in determining the critical behavior of the system depends crucially on the respective eigenvalues λi. With u (n) i given by (15), we have three possible courses for a given coordinate ui. (a) If λi > 1, the coordinate ui grows with n and, with successive transformations, becomes more and more signiﬁcant. Clearly, ui in this case is a relevant variable which, by itself, drives the system away from the ﬁxed point — thus making the ﬁxed point unstable. By experience, we know that the temperature parameter t [= (T − Tc)/Tc] and the magnetic ﬁeld parameter h [= µB/kTc] are two basic quantities that vanish at the critical point and are clearly relevant to the problem of phase transitions. We, therefore, expect that our analysis will produce at least two relevant variables, u1 and u2 say, which could be identiﬁed with t and h, respectively, so that u1 = at + O(t2), u2 = bh + O(h2), (16, 17) with both λ1 and λ2 greater than unity. (b) If λi < 1, the coordinate ui decays with n and, with successive transformations, becomes less and less signiﬁcant. Clearly, ui in this case is an irrelevant variable which, by itself, drives the system toward the ﬁxed point. Now, if all the relevant variables are set at zero, then successive transformations (by virtue of the irrelevant variables) will drive the system to the ﬁxed point. We must then be cruising on the critical surface itself (where all trajectories are known to ﬂow into the ﬁxed point). It follows that on the critical surface all relevant variables of the problem are zero; furthermore, the divergence of the correlation length is also tied to the same fact. (c) If λi = 1, the coordinate ui, in the linear approximation, stays constant; it neither grows nor decays very rapidly unless one enters the nonlinear, beyond-scaling, regime of the variable ui. Quite appropriately, ui in this case is termed a marginal variable; it does not affect the critical behavior of the system as signiﬁcantly as a relevant variable does, but it may throw in logarithmic factors along with the conventional power laws. The ability to identify such variables and to predict the consequent departures from simple power-law scaling is one of the added virtues of the RG approach. The above considerations enable us to understand the pattern of ﬂow shown in Figure 14.5. While the points on the critical surface ﬂow into the ﬁxed point, those off this surface ﬂow toward the ﬁxed point by virtue of the irrelevant variables and, at the same 556 Chapter 14. Phase Transitions: The Renormalization Group Approach time, away from it by virtue of the relevant variables; the net result is an initial approach toward but a ﬁnal recession away from the ﬁxed point. Points close to the ﬁxed point and in directions “orthogonal” to the critical surface have only relevant variables to contend with, so right away they move away from the ﬁxed point. It is this part of the ﬂow that determines the critical behavior of the given system. Disregarding the irrelevant variables, we now examine the manner in which the corre- lation length, ξ , and the (singular part of the) free energy, fs, of the system are affected by the transformation (15). In view of equations (7a,b), we have ξ(u1, u2, . . .) = lnξ(λn 1 u1, λn 2 u2, . . .) (18) and fs(u1, u2, . . .) = l−ndfs(λn 1 u1, λn 2 u2, . . .). (19) Identifying u1 with t, as in (16), and remembering the deﬁnition of the critical exponent ν, we obtain from (18) u−ν 1 = ln(λn 1 u1)−ν , (20) with the result that ν = ln l/ ln λ1. (21) At ﬁrst sight one might wonder why ν should depend on l. In fact, it doesn’t because of the following argument. On physical grounds we expect that two successive transformations with scale factors l1 and l2 would be equivalent to a single transformation with scale factor l1l2, that is, 5 A∗ l1 A∗ l2 = A∗ l1l2 . (22) This forces the eigenvalues λi to be of the form l yi , for lyi 1 lyi 2 = (l1l2)yi . (23) Relation (21) then becomes ν = 1/y1, (24) manifestly independent of l. Equation (19) may now be written as fs(t, h, . . .) = l−ndfs(lny1 t, lny2 h, . . .). (25) 5This requirement makes the set of operators Rl a semigroup — not a group because the inverse of Rl does not exist. The reason for the nonexistence of R−1 l is that once a number of degrees of freedom of the system are summed over there is no deﬁnitive way of recreating them. 14.3 The renormalization group: general formulation 557 To ensure that the above relationship is independent of the choice of l, we follow the same line of argument as in Section 14.1, after equation (14.1.9), with the result fs(t, h, . . .) = |t|dν ˜fs(h/|t| 1, . . .), (26) where 1 = y2/y1. (27) Equation (26) is formally the same as the scaling relationship postulated in Section 12.10 and, one might say, argued out in Section 14.1. The big difference here is that not only has this relationship been derived on a ﬁrmer basis but now we also have a recipe for evaluat- ing the critical exponents ν, 1, and so on, from ﬁrst principles. What one has to do here is to determine the RG operator Rl for the given problem, linearize it around the appropri- ate ﬁxed point K ∗, determine the eigenvalues λi (= l yi ) and use equations (24) and (27) to evaluate ν and 1. At the same time, recalling the deﬁnition of the critical exponent α, we infer from (26) that 2 − α = dν; (28) the remaining exponents follow with the help of the scaling relations β = (2 − α) − 1, γ = 21 − (2 − α), δ = 1/β, η = 2 − (γ /ν). (29) We ﬁnd that the hyperscaling relation (28) is an integral part of the RG formulation; it comes out naturally — with no external imposition whatsoever. It is, however, dis- concerting that, according to the above argument, this relation should hold for all d — notwithstanding the fact that, for d > 4, all critical exponents are “stuck” at the mean ﬁeld values and relation (28) gets replaced by 2 − α = 4ν (d > 4), (30) with α = 0 and ν = 1 2 . The reason for this peculiar behavior is somewhat subtle; it arises from the fact that in certain situations an “irrelevant variable” may well raise its “dangerous” head and affect the outcome of the calculation in a rather signiﬁcant manner. To see how this happens, we may consider a continuous spin model, very much like the one considered in Section 13.5, with the probability distribution law p(σ i)dσ i = const. e− 1 2 σ 2 i − ˜uσ 4 i dσ i ( ˜u > 0); (31) compared with equation (13.5.1). The free energy of the system then depends on the parameter ˜u as well as on t and h, and we obtain instead of (25) fs(t, h, ˜u) = l−ndfs ( lny1 t, lny2 h, lny3 ˜u, . . .) . (32) 558 Chapter 14. Phase Transitions: The Renormalization Group Approach Now, using the RG approach, one ﬁnds (see Appendix D of Fisher, 1983) that, for d > 4, y1 = 2, y2 = 1 2 d + 1, y3 = 4 − d, (33) showing very clearly that, for d > 4, the parameter ˜u is an irrelevant variable. One is, therefore, tempted to ignore ˜u and arrive at equation (26), with ν = 1 2 and 1 = (d + 2)/4. (34) The very fact that 1 turns out to be d-dependent shows that there is something wrong here. It turns out that though, on successive transformations, the variable ˜u does tend to zero, its inﬂuence on the function fs does not. It may, therefore, be prudent to write fs(t, h, ˜u) = |t| dν ˜fs(h/|t| 1, ˜u/|t| φ), (35) where φ = y3 y1 = 4 − d 2 . (36) Now, by analysis, one ﬁnds that Lim w→0 ˜fs(v, w) ≈ 1 w F(vw1/2), (37) where F(vw1/2) is a perfectly well-behaved function. The singularity of ˜fs in w changes the picture altogether, and we get in the desired limit fs(t, h, ˜u) ≈ |t|dν+φF (h/|t|1+ 1 2 φ). (38) The “revised” value of △ now is 1rev = d + 2 4 + 4 − d 4 = 3 2 , (39) which is indeed independent of d and agrees with the corresponding mean ﬁeld value. At the same time, the “revised” form of the hyperscaling relation now is 2 − α = d 2 + 4 − d 2 = 2, (40) as stated in (30). The lesson to be learnt here is that the standard derivations of the scaling relations rest on certain assumptions, often left unstated, about the nonsingular or nonvanishing behavior of various scaling functions and their arguments. In many cases these assump- tions are valid and may even be conﬁrmed by explicit calculations or otherwise; in certain circumstances, however, they fail — in which case a scaling relation may change its form. Fortunately, such circumstances are not that common. 14.4 Applications of the renormalization group 559 14.4 Applications of the renormalization group We start our considerations with the models examined in Section 14.2. 14.4.A The Ising model in one dimension The renormalization group transformation in this case is given by equations (14.2.8b and c), namely K ′ 1 = 1 4 ln[cosh(2K1 + K2) cosh(2K1 − K2)] − 1 2 ln cosh K2 (1a) and K ′ 2 = K2 + 1 2 ln[cosh(2K1 + K2)/ cosh(2K1 − K2)], (1b) where K1 = J/kT and K2 = µB/kT . It is straightforward to see that this transformation has a “line of trivial ﬁxed points,” with K1 = 0 and K2 arbitrary. These ﬁxed points pertain to either J = 0 or T = ∞; in either case, one has a correlation length that vanishes. There is also a nontrivial ﬁxed point at K1 = ∞ and K2 = 0, which may be realized by ﬁrst setting B = 0 and then letting T → 0; the correlation length at this ﬁxed point will be inﬁnite. In the vicinity of this point, we have K ′ 1 ≃ K1 − 1 2 ln 2, K ′ 2 ≃ 2K2. (2a, b) Now, since K ∗ 1 = ∞, K1 is not an appropriate variable to carry out an expansion around the ﬁxed point. We may adopt instead a new variable, see equation (13.2.17), namely t = exp(−pK1) (p > 0), (3) so that t∗ = 0; now, in the vicinity of the ﬁxed point, we have t′ ≃ 2p/2t. (4) Identifying K2 as the variable h, and remembering that the scale factor l here is 2, we readily obtain from equations (2b) and (4) y1 = p/2, y2 = 1. (5) The critical exponents of the model now follow straightforwardly from (5); we get ν = 2/p, 1 = 2/p, (6) from which, by equations (14.3.28) and (14.3.29), α = 2 − 2/p, β = 0, γ = 2/p, δ = ∞, η = 1, (7) 560 Chapter 14. Phase Transitions: The Renormalization Group Approach in complete agreement with the results found in Section 13.2. As for the choice of p, see remarks following equation (13.3.21). 14.4.B The spherical model in one dimension The RG transformation in this case is given by equations (14.2.25b, c, and d), namely K ′ 1 = K 2 1 23 , K ′ 2 = K2 ( 1 + K1 3 ) , 3′ = 3 − K 2 1 23 , (8a, b, c) where K1 = J/kT , K2 = µB/kT , and 3 = λ/kT , λ being the “spherical ﬁeld” that was employed to take care of the constraint on the model. The nontrivial ﬁxed point is again at T = 0, where λ = J [see equation (13.5.24), with d = 1] and hence 3 = K1. Equations (8) then reduce to the linearized form (valid for small T ) K ′ 1 ≃ 1 2 K1, K ′ 2 ≃ 2K2, 3′ ≃ 1 2 3. (9a, b, c) Equations (9a) and (9c) contain essentially the same information, namely T ′ ≃ 2T . Clearly, T itself is a good variable for expansion in this case — giving y1 = 1. Equation (9b), just like (2b), gives y2 = 1, and we obtain ν = 1, 1 = 1, (10) whereby α = 1, β = 0, γ = 1, δ = ∞, η = 1, (11) in complete agreement with the results for one-dimensional models with n ≥ 2, as quoted in equation (13.3.20). 14.4.C The Ising model in two dimensions The RG transformation in this case is given by equations (14.2.45) through (14.2.47), namely K ′ = 1 4 ln cosh 4K , (12) L′ = 1 8 ln cosh 4K , (13) and M ′ = 1 8 ln cosh 4K − 1 2 ln cosh 2K . (14) It will be recalled that, while effecting this transformation, we started only with nearest- neighbor interactions (characterized by a single parameter K = βJ) but, due to the 14.4 Applications of the renormalization group 561 connectivity of the lattice, ended up with more — namely, the next-nearest-neighbor interactions (characterized by L′) and the four-spin interactions (characterized by M ′) — in addition to the nearest-neighbor interactions (characterized by K ′). On subsequent transformations, still higher-order interactions come into play and the problem becomes formidable unless some approximations are introduced. In one such approximation, due originally to Wilson (1975), we discard all interactions other than the ones represented by the parameters K and L, and at the same time assume K and L to be small enough so that equations (12) and (13) reduce to K ′ = 2K 2, L′ = K 2. (15a, b) Now, if the parameter L had been introduced right in the beginning, the transformation equations, in this very approximation, would have been K ′ = 2K 2 + L, L′ = K 2. (16a, b) We shall treat equations (16) as if they were the exact transformation equations of the problem and see what they lead to. It is straightforward to see that the transformation (16) has a nontrivial ﬁxed point at K ∗ = 1 3 , L∗ = 1 9 . (17) Linearizing around this ﬁxed point, we get k′ 1 = 4 3 k1 + k2, k′ 2 = 2 3 k1, (18) where k1 and k2 represent deviations of the parameters K and L from the ﬁxed-point val- ues K ∗ and L∗, respectively. The transformation matrix A ∗ l of equation (14.3.12) is then given by A∗√ 2 =    4 3 1 2 3 0   , (19) whose eigenvalues are λ1 = 1 3 (2 + √ 10), λ2 = 1 3 (2 − √10) (20a, b) and whose eigenvectors are φ1 ∼ ( 2 + √10 2 ) , φ2 ∼ ( 2 − √ 10 2 ) . (21a, b) The scaling ﬁelds ui are then determined by equation (14.3.13a) which, on inversion, gives u1 ∼ {2k1 + (√ 10 − 2)k2}, u2 ∼ {2k1 − ( √10 + 2)k2}. (22a, b) 562 Chapter 14. Phase Transitions: The Renormalization Group Approach Clearly, the ﬁeld u1, with λ1 > 1, is the relevant variable of the problem, while the ﬁeld u2 is irrelevant. The “critical curve” in the (K , L)-plane is determined by the condition u1 = 0, while the linear part of this curve, in the vicinity of the ﬁxed point (u = 0), is mapped by the relation (22a). In terms of the variables k1 and k2, this segment of the critical curve is given by the equation k2 ≈ − √10 + 2 3 k1, (23) which represents a straight line of slope −1.7208; see Figure 14.6. To determine the physical critical point of this model, we have to locate on the criti- cal curve a point with L = 0, for the original problem had no interactions other than the one represented by the parameter K ; the corresponding value of K would be our Kc.6 This requires a mapping of the critical curve right up to the K -axis. While this has been done numerically (Wilson, 1975), a crude estimate of Kc can be made by simply extending the straight-line segment (23) down to the desired limit. One thus obtains 7 Kc = 1 3 + 1 9 3 √10 + 2 = 4 + √ 10 18 = 0.3979, (24) which may be compared with the exact result found in Section 13.4, namely 0.4407. 0.2 L 0.1 0.0 0.1 0.2 0.3 0.4 0.5 K Kc (K∗, L∗) FIGURE 14.6 A section of the critical curve for the two-dimensional Ising model near the nontrivial ﬁxed point ( K ∗ = 1 3 , L∗ = 1 9 ) . Points on the critical curve ﬂow into the ﬁxed point, while those off it ﬂow away toward the trivial ﬁxed point (K ∗ = L∗ = 0) or (K ∗ = L∗ = ∞). 6Remember that at each and every point on the critical surface — in this case, the critical curve — the correlation length is inﬁnite; accordingly, each and every such point is qualiﬁed to be a critical point. The physical critical point is the one that is free of unnecessary parameters. 7The result obtained through numerical analysis was 0.3921. 14.4 Applications of the renormalization group 563 Another quantity that can be estimated here is the critical exponent ν. From equa- tions (14.3.21) and (14.3.20a),one obtains ν = ln l ln λ1 = ln √ 2 ln[(2 + √ 10)/3] = 0.6385, (25) which may be compared with the exact value 1. Even though a comparison of the results obtained here with the ones following from exact analysis is not very ﬂattering, the basic merits of the RG approach are quite obvious. One important aspect of critical phenomena, namely their universality over a large class of systems, is manifest even in this simple example. Imagine, for instance, that in the case of the given system a next-nearest-neighbor interaction L0 were indeed present. Our approximate treatment would then lead to the same ﬁxed point and the same criti- cal curve as above, but our physical critical point would now be given by that “point on the critical curve whose L-value is L0”; we may denote this critical point by Kc(L0). As for the critical behavior, it will still be determined by an expansion around the ﬁxed point, for that is where the “relevant part” of the ﬂow is; see again Figure 14.6. Clearly, the crit- ical behavior of the given system, insofar as exponents are concerned, will be the same, regardless of the actual value of L0. And, by extension, the same will be true of any two systems which have the same basic topology but differ only in the details of the spin–spin interactions. As for the accuracy of the results obtained here, improvements are needed in several important respects. First of all, the exclusion of all interaction parameters other than K and L constitutes a rather inadequate approximation; one should at least include the four-spin interaction, represented by the parameter M, and may possibly ignore the ones that appear on successive transformations. Next, the assumption that the parameters K and L are small is also unjustiﬁed, especially for K ; this makes a numerical approach to the problem rather essential. Thirdly, we disregarded the renormalization of the spins, from the original σ (r) to σ ′(r′), as required by equation (14.1.23); in the present problem, this would amount to introducing a factor of ( √2)η/2, that is, 21/16, for η here is 1 4 . In the actual treatment, one may have to introduce an unknown parameter, ρ, and determine its “true” value by theo- retical analysis (see Wilson, 1975). Highly sophisticated procedures have been developed over the years to accommodate (or circumvent) these problems, leading to very accurate — in fact, almost exact — results for the model under considerations. For details, see the review article by Niemeijer and van Leeuwen (1976), where references to other pertinent literature on the subject can also be found. 8 14.4.D The ε-expansion Application of the RG approach to systems in higher dimensions, namely with d > 2, presents serious mathematical difﬁculties. One is then forced to resort to approximation procedures such as the ε-expansion, ﬁrst introduced by Wilson (1972); see also Wilson 8In this reference one can also ﬁnd a systematic method of constructing the scaling function fs(u1, u2, . . .) from a knowledge of the regular function f (K ′ 0) of equation (14.3.4). 564 Chapter 14. Phase Transitions: The Renormalization Group Approach and Fisher (1972). This procedure was inspired by the observation that the ﬁeld-theoretic calculations of the RG formulation become especially simple as the upper critical dimen- sion, d = 4, is approached; it, therefore, seemed desirable to introduce a parameter ε(= 4 − d) and carry out expansions of the various quantities of interest around ε = 0. The model adopted for these calculations was the same as the one referred to in Section 14.3, namely the continuous, n-vector spin model, with the probability distribution given by equation (14.3.31). 9 An important advantage of using continuous spins σ (r){= σ (µ)(r), µ = 1, . . . , n}, with −∞ < σ (µ) < ∞, is that one can introduce Fourier transforms σ (q) and make use of the “momentum shell integration” technique of Wilson (1971). The parameters of interest now are (see Fisher, 1983) r = T − T0 T0R2 0 = t0 R2 0 , u = ˜u T 2ad T 2 0 R4 0 (26a, b) and, of course, the magnetic ﬁeld parameter h; here, T0 denotes the mean-ﬁeld critical temperature qJ/k (q being the coordination number), R0 is a measure of the range of interactions, a is the lattice constant, whereas ˜u is the real-space parameter appearing in equation (14.3.31). The transformation equations, with a scale factor l, turn out to be r′ = l2r + 4(l2 − 1)c(n + 2)u − l2 ln l(n + 2)(2π 2)−1ru, (27a) u′ = (1 + ε ln l)u − (n + 8) ln l(2π 2)−1u2, (27b) and h′ = l3 ( 1 − 1 2 ε ln l) h, (27c) correct to the orders displayed; the parameter c in equation (27a) is related to a cutoff in the momentum space which, in turn, is a reﬂection of the underlying lattice structure. Transformation (27) has two ﬁxed points — the so-called Gaussian ﬁxed point, with r∗ = u∗ = h ∗ = 0, (28) and a non-Gaussian ﬁxed point, with r∗ = − 8π 2c(n + 2) (n + 8) ε, u∗ = 2π 2 (n + 8) ε, h∗ = 0. (29) We now examine two distinct situations. 9It can be shown that, by a suitable transformation, the Ising model (n = 1), which is a discrete (rather than a con- tinuous) model, can also be rendered “continuous” with a probability distribution similar to (14.3.31). For details, see Appendix A in Fisher (1983). 14.4 Applications of the renormalization group 565 Dimension d ≳ 4, so that ε is a small negative number One readily sees from equation (27b) that the parameter u in this case decreases on trans- formation, so on successive transformations it will tend to zero. Clearly, only the Gaussian ﬁxed point is the one appropriate to this case. Linearizing around this point, we obtain for the transformation matrix A∗ l A∗ l = ( l2 4(l2 − 1)c(n + 2) 0 1 + ε ln l ) , (30) with eigenvalues λr = l2, λu = (1 + ε ln l) < 1 (31) and, of course, λh = l3 ( 1 − 1 2 ε ln l) . (32) It follows that y1 = 2, y2 ≈ 3 − 1 2 ε, y3 ≈ ε, (33) as in equation (14.3.33). Note that the parameter u in this case is an irrelevant variable but, as discussed at the end of Section 14.3, it is a dangerously irrelevant variable that does eventually affect the results of the calculation in hand. Dimension d ≲ 4, so that ε is a small positive number The parameter u now behaves very differently. If it is already zero, it stays so; otherwise, it moves away from that value, carrying the system to some other ﬁxed point — possibly the non-Gaussian one, with coordinates given in (29). The resulting pattern of ﬂow in the (r, u)- plane is shown in Figure 14.7; clearly, the Gaussian ﬁxed point is no longer appropriate and the problem now revolves around the non-Gaussian ﬁxed point instead. Linearizing around the latter, we obtain A∗ l =  l2 {1 − n + 2 n + 8 ε ln l} 4(l2 − 1)c(n + 2) 0 1 − ε ln l  , (34) with eigenvalues l2 {1 − n + 2 n + 8 ε ln l} and (1 − ε ln l) < 1. (35) We note that of the “generalized coordinates” u1 and u2, which are certain linear combi- nations of the parameters 1r(= r − r∗) and 1u(= u − u∗), only u1 is a relevant variable of 566 Chapter 14. Phase Transitions: The Renormalization Group Approach r ∗ (r ∗, u ∗) r(0, 0) u ∗ u FIGURE 14.7 A section of the critical curve and a sketch of the RG ﬂows in the (r, u)-plane for 0 < ε ≪ 1. Note that the critical curve is straight only to order ε. the problem. 10 Identifying u1 with the temperature parameter t, we obtain yt ≈ 2 − n + 2 n + 8 ε. (36) Combining this with expression (33) for yh, namely yh ≈ 3 − 1 2 ε, (37) we obtain, see equations (14.3.24), (14.3.27), (14.3.28), and (14.3.29), ν ≈ 1 2 + n + 2 4(n + 8) ε, 1 ≈ 3 2 + n − 1 2(n + 8) ε, (38) which gives α ≈ 4 − n 2(n + 8) ε, β ≈ 1 2 − 3 2(n + 8) ε, γ ≈ 1 + n + 2 2(n + 8) ε, (39) δ ≈ 3 + ε, η ≈ 0, (40) correct to the ﬁrst power in ε. For obvious reasons the value of ε of greatest interest to us is ε = 1, for which the above results are totally inadequate; they do show the correct trends, though. For better numeri- cal accuracy it is essential to extend these calculations to higher orders in ε. Considerable 10It can be seen quite easily that the generalized coordinate u2 is directly proportional to 1u, making u an irrelevant variable of the problem; see Problem 14.6, with a21 = 0. 14.4 Applications of the renormalization group 567 progress has been made in this direction, so that we now have expressions available that include terms up to ε3 and, in some cases, even ε4; for details, see Wallace (1976). One wonders if that degree of extension would be good enough for obtaining reliable results for ε as large as 1. The answer is yes, and we will illustrate it with an example. For the spherical model we know exact values of the various critical exponents which may, for the purpose of illustration, be expressed as power series in ε. Thus, for instance, γ = 2 d − 2 = ( 1 − 1 2 ε)−1 = 1 + 1 2 ε + 1 4 ε2 + 1 8 ε3 + 1 16 ε4 + · · · . (41) Since the radius of convergence of this series is 2, the value 1 of ε is not really as large as it seems. In fact, the terms displayed in (41) already give, for ε = 1, γ = 1.9375, as opposed to the correct value 2. The situation is clearly encouraging and, with better methods of summing up diagrams, the convergence of the ε-expansions can be improved greatly. In fact, some of the entries in Table 13.1 were originally obtained (or at least rechecked) with the help of this method. Before closing this subsection we would like to point out a somewhat unusual piece of information contained in the ﬁrst-order results obtained above. This refers to the exponent α, for which we note the prediction that for large n it is negative and hence the (singular part of the) speciﬁc heat vanishes at T = Tc (which we know to be the case with the spher- ical model) whereas for small n it is positive and hence the speciﬁc heat diverges (which we know to be the case with Ising-like systems). The inversion, from one case to the other, takes place at n = 4 where α, according to the ﬁrst-order expression (39), vanishes. The inclusion of the second-order term in ε upholds this prediction qualitatively but changes it quantitatively. We now have α ≈ 4 − n 2(n + 8) ε − (n + 2)2(n + 28) 4(n + 8)3 ε2, (42) so that, with ε = 1, the inversion takes place between n = 1 and n = 2 — in agreement with the more accurate results quoted in Section 13.7. 14.4.E The 1/n expansion Another approach to the problem of determining critical exponents, as functions of d and n, is to adopt the limiting case n = ∞ as the starting point and carry out expansions in powers of the small quantity 1/n. Clearly, the leading terms in these expansions would pertain to the spherical model, which has been studied in Section 13.5, and the correction terms would enable us to get some useful information on models with ﬁnite n. We quote 568 Chapter 14. Phase Transitions: The Renormalization Group Approach some ﬁrst-order results here: 11 η = 4(4 − d)Sd d 1 n + O ( 1 n2 ) , (43) γ = 2 d − 2 {1 − 6Sd n + O ( 1 n2 )} , (44) and α = − 4 − d d − 2 { 1 − 8(d − 1)Sd 4 − d 1 n + O ( 1 n2 )} , (45) where Sd = sin{π(d − 2)/2}0(d − 1) 2π{0(d/2)}2 (2 < d < 4). (46) We note that the coefﬁcients of expansion in this approach are functions of d just as the coefﬁcients of expansion in the preceding approach were functions of n; in this sense, the two expansions are complementary to one another. Unfortunately, there has not been much progress in the evaluation of further terms of these expansions (except for the one mentioned in the note); accordingly, the usefulness of this approach has been rather limited. 14.4.F Other topics As mentioned earlier, the renormalization group approach has provided a very clear expla- nation of the concept of universality, in that it arises when several physical systems, despite their microscopic structural differences, are governed by a common ﬁxed point and hence display a common critical behavior. Typically, this behavior is linked to the dimensionality d of the physical space, the dimensionality n of the spin vector σ and the range of the spin–spin interaction. Now, depending on the precise nature of the Hamil- tonian and the relative importance of the various parameters therein, it is quite possible that under certain circumstances the critical behavior of the system may “cross over” from being characteristic of one ﬁxed point to being characteristic of another ﬁxed point. For instance, we may write for the spin–spin interaction in the lattice Hint = − 1 2 ∑ r,r′ ∑ α,β J αβ (r − r′)σ α(r)σ β (r′) α, β = 1, . . . , n. (47) 11In the special case d = 3, the expansion for η is known to a higher order, namely η = 8 3π 2n − ( 8 3 )3 1 π 4n2 + O ( 1 n3 ) . 14.4 Applications of the renormalization group 569 If the given interaction is isotropic in the physical space but anisotropic in the spin com- ponents (assumed three in number), so that J αβ = J αδαβ , then the system is ordinarily supposed to be a Heisenberg ferromagnet; however, the anisotropy of the interaction may ﬁnally drive the system toward an Ising ﬁxed point (if one of the J α dominates over the other two) or toward an XY ﬁxed point (if two of the J α are equally strong and dominate over the third one). In either case, we encounter what is generally referred to as a crossover phenomenon. Similarly, anisotropy in the physical space, J(R) = J(Ri)δij or K (R)RiRj, may result in a crossover from a d-dimensional behavior to a d′-dimensional behavior (where d′ < d). In the same vein, one may consider a long-range interaction, J(R) ∼ R−d−σ δij, leading to a critical behavior which, for σ < 2, is quite seriously σ -dependent; see, for instance, Prob- lem 13.22. However, as σ goes over from the value 2− to 2+, the system crosses over to the universality class characterized by a short-range interaction and remains in that class for all σ > 2. Crossover phenomena constitute a very fascinating topic in the subject of phase transitions but we cannot pursue them here any more; the interested reader may refer to an excellent review by Aharony (1976). Another topic of considerable interest deals with the so-called interfacial phase tran- sitions in both magnets and ﬂuids. In his seminal paper of 1944, Onsager included in his model a row of “mismatched spins,” calculated the boundary tension (or what is more commonly referred to as the interfacial free energy) of this row and examined how this quantity vanished as T approached Tc. In the case of a ﬂuid system, this corresponds to the disappearance of the meniscus between the liquid and the vapor and hence to the vanishing of the conventional surface tension as T → Tc−; see, in this connection, Prob- lem 12.27. A theoretical study of such interfacial layers involves consideration of the free energy of an inhomogeneous system, which has been a subject of considerable research for quite some time. We refer the interested reader to two review articles — by Abraham (1986) and by Jasnow (1986) — for further reading on this topic. A major ingredient employed by the RG approach is the fact that the critical behav- ior of a system is invariant under a scale transformation. It did not take very long to realize that an important connection exists between this transformation and the well-known con- formal transformation in a complex plane, for the latter too is, roughly speaking, a scale transformation in which the scale factor l varies continuously with position. Though, in principle, this connection could be relevant in all dimensions, the most fruitful applica- tions have been in the realm of two dimensions (where the conformal group consists of analytic functions of a complex variable). Among the important results emerging from the conformal transformation approach, one may mention the form of the many-point cor- relation functions, the critical behavior of ﬁnite-sized strips of different sizes and shapes, and the nature of the surface critical effects. For details, see the review article by Cardy (1987). Another area of interest pertains to the so-called multicritical points, for which refer- ence may be made to Lawrie and Sarbach (1984) for theoretical studies and to Knobler and Scott (1984) for experimental results. 570 Chapter 14. Phase Transitions: The Renormalization Group Approach 14.5 Finite-size scaling In our study of phase transitions so far, we generally worked in the thermodynamic limit, that is, we started with a lattice of size L1 × . . . × Ld, containing N1 × . . . × Nd spins (where Nj = Lj/a, a being the lattice constant), but at some appropriate stage of the calculation resorted to the limit Lj → ∞. This limiting process is crucial in some important respects; while it simpliﬁes subsequent calculations, it also generates singularities which, as we know, are a hallmark of systems undergoing phase transitions. It is of considerable inter- est, both theoretically and experimentally, to ﬁnd out what happens (or does not happen) if some of the Lj are allowed to stay ﬁnite. The resulting analysis is quite complicated, but considerable progress has been made in this direction during the last 25 years or so. Accordingly, a whole new subject entitled “ﬁnite-size scaling” has emerged, of which only a brief summary will be presented here. The reader interested in further details may refer to Barber (1983), Cardy (1988), and Privman (1990). To ﬁx ideas, we start with a d-dimensional bulk system (“bulk” in the sense that it is inﬁ- nite in all its dimensions) that undergoes a phase transition at a ﬁnite critical temperature Tc(∞); clearly, the dimensionality d must be greater than the “lower critical dimension” d<. We also assume that d is less than the “upper critical dimension” d>, so that the critical exponents of the system are d-dependent and obey the hyperscaling relation dν = 2 − α = 2β + γ . (1) We now consider a similar system that is inﬁnite in only d′ dimensions, where d′ < d, and ﬁnite in the remaining dimensions; the geometry of this system may be expressed as Ld−d′ × ∞d′ , where L ≫ a and, for simplicity, is taken to be the same in all ﬁnite dimen- sions. We may expect this system to be critical at a ﬁnite temperature Tc(L), not very different from Tc(∞). In reality, this is so only if d′ too is greater than d<; otherwise, the system continues to be regular at all ﬁnite temperatures and the criticality sets in only at T = 0. 12 The cases d′ > d< and d′ ≤ d<, therefore, merit separate treatments. Our primary goal here is to determine the L-dependence of the various physical quan- tities pertaining to the system when the system is undergoing a phase transition. We attain this goal by setting up a ﬁnite-size scaling law that generalizes equation (12.10.7) or equa- tion (14.3.26) to systems with a ﬁnite L. Now, since the only relevant length in the region of a phase transition is the correlation length ξ of the system, it is natural that we scale L with ξ — leading to the combination (L/ξ ) ∼ Ltν = (L1/ν t)ν . (2) At the same time, the combination (h/t1) appearing in the bulk scaling law may be written as (h/t1) = (hL1/ν )/(L1/ν t)1. (3) 12For the special case d′ = 0, when the system is fully ﬁnite, this point has already been emphasized in Section 12.1. Here we assert that, even when some of the system dimensions are inﬁnite (and hence the total number of spins is inﬁnite), a ﬁnite-temperature singularity does not arise unless the number of those inﬁnite dimensions exceeds d<. 14.5 Finite-size scaling 571 The appropriate combinations of L with t and h, therefore, are L1/νt and L1/νh, respec- tively. The “singular” part of the free energy density of the system may then be written in the form (see Privman and Fisher, 1984) f (s)(t, h; L) ≡ A(s) VkT ≈ L−dY (x1, x2), (4) where x1 and x2 are the scaled variables of the system, namely x1 = C1L1/ν t, x2 = C2L1/ν h, (5a, b) with t = T − Tc(∞) Tc(∞) , h = µB kT |t|, h ≪ 1, (6a, b) while C1 and C2 are certain nonuniversal scale factors peculiar to the system under study. Expressed in terms of the variables x1 and x2, the function Y is expected to be a univer- sal function — common to all systems in the same universality class as the system under study. Of course, the deﬁnition of the universality class will now include (apart from the conventional parameters d, n, and the range of the spin–spin interaction) the parameter d′ as well as the nature of the boundary conditions imposed on the system (which, unless stated otherwise, will be assumed to be periodic). We note that, in the limit L → ∞, expression (4) reduces to equation (12.10.7), provided that the function Y has the asymptotic form Y (x1, x2) ≈ |x1|dν f±(x2/|x1| 1) |x1|, x2 ≫ 1, (7) thus identifying the nonuniversal parameters F and G with C dν 1 and C2/C1 1 , respectively. This enables us to write C1 and C2 in terms of F and G, namely C1 ∼ F 1/(2−α), C2 ∼ F (β+γ )/(2−α)G, (8a, b) which provides a means of determining the nonuniversal parameters C1 and C2 from a knowledge of the bulk parameters F and G; any other factors appearing in (8) would be universal. Once C1 and C2 are known, no more nonuniversal amplitudes are needed to describe the behavior of the system — regardless of whether it is ﬁnite-sized or inﬁnite in extent. We are now in a position to examine the consequences of the scaling law (4). With appropriate differentiations, we obtain from equation (4) the following expres- sions for the zero-ﬁeld susceptibility per unit volume and the “singular” part of the zero-ﬁeld speciﬁc heat per unit volume: χ0(t; L) = − 1 V ( ∂ 2A(s) ∂B2 ) B=0 ≈ − kT µ2C2 2 L21/ν−d (kT )2 ( ∂ 2Y (x1, x2) ∂x2 2 ) x2=0 = µ2C2 2 Lγ /ν kT Yχ (x1), (9) 572 Chapter 14. Phase Transitions: The Renormalization Group Approach and c(s) 0 (t; L) = − T V ( ∂ 2A(s) ∂T 2 ) B=0 ≈ − kT 2C2 1 L2/ν−d T 2 c (∞) ( ∂ 2Y (x1, x2) ∂x2 1 ) x2=0 = kT 2C2 1 Lα/ν T 2 c (∞) Yc(x1), (10) where Yχ (x1) and Yc(x1) are appropriate derivatives of the universal function Y (x1, x2) and, hence, are themselves universal. We may, for further analysis, supplement the above results with the corresponding ones for the correlation length of the ﬁnite-sized system, namely ξ(t, h; L) = LS(x1, x2) (11) and ξ0(t; L) = LS(x1), (12) where S(x1) = S(x1, 0); note that the functions S(x1, x2) and S(x1) are also universal. We shall now focus our attention on equations (9), (10), and (12), to see what messages they deliver in different regimes of the variables T and L. Case A: T ≳ Tc(∞) With t > 0 and L ≫ a, the variable x1 in this regime would be positive and much greater than unity. The functions Yχ , Yc, and S are then expected to assume the form Yχ (x1) ≈ 0x−γ 1 , Yc(x1) ≈ Ax−α 1 , S(x1) ≈ Nx−ν 1 , (13a, b, c) so that we recover the standard bulk results χ0 ≈ µ20C−γ 1 C2 2 kTc(∞) t−γ , c(s) 0 ≈ kAC2−α 1 t−α, ξ0 ≈ NC−ν 1 t−ν , (14a, b, c) complete with nonuniversal amplitudes and universal factors. The effect of L in this regime appears only as a correction to the bulk results; under periodic boundary conditions, such correction terms turn out to be exponentially small, that is, O(e−L/ξ0 ) where ξ0 ∼ a.13 Case B: T ≃ Tc(∞) This case refers to the “core region” where |x1| is of order unity and hence |t| is of order L−1/ν; the bulk critical point, t = 0, is at the heart of this region. Equations (9), (10), and (12) now yield the ﬁrst signiﬁcant results of ﬁnite-size scaling, namely χ0 ∼ µ2C2 2 kTc(∞) Lγ /ν , c(s) 0 ∼ kC2 1 Lα/ν , ξ0 ∼ L. (15a, b, c) 13See, for instance, Luck (1985), and Singh and Pathria (1985b, 1987a). 14.5 Finite-size scaling 573 Case C: T < Tc(∞) Here we must distinguish between the cases d′ > d< and d′ ≤ d<. In the ﬁrst case, the sys- tem becomes critical at a temperature Tc(L) that is not too far removed from Tc(∞); in the second, the system remains regular at all ﬁnite temperatures and becomes critical only at T = 0. (i) d′ > d< In view of the fact that the system is now singular at T = Tc(L) rather than at Tc(∞), it seems natural to deﬁne a shifted temperature variable ˙t such that ˙t = T − Tc(L) Tc(∞) ; (16) compare this with (6a). Thus, for any temperature T , ˙t = t − τ ; τ = [Tc(L) − Tc(∞)]/Tc(∞), (17) which prompts us to deﬁne a shifted scaled variable ˙x1 = C1L1/ν ˙t = x1 − X ; X = C1L1/ν τ . (18) Clearly, the scaling functions governing the system would now be singular at ˙x1 = 0, that is, at x1 = X . With no other arguments present, we presume that |X | will be of order unity; the shift in Tc is thus given by |τ | = |X |C−1 1 L−1/ν = O(L−1/ν ). (19) Now, as T → Tc(L), the correlation length of the system approaches inﬁnity — with the result that, insofar as the qualitative nature of the critical behavior is concerned, the ﬁnite variable L, however large, becomes essentially unimportant. The behavior of the system, in the immediate neighborhood of Tc(L), would, therefore, be characteristic of a d′-dimensional bulk system rather than of a d-dimensional one; accordingly, it would be governed by the critical exponents ˙α, ˙β, . . . pertaining to d′ dimensions rather than by the exponents α, β, . . . pertaining to d dimensions. We, therefore, expect that, as ˙x1 → 0, the functions Yχ , Yc, and S of equations (9), (10), and (12) assume the form Yχ (x1) ≈ ˙0 ˙x− ˙γ 1 , Yc(x1) ≈ ˙A˙x− ˙α 1 , S(x1) ≈ ˙N ˙x−˙ν 1 , (20a, b, c) with the result that χ0 ≈ [µ2/kTc(∞)] ˙0C− ˙γ 1 C2 2 L(γ − ˙γ )/ν ˙t− ˙γ , (21a) c(s) 0 ≈ k ˙AC2− ˙α 1 L(α− ˙α)/ν ˙t− ˙α, (21b) 574 Chapter 14. Phase Transitions: The Renormalization Group Approach and ξ0 ≈ ˙NC−˙ν 1 L(ν−˙ν)/ν ˙t−˙ν . (21c) It is obvious that, for ˙t < 0 but such that |˙t| ≪ 1, the same results would hold — except that ˙t would be replaced by |˙t|. The contents of equations (21), insofar as the dependence on L and ˙t is concerned, have been veriﬁed by direct calculation on a variety of systems over the years; for details, see the review articles by Barber (1983) and Privman (1990) cited earlier. More recently, Allen and Pathria (1989) have veriﬁed the nonuniversal amplitudes as well by carrying out an explicit calculation for the spherical model (n = ∞) in the general geometry Ld−d′ × ∞d′, with both d and d′ greater than d<. Remarkably enough, they found that, just as the critical exponents ˙α, ˙β, . . . are the same functions of d′ as the exponents α, β, . . . are of d, the universal coefﬁcients ˙0, ˙A, . . . too are the same functions of d′ as the coefﬁcients 0, A, . . . are of d; the same is true of the coefﬁcients appearing in the presence of a magnetic ﬁeld (see Allen and Pathria, 1991). One wonders if this would also be the case for general n! (ii) d′ ≤ d< In this case the singularity of the problem lies at T = 0, with the result that at all ﬁnite temperatures the system is regular and hence expressible by smooth, analytic functions. We may, therefore, generalize the scaling law (4) to apply at all temperatures down to T = 0 by simply allowing the scale factors C1 and C2 to become T -dependent and writing (after Singh and Pathria, 1985b, 1986a) x1 = ˜C1(T )L1/ν t, x2 = ˜C2(T )L1/ν h, (22a, b) leaving t and h unchanged; the quantities ˜C1 and ˜C2 must be such that, as T → Tc(∞) from below, they approach the quantities C1 and C2 of equations (5). Expressions (9) and (10) now take the form χ0(t; L) = µ2 ˜C2 2 Lγ /ν kT Yχ (x1) (23) and c(s) 0 (t; L) = kT 2 [ ∂ ∂T ( ˜C1t) ]2 Lα/ν Yc(x1), (24) respectively, while expression (12) remains formally the same. Now, as we approach the critical temperature Tc (which is zero here), we again expect the quantities χ0, c(s) 0 , and ξ0 to behave in a manner characteristic of a d′-dimensional bulk system. So, let us assume that, in limit d → 0, our scale factors behave as ˜C1 ∼ T r, ˜C2 ∼ T s (T → 0), (25a, b) 14.5 Finite-size scaling 575 and our universal functions behave as Yχ (x1) ∼ |x1|θ , Yc(x1) ∼ |x1| φ, S(x1) ∼ |x1| σ (x1 → −∞). (26a, b, c) The resulting T -dependence of χ0, c(s) 0 , and ξ0 then is χ0 ∼ T 2s−1+θ r, c(s) 0 ∼ T (2+φ)r, ξ0 ∼ T σ r. (27a, b, c) The corresponding results for an n-vector, d′-dimensional model (with n ≥ 2 and d′ < d<, where d< = 2) are 14 χ0 ∼ T −2/(2−d′), c(s) 0 ∼ T d′/(2−d′), ξ0 ∼ T −1/(2−d′). (28a, b, c) Comparing (27) with (28), we infer that θ = 1 r [1 − 2s − 2 2 − d′ ] , φ = d′ r(2 − d′) − 2, σ = −1 r(2 − d′) . (29a, b, c) Very shortly we shall ﬁnd, see equations (44), that r = −1/ν(d − 2), s = β/ν(d − 2), (30a, b) with the results θ = 2β + νd′(d − 2) (2 − d′) , φ = − νd′(d − 2) (2 − d′) − 2, σ = ν(d − 2) (2 − d′) . (31a, b, c) The L-dependence of the various quantities now turns out to be χ0 ∼ L(γ +θ)/ν ∼ L2(d−d′)/(2−d′) (32a) c(s) 0 ∼ L(α+φ)/ν ∼ L−2(d−d′)/(2−d′) (32b) and ξ0 ∼ L1+σ/ν ∼ L(d−d′)/(2−d′). (32c) It is remarkable that in these last expressions the critical exponents pertaining to d dimen- sions have disappeared altogether and the resulting powers of L depend entirely on the geometry of the system! Expression (32a) agrees with the earlier results for χ0 pertaining to a “block” geometry (d′ = 0) and to a “cylindrical” geometry (d′ = 1), namely χ0 ∼ { Ld for d′ = 0 (33a) L2(d−1) for d′ = 1; (33b) 14For the spherical model (n = ∞), these results appear in Section 13.5; see equations (13.5.34), (13.5.35), and (13.5.64). Since the criticality in this case occurs at absolute zero, these results hold for all models with continuous symmetry, that is, with n ≥ 2. See, for instance, Section 13.3, where n is general but d′ = 1. 576 Chapter 14. Phase Transitions: The Renormalization Group Approach see Fisher and Privman (1985). For d′ = 2, the L-dependence of the various quantities studied here becomes exponential instead of a power law. To obtain results valid for all T in the range 0 < T < Tc(∞), we need to know the full T -dependence of the scale factors ˜C1 and ˜C2. It turns out that this too can be determined from the properties of the corresponding bulk system — in particular, from the ﬁeld-free bulk correlation function G(R, T ), which is known to possess the following forms: G(R, T ) ∼ R−(d−2+η) T = Tc(∞) (34) and G(R, T ) = m2 0(T ) + A(T )R−(d−2) T < Tc(∞), (35) where m0(T ) is the order parameter of the bulk system and A(T ) another system- dependent parameter. 15 Now, the correlation function of the ﬁnite-sized system may be written in the scaled form G(R, t, h; L) ≈ ˜D(T )R−(d−2+η)Z(x1, x2, x3), (36) where the scaled variables x1 and x2 are the same given by equations (22a, b) while x3 = R/L; as usual, the scale factor ˜D(T ) is nonuniversal while the function Z(x1, x2, x3) is universal. Expression (36) already conforms to (34), with x1 = x2 = x3 = 0. For conformity with (35), the function Z must possess the following asymptotic form: Z(x1, x2, x3) ≈ Z1(|x1| ν x3)d−2+η + Z2(|x1| ν x3)η x1 → −∞, x2 = 0, x3 → 0, (37) with Z1 = m2 0(T ) ˜D(T )[ ˜C1(T )|t|]ν(d−2+η) , Z2 = A(T ) ˜D(T )[ ˜C1(T )|t|]νη . (38a, b) It follows that ˜C1(T )|t| ∼ [ m2 0(T ) A(T ) ]1/ν(d−2) , ˜D(T ) ∼ [ Aβ (T ) mνη 0 (T ) ]2/ν(d−2) ; (39a, b) here, use has been made of the fact that ν(d − 2 + η) = (2 − α) − γ = 2β. (40) We shall now establish a relationship between the scale factors ˜C2 and ˜D. For this, we utilize the ﬂuctuation–susceptibility relation (12.11.12) which, with the help of 15Note that the exponent η appears only in equation (34) and not in (35); for details, see Schultz et al. (1964) and Fisher et al. (1973). 14.5 Finite-size scaling 577 expression (36), gives for the zero-ﬁeld susceptibility per unit volume χ0(t; L) = µ2 ˜D(T ) a2dkT ∫ Z(x1, 0, R/L) Rd−2+η ddR = µ2 ˜D(T ) a2dkT L2−ηZχ (x1), (41) where Zχ is another universal function. Comparing (41) with (23), we get ˜D(T ) ∼ a2d ˜C2 2 (T ). (42) Equation (39b) now gives ˜C2(T ) ∼ a−d[Aβ (T )/mνη 0 (T )] 1/ν(d−2). (43) Equations (39) and (43) give us the full T -dependence of the scale factors ˜C1, ˜C2, and ˜D for all T in the range 0 < T < Tc(∞); these equations were ﬁrst derived by Singh and Pathria (1987a). Before utilizing these results we note that since, in the limit T → 0, m0(T ) approaches a constant value while A(T ) ∼ T , expressions (39a) and (43) yield ˜C1|t| ∼ T −1/ν(d−2), ˜C2 ∼ T β/ν(d−2), (44a, b) exactly as stipulated in equations (25) and (30). As for the T -dependence of the quantities χ0, c(s) 0 , and ξ0, we observe that, regardless of whether we keep L ﬁxed and let T → 0 or keep T ﬁxed and let L → ∞, in either case x1 → −∞; the asymptotic forms (26) of the universal functions Yχ , Yc, and S, therefore, apply throughout the region under study. Now, with θ, φ, and σ given by equations (31), our ﬁnal results for χ0, c(s) 0 , and ξ0 turn out to be χ0 ∼ µ2A(T ) a2dkT [ m2 0(T ) A(T ) ]2/(2−d′) L2(d−d′)/(2−d′), (45) c(s) 0 ∼ k { T ∂ ∂T [ m2 0(T ) A(T ) ]}2 [ m2 0(T ) A(T ) ]−(4−d′)/(2−d′) L−2(d−d′)/(2−d′), (46) and ξ0 ∼ [ m2 0(T ) A(T ) ]1/(2−d′) L(d−d′)/(2−d′), (47) complete with nonuniversal amplitudes. Comparing (45) with (47), we ﬁnd that, in the regime under study, χ0/ξ 2 0 ∼ µ2A(T )/a2dkT , (48) 578 Chapter 14. Phase Transitions: The Renormalization Group Approach a function of T only. In the case of the spherical model, since A(T ) is proportional to T at all T < Tc(∞), see equation (13.5.71), the quantity χ0/ξ 2 0 is a constant — independent of both T and L; see also equation (13.5.64). It is important to note that the above formulation ties very neatly with the one provided by the scale factors C1 and C2 of equations (5) that covered cases A and B pertaining to the regions T ≳ Tc(∞) and T ≃ Tc(∞), respectively. To see this, we observe that, as T → Tc(∞) from below, m0(T ) becomes ∼ |t|β and A(T ) ∼ |t|νη; expressions (39a) and (43) then assume the form ˜C1(T )|t| ∼ |t| (2β−νη)/ν(d−2) ∼ |t|1 (49a) and ˜C2(T ) ∼ |t| 0. (49b) Clearly, ˜C1(T ) and ˜C2(T ) now assume some constant values that may be identiﬁed with C1 and C2 — thus providing a uniﬁed formulation through the same universal func- tions Y (x1, x2), S(x1, x2), and Z(x1, x2, x3) covering the regions of both ﬁrst-order and second-order phase transitions! Remarkable though it is, this ﬁnding is not really surpris- ing because, with L ﬁnite and d′ ≤ d<, the system is critical only at T = 0 and analytic everywhere else; so, its properties should indeed be expressible by a single set of func- tions throughout. Of course, as L → ∞, the criticality spreads all the way from T = 0 to T = Tc(∞). As regards the spin dimensionality n, our results for cases A, B, and C(i) were quite gen- eral; only in case C(ii) did we specialize to systems with continuous symmetry (n ≥ 2). With a slight modiﬁcation, the case of discrete symmetry (n = 1) can also be taken care of. The net result essentially is the replacement of the number 2 in equations (28) and henceforth by the “lower critical dimension,” d<, of the system — leading to results such as 16 χ0 ∼ Lζ , c(s) 0 ∼ L−ζ , ξ0 ∼ Lζ /d< T < Tc(∞), (50a, b, c) with ζ = d<(d − d′)/(d< − d′); compared with equations (32). Once again, the L- dependence of the various quantities of interest follows a power law, which changes to an exponential when d′ = d<; in the case of scalar models, this happens at d′ = 1. Throughout this discussion we have assumed that the total dimensionality d of the system is less than the “upper critical dimension” d>. The case d ≥ d> presents some special problems but the net result is that, while the situation in the region T < Tc(∞) is described by the same set of expressions as above, in the region T ≃ Tc(∞) it is con- siderably modiﬁed. For instance, one now gets in the region T ≃ Tc(∞), for d > d> and d′ < d<, χ0 ∼ L2(d−d′)/(d>−d′), c(s) 0 ∼ L0, ξ0 ∼ L(d−d′)/(d>−d′), (51a, b, c) 16See, for instance, Singh and Pathria (1986b). Problems 579 which may be compared with the corresponding results, (15a, b, c), for d < d>. Further- more, if d = d> and/or d′ = d<, factors containing ln L appear along with the power laws displayed in (51). For details, see Singh and Pathria (1986b, 1988, 1992). Finally we would like to emphasize the fact that ﬁnite-size effects in any given system are quite sensitive to the choice of the boundary conditions imposed on the system. For simplicity, we assumed the boundary conditions to be periodic. In real situations, there may be reasons to adopt different boundary conditions such as antiperiodic, free, and so on. This, in general, changes the mathematical character of the ﬁnite-size effects and the ﬁnite-size corrections in not only the singular part(s) of the various quantities stud- ied but in their regular part(s) as well. For comparison between theory and experiment, this aspect of the problem is of vital importance and deserves a close scrutiny. For lack of space we cannot go into this matter any further here; the interested reader may refer to a review article by Privman (1990), where other references on this topic can also be found. An allied subject in this regard is the “critical behavior of surfaces,” for which reference may be made to Binder (1983) and Diehl (1986). Problems 14.1. Show that the decimation transformation of a one-dimensional Ising model, with l = 2, can be written in terms of the transfer matrix P as P ′ {K ′} = P2{K }, (1) where K and K ′ are the coupling constants of the original and the decimated lattice, respectively. Next show that, with P given by (P{K }) = eK0 (eK1+K2 e−K1 e−K1 eK1−K2 ), (2) see equation (13.2.4), relation (1) leads to the same transformation equations among K and K ′ as (14.2.8a, b, and c). 14.2. Verify that expression (15) of Section 14.2 indeed satisﬁes the functional equation (14) for the ﬁeld-free Ising model in one dimension. Next show (or at least verify) that, with the ﬁeld present, the functional equation (11), with K ′ given by (8), is satisﬁed by the more general expression f (K1, K2) = − ln [eK1 cosh K2 + { e−2K1 + e2K1 sinh 2 K2}1/2] . 14.3. Verify that expression (32) of Section 14.2 indeed satisﬁes the functional equation (31) for the ﬁeld-free spherical model in one dimension. Next show (or at least verify) that, with the ﬁeld present, the functional equation (27), with K ′ given by (25), is satisﬁed by the more general expression f (K1, K2, 3) = 1 2 ln   3 + √32 − K 2 1 2π   − K 2 2 4(3 − K1) , where 3 is determined by the constraint equation ∂f ∂3 = 1 2 √32 − K 2 1 + K 2 2 4 (3 − K1)2 = 1. 580 Chapter 14. Phase Transitions: The Renormalization Group Approach 14.4. Consider the ﬁeld-free spherical model in one dimension whose partition function is given by equation (14.2.24) as well as by (14.2.19), with K ′ 2 = K2 = 0. Substituting σ ′ j = (23/K1)1/2s′ j in the former and comparing the resulting expression with the latter, show that QN (K1, 3) = ( 2π K1 )N ′/2 QN ′ (K1, 3′′), where N ′ = 1 2 N and 3′′ = (232/K1) − K1. This leads to the functional relation f (K1, 3) = − 1 4 ln ( 2π K1 ) + 1 2 f (K1, 3′′). Check that expression (14.2.32) satisﬁes this relation. 14.5. An approximate way of implementing an RG transformation on a square lattice is provided by the so-called Migdal–Kadanoff transformation17 shown in Figure 14.8. It consists of two essential steps: (i) First, one-half of the bonds in the lattice are simply removed, so as to change the length scale of the lattice by a factor of 2; to compensate for this, the coupling strength of the remaining bonds is changed from J to 2J. This takes us from Figure 14.8(a) to Figure 14.8(b). (ii) Next, the sites marked by crosses in Figure 14.8(b) are eliminated by a set of one-dimensional decimation transformations, leading to Figure 14.8(c) with coupling strength J ′. (a) Show that the recursion relation for a spin- 1 2 Ising model on a square lattice, according to the above transformation, is x′ = 2x2/(1 + x4), where x = exp(−2K ) and x′ = exp(−2K ′). Disregarding the trivial ﬁxed points x∗ = 0 and x∗ = 1, show that a nontrivial ﬁxed point of this transformation is x∗ = 1 3 [ −1 + 2 √2 sinh { 1 3 sinh−1 17 2 √2 }] ≃ 0.5437; compare this with the actual value of xc, which is (√2 − 1) ≃ 0.4142. (b) Linearizing around this nontrivial ﬁxed point, show that the eigenvalue λ of this transformation is λ = 2(1 − x∗)/x∗ ≃ 1.6785 and hence the exponent ν = ln 2/ ln λ ≃ 1.338; compare this with the actual value of ν, which is 1. JJ JJ 2J 2J (a) (b) (c) J 9 FIGURE 14.8 Migdal–Kadanoff transformation on a square lattice. 17See Kadanoff (1976a). Problems 581 14.6. Consider the linearized RG transformation (14.3.12), with A∗ l = (a11 a12 a21 a22 ) , (3) such that (a11a22 − a12a21) ̸= 0. We now introduce the “generalized coordinates” u1 and u2 through equations (14.3.13); clearly, u1 and u2 are certain linear combinations of the system parameters k1 and k2. (a) Show that the slopes of the lines u1 = 0 and u2 = 0, in the (k1, k2)-plane, are m1 = a21 λ2 − a22 = λ2 − a11 a12 and m2 = a21 λ1 − a22 = λ1 − a11 a12 , respectively; here, λ1 and λ2 are the eigenvalues of the matrix A∗ l . Verify that the product m1m2 = −a21/a12 and hence the two lines are mutually perpendicular if and only if a12 = a21. (b) Check that, in the special case when a12 = 0 but a21 ̸= 0, the above slopes assume the simple form m1 = ∞ and m2 = a21/ (a11 − a22) whereas, in the special case when a21 = 0 but a12 ̸= 0, they become m1 = (a22 − a11) /a12 and m2 = 0; note that Figure 14.7 pertains to the latter case. (c) Examine as well the cases for which either a11 or a22 is zero; Figure 14.6 pertains to the latter of these cases. 14.7. Check that the critical exponents (14.4.38) through (14.4.40), in the limit n → ∞, agree with the corresponding exponents for the spherical model of Section 13.5 with d ≲ 4. 14.8. Show, from equations (14.4.43) through (14.4.46), that for d ≲ 4 η ≃ 1 2n ε2, γ ≃ 1 + 1 2 (1 − 6 n ) ε, α ≃ − 1 2 (1 − 12 n ) ε, where ε = (4 − d) ≪ 1. Check that these results agree with the ones following from equations (14.4.38) through (14.4.40) for n ≫ 1. 14.9. Using the various scaling relations, derive from equations (14.4.43) through (14.4.45) comparable expressions for the remaining exponents β, δ, and ν. Repeat for these exponents the exercise suggested in the preceding problem. 15 Fluctuations and Nonequilibrium Statistical Mechanics In this course we have been mostly concerned with the evaluation of statistical averages of the various physical quantities; these averages represent, with a high degree of accu- racy, the results expected from relevant measurements on the given system in equilibrium. Nevertheless, there do occur deviations from, or ﬂuctuations about, these mean values. Even though they are generally small, their study is of great physical interest for several reasons. First, such a study enables us to develop a mathematical scheme with the help of which the magnitude of the relevant ﬂuctuations, under a variety of physical situations, can be estimated. Not surprisingly, we ﬁnd that while in a single-phase system the ﬂuctu- ations are thermodynamically negligible but they can assume considerable importance in multiphase systems, especially in the neighborhood of a critical point. In the latter case, we obtain a rather high degree of spatial correlation among the molecules of the system which, in turn, gives rise to phenomena such as critical opalescence. Second, it provides a natural framework for understanding a class of phenomena that come under the heading “Brownian motion”; these phenomena relate properties such as the mobility of a ﬂuid system, its coefﬁcient of diffusion, and so on, with temperature through the so-called Einstein relations. The mechanism of Brownian motion is vital in for- mulating, and in a certain sense answering, questions as to how “a given physical system, which is not in a state of equilibrium, ﬁnally approaches such a state” while “a physical system, which is already in a state of equilibrium, persists to stay in that state.” Third, the study of ﬂuctuations, as a function of time, leads to the concept of certain “correlation functions” that play a vital role in relating the dissipative properties of a sys- tem, such as the viscous resistance of a ﬂuid or the electrical resistance of a conductor, with the microscopic properties of the system in a state of equilibrium; this relation- ship (between irreversible processes on one hand and equilibrium properties on the other) manifests itself in the so-called ﬂuctuation–dissipation theorem. At the same time, a study of the “frequency spectrum” of ﬂuctuations, which is related to the time-dependent correlation function through the fundamental theorem of Wiener and Khintchine, is of considerable value in assessing the “noise” met with in electrical circuits as well as in the transmission of electromagnetic signals. Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00015-3 © 2011 Elsevier Ltd. All rights reserved. 583 584 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics 15.1 Equilibrium thermodynamic ﬂuctuations We begin by deriving a probability distribution law for the ﬂuctuations of certain basic thermodynamic quantities pertaining to a given physical system; the mean square ﬂuctu- ations can then be evaluated, in a straightforward manner, with the help of this law. We assume that the given system, which may be referred to as 1, is embedded in a reservoir, which may be referred to as 2, such that a mutual exchange of energy, and of volume, can take place between the two; of course, the overall energy E and the overall volume V are supposed to be ﬁxed. For convenience, we do not envisage an exchange of particles here, so the numbers N1 and N2 remain individually constant. The equilibrium division of E into E1 and E2, and of V into V 1 and V 2, must be such that parts 1 and 2 of the composite sys- tem (1 + 2) have a common temperature T ∗ and a common pressure P∗; see Sections 1.2 and 1.3, especially equations (1.3.6). Of course, the entropy of the composite system will have its largest value in the equilibrium state; in any other state, such as the one character- ized by a ﬂuctuation, it must have a lower value. If 1S denotes the deviation in the entropy of the composite system from its equilibrium value S0, then 1S ≡ S − S0 = k ln \u0000f − k ln \u00000, (1) where \u0000f (or \u00000) denotes the number of distinct microstates of the system (1 + 2) in the presence (or in the absence) of a ﬂuctuation from the equilibrium state; see equation (1.2.6). The probability that the proposed ﬂuctuation may indeed occur is then given by p ∝ \u0000f ∝ exp(1S/k); (2) see Section 3.1, especially equation (3.1.3). In terms of other thermodynamic quantities, we may write 1S = 1S1 + 1S2 = 1S1 + f∫ 0 dE2 + P2dV2 T2 ; (3) note that the pressure P2 and the temperature T2 of the reservoir may, in principle, vary during the build-up of the ﬂuctuation! Now, even if the ﬂuctuation is sizable from the point of view of system 1, it will be small from the point of view of 2. The “variables” P2 and T2 may, therefore, be replaced by the constants P∗ and T ∗, respectively; at the same time, the increments dE2 and dV2 may be replaced by −dE1 and −dV1, respectively. Equation (3) then becomes 1S = 1S1 − (1E1 + P∗1V1)/T ∗. (4) Accordingly, formula (2) takes the form p ∝ exp{−(1E1 − T ∗1S1 + P∗1V1)/kT ∗}. (5) 15.1 Equilibrium thermodynamic ﬂuctuations 585 Clearly, the probability distribution law (5) does not depend, in any manner, on the peculiarities of the reservoir in which the given system was supposedly embedded. For- mula (5), therefore, applies equally well to a system that attained equilibrium in a statistical ensemble (or, for that matter, to any macroscopic part of a given system itself). Conse- quently, we may drop the sufﬁx 1 from the symbols 1E1, 1S1, and 1V1, and the star from the symbols P∗ and T ∗, and write p ∝ exp{−(1E − T 1S + P1V )/kT }. (6) In most cases, the ﬂuctuations are exceedingly small in magnitude; the quantity 1E may, therefore, be expanded as a Taylor series about the equilibrium value (1E)0 = 0, with the result 1E = ( ∂E ∂S ) 0 1S + ( ∂E ∂V ) 0 1V + 1 2 [( ∂ 2E ∂S2 ) 0 (1S) 2 + 2 ( ∂ 2E ∂S∂V ) 0 1S1V + ( ∂ 2E ∂V 2 ) 0 (1V ) 2] + · · · (7) Substituting (7) into (6) and retaining terms up to second order only, we obtain p ∝ exp{−(1T 1S − 1P1V )/2kT }; (8) here, use has been made of the relations ( ∂E ∂S ) 0 = T , ( ∂E ∂V ) 0 = −P, (9) and of the fact that the expression within the square brackets in (7) is equivalent to 1 ( ∂E ∂S ) 0 1S + 1 ( ∂E ∂V ) 0 1V = 1T 1S − 1P1V . (10) With the help of (8), the mean square ﬂuctuations of various physical quantities and the statistical correlations among different ﬂuctuations can be readily calculated. We note, however, that of the four 1 terms appearing in this formula only two can be chosen inde- pendently; the other two must assume the role of “derived quantities.” For instance, if we choose 1T and 1V to be the independent variables, then 1S and 1P can be written as 1S = ( ∂S ∂T ) V 1T + ( ∂S ∂V ) T 1V = CV T 1T + ( ∂P ∂T ) V 1V (11) and 1P = ( ∂P ∂T ) V 1T + ( ∂P ∂V ) T 1V = ( ∂P ∂T ) V 1T − 1 κT V 1V , (12) 586 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics κT being the isothermal compressibility of the system. Substituting (11) and (12) into (8), we get p ∝ exp { − CV 2kT 2 (1T )2 − 1 2kT κT V (1V ) 2} , (13) which shows that the ﬂuctuations in T and V are statistically independent, Gaussian variables! A quick glance at (13) yields the results (1T )2 = kT 2 CV , (1V )2 = kT κT V , (14a) while (1T 1V ) = 0. (14b) Similarly, if we choose 1S and 1P as our independent variables, we are led to the distribution law p ∝ exp { − 1 2kCP (1S) 2 − κSV 2kT (1P) 2} , (15) which gives (1S)2 = kCP, (1P)2 = kT κSV , (16a) while (1S1P) = 0; (16b) here, κS denotes the adiabatic compressibility of the system. We note that, in general, the mean square ﬂuctuation of an extensive quantity is directly proportional to the size of the system while that of an intensive quantity is inversely pro- portional to the same; in either case, the relative, root-mean-square ﬂuctuation of any quantity is inversely proportional to the square root of the size of the system. Thus, except for situations such as the ones met with in a critical region, normal ﬂuctuations are ther- modynamically negligible. This does not mean that ﬂuctuations are altogether irrelevant to the physical phenomena taking place in the system; in fact, as will be seen in the sequel, the very presence of ﬂuctuations at the microscopic level is of fundamental importance to several properties of the system displayed at the macroscopic level! With the help of the foregoing results, we may evaluate the mean square ﬂuctuation in the energy of the system. With T and V as independent variables, we have 1E = ( ∂E ∂T ) V 1T + ( ∂E ∂V ) T 1V . (17) 15.2 The Einstein–Smoluchowski theory of the Brownian motion 587 Squaring this expression and taking averages, keeping in mind equations (14), we get (1E)2 = kT 2CV + kT κT V {( ∂E ∂V ) T }2 = kT 2CV + kT κT ( N 2 V ) {( ∂E ∂N ) T }2 . (18) Now, the results derived in the preceding paragraphs determine the ﬂuctuations of the various physical quantities pertaining to any macroscopic subsystem of a given system, provided that the number of particles in the subsystem remains ﬁxed. The expression (14b) for (1V )2 may, therefore, be used to derive an expression for the mean square ﬂuctuation of the variable v (the volume per particle) and the variable n (the particle density) of the subsystem. We readily obtain (1v)2 = kT κT V /N 2, (1n)2 = 1 v4 (1v)2 = kT κT N 2/V 3; (19) note that the last result obtained here is in complete agreement with equation (4.5.7), which was derived on the basis of the grand canonical ensemble. A little reﬂection shows that this result applies equally well to a subsystem with a ﬁxed volume V and a ﬂuctuating number of particles N. The mean square ﬂuctuation in N is then given by (1N)2 = V 2(1n)2 = kT κT N 2/V . (20) Substituting (20) into (18), we obtain once again the grand canonical result for (1E)2, namely (1E)2 = kT 2CV + (1N)2{(∂E/∂N)T }2, (21) as in equation (4.5.14). In passing, we note that the ﬁrst part of expression (21) denotes the mean square ﬂuc- tuation in the energy E of a subsystem for which both N and V are ﬁxed, just as we have in the canonical ensemble (N, V , T ). Conversely, if we assume the energy E to be ﬁxed, then the temperature of the subsystem will ﬂuctuate, and the mean square value of the quantity 1T will be given by (kT 2CV ) divided by the square of the thermal capacity of the subsystem. The net result will, therefore, be (kT 2/CV ), which is the same as in (14a). 15.2 The Einstein–Smoluchowski theory of the Brownian motion The term “Brownian motion” derives its name from the botanist Robert Brown who, in 1828, made careful observations on the tiny pollen grains of a plant under a microscope. In his own words: “While examining the form of the particles immersed in water, I observed 588 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics many of them very evidently in motion. These motions were such as to satisfy me . . . that they arose neither from currents in the ﬂuid nor from its gradual evaporation, but belonged to the particle itself.” We now know that the real source of this motion lies in the incessant, and more or less random, bombardment of the Brownian particles, as these grains (or, for that matter, any colloidal suspensions) are usually referred to, by the molecules of the surrounding ﬂuid. It was Einstein who, in a number of papers (beginning in 1905), ﬁrst provided a sound theoretical analysis of the Brownian motion on the basis of the so-called “random walk problem” and thereby established a far-reaching relationship between the irreversible nature of this phenomenon and the mechanism of molecular ﬂuctuations. To illustrate the essential theme of Einstein’s approach, we ﬁrst consider the problem in one dimension. Let x(t) denote the position of the Brownian particle at time t, given that its position coincided with the point x = 0 at time t = 0. To simplify matters, we assume that each molecular impact (which, on an average, takes place after a time τ ∗) causes the particle to jump a (small) distance l — of constant magnitude — in either a positive or negative direction along the x-axis. It seems natural to regard the possibilities 1x = +l and 1x = −l to be equally likely; though somewhat less natural, we may also regard the successive impacts on, and hence the successive jumps of, the Brownian particle to be mutually uncorrelated. The probability that the particle is found at the point x at time t is then equal to the probability that, in a series of n (= t/τ ∗) successive jumps, the particle makes m (= x/l) more jumps in the positive direction of the x-axis than in the negative, that is, it makes 1 2 (n + m) jumps in the positive direction and 1 2 (n − m) in the negative. 1 The desired probability is then given by the binomial expression pn(m) = n! { 1 2 (n + m) }! { 1 2 (n − m)} ! ( 1 2 )n , (1) with the result that m = 0 and m2 = n. (2) Thus, for t ≫ τ ∗, we have for the net displacement of the particle x(t) = 0 and x2(t) = l2 t τ ∗ ∝ t1. (3) Accordingly, the root-mean-square displacement of the particle is proportional to the square root of the time elapsed: xr.m.s. = √( x2(t)) = l√ (t/τ ∗) ∝ t1/2. (4) It should be noted that the proportionality of the net overall displacement of the Brownian particle to the square root of the total number of elementary steps is a typical consequence 1Since the quantities x and t are macroscopic in nature while l and τ ∗ are microscopic, the numbers n and m are much larger than unity; consequently, it is safe to assume that they are integral as well. 15.2 The Einstein–Smoluchowski theory of the Brownian motion 589 of the random nature of the steps and it manifests itself in a large variety of phenomena in nature. In contrast, if the successive steps were fully coherent (or else if the motion were completely predictable and reversible over the time interval t),2 then the net displacement of the Brownian particle would have been proportional to t1. Smoluchowski’s approach to the problem of Brownian motion, which appeared in 1906, was essentially the same as that of Einstein; the difference lay primarily in the math- ematical procedure. Smoluchowski introduced the probability function pn(x0|x), which denotes the “probability that, after a series of n steps, the Brownian particle, initially at the point x0, reaches the point x”; the number x here denotes the distance traveled by the Brownian particle in terms of the length of the elementary step. Clearly, pn(x0|x) = ∞∑ z=−∞ pn−1(x0|z)p1(z|x) (n ≥ 1); (5) moreover, since a single step is equally likely to take the particle to the right or to the left, p1(z|x) = 1 2 δz,x−1 + 1 2 δz,x+1, (6) while p0(z|x) = δz,x. (7) Equation (5) is known as the Smoluchowski equation. To solve it, we introduce a generating function Qn(ξ ), namely Qn(ξ ) = ∞∑ x=−∞ pn(x0|x)ξ x−x0 , (8) from which it follows that Q0(ξ ) = ∞∑ x=−∞ p0(x0|x)ξ x−x0 = ∞∑ x=−∞ δx0,xξ x−x0 = 1. (9) Substituting (6) into (5), we obtain pn(x0|x) = 1 2 pn−1(x0|x − 1) + 1 2 pn−1(x0|x + 1). (10) 2The term “reversible” here is related to the fact that the Newtonian equations of motion, which govern this class of phenomena, preserve their form if the direction of time is reversed (i.e., if we change t to −t, etc.); alternatively, one would expect that if at any instant of time we reverse the velocities of the particles in a given mechanical system, the system would “retrace” its path exactly. This is not true of equations describing “irreversible” phenomena, such as the diffusion equation (19), with which the phenomenon of Brownian motion is intimately related. 590 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics Multiplying (10) by ξ x−x0 and adding over all x, we obtain the recurrence relation Qn(ξ ) = 1 2 [ξ + (1/ξ )]Qn−1(ξ ), (11) so that, by iteration, Qn(ξ ) = { 1 2 [ξ + (1/ξ )]}n Q0(ξ ) = (1/2)n[ξ + (1/ξ )]n. (12) Expanding this expression binomially and comparing the result with (8), we get pn(x0|x) = ( 1 2 )n n! { 1 2 (n + x − x0)}! { 1 2 (n − x + x0)}! for |x − x0| ≤ n 0 for |x − x0| > n. (13) Identifying (x − x0) with m, we ﬁnd this result to be in complete agreement with our previ- ous result (1).3 Accordingly, any conclusions drawn from the Smoluchowski approach will be the same as the ones drawn from the Einstein approach. To obtain an asymptotic form of the function pn(m), we apply Stirling’s formula, n! ≈ (2π n)1/2(n/e)n, to the factorials appearing in (1), with the result ln pn(m) ≈ ( n + 1 2 ) ln n − 1 2 (n + m + 1) ln { 1 2 (n + m) } − 1 2 (n − m + 1) ln { 1 2 (n − m)} − n ln 2 − 1 2 ln(2π). For m ≪ n (which is generally true because m = 0 and mr.m.s. = n1/2, while n ≫ 1), we obtain pn(m) ≈ 2 √ (2πn) exp(−m 2/2n). (14) Taking x to be a continuous variable (and remembering that pn(m) ≡ 0 either for even val- ues of m or for odd values of m, so that in the distribution (14), 1m = 2 and not 1), we may write this result in the Gaussian form: p(x)dx = dx √(4π Dt) exp ( − x2 4Dt ) , (15) where D = l2/2τ ∗. (16) 3It is easy to recognize the additional fact that if n is even, then pn(m) ≡ 0 for odd m, and if n is odd, then pn(m) ≡ 0 for even m. 15.2 The Einstein–Smoluchowski theory of the Brownian motion 591 Later on, we shall see that the quantity D introduced here is identical to the diffusion coefﬁcient of the given system; equation (16) connects this quantity with the microscopic quantities l and τ ∗. To appreciate this connection, one has simply to note that the prob- lem of Brownian motion can also be looked on as a problem of “diffusion” of Brownian particles through the medium of the ﬂuid; this point of view is also due to Einstein. How- ever, before we embark on these considerations, we would like to present here the results of an actual observation made on the Brownian motion of a spherical particle immersed in water; see Lee, Sears, and Turcotte (1963). It was found that the 403 values of the net dis- placement 1x of the particle, observed after successive intervals of 2 seconds each, were distributed as follows: Displacement 1x, in units of µ(= 10−4cm) Frequency of occurrence n less than −5.5 0 between −5.5 and −4.5 1 between −4.5 and −3.5 2 between −3.5 and −2.5 15 between −2.5 and −1.5 32 between −1.5 and −0.5 95 between −0.5 and +0.5 111 between +0.5 and +1.5 87 between +1.5 and +2.5 47 between +2.5 and +3.5 8 between +3.5 and +4.5 5 greater than +4.5 0 The mean square value of the displacement here turns out to be: (1x)2 = 2.09 × 10−8cm2. The observed frequency distribution has been plotted as a “block diagram” in Figure 15.1. We have included, in this ﬁgure, a Gaussian curve based on the observed value of the mean square displacement; we ﬁnd that the experimental data ﬁt the theoretical curve fairly well. We can also derive here an experimental value for the diffusion coefﬁcient of the medium; we obtain: D = (1x)2/2t = 5.22 × 10−9cm2/s.4 We now turn to the study of the Brownian motion from the point of view of diffusion. We denote the number density of the Brownian particles in the ﬂuid by the symbol n(r, t) and their current density by j(r, t){= n(r, t)v(r, t)}; then, according to Fick’s law, j(r, t) = −D∇n(r, t), (17) 4In the next section we shall see that, for a spherical particle, D = kT /6πηa where η is the coefﬁcient of viscosity of the medium and a the radius of the Brownian particle. In the case under study, T ≃ 300 K, η ≃ 10−2 poise, and a ≃ 4 × 10−5 cm. Substituting these values, we obtain for the Boltzmann constant: k ≃ 1.3 × 10−16erg/K. 592 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics 100 50 0211 2 n (\u0002X ) 34562223242526 \u0002x \u0003 FIGURE 15.1 The statistical distribution of the successive displacements, 1x, of a Brownian particle immersed in water: (1x)r.m.s. ≃ 1.45 µ. where D denotes for the diffusion coefﬁcient of the medium. We also have here the equation of continuity, namely ∇ · j(r, t) + ∂n(r, t) ∂t = 0. (18) Substituting (17) into (18), we obtain the diffusion equation ∇2n(r, t) − 1 D ∂n(r, t) ∂t = 0. (19) Of the various possible solutions of this equation, the one relevant to the present situa- tion is n(r, t) = N (4πDt)3/2 exp ( − r2 4Dt ) , (20) which is a spherically symmetric solution and is already normalized: ∞∫ 0 n(r, t)4π r2dr = N, (21) N being the total number of (Brownian) particles immersed in the ﬂuid. A comparison of the (three-dimensional) result (20) with the (one-dimensional) result (15) brings out most vividly the relationship between the random walk problem on one hand and the phenomenon of diffusion on the other. It is clear that in the last approach we have considered the motion of an “ensemble” of N Brownian particles placed under “equivalent” physical conditions, rather than consid- ering the motion of a single particle over a length of time (as was done in the random walk approach). Accordingly, the averages of the various physical quantities obtained here will be in the nature of “ensemble averages”; they must, of course, agree with the long-time averages of the same quantities obtained earlier. 15.3 The Langevin theory of the Brownian motion 593 Now, by virtue of the distribution (20), we obtain ⟨r(t)⟩ = 0; ⟨r2(t)⟩ = 1 N ∞∫ 0 n(r, t)4π r4dr = 6Dt ∝ t1, (22) in complete agreement with our earlier results, namely x(t) = 0; x2(t) = l2t/τ ∗ = 2Dt ∝ t1. (23) Thus, the “ensemble” of the Brownian particles, initially concentrated at the origin, “dif- fuses out” as time increases, the nature and the extent of its spread at any time t being given by equations (20) and (22), respectively. The diffusion process, which is clearly irrever- sible, gives us a fairly good picture of the statistical behavior of a single particle in the ensemble. However, the important thing to bear in mind is that, whether we focus our attention on a single particle in the ensemble or look at the ensemble as a whole, the ulti- mate source of the phenomenon lies in the incessant, and more or less random, impacts received by the Brownian particles from the molecules of the ﬂuid. In other words, the irreversible character of the phenomenon ultimately arises from the random, ﬂuctuating forces exerted by the ﬂuid molecules on the Brownian particles. This leads us to another systematic theory of the Brownian motion, namely the theory of Langevin (1908). For a detailed analysis of the problem, see Uhlenbeck and Ornstein (1930), Chandrasekhar (1943, 1949), MacDonald (1948–1949), and Wax (1954). 15.3 The Langevin theory of the Brownian motion We consider the simplest case of a “free” Brownian particle, surrounded by a ﬂuid envi- ronment; the particle is assumed to be free in the sense that it is not acted on by any other force except the one arising from the molecular bombardment. The equation of motion of the particle will then be M dv dt = F (t), (1) where M is the particle mass, v(t) the particle velocity, and F (t) the force acting on the particle by virtue of the impacts received from the ﬂuid molecules. Langevin suggested that the force F (t) may be written as a sum of two parts: (i) an “averaged-out” part, which represents the viscous drag, −v/B, experienced by the particle (accordingly, B is the mobil- ity of the system, that is, the drift velocity acquired by the particle by virtue of a unit “external” force) 5 and (ii) a “rapidly ﬂuctuating” part F(t) which, over long intervals of 5If Stokes’s law is applicable, then B = 1/(6πηa), where η is the coefﬁcient of viscosity of the ﬂuid and a the radius of the particle (assumed spherical). 594 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics time (as compared to the characteristic time τ ∗), averages out to zero; thus, we may write M dv dt = − v B + F(t); F(t) = 0. (2) Taking the ensemble average of (2), we obtain6 M d dt ⟨v⟩ = − 1 B ⟨v⟩, (3) which gives ⟨v(t)⟩ = v(0) exp(−t/τ ) (τ = MB). (4) Thus, the mean drift velocity of the particle decays, at a rate determined by the relaxation time τ , to the ultimate value zero. We note that this result is typical of the phenomena governed by dissipative properties such as the viscosity of the ﬂuid; the irreversible nature of the result is also evident. Dividing (2) by the mass of the particle, we obtain an equation for the instantaneous acceleration, namely dv dt = − v τ + A(t); A(t) = 0. (5) We now construct the scalar product of (5) with the instantaneous position r of the particle and take the ensemble average of the product. In doing so, we make use of the facts that (i) r · v = 1 2 (dr2/dt), (ii) r · (dv/dt) = 1 2 (d2r2/dt2) − v2, and (iii) ⟨r · A⟩ = 0. 7 We obtain d2 dt2 ⟨r2⟩ + 1 τ d dt ⟨r2⟩ = 2⟨v2⟩. (6) If the Brownian particle has already attained thermal equilibrium with the molecules of the ﬂuid, then the quantity ⟨v2⟩ in this equation may be replaced by its equipartition value 3kT /M. The equation is then readily integrated, with the result ⟨r2⟩ = 6kT τ 2 M { t τ − (1 − e−t/τ )} , (7) 6The process of “averaging over an ensemble” implies that we are imagining a large number of systems similar to the one originally under consideration and are taking an average over this collection at any time t. By the very nature of the function F(t), the ensemble average ⟨F(t)⟩ must be zero at all times. 7This is so because we have no reason to expect a statistical correlation between the position r(t) of the Brownian particle and the force F(t) exerted on it by the molecules of the ﬂuid; see, however, Manoliu and Kittel (1979). Of course, we do expect a correlation between the variables v(t) and F(t); consequently, ⟨v · F⟩ ̸= 0 (see Problem 15.7). 15.3 The Langevin theory of the Brownian motion 595 where the constants of integration have been so chosen that at, t = 0, both ⟨r2⟩ and its ﬁrst time-derivative vanish. We observe that, for t ≪ τ , ⟨r2⟩ ≃ 3kT M t2 = ⟨v2⟩t2, (8)8 which is consistent with the reversible equations of motion whereby one would simply have r = vt. (9) On the other hand, for t ≫ τ , ⟨r2⟩ ≃ 6kT τ M t = (6BkT )t, (10)9 which is essentially the same as the Einstein–Smoluchowski result (15.2.22); incidentally, we obtain here a simple, but important, relationship between the coefﬁcient of diffusion D and the mobility B, namely D = BkT , (11) which is generally referred to as the Einstein relation. The irreversible character of equation (10) is self-evident; it is also clear that it arises essentially from the viscosity of the medium. Moreover, the Einstein relation (11), which connects the coefﬁcient of diffusion D with the mobility B of the system, tells us that the ultimate source of the viscosity of the medium (as well as of diffusion) lies in the random, ﬂuctuating forces arising from the incessant motion of the ﬂuid molecules; see also the ﬂuctuation–dissipation theorem of Section 15.6. In this context, if we consider a particle of charge e and mass M moving in a viscous ﬂuid under the inﬂuence of an external electric ﬁeld of intensity E, then the “coarse- grained” motion of the particle will be determined by the equation M d dt ⟨v⟩ = − 1 B ⟨v⟩ + eE; (12) compare this to equation (3). The “terminal” drift velocity of the particle would now be given by the expression (eB)E, which prompts one to deﬁne (eB) as the “mobility” of the system and denote it by the symbol µ. Consequently, one obtains, instead of (11), D = kT e µ, (13) which, in fact, is the original version of the Einstein relation; sometimes this is also referred to as the Nernst relation. 8Note that the limiting solution (8) corresponds to “dropping out” the second term on the left side of equation (6). 9Note that the limiting solution (10) corresponds to “dropping out” the ﬁrst term on the left side of equation (6). 596 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics So far we have not felt any direct inﬂuence of the rapidly ﬂuctuating term A(t) that appears in the equation of motion (5) of the Brownian particle. For this, let us try to eval- uate the quantity ⟨v2(t)⟩ which, in the preceding analysis, was assumed to have already attained its “limiting” value 3kT /M. For this evaluation we replace the variable t in equa- tion (5) by u, multiply both sides of the equation by exp(u/τ ), rearrange and integrate over du between the limits u = 0 and u = t; we thus obtain the formal solution v(t) = v(0)e−t/τ + e−t/τ t∫ 0 eu/τ A(u)du. (14) Thus, the drift velocity v(t) of the particle is also a ﬂuctuating function of time; of course, since ⟨A(u)⟩ = 0 for all u, the average drift velocity is given by the ﬁrst term alone, namely ⟨v(t)⟩ = v(0)e−t/τ , (15) which is the same as our earlier result (4). For the mean square velocity ⟨v2(t)⟩, we now obtain from (14) ⟨v2(t)⟩ = v2(0)e−2t/τ + 2e−2t/τ  v(0) · t∫ 0 eu/τ ⟨A(u)⟩du   + e−2t/τ t∫ 0 t∫ 0 e(u1+u2)/τ ⟨A(u1) · A(u2)⟩du1du2. (16) The second term on the right side of this equation is identically zero, because ⟨A(u)⟩ van- ishes for all u. In the third term, we have the quantity ⟨A(u1) · A(u2)⟩, which is a measure of the “statistical correlation between the value of the ﬂuctuating variable A at time u1 and its value at time u2”; we call it the autocorrelation function of the variable A and denote it by the symbol KA(u1, u2) or simply by K (u1, u2). Before proceeding with (16) any further, we place on record some of the important properties of the function K (u1, u2). (i) In a stationary ensemble (i.e., one in which the overall macroscopic behavior of the systems does not change with time), the function K (u1, u2) depends only on the time interval (u2 − u1). Denoting this interval by the symbol s, we have K (u1, u1 + s) ≡ ⟨A(u1) · A(u1 + s)⟩ = K (s), independently of u1. (17) (ii) The quantity K (0), which is identically equal to the mean square value of the variable A at time u1, must be positive deﬁnite. In a stationary ensemble, it would be a constant, independent of u1: K (0) = const. > 0. (18) (iii) For any value of s, the magnitude of the function K (s) cannot exceed K (0). 15.3 The Langevin theory of the Brownian motion 597 Proof : Since ⟨|A(u1) ± A(u2)|2⟩ = ⟨A 2(u1)⟩ + ⟨A 2(u2)⟩ ± 2(A(u1) · A(u2)⟩ = 2{K (0) ± K (s)} ≥ 0, the function K (s) cannot go outside the limits −K (0) and +K (0); consequently, |K (s)| ≤ K (0) for all s. (19) (iv) The function K (s) is symmetric about the value s = 0, that is, K (−s) = K (s) = K (|s|). (20) Proof : K (s) ≡ ⟨A(u1) · A(u1 + s)⟩ = ⟨A(u1 − s) · A(u1)⟩ 10 = ⟨A(u1) · A(u1 − s)⟩ ≡ K (−s). (v) As s becomes large in comparison with the characteristic time τ ∗, the values A(u1) and A(u1 + s) become uncorrelated, that is K (s) ≡ ⟨A(u1) · A(u1 + s)⟩ −−−−−−−→ s≫τ ∗ ⟨A(u1)⟩ · ⟨A(u1 + s)⟩ = 0. (21) In other words, the “memory” of the molecular impacts received during a given interval of time, say between u1 and u1 + du1, is “completely lost” after a lapse of time large in comparison with τ ∗. It follows that the magnitude of the function K (s) is signiﬁcant only so long as the variable s is of the same order of magnitude as τ ∗. Figures 15.7 through 15.9 later in this chapter show the s-dependence of certain typical correlation functions K (s); they fully conform to the properties listed here. We now evaluate the double integral appearing in (16): I = t∫ 0 t∫ 0 e(u1+u2)/τ K (u2 − u1)du1du2. (22) Changing over to the variables S = 1 2 (u1 + u2) and s = (u2 − u1), (23) the integrand becomes exp(2S/τ )K (s), the element (du1du2) gets replaced by the corre- sponding element (dSds) while the limits of integration, in terms of the variables S and s, 10This is the only crucial step in the proof. It involves a “shift,” by an amount s, in both instants of the measurement process; the equality results from the fact that the ensemble is supposed to be stationary. 598 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics u2 u1 0 0s\u00020 s \u0002\u0003 t s \u0002\u0003 2 SS\u00020 S \u0002 t /2 S \u0002 t s \u0002\u0004 2 S s \u0002\u0004 t s \u0002 2( S \u0004 t ) s \u0002 2( t \u0004 S ) t t FIGURE 15.2 Limits of integration, of the double integral I, in terms of the variables S and s. can be read from Figure 15.2; we ﬁnd that, for 0 ≤ S ≤ t/2, s goes from −2S to +2S while, for t/2 ≤ S ≤ t, it goes from −2(t − S) to +2(t − S). Accordingly, I = t/2∫ 0 e2S/τ dS +2S∫ −2S K (s)ds + t∫ t/2 e2S/τ dS +2(t−S)∫ −2(t−S) K (s)ds. (24) In view of property (v) of the function K (s), see equation (21), the integrals over s draw signiﬁcant contribution only from a very narrow region, of the order of τ ∗, around the value s = 0 (i.e., from the shaded region in Figure 15.2); contributions from regions with larger values of |s| are negligible. Thus, if t ≫ τ ∗, the limits of integration for s may be replaced by −∞ and +∞, with the result I ≃ C t∫ 0 e2S/τ dS = C τ 2 (e2t/τ − 1), (25) where C = ∞∫ −∞ K (s)ds. (26) Substituting (25) into (16), we obtain ⟨v2(t)⟩ = v2(0)e−2t/τ + C τ 2 (1 − e−2t/τ ). (27) Now, as t → ∞, ⟨v2(t)⟩ must tend to the equipartition value 3kT /M; therefore, C = 6kT /Mτ (28) 15.3 The Langevin theory of the Brownian motion 599 and hence ⟨v2(t)⟩ = v2(0) + { 3kT M − v2(0) } (1 − e−2t/τ ). (29)11 We note that if v2(0) were itself equal to the equipartition value 3kT /M, then ⟨v2(t)⟩ would always remain the same, which shows that statistical equilibrium, once attained, has a natural tendency to persist. Substituting (29) into the right side of (6), we obtain a more representative description of the manner in which the quantity ⟨r2⟩ varies with t; we thus have d2 dt2 ⟨r2⟩ + 1 τ d dt ⟨r2⟩ = 2v2(0)e−2t/τ + 6kT M (1 − e−2t/τ ), (30) with the solution ⟨r2⟩ = v2(0)τ 2(1 − e−t/τ ) 2 − 3kT M τ 2(1 − e−t/τ )(3 − e−t/τ ) + 6kT τ M t. (31) Solution (31) satisﬁes the initial conditions that both ⟨r2⟩ and its ﬁrst time-derivative van- ish at t = 0; moreover, if we put v2(0) = 3kT /M, it reduces to solution (7) obtained earlier. Once again, we note the reversible nature of the motion for t ≪ τ , with ⟨r2⟩ ≃ v2(0)t2, and its irreversible nature for t ≫ τ , with ⟨r2⟩ ≃ (6BkT )t. Figures 15.3 and 15.4 show the variation, with time, of the ensemble averages ⟨v2(t)⟩ and ⟨r2(t)⟩ of a Brownian particle, as given by equations (29) and (31), respectively. All important features of our results are manifestly evident in these plots. Brownian motion continues to be a topic of contemporary research nearly 200 years after Brown’s discovery and over 100 years after Einstein and Smoluchowski’s analysis and early measurements by Perrin. The renewed interest is due to the growth in the techno- logical importance of colloids across a wide range of ﬁelds and the development of digital video and computer image analysis. An interesting example is the detailed observation and analysis of rotational and two-dimensional translational Brownian motion of ellipsoidal particles by Han et al. (2006) in a thin microscope slide. The case of rotational Brownian motion was ﬁrst analyzed by Einstein (1906b) and ﬁrst measured by Perrin (1934, 1936). Both rotational and translational modes diffuse according to Langevin dynamics but the translational diffusion is coupled to the rotational diffusion since the translational diffu- sion constant parallel to the longer axis is larger than the diffusion constant perpendicular 11One may check that d dt ⟨v2(t)⟩ = 2 τ [ v2(∞) − ⟨v2(t)⟩] = − 2 τ 1⟨v2(t)⟩, where v2(∞) = 3kT /M and 1⟨v2(t)⟩ is the “deviation of the quantity concerned from its equilibrium value.” In this form of the equation, we have a typical example of a “relaxation phenomenon,” with relaxation time τ/2. 600 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics 2 1 021 3 2 1 3 t τ<v 2(t)>3kT/M FIGURE 15.3 The mean square velocity of a Brownian particle as a function of time. Curves 1, 2, and 3 correspond, respectively, to the initial conditions v2(0) = 6kT /M, 3kT /M, and 0. 3 2 1 00123 3 2 1 4 t τ<r 2(t)>6BkTτ FIGURE 15.4 The mean square displacement of a Brownian particle as a function of time. Curves 1, 2, and 3 correspond, respectively, to the initial conditions v2(0) = 6kT /M, 3kT /M, and 0. to that axis. The rotational diffusion and both long-axis (a) and short-axis (b) body-frame diffusions are all Gaussian: pθ (1θ, t) = 1 √ 4π Dθ t exp ( − (1θ)2 4Dθ t ) , (32a) pa(1xa, t) = 1 √ 4π Dat exp ( − (1xa)2 4Dat ) , (32b) pb(1xb, t) = 1 √ 4πDbt exp ( − (1xb)2 4Dbt ) , (32c) 15.3 The Langevin theory of the Brownian motion 601 with diffusion constants Dθ , Da, and Db. Experiments have observed the complex two-dimensional spatial diffusion at short times (t ≲ τθ = 1/(2Dθ )), as predicted by the Langevin theory. The long-time (t ≫ τθ ) spatial diffusion is isotropic with diffusion con- stant D = (Da + Db)/2. 15.3.A Brownian motion of a harmonic oscillator An analysis similar to the one for a diffusing Brownian particle can also be performed for a particle in a harmonic oscillator potential that prevents the particle from diffus- ing away from the origin and allows a more general analysis of the relationship between the position and velocity response functions and the power spectra of the ﬂuctua- tions; see Kappler (1938) and Chandrasekhar (1943). The one-dimensional equation of motion for a Brownian particle of mass M in a harmonic oscillator potential with spring constant Mω2 0 is d2x dt2 + γ dx dt + ω2 0x = F(t) M , (33) where γ (= 6πηa/M) is the damping coefﬁcient of a spherical particle in a ﬂuid with viscosity η. Just as in the case of diffusive Brownian motion, the force F(t) can be a time- dependent external force designed to explore the response function or a time-dependent random force due to collisions with molecules in the ﬂuid to analyze the equilibrium ﬂuc- tuations. Assuming the system was in equilibrium in the distant past, the position at time t is given by x(t) = t∫ −∞ χxx(t − t′)F(t′)dt′, (34) where χxx(s) = 1 Mω1 e− γ s 2 sin (ω1s) (35) is the xx response function and ω1 = √ ω2 0 − γ 2 4 . 12 The velocity response is given by v(t) = t∫ −∞ χvx(t − t′)F(t′)dt′, (36) 12This form of the response function assumes that the oscillator is underdamped. The notation χxx refers to the notation used in Section 15.6.A in which the response of the position coordinate x depends on the applied ﬁeld F that couples to the Hamiltonian via a term −F(t)x(t). 602 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics where χvx(s) = 1 M e− γ s 2 (cos (ω1s) − γ 2ω1 sin (ω1s) ) . (37) The response of the system can be decomposed into a sum of independent terms involving a sinusoidal applied force ˆF(ω)eiωt. This takes the form ˆx(ω) = ˜χxx(ω) ˆF(ω), (38) where the frequency-dependent response function can be decomposed into real and imaginary parts ˆχ ′ xx(ω) and ˆχ ′′ xx(ω): ˜χxx(ω) = ∞∫ 0 χxx(s)eiωsds = ˆχ ′ xx(ω) + i ˆχ ′′ xx(ω), (39a) ˆχ ′ xx(ω) = ω2 0 − ω2 M[(ω2 0 − ω2)2 + γ 2ω2] , (39b) ˆχ ′′ xx(ω) = γ ω M[(ω2 0 − ω2)2 + γ 2ω2] . (39c) The real part here describes the dispersion and the imaginary part describes the dissipa- tion, that is, it sets the average rate of energy dissipation due to the sinusoidal external force. Now let’s consider the natural ﬂuctuations of the position and the velocity of the parti- cle in equilibrium due to the random collisions with the atoms in the ﬂuid. We will use the same Langevin formalism as was used earlier with Brownian motion of a free particle. The random force averages to zero and is assumed to be delta-function correlated in time: ⟨F⟩ = 0, (40a) 〈 F(t)F(t′)〉 = 0δ(t − t′), (40b) where 0 = 2γ MkT . With this choice, the long-time average position and velocity of the particle are both zero, ⟨x(t)⟩ = ⟨v(t)⟩ = 0, (41) and the average of the squares of the position and velocity both obey the equipartition theorem: ⟨x2(t)⟩ = kT Mω2 0 , ⟨v2(t)⟩ = kT M . (42a,b) 15.4 Approach to equilibrium: the Fokker–Planck equation 603 The xx correlation function is given by Gxx(t − t′) = 〈 x(t)x(t′)〉 = kT Mω2 0 exp ( −γ |t − t′| 2 ) (cos (ω1|t − t′| ) + γ 2ω1 sin ( ω1|t − t′|) ) , (43) and the xx power spectrum by Sxx(ω) = ∞∫ −∞ Gxx(s)eiωsds = 2γ kT M 1 ( ω2 0 − ω2)2 + γ 2ω2 . (44) Note that the imaginary part of the response function, ˆχ ′′ xx(ω), in equation (39c) is propor- tional to the power spectrum Sxx(ω): ˆχ ′′ xx(ω) = ω 2kT Sxx(ω). (45) This result indicates that the dissipation that results from driving a system out of equilib- rium by an external force is proportional to the power spectrum of the natural ﬂuctuations that occur in equilibrium. While this result was derived here for a very speciﬁc model, it constitutes an example of the very general ﬂuctuation–dissipation theorem we will derive in Section 15.6.A. 15.4 Approach to equilibrium: the Fokker–Planck equation In our analysis of the Brownian motion we have considered the behavior of a dynamical variable, such as the position r(t) or the velocity v(t) of a Brownian particle, from the point of view of ﬂuctuations in the value of the variable. To determine the average behavior of such a variable, we sometimes invoked an “ensemble” of Brownian particles immersed in identical environments and undergoing diffusion. A treatment along these lines was carried out toward the end of Section 15.2, and the most important results of that treat- ment are summarized in equation (15.2.20) for the density function n(r, t) and in equation (15.2.22) for the mean square displacement ⟨r2(t)⟩. A more generalized way of looking at “the manner in which, and the rate at which, a given distribution of Brownian particles approaches a state of thermal equilibrium” is provided by the so-called Master Equation, a simpliﬁed version of which is known as the Fokker–Planck equation. For illustration, we examine the displacement, x(t), of the given set of particles along the x-axis. At any time t, let f (x, t)dx be the probability that an arbi- trary particle in the ensemble may have a displacement between x and x + dx. The function 604 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics f (x, t) must satisfy the normalization condition ∞∫ −∞ f (x, t)dx = 1. (1) The Master Equation then reads: ∂f (x, t) ∂t = ∞∫ −∞ {−f (x, t)W (x, x′) + f (x′, t)W (x′, x)}dx′, (2) where W (x, x′)dx′δt denotes the probability that, in a short interval of time δt, a parti- cle having displacement x makes a “transition” to having a displacement between x′ and x′ + dx′.13 The ﬁrst part of the integral in equation (2) corresponds to all those transitions that remove particles from the displacement x at time t to some other displacement x′ and, hence, represent a net loss to the function f (x, t); similarly, the second part of the integral corresponds to all those transitions that bring particles from some other displacement x′ at time t to the displacement x and, hence, represent a net gain to the function f (x, t). 14 The structure of the Master Equation is thus founded on very simple and straightfor- ward premises. Of course, under certain conditions, this equation, or any generalization thereof (such as the one including velocity, or momentum, coordinates in the argument of f ), can be reduced to the simple form ∂f ∂t = − f − f0 τ , (3) which has proved to be a very useful ﬁrst approximation for studying problems related to transport phenomena. Here, f0 denotes the equilibrium distribution function (for ∂f /∂t = 0 when f = f0), while τ is the relaxation time that determines the rate at which the ﬂuctuations in the system drive it to a state of equilibrium. In studying Brownian motion on the basis of equation (2), we can safely assume that it is only transitions between “closely neighboring” states x and x′ that have an apprecia- ble probability of occurring; in other words, the transition probability function W (x, x′) is sharply peaked around the value x′ = x and falls rapidly to zero away from x. Denoting the interval (x′ − x) by ξ , we may write W (x, x′) → W (x; ξ ), W (x′, x) → W (x′; −ξ ) (4) 13We are tacitly assuming here a “Markovian” situation where the transition probability function W (x, x′) depends only on the present position x (and, of course, the subsequent position x′) of the particle but not on the previous history of the particle. 14In the case of fermions, an account must be taken of the Pauli exclusion principle, which controls the “occupation of single-particle states in the system”; for instance, we cannot, in that case, consider a transition that tends to transfer a particle to a state that is already occupied. This requires an appropriate modiﬁcation of the Master Equation. 15.4 Approach to equilibrium: the Fokker–Planck equation 605 where W (x; ξ ) and W (x′; −ξ ) have sharp peaks around the value ξ = 0 and fall rapidly to zero elsewhere.15 This enables us to expand the right side of (2) as a Taylor series around ξ = 0. Retaining terms up to second order only, we obtain ∂f (x, t) ∂t = − ∂ ∂x {µ1(x)f (x, t)} + 1 2 ∂ 2 ∂x2 {µ2(x)f (x, t)}, (5) where µ1(x) = ∞∫ −∞ ξ W (x; ξ )dξ = ⟨δx⟩δt δt = ⟨vx⟩ (6) and µ2(x) = ∞∫ −∞ ξ 2W (x; ξ )dξ = ⟨(δx)2⟩δt δt . (7) Equation (5) is the so-called Fokker–Planck equation, which occupies a classic place in the ﬁeld of Brownian motion and ﬂuctuations. We now consider a speciﬁc system of Brownian particles (of negligible mass), each par- ticle being acted on by a linear restoring force, Fx = −λx, and having mobility B in the surrounding medium; the assumption of negligible mass implies that the relaxation time τ (= MB) of equation (15.3.4) is very small, so the time t here may be regarded as very large in comparison with that τ . The mean viscous force, −⟨vx⟩/B, is then balanced by the linear restoring force, with the result that − ⟨vx⟩ B + Fx = 0 (8) and hence ⟨vx⟩ ≡ µ1(x) = −λBx. (9) Next, in view of equation (15.3.10), we have ⟨(δx)2⟩ δt ≡ µ2(x) = 2BkT ; (10) it will be noted that the inﬂuence of λ on this quantity is being neglected here. Substituting (9) and (10) into (5), we obtain ∂f ∂t = λB ∂ ∂x (xf ) + BkT ∂ 2f ∂x2 . (11) 15Clearly, this assumption limits our analysis to what may be called the “Brownian motion approximation,” in which the object under consideration is presumed to be on a very different scale of magnitude than the molecules constituting the environment. It is obvious that if one tries to apply this sort of analysis to “understand” the behavior of molecules themselves, one cannot hope for anything but a “crude, semiquantitative” outcome. 606 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics Now we apply equation (11) to an “ensemble” of Brownian particles, initially concen- trated at the point x = x0. To begin with, we note that, in the absence of the restoring force (λ = 0), equation (11) reduces to the one-dimensional diffusion equation ∂f ∂t = D ∂ 2f ∂x2 (D = BkT ), (12) which conforms to our earlier results (15.2.19) and (15.3.11). The present derivation shows that the process of diffusion is essentially a “random walk, at the molecular level.” In view of equation (15.2.20), the function f (x, t) here would be f (x, t) = 1 (4π Dt)1/2 exp { − (x − x0)2 4Dt } , (13) with x = x0 and x2 = x2 0 + 2Dt; (14) the last result shows that the mean square distance traversed by the particle(s) increases linearly with time, without any upper limit on its value. The restoring force, however, puts a check on the diffusive tendency of the particles. For instance, in the presence of such a force (λ ̸= 0), the terminal distribution f∞ (for which ∂f /∂t = 0) is determined by the equation ∂ ∂x (xf∞) + kT λ ∂ 2f∞ ∂x2 = 0, (15) which gives f∞(x) = ( λ 2πkT )1/2 exp ( − λx2 2kT ) , (16) with x = 0 and x2 = kT /λ. (17) The last result agrees with the fact that the mean square value of x must ultimately comply with the equipartition theorem, namely ( 1 2 λx2) ∞ = 1 2 kT . From the point of view of equilib- rium statistical mechanics, if we regard Brownian particles with kinetic energy p2 x/2m and potential energy 1 2 λx2 as loosely coupled to a thermal environment at temperature T , then we may directly write feq(x, px)dxdpx ∝ e−(p2 x/2m+λx2/2)/kT dxdpx. (18) On integration over px, expression (18) leads directly to the distribution function (16). 15.4 Approach to equilibrium: the Fokker–Planck equation 607 f (x,t ) t 5 0 t 5` kT λ x0 t 5 x 0 1 2λB FIGURE 15.5 The distribution function (19) at times t = 0, t = 1/(2λB), and t = ∞. The general solution of equation (11), relevant to the ensemble under consideration, is given by f (x, t) = { λ 2πkT (1 − e−2λBt ) }1/2 exp { − λ(x − x0e−λBt )2 2kT (1 − e−2λBt ) } , (19) with x = x0e−λBt and x2 = x2 0e−2λBt + kT λ (1 − e−2λBt ); (20) in the limit λ → 0, we recover the purely “diffusive” situation, as described by equa- tions (13) and (14), while for t ≫ (λB)−1, we approach the “terminal” situation, as described by equations (16) and (17). Figure 15.5 shows the manner in which an ensem- ble of Brownian particles approaches a state of equilibrium under the combined inﬂuence of the restoring force and the molecular bombardment; clearly, the relaxation time of the present process is ∼ (λB)−1. A physical system to which the foregoing theory is readily applicable is provided by the oscillating component of a moving-coil galvanometer. Here, we have a coil of wire and a mirror that are suspended by a ﬁne ﬁber, so they can rotate about a vertical axis. Random, incessant collisions of air molecules with the suspended system produce a succession of torques of ﬂuctuating intensity; as a result, the angular position θ of the system continu- ally ﬂuctuates and the system exhibits an unsteady zero. This is clearly another example of the Brownian motion! The role of the viscous force in this case is played by the mechanism of air damping (or, else, electromagnetic damping) of the galvanometer, while the restor- ing torque, Nθ = −cθ , arises from the torsional properties of the ﬁber. In equilibrium, we 608 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics expect that ( 1 2 cθ 2) = 1 2 kT , that is, θ 2 = kT c ; (21) compare this to equation (17). An experimental determination of the mean square deﬂec- tion, θ 2, of such a system was made by Kappler (1931) who, in turn, applied his results to derive, with the help of equation (21), an empirical value for the Boltzmann constant k (or, for that matter, the Avogadro number NA). The system used by Kappler had a moment of inertia I = 4.552 × 10−4 g cm2 and a time period of oscillation τ = 1379 s; accordingly, the constant c of the restoring torque had a value given by the formula τ = 2π(I/c)1/2, so that c = 4π 2(I/τ 2) = 9.443 × 10 −9g cm2s−2/rad. The observed value of θ 2, at a temperature of 287.1 K, was 4.178 × 10−6. Substituting these numbers in (21), Kappler obtained: k = 1.374 × 10−16 erg K−1. And, since the gas constant R is equal to 8.31 × 107 erg K−1mole −1, he obtained for the Avogadro number: NA = R/k = 6.06 × 1023 mole −1. One might expect that by suspending the mirror system in an “evacuated” casing the ﬂuctuations caused by the collisions of the air molecules could be severely reduced. This is not true because even at the lowest possible pressures there still remain a tremendously large number of molecules in the system that keep the Brownian motion “alive.” The inter- esting part of the story, however, is that the mean square deﬂection of the system, caused by molecular bombardment, is not at all affected by the density of the molecules; for a sys- tem in equilibrium, it is determined solely by the temperature. This situation is depicted, rather dramatically, in Figure 15.6 where we have two traces of oscillations of the mir- ror system, the upper one having been taken at the atmospheric pressure and the lower one at a pressure of 10−4 mm of mercury. The root-mean-square deviation is very nearly the same in the two cases! Nevertheless, one does note a difference of “quality” between the two traces that relates to the “frequency spectrum” of the ﬂuctuations and arises for the following reason. When the density of the surrounding gas is relatively high, the molecular impulses come in rapid succession, with the result that the individual deﬂec- tions of the system are large in number but small in magnitude. As the pressure is lowered, the time intervals between successive impulses become longer, making the individual deﬂections smaller in number but larger in magnitude. However, the overall deﬂection, observed over a long interval of time, remains essentially the same. FIGURE 15.6 Two traces of the thermal oscillations of a mirror system suspended in air; the upper trace was taken at the atmospheric pressure, the lower one at a pressure of 10−4 mm of mercury. 15.5 Spectral analysis of ﬂuctuations: the Wiener–Khintchine theorem 609 15.5 Spectral analysis of ﬂuctuations: the Wiener–Khintchine theorem We have already made reference to the (spectral) quality of a ﬂuctuation pattern. Refer- ring once again to the patterns shown in Figure 15.6, we note that, even though the mean square ﬂuctuation of the variable θ is the same in the two cases, the second pattern is far more “jagged” than the ﬁrst; in other words, the high-frequency components are far more prominent in the second pattern. At the same time, there is a lot more “predictabil- ity” in the ﬁrst pattern (insofar as it is represented by a much smoother curve); in other words, the correlation function, or the memory function, K (s) of the ﬁrst pattern extends over much larger values of s. In fact, these two aspects of a ﬂuctuation process, namely its time-dependence and its frequency spectrum, are very closely related to one another. And the most natural course for studying this relationship is to carry out a Fourier analysis of the given process. For this study we consider only those variables, y(t), whose mean square value, ⟨y2(t)⟩, has already attained an equilibrium, or stationary, value: ⟨y2(t)⟩ = const. (1) Such a variable is said to be statistically stationary. As an example of such a variable, we may recall the velocity v(t) of a “free” Brownian particle at times t much larger than the relaxation time τ , see equation (15.3.29), or the displacement x(t) of a Brownian particle moving under the inﬂuence of a restoring force (Fx = −λx) at times t much larger than (λB)−1, see equation (15.4.20). Now, if the variable y(t) were strictly periodic (and hence completely predictable), with a time period T = 1/f0, then we could write y(t) = a0 + ∞∑ n=1 an cos(2π nf0t) + ∞∑ n=1 bn sin(2πnf0t), (2) where a0 = 1 T T∫ 0 y(t)dt, (3) an = 2 T T∫ 0 y(t) cos(2π nf0t)dt, (4) and bn = 2 T T∫ 0 y(t) sin(2π nf0t)dt; (5) in this case, the coefﬁcients a and b would be completely known and would deﬁne, with no uncertainty, the frequency spectrum of the variable y(t). If, on the other hand, the given 610 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics variable is more or less a random function of time, then the coefﬁcients a and b would themselves be statistical in nature. To apply the concept of periodicity to such a function, we must take the “time interval of repetition” to be inﬁnitely large, that is, we let f0 → 0. In the proposed limit, equation (3) would read a0 = Lim T →∞ 1 T T∫ 0 y(t)dt ≡ ⟨y(t)⟩; (6) thus, the coefﬁcient a0, which represents the mean (or d.c.) value of the variable y, may be determined either by taking a time average (over a sufﬁciently long interval) of the variable or by taking an ensemble average (at any instant of time t). For convenience, and without loss of generality, we take a0 = 0; in other words, we assume that from the actual values of the variable y(t) its mean value, ⟨y(t)⟩, has already been subtracted. 16 Taking the ensemble average of equations (4) and (5), we obtain, for all n, ⟨an⟩ = ⟨bn⟩ = 0. (7) However, by taking the ensemble average of equation (2) squared, we obtain ⟨y2(t)⟩ = ∑ n 1 2 ⟨a2 n⟩ + ∑ n 1 2 ⟨b 2 n⟩ = ∑ n 1 2 {⟨a2 n⟩ + ⟨b 2 n⟩} = const. (8) The term 1 2 {⟨a2 n⟩ + ⟨b2 n⟩} represents the respective “share,” belonging to the frequency nf0, in the total, time-independent value of the quantity ⟨y2(t)⟩. Now, in view of the random- ness of the phases of the various components, we have, for all n, ⟨a2 n⟩ = ⟨b2 n⟩; consequently, equation (8) may be written as ⟨y2⟩ = ∑ n ⟨a2 n⟩ ≃ ∞∫ 0 w( f )df , (9) where ⟨a2 n⟩ = w(nf0)1(nf0), that is, w(nf0) = 1 f0 ⟨a2 n⟩; (10) the function w( f ) deﬁnes the power spectrum of the variable y(t). We shall now show that the power spectrum w( f ) of the ﬂuctuating variable y(t) is completely determined by its autocorrelation function K (s). For this, we make use of 16Obviously, this does not affect the spectral quality of the ﬂuctuations, except that now we do not have a compo- nent with frequency zero. To represent the actual situation, one may have to add, to the resulting spectrum, a suitably weighted δ( f )-term. 15.5 Spectral analysis of ﬂuctuations: the Wiener–Khintchine theorem 611 equation (4), which gives ⟨a2 n⟩ = 4f 2 0 1/f0∫ 0 1/f0∫ 0 ⟨y(t1)y(t2)⟩ cos(2π nf0t1) cos(2πnf0t2)dt1dt2. (11) Changing over to the variables S = 1 2 (t1 + t2) and s = (t2 − t1), and remembering that the interval T over which the integrations extend is much larger than the duration over which the “memory” of the variable y lasts, we obtain ⟨a2 n⟩ ≃ 2f 2 0 1/f0∫ S=0 ∞∫ s=−∞ K (s){cos(2π nf0s) + cos(4π nf0S)}dSds; (12) compare this to the steps that led us from equations (15.3.22) to (15.3.25) and (15.3.26). The second part of the integral in (12) vanishes on integration over S; the ﬁrst part then gives ⟨a2 n⟩ = 4f0 ∞∫ 0 K (s) cos(2πnf0s)ds. (13) Comparing (13) with (10), we obtain the desired formula w( f ) = 4 ∞∫ 0 K (s) cos(2πfs)ds. (14) Taking the inverse of (14), we obtain K (s) = ∞∫ 0 w( f ) cos(2π fs)df . (15) For s = 0, formula (15) yields the important relationship K (0) = ∞∫ 0 w( f )df = ⟨y2⟩; (16) see equation (9) as well as the deﬁnition of the autocorrelation function of the variable y, namely K (s) = ⟨y(t1)y(t1 + s)⟩. Equations (14) and (15), which connect the complementary functions w( f ) and K (s), constitute a theorem that goes after the names of Wiener (1930) and Khintchine (1934). 612 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics We shall now look at some special cases of the variable y(t) to illustrate the use of the Wiener–Khintchine theorem. Case 1 If the given variable y(t) is extremely irregular, and hence unpredictable, then its correla- tion function K (s) would extend over a negligibly small range of the time interval s. 17 We may then write K (s) = cδ(s). (17a) Equation (14) then gives w( f ) = 2c for all f . (17b) A spectrum in which the distribution (of power) over different frequencies is uniform is known as a “ﬂat” or a “white” spectrum. We note, however, that if the uniformity of distri- bution were literally true for all frequencies, from 0 to ∞, then the integral in (16), which is identically equal to ⟨y2⟩, would diverge! We, therefore, expect that, in any realistic sit- uation, the correlation function K (s) will not be as sharply peaked as in (17a). Typically, K (s) will extend over a small range, O(σ ), of the variable s, which in turn will deﬁne a “frequency zone,” with f = O(1/σ ), such that the function w( f ) would undergo a change of character as f passes through this zone; toward lower frequencies, w( f ) → const. ̸= 0, while toward higher frequencies, w( f ) → const. = 0. One possible representation of this situation is shown in Figure 15.7 where we have taken, rather arbitrarily, K (s) = K (0) sin(as) as (a > 0), (18a) for which w( f ) = 2π a K (0) for f < a 2π 0 for f > a 2π . (18b) In the limit a → ∞, equations (18) reduce to (17), with c = πa−1K (0). Case 2 On the other hand, if the variable y(t) is extremely regular, and hence predictable, then its correlation function would extend over large values of s; its power spectrum would then appear in the form of “peaks,” located at certain “characteristic frequencies” of the vari- able. In the simplest case of a monochromatic variable, with characteristic frequency f ∗, the correlation function would be K (s) = K (0) cos(2π f ∗s), (19a) 17This is essentially true of the rapidly ﬂuctuating force F(t) experienced by a Brownian particle due to the incessant molecular impulses received by it. 15.5 Spectral analysis of ﬂuctuations: the Wiener–Khintchine theorem 613 0 \u0002 2\u00022\u000222\u0002 K(s) a 5 2 a 5 1 s a 52 a 5 1 0w (f ) f 1 2\u0002 1 \u0002 FIGURE 15.7 The autocorrelation function K (s) and the power distribution function w( f ) of a given variable y(t); the parameter a appears in terms of an arbitrary unit of (time)−1. for which w( f ) = K (0)δ( f − f ∗); (19b) see Figure 15.8. A very special case arises when f ∗ = 0; then, both y(t) and K (s) are constant in value, and the function w( f ) is peaked at the d.c. frequency f = 0. Case 3 If the variable y(t) represents a signal that arises from, or has been ﬁltered through, a lightly damped tuned circuit (a “narrowband” ﬁlter), then its power will be distributed over a “hump” around the mean frequency f ∗. The function K (s) will then appear in the nature of an “attenuated” function whose time scale, σ , is determined by the width, 1f , of the hump in the power spectrum. A situation of this kind is shown in Figure 15.9. The relevance of spectral analysis to the problem of the actual observation of a ﬂuc- tuating variable is best brought out by examining the power spectrum of the velocity v(t) of a Brownian particle. Considering the x-component alone, the autocorrelation function Kvx (s), or simply K (s), in this case is given by K (s) = kT M e−|s|/τ (τ = MB); (20) 614 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics f ∗ f 0\u00022 f ∗ K (s) 0 s \u00021 f ∗ 1 f ∗ 2 f ∗w (f ) FIGURE 15.8 The autocorrelation function K (s) and the power distribution function w( f ) of a monochromatic variable y(t), with characteristic frequency f ∗. see equation (15.6.10). The power spectrum w( f ) is then given by the expression w( f ) = 4kT M ∞∫ 0 e−s/τ cos(2π fs)ds = 4kT τ M 1 1 + (2π f τ )2 , (21) which indeed satisﬁes the relationship ∞∫ 0 w( f )df = 2kT πM tan −1(2πf τ ) ∣ ∣ ∣ ∞ 0 = kT M = ⟨v2 x⟩, (22) in agreement with the equipartition theorem (as applied to a single component of the velocity v). For f ≪ τ −1, the power distribution is practically independent of f , which implies a practically “white” spectrum, with w( f ) ≃ 4kT τ M = 4BkT . (23) 15.5 Spectral analysis of ﬂuctuations: the Wiener–Khintchine theorem 615 f ∗ 1 2\u0002 f 0 0 K(s) s 2\u0002\u00032\u0002 \u0002\u0003\u0002w (f ) FIGURE 15.9 The autocorrelation function K (s) and the power distribution function w( f ) of a variable that has been ﬁltered through a lightly damped tuned circuit, with mean frequency f ∗ and width 1f ∼ (1/σ ). We can then write for the velocity ﬂuctuations in the frequency range ( f , f + 1f ), with f ≪ τ −1, ⟨1v2 x⟩( f , f +1f ) ≃ w( f )1f ≃ (4BkT )1f . (24) In general, our measuring instrument (or the eye, in the case of a visual examination of the particle) has a ﬁnite response time τ0, as a consequence of which it is unable to respond to frequencies larger than, say, τ −1 0 . The observed ﬂuctuation is then given by the “pruned” expression ⟨v2 x⟩obs ≃ 1/τ0∫ 0 w( f )df = 2kT π M tan −1 ( 2π τ τ0 ) , (25) instead of the “full” expression (22). In a typical case, the mass of the Brownian particle M ∼ 10−12g, its diameter 2a ∼ 10−4 cm, and the coefﬁcient of viscosity of the ﬂuid η ∼ 10−2 poise, so that the relaxation time τ = M/(6πηa) ∼ 10−7 seconds. However, the response time τ0, in the case of visual observation, is of the order of 10−1 s; clearly, τ/τ0 ∼ 10−6 ≪ 1. 616 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics Equation (25) then reduces to18 ⟨v2 x⟩obs ≃ 4kT τ Mτ0 ≪ kT M ; (26) thus, in view of the ﬁniteness of the response time τ0, the observed root-mean-square velocity of the Brownian particle will be down by a factor of 2(τ/τ0)1/2 ∼ 10−3; numeri- cally, this takes us down from a root-mean-square velocity which, at room temperatures, is ∼ 10−1 cm/s to a value ∼ 10−4 cm/s. It is gratifying to note that the outcome of actual observations of Brownian particles is in complete agreement with the latter result; for a more detailed analysis of this question, see MacDonald (1950). The foregoing discussion highlights the fact that, in the process of observing a ﬂuctuating variable, our measuring instrument picks up signals over only a limited range of frequencies (as determined by the response time of the instrument); signals belonging to higher frequencies are simply left out. The theory of this section can be readily applied to ﬂuctuations in the motion of elec- trons in an (L, R) circuit. Corresponding to equations (21) through (24), we now have for ﬂuctuations in the electric current I w( f ) = 4kT τ ′ L 1 1 + (2π f τ ′)2 ( τ ′ = L R ) , (27) so that ∞∫ 0 w( f )df = kT L = ⟨I 2⟩, (28) in agreement with the equipartition theorem: ⟨ 1 2 LI 2⟩ = 1 2 kT . For f ≪ 1/τ ′, equation (27) reduces to w( f ) ≃ 4kT R , (29) which, once again, implies “white” noise; accordingly, for low frequencies, ⟨1I 2⟩( f , f +1f ) ≃ w( f )1f ≃ 4kT R 1f . (30) Equivalently, we obtain for ﬂuctuations in the voltage ⟨1V 2⟩( f , f +1f ) ≃ (4RkT )1f . (31) Equation (31) constitutes the so-called Nyquist theorem, which was ﬁrst discovered empir- ically by Johnson (1927a,b; 1928) and was later derived by Nyquist (1927–1928) on the basis 18The ﬂuctuations constituting this result belong entirely to the region of the “white” noise, with 1f = 1/τ0; see equation (24), with B = τ/M. 15.6 The ﬂuctuation–dissipation theorem 617 of an argument involving the second law of thermodynamics and the exchange of energy between two resistances in thermal equilibrium.19 15.6 The ﬂuctuation–dissipation theorem In Section 15.3 we obtained a result of considerable importance, namely 1 B ≡ M τ = M 2 6kT C = M 2 6kT ∞∫ −∞ KA(s)ds = 1 6kT ∞∫ −∞ KF (s)ds; (1) see equations (15.3.4), (15.3.26), and (15.3.28). Here, KA(s) and KF (s) are, respectively, the autocorrelation functions of the ﬂuctuating acceleration A(t) and the ﬂuctuating force F(t) experienced by the Brownian particle: KA(s) = ⟨A(0) · A(s)⟩ = 1 M 2 ⟨F(0) · F(s)⟩ = 1 M 2 KF (s). (2)20 Equation (1) establishes a fundamental relationship between the coefﬁcient, 1/B, of the “averaged-out” part of the total force F (t) experienced by the Brownian particle due to the impacts of the ﬂuid molecules and the statistical character of the “ﬂuctuating” part, F(t), of that force; see Langevin’s equation (15.3.2). In other words, it relates the coefﬁcient of viscosity of the ﬂuid, which represents dissipative forces operating in the system, with the temporal character of the molecular ﬂuctuations; the content of equation (1) is, therefore, referred to as a ﬂuctuation–dissipation theorem. The most striking feature of this theorem is that it relates, in a fundamental manner, the ﬂuctuations of a physical quantity pertaining to the equilibrium state of a given system to a dissipative process which, in practice, is realized only when the system is subject to an external force that drives it away from equilibrium. Consequently, it enables us to deter- mine the nonequilibrium properties of the given system on the basis of a knowledge of the thermal ﬂuctuations occurring in the system when the system is in one of its equilibrium 19We note that the foregoing results are essentially equivalent to Einstein’s original result for charge ﬂuctuations in a conductor, namely ⟨δq2⟩t = 2kT R t; compare, as well, the Brownian-particle result: ⟨x2⟩t = 2BkTt. 20We note that the functions KA(s) and KF (s), which are nonzero only for s = O(τ ∗), see equation (15.3.21), may, for certain purposes, be written as KA(s) = 6kT M 2B δ(s) and KF (s) = 6kT B δ(s). In this form, the functions are nonzero only for s = 0. 618 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics states! For an expository account of the ﬂuctuation–dissipation theorem, the reader may refer to Kubo (1966). At this stage we recall that in equation (15.3.11) we obtained a relationship between the diffusion coefﬁcient D and the mobility B, namely D = BkT . Combining this with equation (1), we get 1 D = 1 6(kT )2 ∞∫ −∞ KF (s)ds. (3) Now, the diffusion coefﬁcient D can be related directly to the autocorrelation function Kv(s) of the ﬂuctuating variable v(t). For this, one starts with the observation that, by deﬁnition, r(t) = t∫ 0 v(u)du, (4) which gives ⟨r2(t)⟩ = t∫ 0 t∫ 0 ⟨v(u1) · v(u2)⟩du1du2. (5) Proceeding in the same manner as for the integral in equation (15.3.22), one obtains ⟨r2(t)⟩ = t/2∫ 0 dS +2S∫ −2S Kv(s)ds + t∫ t/2 dS +2(t−S)∫ −2(t−S) Kv(s)ds; (6) compare this to equation (15.3.24). The function Kv(s) can be determined by making use of expression (15.3.14) for v(t) and following exactly the same procedure as for determining the quantity ⟨v2(t)⟩, which is nothing but the maximal value, Kv(0), of the desired function. Thus, one obtains Kv(s) =    v2(0)e−(2t+s)/τ + 3kT M e−s/τ (1 − e−2t/τ ) for s > 0 (7) v2(0)e−(2t+s)/τ + 3kT M es/τ (1 − e−2(t+s)/τ ) for s < 0; (8) compare these results to equation (15.3.27). It is easily seen that formulae (7)and (8) can be combined into a single one, namely Kv(s) = v2(0)e−|s|/τ + { 3kT M − v2(0)} (e−|s|/τ − e−(2t+s)/τ ) for all s; (9) 15.6 The ﬂuctuation–dissipation theorem 619 compare this to equation (15.3.29). In the case of a “stationary ensemble,” Kv(s) = 3kT M e−|s|/τ , (10) which is consistent with property (15.3.20). It should be noted that the time scale for the correlation function Kv(s) is provided by the relaxation time τ of the Brownian motion, which is many orders of magnitude larger than the characteristic time τ ∗ that provides the time scale for the correlation functions KA(s) and KF (s). It is now instructive to verify that the substitution of expression (10) into (6) leads to formula (15.3.7) for ⟨r2⟩, while the substitution of the more general expression (9) leads to formula (15.3.31); see Problem 15.17. In either case, ⟨r2⟩ −−−→ t≫τ 6Dt. (11) In the same limit, equation (6) reduces to ⟨r2⟩ ≃ t∫ 0 dS ∞∫ −∞ Kv(s)ds = t ∞∫ −∞ Kv(s)ds. (12) Comparing the two results, we obtain the desired relationship: D = 1 6 ∞∫ −∞ Kv(s)ds. (13) In passing, we note, from equations (3) and (13), that ∞∫ −∞ Kv(s)ds ∞∫ −∞ KF (s)ds = (6kT )2; (14) see also Problem 15.7. It is not surprising that the equations describing a ﬂuctuation–dissipation theorem can be adapted to any situation that involves a dissipative mechanism. For instance, ﬂuctua- tions in the motion of electrons in an electric resistor give rise to a “spontaneous” thermal e.m.f., which may be denoted as B(t). In the spirit of the Langevin theory, this e.m.f. may be split into two parts: (i) an “averaged-out” part, −RI(t), which represents the resistive (or dissipative) aspect of the situation, and (ii) a “rapidly ﬂuctuating” part, V (t), which, over long intervals of time, averages out to zero. The “spontaneous” current in the resistor is then given by the equation L dI dt = −RI + V (t); ⟨V (t)⟩ = 0. (15) 620 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics Comparing this with the Langevin equation (15.3.2) and pushing the analogy further, we infer that there exists a direct relationship between the resistance R and the temporal character of the ﬂuctuations in the variable V (t). In view of equations (1) and (13), this relationship would be R = 1 6kT ∞∫ −∞ ⟨V (0) · V (s)⟩ds (16) or, equivalently, 1 R = 1 6kT ∞∫ −∞ ⟨I(0) · I(s)⟩ds. (17) A generalization of the foregoing result has been given by Kubo (1957, 1959); see, for instance, Problem 6.19 in Kubo (1965), or Section 23.2 of Wannier (1966). On generaliza- tion, the electric current density j(t) is given by the expression ji(t) = ∑ l t∫ −∞ El(t′)8li(t − t′)dt′ (i, l = x, y, z); (18) here, E(t) denotes the applied electric ﬁeld while 8li(s) = 1 kT ⟨jl(0)ji(s)⟩. (19) Clearly, the quantities kT 8li(s) are the components of the autocorrelation tensor of the ﬂuctuating vector j(t). In particular, if we consider the static case E = (E, 0, 0), we obtain for the conductivity of the system σxx ≡ jx E = t∫ −∞ 8xx(t − t′)dt′ = ∞∫ 0 8xx(s)ds = 1 2kT ∞∫ −∞ ⟨ jx(0)jx(s)⟩ds, (20) which may be compared with equation (17). If, on the other hand, we take E = (E cos ωt, 0, 0), we obtain instead σxx(ω) = 1 2kT ∞∫ −∞ ⟨ jx(0)jx(s)⟩e−iωsds. (21) 15.6 The ﬂuctuation–dissipation theorem 621 Taking the inverse of (21), we get ⟨jx(0)jx(s)⟩ = kT π ∞∫ −∞ σxx(ω)eiωsdω. (22) If we now assume that σxx(ω) does not depend on ω (and may, therefore, be denoted by the simpler symbol σ ), then ⟨jx(0)jx(s)⟩ = (2kT σ )δ(s); (23) see footnote 20. A reference to equations (15.5.17) shows that, in the present approxima- tion, thermal ﬂuctuations in the electric current are charaterized by a “white” noise. 15.6.A Derivation of the ﬂuctuation–dissipation theorem from linear response theory In this section we will show that the nonequilibrium response of a thermodynamic system to a small driving force is very generally related to the time-dependence of equilibrium ﬂuctuations. In hindsight, this is not too surprising since natural ﬂuctuations about the equilibrium state also induce small deviations of observables from their average val- ues. The response of the system to these natural ﬂuctuations should be the same as the response of the system to deviations from the equilibrium state as caused by small driving forces; see Martin (1968), Forster (1975), and Mazenko (2006). Let us compute the time-dependent changes to an observable A caused by a small time-dependent external applied ﬁeld h(t) that couples linearly to some observable B. The Hamiltonian for the system then becomes H(t) = H0 − h(t)B, (24) where H0 is the unperturbed Hamiltonian in the equilibrium state. Remarkably, the calcu- lation for determining the nonequilibrium response to the driving ﬁeld is easiest using the quantum-mechanical density matrix approach developed in Section 5.1. The equilibrium density matrix is given by ˆρeq = exp(−βH0) Tr (exp(−βH0) ) , (25) where equilibrium averages involve traces over the density matrix: ⟨A⟩eq = Tr (A ˆρeq) . (26) When the Hamiltonian includes a small time-dependent ﬁeld h(t), then this additional term drives the system slightly out of equilibrium. We will assume that the ﬁeld was zero in the distant past so the system was initially in the equilibrium state deﬁned by the 622 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics Hamiltonian H0. We then turn on the ﬁeld and measure the time-dependent deviations of the observable A from its equilibrium value. The small time-dependent applied ﬁeld h(t) induces a small change to the density matrix ˆρ(t) = ˆρeq + δ ˆρ(t). (27) The equation of motion of the density matrix in equation (5.1.10) gives ∂ ˆρ ∂t = ∂δ ˆρ ∂t = 1 iℏ [H, ˆρ(t) ] ≈ 1 iℏ ([ H0, δ ˆρ] − h(t) [B, ˆρeq]) , (28) where [, ] denotes the commutator. Since we are considering only the linear response of the system to the applied ﬁeld, we have ignored the higher-order term proportional to h(t) [ B, δ ˆρ] . Solving (28) for the time-dependent change to the density matrix, we get δ ˆρ(t) = i ℏ t∫ −∞ h(t′) exp ( −iH0(t − t′) ℏ ) [B, ˆρeq] exp ( iH0(t − t′) ℏ ) dt′. (29) This form uses the interaction representation in which operators evolve in time due to the unperturbed Hamiltonian H0. We can use the change in the density matrix at time t to calculate the change in the observable A compared to its equilibrium value, namely ⟨δA(t)⟩ = ⟨A(t)⟩ − ⟨A⟩eq = Tr ( A ˆρ(t) ) − Tr (A ˆρeq) = Tr ( Aδ ˆρ(t) ) . (30) Using the cyclic property of traces, Tr (QRS) = Tr (SQR), we ﬁnd that ⟨δA(t)⟩ is the convolu- tion of a response function with the applied ﬁeld: ⟨δA(t)⟩ = i ℏ t∫ −∞ 〈[A(t), B(t′)]〉 eq h(t′)dt′. (31) Note that this nonequilibrium response function of the system to the driving force depends on the equilibrium average of the commutator of the observables A and B at dif- ferent times. The effect of the ﬁeld on the observable A is causal since ⟨δA(t)⟩ depends only on the applied ﬁeld at earlier times. Since the relation is linear, time-translationally invariant, and causal, the Fourier spectra of ⟨δA⟩ and h, namely δ ˆA(ω) = ∞∫ −∞ ⟨δA(t)⟩ eiωt dt, and (32a) ˆh(ω) = ∞∫ −∞ h(t)eiωt dt, (32b) are related by δ ˆA(ω) = ( ˆχ ′ AB(ω) + i ˆχ ′′ AB(ω) ) ˆh(ω), (33) 15.6 The ﬂuctuation–dissipation theorem 623 where ˆχ ′′ AB(ω) is given by ˆχ ′′ AB(ω) = 1 2ℏ ∞∫ −∞ ⟨[A(t), B(0)]⟩eq eiωt dt. (34) The quantity ˆχ ′ AB(ω) is given by the Kramers–Kronig relation using the principal part P of an inﬁnite integral over ˆχ ′′ AB(ω): ˆχ ′ AB(ω) = P ∞∫ −∞ ˆχ ′′ AB(ω′) ω′ − ω dω′ π . (35) If A and B are the same operator, then ˆχ ′ AA(ω) and ˆχ ′′ AA(ω) are, respectively, the real and imaginary parts of the response function. If A and B have the same symmetry under time- reversal, ω ˆχ ′′ AB(ω) is real and is an even function of ω. For a set of observables Ai, the set of response functions ω ˆχ ′′ ij(ω) form a symmetric positive matrix that gives the rate of energy dissipation due to the external driving forces. See Jackson (1999) for a general causality discussion and Martin (1968), Forster (1975), or Mazenko (2006) for the details of this calculation. Now we consider the equilibrium temporal correlations between the ﬂuctuations of the observables A and B, namely GAB(t − t′) = 〈 δA(t)δB(t′) 〉 eq . (36) At equal times, this measures the AB equilibrium ﬂuctuations described in Section 15.1, that is, GAB(0) = ⟨δAδB⟩eq. The power spectrum of the AB equilibrium ﬂuctuations is deﬁned by SAB(ω) = ∞∫ −∞ GAB(t)eiωt dt = ∞∫ −∞ ⟨δA(t)δB(0)⟩eq eiωt dt. (37) The similarity between the forms of SAB(ω) and ˆχ ′′ AB(ω) in equations (34) and (37) leads to an important relation between the power spectrum and the linear response function, namely the ﬂuctuation–dissipation theorem: ˆχ ′′ AB(ω) = 1 2ℏ (1 − e−βℏω) SAB(ω). (38) The power spectrum SAB(ω) measures equilibrium ﬂuctuations whereas ˆχ ′′ AB(ω) is propor- tional to the average rate of power dissipation that results from the time-varying applied ﬁeld. The classical limit of the ﬂuctuation–dissipation theorem is obtained by letting ℏω/kT → 0 with the result ˆχ ′′ AB(ω) = ω 2kT SAB(ω); (39) compare this to equation (15.3.45). More complete discussions of the ﬂuctuation– dissipation theorem can be found in Martin (1968), Forster (1975), and Mazenko (2006). 624 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics 15.6.B Inelastic scattering Inelastic scattering is an important experimental technique for measuring the dynamical behavior of materials. By measuring the intensity of radiation scattered from a sample as a function of wavevector transfer and frequency change relative to the incident monochro- matic radiation source, one can measure the spatio-temporal correlations in the material. This technique is now commonly applied to the scattering of neutrons, electrons, light, and x-rays. The frequency changes in the scattered wave are caused by inelastic scattering from quantum excitations in the sample; see Forster (1975), Squires (1997), and Mazenko (2006). The frequency-dependent scattering intensity is directly proportional to the dynamical structure factor S(k, ω) = 1 N ∞∫ −∞ 〈 ∑ i,j e−ik·(ri(t)−rj(0))〉 eiωt dt, (40) where k represents the wavevector transfer of the scattering process and ω represents the frequency difference from that of the incident beam. A positive value of ω corresponds to a detected frequency that is less than the frequency of the incident beam. The dynamical structure factor S(k, ω) encodes both the spatial and temporal equilibrium correlations of ﬂuctuations in the material and can be decomposed into two terms, one that represents scattering from a single particle at different times and another that represents scattering from different particles: S(k, ω) = Sself(k, ω) + Scoherent(k, ω), (41a) Sself(k, ω) = 1 N ∞∫ −∞ 〈∑ i e−ik·(ri(t)−ri(0))〉 eiωt dt, (41b) Scoherent(k, ω) = 1 N ∞∫ −∞ 〈∑ i̸=j e−ik·(ri(t)−rj(0))〉 eiωt dt. (41c) The dynamical structure factor S(k, ω) can also be written in terms of the spatio- temporal Fourier transforms of the time-dependent density n(r, t) to connect it to the power spectrum as deﬁned in Section 15.6.A: S(k, ω) = SAB(ω) = ∞∫ −∞ ⟨δA(t)δB(0)⟩ eiωt dt, (42a) δA(t) = 1 √ N ∫ e−ik·rδn(r, t)dr = 1 √ N ˆn−k(t), (42b) δB(0) = 1 √ N ∫ eik·rδn(r, 0)dr = 1 √ N ˆnk(0). (42c) 15.6 The ﬂuctuation–dissipation theorem 625 Positive frequency changes ω > 0 represent scattering events that create quantum exci- tations in the material with energy ℏω and are referred to as Stokes scattering. Negative frequency changes are called anti-Stokes scattering and correspond to scattering events that destroy an excitation in the material with energy ℏω. Since an excitation must ﬁrst exist in order for it to be destroyed, the anti-Stokes scattering rate in equilibrium is lower relative to the Stokes scattering rate by the Boltzmann factor for the excitation: S(k, −ω) = e−βℏωS(k, ω). (43) This relation is sometimes used in Raman scattering to measure the temperature of the sample. The heights of Stokes and anti-Stokes peaks are symmetric if the excitation ener- gies are small compared to thermal energies, that is ℏω ≪ kT . The static structure factor S(k) in equation (10.7.18) is obtained by integrating S(k, ω) over all ω: S(k) = 1 2π ∞∫ −∞ S(k, ω)dω. (44) This singles out equal-time scattering events and corresponds to quasielastic scattering measurements that are unable to resolve the energy changes due to the excitations in the material. Three commonly measured types of inelastic laser scattering are: Raman scattering, Brillouin scattering, and Rayleigh scattering. Raman scattering measures electronic, vibra- tional, and rotational excitations of atoms and molecules, electronic band structure, and optical phonon modes. Brillouin scattering measures long-wavelength acoustic sound modes. The widths of Raman and Brillouin scattering peaks are determined by the life- times of their respective modes. Rayleigh scattering measures the heat diffusion mode centered at ω = 0 with width proportional to the thermal diffusivity. The wavelength of visible light is large compared to atomic scales, so the wavevector transfers possible with light scattering are very small compared to the size of the Brillouin zone. This limita- tion is removed for inelastic x-ray and neutron scattering where experiments can probe wavevectors away from the center of the Brillouin zone. The dynamical scattering of a laser beam from a liquid includes three peaks: a Rayleigh peak centered at ω = 0 due to scattering from the thermal ﬂuctuations in the liquid and the Stokes and anti-Stokes Brillouin peaks at ωk ≈ ± ck due to scattering from acoustic phonons with sound speed c. For scattering in this wavevector and frequency range, the dynamical structure factor is symmetric in ω since ℏω ≪ kT . An early Brillouin scatttering measurement of the dynamical structure factor of a liquid is shown in Figure 15.10. The ﬂuctuation–dissipation theorem enables one to develop a theory of the dynamical structure factor based on the hydrodynamic response of a system that is weakly perturbed from equilibrium. In the case of a ﬂuid, small perturbations in pressure and tempera- ture result in propagating sound waves and thermal diffusion. This results in the following 626 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics \u0002\u0003\u0004\u0005 0 FIGURE 15.10 Dynamical structure factor for carbon tetrachloride using 632.8 nm He-Ne laser with a 90◦ scattering angle. The structure factor is symmetric since ℏω ≪ kT . The Landau-Placzek ratio of the integrated intensity under the Rayleigh peak to the integrated intensities under the two Brillouin peaks is related to ratio of the constant- pressure heat capacity to the constant-volume heat capacity: IR/(2IB) = CP/CV − 1 = 0.72 ± 0.03, Landau and Placzek (1934). The locations of the Brillouin peaks give the sound speed and the widths of the peaks measure the thermal diffusivity and sound attenuation coefﬁcient of the liquid; see equation (45). From Cummins and Gammon (1966), reprinted with permission; copyright © 1966, American Institute of Physics. theoretical form for the dynamical structure factor: S(k, ω) = S(k) [( γ − 1 γ ) 2DT k2 ω2 + (DT k2)2 + 1 γ ( 0k2 (ω2 − c2k2)2 + (0k2)2 + 0k2 (ω2 + c2k2)2 + (0k2)2 )] . (45) The parameters in equation (45) are the thermal diffusivity DT , the sound speed c, and the sound attenuation coefﬁcient 0, while γ = CP/CV is the ratio of the constant-pressure and constant-volume heat capacities; see Forster (1975) and Hansen and McDonald (1986). 15.7 The Onsager relations Most physical phenomena exhibit a kind of symmetry, sometimes referred to as reci- procity, that arises from certain basic properties of the microscopic processes that operate behind the (observable) macroscopic situations. A notable example of this is met with in the thermodynamics of irreversible processes where one deals with a variety of ﬂow processes, such as heat ﬂow, electric current, mass transfer, and so on. These ﬂows (or “currents”) are driven by “forces,” such as a temperature difference, a potential difference, a pressure difference, and so on, which come into play because of a natural tendency 15.7 The Onsager relations 627 among physical systems which happen to be out of equilibrium to approach a state of equilibrium. If the given state of the system is not too far removed from a state of equilibrium, then one might assume a linear relationship between the forces Xi and the currents ˙xi: ˙xi = γijXj, (1) where γij are the kinetic coefﬁcients of the system.21 Simple examples of such coefﬁcients are thermal conductivity, electrical conductivity, diffusion coefﬁcient, and so on. There are, however, nondiagonal elements, γij(i ̸= j), as well that may or may not vanish; they are responsible for the so-called cross effects. It is the symmetry properties of the matrix (γij) that form the subject matter of this section. The most obvious way to approach this problem is to consider the entropy, S(xi), of the system in the disturbed state relative to its maximal value, S(˜xi), in the relevant state of equilibrium. It is the natural tendency of the function S(xi) to approach its maximal value S(˜xi) that brings into play the driving forces Xi; these forces give rise to currents ˙xi, which take the “coordinates” xi toward their equilibrium values ˜xi. If the deviations (xi − ˜xi) are small, then the function S(xi) may be expressed as a Taylor series around the values xi = ˜xi; retaining terms up to the second order only, we have S(xi) = S(˜xi) + ( ∂S ∂xi ) xi=˜xi (xi − ˜xi) + 1 2 ( ∂ 2S ∂xi∂xj ) xi, j=˜xi, j (xi − ˜xi)(xj − ˜xj). (2) In view of the fact that the function S(xi) is maximum at xi = ˜xi, its ﬁrst derivatives vanish; we may, therefore, write 1S ≡ S(xi) − S(˜xi) = − 1 2 βij(xi − ˜xi)(xj − ˜xj), (3) where βij = − ( ∂ 2S ∂xi∂xj ) xi, j=˜xi, j = β ji. (4) The driving forces Xi may be deﬁned in the spirit of the second law of thermodynamics, that is, Xi = ( ∂S ∂xi ) = −βij(xj − ˜xj). (5) 21In writing equation (1), and other subsequent equations, we follow the summation convention that implies an automatic summation over a repeated index. 628 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics We note that in the present approximation the forces Xi depend linearly on the dis- placements (xi − ˜xi); in the state of equilibrium, they vanish. Now, in view of equation (15.1.2), the ensemble average of the product xiXj is given by ⟨xiXj⟩ = ∫ ∞ −∞(xiXj) exp {− 1 2k βij(xi − ˜xi)(xj − ˜xj)} ∏ i dxi ∫ ∞ −∞ exp {− 1 2k βij(xi − ˜xj)(xj − ˜xj)} ∏ i dxi ; (6) the limits of integration in (6) have been extended to −∞ and +∞ because the integrals here do not draw any signiﬁcant contribution from large values of the variables involved. In the same way, ⟨xi⟩ = ∫ ∞ −∞ xi exp {− 1 2k βij(xi − ˜xi)(xj − ˜xj)} ∏ i dxi ∫ ∞ −∞ exp { − 1 2k βij(xi − ˜xi)(xj − ˜xj) } ∏ i dxi = ˜xi. (7) Differentiating (7) with respect to ˜xj (and remembering that the integral in the denomina- tor is a constant, independent of the actual values of the quantities ˜xi), and comparing the resulting expression with (6), we obtain the remarkable result ⟨xiXj⟩ = −kδij. (8) We now proceed toward the key point of the argument. First of all, we note that, though equations (1) are concerned with irreversible phenomena, the microscopic pro- cesses underlying these phenomena obey time reversal, which means that the temporal correlations of the relevant variables are the same whether measured forward or backward in time. Thus, ⟨xi(0)xj(s)⟩ = ⟨xi(0)xj(−s)⟩; (9) also, by a shift in the zero of time, ⟨xi(0)xj(−s)⟩ = ⟨xi(s)xj(0)⟩. (10) Combining (9) and (10), we get ⟨xi(0)xj(s)⟩ = ⟨xi(s)xj(0)⟩. (11) If we now subtract, from both sides of this equation, the quantity ⟨xi(0)xj(0)⟩, divide the resulting equation by s and let s → 0, we obtain ⟨xi(0)˙xj(0)⟩ = ⟨˙xi(0)xj(0)⟩. (12) 15.7 The Onsager relations 629 Substituting from (1) and making use of (8), we obtain on the left side of (12) ⟨xi(0)γ jlXl(0)⟩ = −kγ jlδil = −kγ ji and on its right side ⟨γilXl(0)xj(0)⟩ = −kγilδ jl = −kγij. It follows that γij = γ ji. (13) Equations (13) constitute the Onsager reciprocity relations; they were ﬁrst derived by Onsager in 1931 and have become an essential part of the thermodynamics of irreversible phenomena. In view of equations (1) and (13), the currents ˙xi may be written as ˙xi = ∂f ∂Xi , (14) where the generating function f is a quadratic function of the forces Xi: f = 1 2 γijXiXj. (15) The function f is especially important in that it determines directly the rate at which the entropy of the system changes with time: ˙S = ∂S ∂xi ˙xi = Xi ˙xi = Xi ∂f ∂Xi = 2f . (16) As the system approaches the state of equilibrium, its entropy must increase toward the equilibrium value S(˜xi). The function f must, therefore, be positive deﬁnite, which places certain restrictions on the coefﬁcients γij. Analogous to equation (1), we could also write ˙Xi = ζij(x j − ˜x j), (17) the quantities ζij being another set of coefﬁcients pertaining to the system. From equa- tions (1) and (5), on the other hand, we obtain ˙Xi = −βij ˙x j = −βij(γ jlXl) = −βijγ jl{−βlm(xm − ˜xm)} = βijγ jlβlm(xm − ˜xm). (18) Comparing (17) and (18), we obtain a relationship between the new coefﬁcients ζij and the kinetic coefﬁcients γij: ζim = βijγ jlβlm. (19) 630 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics Now, in view of the symmetry properties of the matrices β and γ , we get ζim = ζmi; (20) thus, the coefﬁcients ζij, introduced through the phenomenological equations (17), also obey the reciprocity relations. It then follows that the quantities ˙Xi, see equation (14), may be written as, ˙Xi = ∂f ′ ∂xi , (21) where f ′ = 1 2 ζij(xi − ˜xi)(x j − ˜x j). (22) The entropy change dS may now be written as dS = ∂S ∂x j dx j = X jdx j = −β ji(xi − ˜xi)dx j = (xi − ˜xi)d{−βij(x j − ˜x j)} = (xi − ˜xi)dXi, (23) so that ∂S ∂Xi = (xi − ˜xi); (24) clearly, the entropy S is now regarded as an explicit function of the forces Xi (rather than of the coordinates xi). The time derivative of S now takes the form ˙S = ∂S ∂Xi ˙Xi = (xi − ˜xi) ∂f ′ ∂xi = 2f ′. (25) Comparing (16) and (25), we conclude that the functions f and f ′ are, in fact, the same; they are only expressed in terms of two different sets of variables. It seems important to mention here that Onsager’s reciprocity relations have an inti- mate connection with the ﬂuctuation–dissipation theorem of the preceding section. Fol- lowing equations (15.6.18) and (15.6.19), and adopting the summation convention, we have in the present context ˙xi(t) = 1 kT t∫ −∞ El(t′)⟨˙xl(t′)˙xi(t)⟩dt′ (26) or, setting (t − t′) = s, ˙xi(t) = 1 kT ∞∫ 0 El(t − s)⟨˙xl(t − s)⟨˙xi(t)⟩ds; (27) 15.7 The Onsager relations 631 compare this to equation (1). Interchanging the indices i and l, we obtain ˙xl(t) = 1 kT ∞∫ 0 Ei(t − s)⟨˙xi(t − s)˙xl(t)⟩ds. (28) The crucial point now is that the correlation functions appearing in equations (27) and (28) are identical in value, for ⟨˙xl(t − s)˙xi(t)⟩ = ⟨˙xl(0)˙xi(s)⟩ = ⟨˙xl(0)˙xi(−s)⟩ = ⟨˙xl(t)˙xi(t − s)⟩; (29) in establishing (29), the ﬁrst and third steps followed from “a shift in time” while the sec- ond step followed from the “principle of dynamical reversibility of microscopic processes.” The equivalence depicted in equation (29) is, in essence, the content of Onsager’s reci- procity relations. In particular, if the correlation functions appearing in (27) and (28) are sharply peaked at the value s = 0, then these equations reduce to the phenomenological equations (1), and equation (29) becomes synonymous with the Onsager relations (13). In the end, we make some further remarks concerning relations (13). We recall that, in arriving at these relations, we had to make an appeal to the invariance of the microscopic processes under time reversal. The situation is somewhat different in the case of a “system in rotation” (or a “system in an external magnetic ﬁeld”), for then the invariance under time reversal holds only if there is also a simultaneous change of sign of the angular veloc- ity \u0000 (or of the magnetic ﬁeld B). The kinetic coefﬁcients, which in this case might depend on the parameter \u0000 (or B), will now satisfy the relations γij(\u0000) = γ ji(−\u0000) (13a) and γij(B) = γ ji(−B). (13b) In addition, our proof here rested on the implicit assumption that the quantities xi themselves do not change under time reversal. If, for some reason, these quantities are proportional to the velocities of a certain macroscopic motion, then they will also change their sign under time reversal. Now, if both xi and x j belong to this category, then equation (12), which is crucial to our proof, would remain unaltered; consequently, the coefﬁcients γij and γ ji would still be equal. However, if only one of them belongs to this category while the other one does not, then equation (12) would change to ⟨xi(0)˙xj(0)⟩ = −⟨˙xi(0)xj(0)⟩; (12′) the coefﬁcients γij and γ ji would then obey the relations γij = −γ ji. (13′) 632 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics For the application of Onsager’s relations to different physical problems, reference may be made to the monographs by de Groot (1951), de Groot and Mazur (1962), and Prigogine (1967). Problems 15.1. Making use of expressions (15.1.11) and (15.1.12) for 1S and 1P, and expressions (15.1.14) for (1T )2, (1V )2, and (1T 1V ), show that (a) (1T 1S) = kT ; (b) (1P1V ) = −kT ; (c) (1S1V ) = kT (∂V /∂T )P; (d) (1P1T ) = kT 2C−1 V (∂P/∂T )V . [Note that results (a) and (b) give: (1T 1S − 1P1V ) = 2kT , which follows directly from the probability distribution function (15.1.8).] 15.2. Establish the probability distribution (15.1.15), which leads to the expressions in (15.1.16) for (1S)2, (1P)2, and (1S1P). Show that these results can also be obtained by following the procedure of the preceding problem. 15.3. If we choose the quantities E and V as “independent” variables, then the probability distribution function (15.1.8) does not reduce to a form as simple as (15.1.13) or (15.1.15); it is marked instead by the presence, in the exponent, of a cross term proportional to the product 1E1V . Consequently, the variables E and V are not statistically independent : (1E1V ) ̸= 0. Show that (1E1V ) = kT {T ( ∂V ∂T ) P + P ( ∂V ∂P ) T } ; verify as well expressions (15.1.14) and (15.1.18) for (1V )2 and (1E)2. [Note that in the case of a two-dimensional normal distribution, namely p(x, y) ∝ exp {− 1 2 (ax2 + 2bxy + cy2) } , the quantities ⟨x2⟩, ⟨xy⟩, and ⟨y2⟩ can be obtained in a straightforward manner by carrying out a logarithmic differentiation of the formula ∞∫ −∞ ∞∫ −∞ exp {− 1 2 (ax2 + 2bxy + cy2} dx dy = 2π √ (ac − b2) with respect to the parameters a, b, and c. This leads to the covariance matrix of the distribution, namely ( ⟨x2⟩ ⟨xy⟩ ⟨yx⟩ ⟨y2⟩ ) = 1 (ac − b2) ( c −b −b a ) . If b = 0, then ⟨x2⟩ = 1/a, ⟨xy⟩ = 0, ⟨y2⟩ = 1/c.]22 15.4. A string of length l is stretched, under a constant tension F, between two ﬁxed points A and B. Show that the mean square (ﬂuctuational) displacement y(x) at point P, distant x from A, is given by {y(x)}2 = kT Fl x(l − x). 22For the covariance matrix of an n-dimensional normal distribution, see Landau and Lifshitz (1958), Section 110. Problems 633 Further show that, for x2 ≥ x1, y(x1)y(x2) = kT Fl x1(l − x2). [Hint : Calculate the energy, 8, associated with the ﬂuctuation in question; the desired probability distribution is then given by p ∝ exp(−8/kT ), from which the required averages can be readily evaluated.] 15.5. How small must the volume, VA, of a gaseous subsystem (at normal temperature and pressure) be, so that the root-mean-square deviation in the number, NA, of particles occupying this volume be 1 percent of the mean value NA? 15.6. Pospiˇsil (1927) observed the Brownian motion of soot particles, of radii 0.4 × 10−4 cm, immersed in a water–glycerine solution, of viscosity 0.0278 poise at a temperature of 18.8◦C. The observed value of x2, in a 10-second time interval, was 3.3 × 10−8cm2. Making use of these data, determine the Boltzmann constant k. 15.7. In the notation of Section 15.3, show that for a Brownian particle ⟨v(t) · F(t)⟩ = 3kT /τ , while ⟨v(t) · F (t)⟩ = 0. On the other hand, ⟨r(t) · F (t)⟩ = −3kT , while ⟨r(t) · F(t)⟩ = 0. 15.8. Integrate equation (15.3.14) to obtain r(t) = v(0)τ (1 − e−t/τ ) + τ t∫ 0 {1 − e(u−t)/τ }A(u)du, so that r(0) = 0. Taking the square of this expression and making use of the autocorrelation function KA(s), derive formula (15.3.31) for ⟨r2(t)⟩. 15.9. While detecting a very feeble current with the help of a moving-coil galvanometer, one must ensure that an observed deﬂection is not just a stray kick arising from the Brownian motion of the suspended system. If we agree that a deﬂection θ, whose magnitude exceeds 4θr.m.s.[= 4(kT /c)1/2], is highly unlikely to be due to the Brownian motion, we obtain a lower limit to the magnitude of the current that can be reliably recorded with the help of the given galvanometer. Express this limiting current in terms of the time period τ and the critical damping resistance Rc of the galvanometer. 15.10. (a) Integrate Langevin’s equation (15.3.5) for the velocity component vx over a small interval of time δt, and show that ⟨δvx⟩ δt = − vx τ and ⟨(δvx)2⟩ δt = 2kT Mτ . (b) Now, set up the Fokker–Planck equation for the distribution function f (vx, t) and, making use of the foregoing results for µ1(vx) and µ2(vx), derive an explicit expression for this function. Study the various cases of interest, especially the one for which t ≫ τ . 15.11. Generalize the analysis of the Langevin theory of a harmonic oscillator, as given by equation (15.3.33), to the case of an oscillator starting at time t = 0 with the initial position x(0) and the initial velocity v(0). Derive, for this system, the quantities ⟨x2(t)⟩ and ⟨v2(t)⟩ and show that, in the limit ω0 → 0, these expressions reproduce equations (15.3.29) and (15.3.31) while, in the limit M → 0, they lead to the relevant results of Section 15.4. 15.12. Generalize the Fokker–Planck equation to the case of a particle executing Brownian motion in three dimensions. Determine the general solution of this equation and study its important features. 15.13. The autocorrelation function K (s) of a certain statistically stationary variable y(t) is given by (a) K (s) = K (0)e−αs2 cos(2π f ∗s) or by (b) K (s) = K (0)e−α|s| cos(2π f ∗s), 634 Chapter 15. Fluctuations and Nonequilibrium Statistical Mechanics where α > 0. Determine, and discuss the nature of, the power spectrum w( f ) in each of these cases and investigate its behavior in the limits (a) α → 0, (b) f ∗ → 0, and (c) both α and f ∗ → 0. 15.14. Show that if the autocorrelation function K (s) of a certain statistically stationary variable y(t) is given by K (s) = K (0) sin(as) as sin(bs) bs (a > b > 0), then the power spectrum w( f ) of that variable is given by w( f ) = 2π a K (0) for 0 < f ≤ a − b 2π , 2π ab K (0) { a + b 2 − πf } for a − b 2π ≤ f ≤ a + b 2π , 0 for a + b 2π ≤ f < ∞. Verify that the function w( f ) satisﬁes the requirement (15.5.16). [Note that, in the limit b → 0, we recover the situation pertaining to equations (15.5.18).] 15.15. (a) Show that the mean square value of the variable Y (t), deﬁned by the formula Y (t) = u+t∫ u y(u)du, where y(u) is a statistically stationary variable with power spectrum w( f ), is given by ⟨Y 2(t)⟩ = 1 2π 2 ∞∫ 0 w( f ) f 2 {1 − cos(2πft)} df ; and, accordingly, w( f ) = 4πf ∞∫ 0 ∂ ∂t ⟨Y 2(t)⟩ sin(2π ft)dt = 2 ∞∫ 0 ∂ 2 ∂t2 ⟨Y 2(t)⟩ cos(2πft)dt. For details, see MacDonald (1962), Section 2.2.1. A comparison of the last result with equation (15.5.14) suggests that Ky(s) = 1 2 ∂ 2 ∂s2 ⟨Y 2(s)⟩. (b) Apply the foregoing analysis to the motion of a Brownian particle, taking y to be the velocity of the particle and Y its displacement. 15.16. Show that the power spectra wv( f ) and wA( f ) of the ﬂuctuating variables v(t) and A(t) that appear in the Langevin equation (15.3.5) are connected by the relation wv( f ) = wA( f ) τ 2 1 + (2π f τ )2 , τ being the relaxation time of the problem. Hence, by equation (15.5.21) wA( f ) = 12kT /Mτ . Problems 635 15.17. (a) Verify equations (15.6.7) through (15.6.9). (b) Substituting expression (15.6.9) for K v(s) into equation (15.6.6), derive formula (15.3.31) for ⟨r2(t)⟩. 15.18. Determine ˆχ ′′ vx(ω) and Svx(ω) for a Brownian particle in a harmonic oscillator potential. Show that the response function and the power spectrum for this case are related by the classical limit of the ﬂuctuation–dissipation theorem. 15.19. Derive the linear response density matrix (15.6.29) from the equation of motion (15.6.28). 15.20. Show that GAB(t) = GBA(t − iβℏ) and use the cyclic property of the traces to derive the ﬂuctuation–dissipation theorem ˆχ ′′ AB(ω) = 1 2ℏ (1 − e−βℏω) SAB(ω). 15.21. Show that GAB(t) = GBA(t − iβℏ). Use this result to show that, in the classical limit, ˆχ ′′ AB(t) becomes 〈 dA(t) dt B(0)〉. Further show that this leads to equation (15.6.39). 15.22. Determine the self-diffusion term in the dynamical structure factor Sself(k, ω) in equation (15.6.41b) for the case of a single particle that diffuses according to the diffusion equation. Assume the process to be Gaussian for which ⟨e f ⟩ = exp ( ⟨f 2/2⟩ ). 15.23. Determine the angular frequency ωk for the Brillouin peaks in water for 90◦ laser scattering, using a He-Ne laser with λ = 632.8 nm. Determine the width of the Rayleigh peak and show that the Brillouin peaks are well-separated from the Rayleigh peak. The thermal diffusivity of water is DT = 1.4 × 10−7 m2/s. 15.24. Describe the dynamical structure factor for Raman scattering for a He-Ne laser with λ = 632.8 nm. The energy level responsible for this scattering has an energy of 0.05 eV and the lifetime of this state is 1 picosecond. Are the Stokes/anti-Stokes scatterings symmetric as ω → −ω at room temperature? 16 Computer Simulations Computer simulations play an important role in modern statistical mechanics. The history of the use of computer simulations in science parallels the history of early digital comput- ing. The people and places involved centered around Los Alamos and other U.S. national laboratories where the ﬁrst digital computers became available for use by scientists after World War II. Early leaders in the development of computer simulation methods included Fermi, Ulam, von Neumann, Teller, Metropolis, Rosenbluth, and others who were also involved in the Manhattan Project (Metropolis, 1987). Computer simulations in statistical mechanics fall into two broad classes: Monte Carlo (MC) and molecular dynamics (MD), although variants span the range between the two. Both methods involve numerically evolving simple models of materials through a set of microstates in order to determine the thermodynamic averages of measurable quantities. Computer simulations provide a means to study physical systems that is complementary to both experiment and theory. The following are a few of the advantages of computer simulations: . Computer simulations can provide insight into the equilibrium and nonequilibrium behavior of model systems for ranges of parameters where theoretical approximations are invalid or untested.. Computer simulations provide a means to test the range of validity of theoretical approximations against speciﬁc model systems.. Computer simulations allow visualization of physical processes that can provide new insights into complex phenomena.. Computer simulations allow detailed examination of behaviors that might not be accessible experimentally.. Computer simulations can be used to examine fundamental physical processes that can be used to guide theory.. Computer simulations can be used to model systems that do not exist in nature to provide assistance in understanding existing materials and engineering new ones. 16.1 Introduction and statistics While certain critical aspects of computer simulation theory should be followed rigorously, much of computer simulation development and use is an art form. There are many possi- ble simulation approaches for any given problem and some choices will be more effective Statistical Mechanics. DOI: 10.1016/B978-0-12-382188-1.00016-5 © 2011 Elsevier Ltd. All rights reserved. 637 638 Chapter 16. Computer Simulations at elucidating important physical properties than others. This brief chapter concentrates on equilibrium simulations but computer simulations are also widely used to model dynamical and nonequilibrium processes. The task of determining equilibrium thermody- namic averages of model systems is accomplished by generating a sequence of microstates that are chosen from the equilibrium ensemble of the model. For example, an MD simula- tion might be used to integrate Newton’s equations of motion for generating a time-series of states in phase space as the system explores the constant-energy hypersurface of the Hamiltonian. By comparison, an MC simulation of the same model might generate a sequence of states chosen by a random walk among the conﬁgurational microstates of the canonical ensemble. Both methods are examples of importance sampling, which focuses computational effort on generating microstates that are representative of the equilibrium ensemble rather than sampling all of the phase space. It is this huge improvement in efﬁ- ciency that makes computer simulations of statistical mechanical models feasible. The sequence of states produced by either method can be used to estimate equilibrium aver- ages. Allen and Tildesley (1990), Binder and Heermann (2002), Frenkel and Smit (2002), and Landau and Binder (2009) provide more detailed discussions of computer simulations and their applications in statistical physics. Let q represent a microstate of the system and A(q) a thermodynamic observable that is a function of the microstate. In an MC simulation, q might represent the positions of all the particles in the system while in an MD simulation q might represent the posi- tions and momenta of all the particles. The observable A(q) might represent the potential energy, virial contribution to the pressure, pair correlation function, and so on. The initial microstate chosen to start a simulation will generally not be typical of the set of microstates that make up the equilibrium ensemble, but the goal of a simulation is to evolve the microstate through a large enough subset of the microstates of the equilibrium ensemble so that averages of observables approach their equilibrium values. After a simulation has run long enough for the system to approach equilibrium, the simulation then generates a sequence of M conﬁgurations, {qj}M j=1, chosen from the set of microstates in the equilib- rium ensemble and stores a sequence of values, {A(qj)}M j=1, for each of the thermodynamic variables one wants to measure. 1 Since the microstates are chosen from the equilibrium ensemble, the equilibrium average of A is approximated by a simple average of the set of values {A(qj)}M j=1. Of course, a simulation can only provide a ﬁnite sequence of states, so a statistical analysis of the uncertainty of the results is a crucial part of any simulation. The equilibrium average of the variable A is given by ⟨A⟩ = ⟨A⟩M ± σM (1) 1Alternatively, one can store the full conﬁguration set of statistically independent microstates for later analysis. This tactic requires a large amount of storage space but is useful if there is a large computational cost of generating statistically independent conﬁgurations and one needs to calculate averages of many different observables at a later time using the stored conﬁgurations. This is sometimes done in large-scale lattice quantum chromodynamics simulations. 16.1 Introduction and statistics 639 where the simulation average ⟨A⟩M and uncertainty σM are determined by ⟨A⟩M = 1 M M∑ j=1 A(qj), (2a) σM = √〈 A2〉 M − ⟨A⟩2 M √M/(2τ + 1) , (2b) 〈 A 2〉 M − ⟨A⟩2 M = 1 M M∑ j=1 [A(qj) − ⟨A⟩M ]2. (2c) The “correlation time” τ is deﬁned as follows. Since the states qj are generated sequentially by the simulation, each new state qj+1 is guaranteed to be close to the previous state qj, so the values A(qj) in the sequence are highly correlated. The correlations in the values of A(qj) decrease with the “correlation time” τ which can be calculated from the correlation function φAA(t), namely φAA(t) = ⟨A(t)A(0)⟩ − ⟨A(t)⟩ ⟨A(0)⟩ 〈 A2〉 − ⟨A⟩2 , (3a) τ = ∑ t>0 φAA(t). (3b) The variable t is a measure of the separation between pairs of conﬁgurations in the ordered sequence. In the case of molecular dynamics simulations, τ represents a physical time for the system to move far enough along its trajectory on the energy surface to result in decorrelated values of A. Monte Carlo simulations explore equilibrium microstates in a random walk, so τ does not correspond to physical time but rather the average number of Monte Carlo sweeps needed to give statistically independent values for A. The quan- tity M/(2τ + 1) represents the number of statistically independent conﬁgurations in the sequence of M values. 2 2The correlations φAA(t) in equation (16.1.3a) can be measured using subsequences of the M conﬁgurations: ⟨A(t)A(0)⟩ ≈ 1 M ′ M ′ ∑ j=1 A(qj+t )A(qj), and ⟨A(t)⟩ ≈ 1 M ′ M ′ ∑ j=1 A(qj+t ). By deﬁnition, the correlation function φAA(0) is unity and the correlations decay to zero as t → ∞. Once one can place a reliable upper bound on the size of the correlation time τ for a given system from a knowledge of its equilibrium correlations, one can simply skip more than τ conﬁgurations between storing values of A(qj) to ensure that the numbers in the sequence are now approximately statistically independent. 640 Chapter 16. Computer Simulations 16.2 Monte Carlo simulations The term Monte Carlo method, named for the gambling casinos in Monaco, was coined by Nicholas Metropolis (1987) – “a suggestion not unrelated to the fact that Stan [Ulam] had an uncle who would borrow money from relatives because he ‘just had to go to Monte Carlo’.” The goal of a Monte Carlo simulation in equilibrium statistical mechanics is to use pseudorandom numbers to draw a representative sample of microstates {q} from the equilibrium probability distribution Peq(q) = exp (−βE(q) ) ∑q′ exp[−βE(q′)] . (1) This means that “instead of choosing conﬁgurations randomly, then weighting them with exp(−E/kT ), we choose conﬁgurations with a probability exp(−E/kT ) and weight them evenly” (Metropolis et al., 1953). If a simulation can accomplish this, then thermodynamic averages can be calculated using the simple averages in equation (16.1.2). This importance sampling of the states provides a huge computational advantage over normal random sampling. The following algorithm accomplishes the goal of randomly selecting microstates q from the set of all microstates with a probability distribution that approaches the equilib- rium distribution (1) (Metropolis et al., 1953; Kalos and Whitlock, 1986; Allen and Tildesley, 1990; Frenkel and Smit, 2002; Binder and Heermann, 2002; Landau and Binder, 2009). Con- sider an ensemble of microstates that has some initial distribution of probabilities P(q, 0) and let the distribution evolve according to the discrete stochastic rate equation P(q, t + 1) = P(q, t) + ∑ q′ P(q′, t)W (q′ → q) − P(q, t) ∑ q′ W (q → q′), (2) where W (q → q′) is the transition rate from state q to state q′. If the transition rate obeys the balance condition ∑ q′ Peq(q′)W (q′ → q) = Peq(q) ∑ q′ W (q → q′), (3) and the random process in equation (2) can reach every microstate from every other microstate in a ﬁnite number of steps, then the ensemble probability will approach the equilibrium distribution: lim t→∞ P(q, t) = Peq(q). (4) In practice, equation (3) is usually implemented using the detailed balance condition Peq(q)W (q → q′) = Peq(q′)W (q′ → q). (5) Evaluating Peq(q) requires summing over all states to determine the partition function, but the ratio Peq(q′)/Peq(q) depends only on the energy difference 1E = E(q′) − E(q). 16.2 Monte Carlo simulations 641 Therefore, the transition rates are related by W (q → q′) = exp(−β1E) W (q′ → q). (6) This guarantees that the sequence of states generated by this stochastic process, begin- ning from any starting conﬁguration, asymptotically becomes equivalent to selecting states by a random walk among the microstates of the equilibrium ensemble. This can be implemented in a computer code, as ﬁrst proposed by Metropolis et al. (1953), using the transition rates W (q → q′) = 1 if 1E ≤ 0, W (q → q′) = exp(−β1E) if 1E > 0. (7) Other choices for the transition rates are possible but this form, named after Metropolis, is one of the most commonly used. 16.2.A Metropolis Monte Carlo algorithm The Metropolis method can be implemented in a computer program by using a pseudo- random number generator rand() that returns pseudorandom numbers that are uniformly distributed on the open unit interval (0.0,1.0); see Appendix I for a discussion of how pseudorandom numbers are generated. First, initialize the system by choosing a starting state q0 from the set of all microstates of the model. It is helpful if q0 is not atypical of the states in the equilibrium ensemble. This reduces the number of steps needed for the system to equilibrate. For example, a disordered liquid-like state would not be the best starting point for a simulation of a crystalline solid. The Metropolis algorithm is deﬁned by the following steps: 1. Generate a random trial state qtrial that is “nearby” the current state qj of the system. “Nearby” here means that the trial state should be almost identical to the current state except for a small random change made, usually, to a single particle or spin. For example, one can create a trial state of a particle simulation by randomly moving one particle to a nearby location xtrial i = xi + 1x(rand() − 0.5), (8) with two more calls to rand( ) to generate ytrial i and ztrial i . The trial state of a spin system usually involves a spin ﬂip or a random rotation of a single spin.3 3There are Monte Carlo algorithms for spin systems that ﬂip spins in large correlated clusters rather than one spin at a time; see Swendsen and Wang (1987) and Wolff (1989). These methods are very effective for simulations of some particu- lar models. Also, one can attempt spin ﬂips of all the spins on noninteracting sublattices at one time since the acceptance of each ﬂip is independent of the other ﬂipped spins. For example, a chessboard pattern update of a spin model in which spins only interact with nearest neighbors of a square lattice can be more efﬁcient for some computer architectures or programming environments. 642 Chapter 16. Computer Simulations 2. Determine the change in the energy of the trial state compared to the previous state, namely 1E = E(qtrial) − E(qj). If 1E ≤ 0, accept the trial state, that is, set qj+1 = qtrial. If 1E > 0, then accept the trial state with probability exp(−β1E). This is accomplished by using an additional call to the pseudorandom number generator. If rand() < exp(−β1E), then accept the trial state. If the interactions are short-ranged, the calculation of the energy change will only involve interactions with a few nearby particles or spins. If the trial state is illegal in some way, that is, it is not an allowed state in the set of all conﬁgurations, then the state should be rejected. This is equivalent to setting the energy change at +∞. If the trial state is rejected for either reason, then set the new state of the system equal to the previous state qj+1 = qj, that is, leave the state at the old value qj, throw away the trial state, and move on. 3. Perform steps 1 and 2 once for each particle or spin in the system. This is often done randomly to ensure detailed balance.4 Steps 1 through 3 deﬁne one Monte Carlo sweep. 4. Repeat steps 1 through 3 for Meq Monte Carlo sweeps to let the system equilibrate. The proper choice of Meq is not obvious a priori. At the very least, all the measures A(q) studied in the simulation should no longer have any obvious monotonic drift by the end of equilibration. This does not guarantee that the system has reached equilibrium since the system could well be trapped in the vicinity of a long-lived metastable state. 5. Repeat steps 1 through 3 for M Monte Carlo sweeps while keeping track of all the thermodynamic variables one wants to measure, namely {A(qj)}M j=1. Use equations (16.1.1) and (16.1.2) to determine the equilibrium averages and uncertainties. To determine averages at a different set of parameters (temperature, density, etc.), change the parameters by a small amount and repeat steps 1 through 5, including the equilibration step 4.5 Using the last conﬁguration of the previous run as the ﬁrst conﬁguration of the next run can often reduce the equilibration time. Figure 16.1 shows a Monte Carlo calculation of the speciﬁc heat of the two-dimensional Ising model on a 128 × 128 square lattice, as compared to the exact solution presented in Section 13.4.A. 4Sequential and other update methods that violate detailed balance are sometimes used for efﬁciency but special care should be taken to ensure that detailed balance is maintained on average. 5Histogram reweighting methods can sometimes be used to reduce the number of temperatures and ﬁelds that need to be simulated (Ferrenberg and Swendsen, 1988). For example, if a spin simulation at coupling K and ﬁeld h collects a histogram that samples the joint energy-magnetization distribution PK ,h(E, M), the distribution at nearby temperatures and ﬁelds is given by PK +1K ,h+1h(E, M) = PK ,h(E, M)e1K E+1h M ∑E,M PK ,h(E, M)e1K E+1h M . Other methods that are now widely used are: parallel tempering, multicanonical Monte Carlo, and “broad histogram” methods. These are particularly effective for studying systems with strongly ﬁrst-order phase transitions. Monte Carlo renormalization group methods are very powerful for studying critical points. For a survey, see Landau and Binder (2009). 16.3 Molecular dynamics 643 3 2 1 001 2 3 4 5C/Nk kT /J FIGURE 16.1 Monte Carlo speciﬁc heat (×’s) of the two-dimensional Ising model on a 128 × 128 lattice, as compared to the exact solution (solid line) from Section 13.4.A; see Kaufman (1948), Ferdinand and Fisher (1967), and Beale (1996). The MC error bars are smaller than the symbols used, except near the bulk critical temperature Tc(∞). Each data point represents an average using 105 Monte Carlo sweeps, except at the bulk critical point where 106 Monte Carlo sweeps were used to mitigate critical slowing down. 16.3 Molecular dynamics The purpose of a molecular dynamics simulation is to integrate Newton’s equations of motion for the set of particles in the given system. One advantage of MD over MC is that it approximates the time evolution of the equations of motion of the system, so MD can be used to study a host of dynamical properties. MD is usually more efﬁcient at simulat- ing systems with long-range interactions since all the particles are updated together. MD is sometimes easier to implement than MC for complex systems since appropriate MC moves are sometimes difﬁcult to derive. There are MD variants that allow simulations of other ensembles, but the simplest case simulates a microcanonical ensemble in which the microstate of the given system explores its energy surface in the phase space; see Allen and Tildesley (1990) and Frenkel and Smit (2002) for details. The equations of motion here are d2ri dt2 = 1 mi F i = − 1 mi ∇iU (r1, r2, .., rN ) , (1) where F i is the force on particle i arising from the N-particle potential energy function U. The MD simulation moves the system forward in time by discrete steps 1t. The most 644 Chapter 16. Computer Simulations commonly used integration method in this context is due to Verlet (1967): ri(t + 1t) = 2ri(t) − ri(t − 1t) + (1t)2 mi F i(t). (2) This is equivalent to the leap-frog and velocity Verlet algorithms that update both positions and velocities of the particles; see Frenkel and Smit (2002). The Verlet method preserves the time-reversal symmetry of the Hamiltonian equations of motion and has an error per step of order (1t)4, while only requiring a single determination of the force on each particle, which is usually the most computationally time-consuming part of the simulation. Most importantly, the Verlet algorithm is symplectic, so the integration is equivalent to an exact solution of a “nearby” ghost Hamiltonian, which results in good long-term stability and good conservation of energy properties. A simulation starts the system in some initial microstate with deﬁned positions and velocities of all the particles, and the integration algorithm steps the positions and veloc- ities of the particles forward in time. The simplest forms of the approximations employed for the velocities and the energy are vi(t) = ri(t + 1t) − ri(t − 1t) 21t , (3a) E = N∑ i=1 mi 2 ( ri(t + 1t) − ri(t − 1t) 21t )2 + U[r1(t), r2(t), .., rN (t)]. (3b) The time-step 1t is chosen to be small as compared to the shortest fundamental time scale in the Hamiltonian, while not so small as to limit the efﬁciency of the program. The numer- ical integration approximates a member of the microcanonical ensemble moving along the constant-energy hypersurface in the phase space. Calculating equilibrium averages properly depends on the Hamiltonian being ergodic; 6 this allows the system to sample all regions of the constant-energy hypersurface, so the MD time-averages are equivalent to averages over the microcanonical ensemble. If the total energy drifts more than some predetermined amount during the course of the simulation, then all the velocities can be rescaled to shift the total energy back to its initial value. Alternatively, one can use a thermostat to maintain the temperature at a desired value; see Frenkel and Smit (2002). 6Since an MD simulation creates a time evolution of the model system, one needs some assurance that the sys- tem is ergodic, that is, the time averages and the ensemble averages are the same. For example, a system of harmonic oscillators is not ergodic. A system of N particles in d dimensions has a 6N-dimensional phase space, so the constant- energy hypersurface has 6N − 1 dimensions. The normal mode solution for N coupled oscillators has 3N constants of the motion, so the system explores only a 3N-dimensional hypersurface. Even making the couplings between particles anharmonic does not eliminate the problem as ﬁrst shown by Fermi, Pasta, and Ulam (1955) and explored theoretically by Kolmogorov (1954), Arnold (1963), and Moser (1962). MD simulations of equilibrium systems presume that the sys- tem is ergodic. There are only a few systems that are provably ergodic but, fortunately, most systems with realistic pair potentials appear to behave ergodically in two or more dimensions. In view of this, MD simulations of one-dimensional systems should be treated as suspect from this perspective. 16.3 Molecular dynamics 645 A commonly used pair interaction for monatomic ﬂuids such as neon and argon is the Lennard-Jones interaction u(r) = 4ε (( D r )12 − ( D r )6) , (4) where D is the molecular diameter and ε is the depth of the attractive well. The Lennard- Jones potential is attractive at long distances, and decays as 1/r6 to model the van der Waals attraction; at short distances, it diverges as 1/r12 to model the Pauli repulsion that prevents overlap of the electronic wavefunctions. Simulations are best carried out using dimensionless parameters. In the case of a ﬂuid with Lennard-Jones interactions, all lengths can be measured in units of D, all energies (including kT ) in units of ε, all forces in units of ε/D, all pressures in units of ε/D3, all times in units of √mD2/ε, and so on. Simu- lations then need to be conducted only for single values of reduced temperature kT /ε, the reduced density nD3, and so on, while measuring observables in reduced units. Compar- isons between simulations and experimental results can then be made using experimental values of D, m, and ε. 7 In dimensionless units, the Lennard-Jones force between a pair of particles is F = ± r r2 ( 48 r12 − 24 r6 ) . (5) Newton’s third law of motion can be used to reduce the number of force calculations by a factor of two. The Lennard-Jones model was ﬁrst studied in an MC simulation by Wood and Parker (1957) and in an MD simulation by Rahman (1964) and Verlet (1967). 16.3.A Molecular dynamics algorithm First, start the system by choosing an initial state by setting the initial positions and veloc- ities of all the particles. The initial velocities are usually set by choosing each component of the velocity vector of each particle from the Maxwell distribution. In reduced units, this is PMaxwell(vx(0)) = 1 √ 2π T exp ( − v2 x(0) 2T ) ; (6) 7For example, the Lennard-Jones parameters appropriate for argon are ε/k = 119.8 K and D = 0.3405 nm (Levelt, 1960; Rowley, Nicholson, and Parsonage, 1975). Interaction potentials are almost always cut off at a ﬁnite distance between molecules to reduce the number of interactions that need to be considered at each time step. For the Lennard-Jones interaction, this is most commonly done at rmax = 2.5D. If the potential is set to zero for distances greater than rmax, then this would leave a small discontinuity in the potential. To eliminate this, the potential is often shifted upward by −u(2.5D) ≃ 0.0163ε, so that the potential is zero at rmax. This allows a direct comparison between MC and MD simula- tions. If the shift is not made in the potential, one could not directly compare the results from MC and MD simulations because the discontinuity in the potential would result in a delta-function force that affects the motion in the MD sim- ulation but not the conﬁgurations in the MC simulation. Comparisons of MC and MD results with experiments need to include perturbations from the shift and the missing tails of the pair potentials. 646 Chapter 16. Computer Simulations see Appendix I to see how to use a uniform pseudorandom number generator to select from a Gaussian distribution. The initial velocities can then be used to set the positions of the particles after the ﬁrst time-step, namely ri(1t) = ri(0) + vi(0)1t + 1 2 (1t)2 mi F i(0). (7) 1. Next, use equation (2) to move the system forward in time through Meq = τeq/1t time steps. The equilibration time τeq must be chosen large enough for the system to equilibrate; see the Monte Carlo discussion in Section 16.2. A thermostat is often used to evolve the system to a state with the desired temperature; see Frenkel and Smit (2002). 2. Now, use equation (2) to move the system forward in time through M = τavg/1t time steps while keeping track of all the thermodynamic variables {A(qj)} one wants to measure. Finally, use equation (16.1.2) to determine the equilibrium averages and uncertainties. To determine averages at a different set of parameters (temperature, density, etc.), change the parameters by a small amount and repeat steps 1 and 2. Using the last conﬁgura- tion of the previous run as the ﬁrst conﬁguration of the new run can often reduce the equilibration time. 16.4 Particle simulations Fluids can be modeled by both MC and MD simulations by placing N particles in a periodic box with volume V interacting via a pair potential. Hansen and McDonald (1986), Allen and Tildesley (1990), and Frenkel and Smit (2002) provide excellent surveys of this topic. Calculating energy changes of trial moves in MC or forces in MD only involves pairs of particles whose closest periodic copies are within the cutoff distance of each other. MC simulations typically sample the canonical ensemble, 8 so they control the temperature and density, and measure the energy, pressure, and so on. MD simulations typically sample the microcanonical ensemble, 9 so they control the energy and density, and they measure the temperature, pressure, and so on. The equipartition theorem gives for the temperature 8Monte Carlo simulations of isobaric or grand canonical ensembles are also widely used by adding PV or µN terms to the Hamiltonian (Frenkel and Smit, 2002). 9Molecular dynamics simulations of other ensembles are possible. For example, one can include extra dynamical variables that allow the total energy or volume to ﬂuctuate in order to approximate a canonical or isobaric ensemble; see Frenkel and Smit (2002). Variants of MC and MD simulations that span the range between the two include hybrid Monte Carlo methods that mix MC and MD methods into one code to take advantage of the strengths of both methods. Alternatively, one can include Langevin random force terms and damping in an MD simulation to create coupling to a heat bath. 16.4 Particle simulations 647 T in a d-dimensional system kT = 1 Nd 〈 N∑ i=1 miv2 i 〉 . (1) The virial equation of state in equations (3.7.15) and (10.7.11) can be used to determine the pressure P in either type of simulation: P nkT = 1 + 1 NdkT 〈∑ i<j F(rij) · rij 〉 = 1 − n 2dkT ∫ du dr rg(r)dr. (2) As discussed in Section 10.7, the pair correlation function of a ﬂuid can be used to measure a variety of thermodynamic properties including the pressure, the isothermal compress- ibility κT , and the scattering structure factor S(k); see equations (10.7.18) through (10.7.21). The pair correlation function g(r) deﬁned in equation (10.7.5) can be determined by col- lecting a histogram of the distances between all pairs of particles periodically during the simulation, accounting for the periodic boundary conditions, and scaling the histogram by an amount proportional to the volume of shells of radius r and thickness 1r. In three dimensions, the pair correlation function is given by g(r) = 2V N 2 ( 4π 3 ) [(r + 1r)3 − r3] 〈 N∑ i<j 11r(rij − r) 〉 , (3) where the step function 11r(ξ ) is unity for 0 < ξ < 1r and zero otherwise. This expression is the ratio of the number of events in each bin in the histogram compared to the average number that would be expected for an ideal gas with the same density. 16.4.A Simulations of hard spheres The system of hard spheres has been studied extensively in both MC and MD simulations, and was the ﬁrst model studied using either method (Metropolis et al., 1953; Adler and Wainwright, 1957, 1959). The pair potential for hard spheres is u(r) = {0 for r > D, ∞ for r ≤ D. (4) Temperature is an irrelevant parameter for the spatial conﬁgurations sampled by this model since the pair potential does not have a ﬁnite energy scale. A full exploration of the phase diagram involves only varying the reduced number density nDd. All thermody- namic properties are either independent of temperature, or scale with temperature in a trivial way. For example, the scaled pressure for a system of hard spheres P/nkT is a func- tion only of the reduced number density nDd. The hard sphere density is often expressed in 648 Chapter 16. Computer Simulations terms of the packing fraction η, the fraction of the volume of the system actually occupied by the spheres. In three dimensions, the volume fraction is given by η = πnD3/6. Since the pair potential is singular, the pressure cannot be calculated using the virial equation (2) but the pressure can be determined using the virial equation of state for hard spheres, namely (10.7.12). An MC code for hard spheres is relatively simple since the energy change in a trial move is either zero or inﬁnity. A trial displacement of a particle is rejected if the trial position of the particle is within a distance D of any other particle, and is accepted otherwise. This was the ﬁrst statistical physics model ever studied in a computer simulation (Metropolis et al., 1953). Implementing MD for hard spheres requires a different approach from the standard MD. Finite-difference integration methods will not work here since the potential is not differentiable. Instead, one can exploit the exact solution to the equations of motion. Each particle travels in a straight line at a constant velocity except at the instants when pairs of particles collide, that is when they are a distance D apart. Due to the singular nature of the potential, the collisions can be uniquely time-ordered. Each collision conserves both kinetic energy and momentum, so the velocities after each collision can be determined analytically from the velocities and the displacement vector between the centers of the two particles at the moment of the collision. The changes in the velocities of the two colliding particles are 1vi = − 1vj = −( rij · vij) rij D2 ∣ ∣ ∣ ∣ ∣ |rij|=D , (5) where ri j and vi j are, respectively, the relative positions and relative velocities of the two particles. The simulation moves the particles forward in time from collision to collision and changes the velocities of the pairs of particles involved in the collisions, as given by equation (5). This was the ﬁrst implementation of the MD method in statistical physics (Alder and Wainwright 1957, 1959). The pair correlation function and the structure factor in the ﬂuid phase are shown in Figure 16.2 and the phase diagram for hard spheres in Figure 16.3. At low densities, the equilibrium phase is a short-range ordered ﬂuid. At high densities, the equilibrium phase of the model is a long-range ordered, face-centered cubic solid. It is worthwhile to note that an attractive interaction is not required for a model to have a crystalline phase. An attractive interaction is, however, required for the formation of a liquid–vapor coexistence line and a critical point. For this reason, the low-density phase of the hard sphere model is often referred to as a ﬂuid phase rather than a liquid phase since the model does not have a liquid–vapor coexistence line. The liquid and solid volume fractions at the liquid–solid coexistence line are ηl ≃ 0.491 ± 0.002 and ηs ≃ 0.543 ± 0.002, respectively. The liquid–solid coexistence pressure is given by P∗ ls = PlsD3/kT ≃ 11.55 ± 0.11; see Speedy (1997). In the low-density ﬂuid phase for η < ηl, the reduced pressure is accurately modeled by the Carnahan–Starling equation of state (10.3.25) P nkT = 1 + η + η2 − η3 (1 − η)3 , (6) 16.4 Particle simulations 649 6 5 4 3 2 1 0 02 4 (a) (b) 68 r /Dg(r) 3.5 3.0 2.5 2.0 1.5 1.0 0.5 0.0020 3010 40 50 60 70 kDS(k) FIGURE 16.2 (a) The pair correlation function g(r) and (b) the static structure factor S(k) for a three-dimensional system of hard spheres at volume fraction η = 0.49 from a Monte Carlo simulation of 2916 particles (M. Glaser, unpublished). This value of the volume fraction is in the liquid phase close to the solid–liquid coexistence line. The solid lines depict the pair correlation function and the static structure factor from the Percus–Yevick approximation; see Percus and Yevick (1958), Wertheim (1963), and Hansen and McDonald (1986). 30 20 10 0 0.0 0.2 0.4 0.6 0.8 \u0002 \u0002l \u0002s \u0002cpP* P* Is FIGURE 16.3 Sketch of the equilibrium phase diagram for hard spheres in three dimensions. The horizontal axis is the volume fraction η = π nD3/6 and the vertical axis is the scaled pressure P∗ = PD3/kT . There are two equilibrium phases: a low-density ﬂuid phase for 0 < η < ηl and a high-density solid phase for ηs < η < ηcp. although there are other good parametizations as well. In the solid phase the pressure is approximately given by P nkT = 3 1 − η∗ − 0.5921 η∗ − 0.7072 η∗ − 0.601 , (7) where η∗(= η/ηcp) is the ratio of the actual packing fraction to the maximum close-packed value ηcp, namely π √ 2/6 ≃ 0.7405 (Speedy, 1997; Frenkel and Smit, 2002). The pressure in the solid phase diverges as the density approaches the close-packed density. The model 650 Chapter 16. Computer Simulations also exhibits a metastable disordered phase for densities between ηl and the random close- packed volume fraction ηrcp ≃ 0.644 ± 0.005; see Rintoul and Torquato (1996). For a survey of hard sphere results, see Mulero et al. (2008). 16.5 Computer simulation caveats Computer simulations are widely used in statistical physics and have played an important role in our understanding of many physical systems. Simulations complement theory and experiment and provide many advantages for the study of systems that are not amenable to exact or approximate theoretical analysis. However, it is important to understand the inherent limitation of this technique. . Computer simulations necessarily involve a limited number of degrees of freedom, typically hundreds to thousands of particles or spins. This is not nearly large enough to display many of the behaviors that occur in thermodynamically large systems. For example, a model of a dense system of 1,000 particles in a three-dimensional cubic box will only have about 10 particles along each linear dimension of the box, so correlations beyond about ﬁve particle diameters are affected by the periodic boundary conditions. Extraction of accurate thermodynamic behavior from such a study will often involve an analysis of the ﬁnite-size scaling behavior of the model for a sequence of systems with different sizes.. Computer simulations necessarily involve a limited time-scale of simulation. Typical molecular time scales are of the order of t0 ≈ a/v, where a a microscopic length scale and v a molecular velocity. For atomic scales near room temperature, a ≈ 0.1 nm and v ≈ 100 m/s, which gives t0 ≈ 10−12 s. In an MD simulation, each time step moves the system forward in time by an amount 1t, which must be much less than t0 in order to aptly integrate the equations of motion, say 1t ≈ 10−14 s. A simulation that moves the system forward through 106 time steps will sample a physical time of only 10 ns, which may not be sufﬁcient to reach many important time-scales of interest in the problem. This is especially problematic when the system has inherently slow time- scales, such as the critical slowing down near second-order phase transitions and the hysteresis near ﬁrst-order phase transitions. Monte Carlo simulations are similarly hampered in that the simulation must run long enough for the model to explore a sufﬁciently large region of the phase space to capture the equilibrium behavior. In favorable cases, this and the previous issue can be mitigated by special simulation methods such as coarse graining, cluster update methods, parallel tempering, multicanonical Monte Carlo methods, Monte Carlo renormalization group, and so on; see footnote 5.. Interactions between particles are usually highly simpliﬁed for computational efﬁciency and the interaction range is usually cut off. Long-range interactions (Couloub, dipole, van der Waals, etc.) need to be resummed or treated via perturbation theory to try to account for their effects. Problems 651 . MC and MD simulations do not directly measure the number of microstates available to the system, so one cannot directly calculate the entropy or the free energy in the same way as other observables. If, for example, a determination of the free energy is necessary to locate a phase transition, then it can be determined by a thermodynamic integration to a state with a theoretically known free energy; see Frenkel and Smit (2002).. MD simulations depend on the ergodicity of the Hamiltonian, so one-dimensional models, models that are weakly perturbed from mechanical equilibrium, and other nearly integrable models may get trapped in low-dimensional orbits that do not fully explore the constant-energy hypersurface of the Hamiltonian; see footnote 6.. All pseudorandom number generators produce some level of correlation in their sequences. Even subtle correlations in pseudorandom number sequences can produce erroneous results in Monte Carlo simulations. Different classes of generators have different weaknesses, so switching to a generator based on a different algorithm will sometimes cure a problem caused by correlations produced by a particular generator. Testing a generator before using it in a simulation is always a good idea; see Appendix I.. It is extremely important to conﬁrm the validity of MC and MD simulation codes. This process is rather different from verifying a theoretical calculation. Some code evaluation and veriﬁcation procedures include: testing the code initially on small systems with known properties, testing the code whenever possible against models with exact solutions or models that have been widely studied in the literature, examining results as a function of system size and run length, and retesting carefully whenever new interactions or code modules are added. In this connection, Frenkel and Smit (2002), Parker (2008), and Landau and Binder (2009) provide lists of good strategies. Problems 16.1. Write a code to test a uniform pseudorandom number generator. If you do not have a canned generator available, write a generator based on L’Ecuyer’s recommended generator in Appendix I. Apply the following tests: average ⟨x⟩ = 1/2, variance 〈 x2〉 − ⟨x⟩2 = 1/12, and the pair correlations test 〈xi+kxi〉 = 1/4 for k ̸= 0. Generate a histogram of pairs of numbers on a two-dimensional unit square and test that the distribution is statistically uniform. 16.2. Write a code to test a Gaussian pseudorandom number generator. If you do not have a canned generator available, write a generator based on the Box-Muller algorithm in Appendix I. Apply the following tests: average ⟨x⟩ = 0, variance 〈x2〉 = 1, and the pair correlations test 〈xi+kxi〉 = 0 for k ̸= 0. Generate a histogram of pairs of numbers in two dimensions and test that the distribution is statistically Gaussian. 16.3. Deﬁne a sequence of correlated random numbers sk = αsk−1 + (1 − α)rk, where rk is a unit-variance, uncorrelated, Gaussian pseudorandom number while 0 < α < 1 deﬁnes the range of the correlations. Show that this sequence is Gaussian distributed, with a zero 652 Chapter 16. Computer Simulations mean. Determine the variance in terms of α and compare your result with equation (16.1.2b). Write a code to determine the correlation function (16.1.3). Plot your measured correlation function and compare it to the exact correlation function. 16.4. Write a Monte Carlo code for a system of N hard spheres of diameter D on a one-dimensional ring of length L with periodic boundary conditions. Calculate the pair correlation function and compare it to equations (13.1.6) and (13.1.7). The pressure of the system is given by P/nkT = 1 + nDg(D+); see equation (10.7.12). Compare your pressure to the one obtained for the exact conﬁgurational partition function ZN = L(L − ND)N−1/N!; see equation (13.1.2). 16.5. Write a Monte Carlo code for a ﬂuid of N hard spheres in a two-dimensional L × L square box with periodic boundary conditions in each direction. Calculate the pair correlation function and determine the scaled pressure using equation (10.7.12), namely P/nkT = 1 + 2ηg(D+). Compare this pressure to the approximate form P/nkT = (1 + η/8)/(1 − η)2. 16.6. Write a Monte Carlo code for a ﬂuid of N hard spheres in a two-dimensional L × L square box and include a one-body gravity term ∑N i=1 mgyi in the algorithm, that is, accept otherwise legal conﬁgurations with probability exp(−βmg1y). You will need to use hard-wall boundary conditions on the top and bottom walls. Determine the average number density as a function of the vertical position in the box. 16.7. Write a molecular dynamics code for N Lennard-Jones particles in a two-dimensional L × L square box. Apply periodic boundary conditions in each direction. Determine the scaled pressure using the virial equation (16.4.2). Calculate and plot the pair correlation function of the system. 16.8. Write a molecular dynamics code for N Lennard-Jones particles in a two-dimensional L × L square box, and include a one-body gravity term in the energy: ∑N i=1 mgyi. Apply periodic boundary conditions in the x-direction but a repulsive WCA (Weeks, Chandler, and Andersen, 1971) potential on the top and bottom walls. The WCA potential is the repulsive part of a Lennard-Jones potential for r/D < (2)1/6, with the potential shifted up by ε. Show that the average kinetic energy per particle is independent of the height y in the box but the average scaled density nD2 depends on the vertical position in the box. 16.9. Write an MC code to simulate the one-dimensional Ising model on a periodic lattice of length L. Calculate the internal energy and speciﬁc heat of the model and compare them to equations (13.2.15) and (13.2.16). Calculate the correlation function G(n) = 〈 si+nsi〉 and it compare to equation (13.2.32). 16.10. Write an MC code to simulate the two-dimensional nearest-neighbor Ising model on a periodic L × L lattice in zero ﬁeld. Calculate the internal energy and the speciﬁc heat of the system as functions of temperature and compare them to the exact results in section 13.4.A. See exact results for the two-dimensional Ising model for various lattice sizes at www.elsevierdirect.com. 16.11. Write an MC code to simulate the two-dimensional nearest-neighbor Ising model on a periodic L × L lattice in zero ﬁeld. Calculate the energy distribution P(E) over a range of temperatures including the critical point. Use this distribution to calculate the internal energy and the speciﬁc heat as functions of temperature. See exact results for the two-dimensional Ising model for various lattice sizes at www.elsevierdirect.com. 16.12. Write an MC code to simulate the one-dimensional XY model. Calculate the internal energy, the speciﬁc heat, the isothermal susceptibility, and the pair correlation function, and compare your results to the analytical results for the n = 2 case in Section 13.2. 16.13. Write an MC code to simulate the two-dimensional XY model. Calculate the internal energy, speciﬁc heat, isothermal susceptibility and the pair correlation function, and compare your results to the theoretical results given in Section 13.7. Appendices A Inﬂuence of boundary conditions on the distribution of quantum states In this appendix we examine, under different boundary conditions, the asymptotic distribution of single-particle states in a bounded continuum. For simplicity, we consider a cuboidal enclosure of sides a, b, and c. The admissible solutions of the free-particle Schr¨odinger equation ∇2ψ + k2ψ = 0 (k = pℏ−1) , (1) which satisfy Dirichlet boundary conditions (namely, ψ = 0 everywhere at the boundary), are then given by ψlmn(r) ∝ sin ( lπx a ) sin ( mπ y b ) sin ( nπz c ) , (2) with k = π ( l2 a2 + m2 b2 + n2 c2 )1/2 ; l, m, n = 1, 2, 3, . . . . (3) Note that in this case none of the quantum numbers l, m, or n can be zero, for that would make the wavefunction identically vanish. If, on the other hand, we impose Neumann boundary conditions (namely, ∂ψ/∂n = 0 everywhere at the boundary), the desired solutions turn out to be ψlmn(r) ∝ cos ( lπ x a ) cos ( mπy b ) cos ( nπz c ) , (4) with l, m, n = 0, 1, 2, . . . ; (5) clearly, the value zero of the quantum numbers is now allowed! In each case, however, the negative- integral values of the quantum numbers do not lead to any new wavefunctions. The total number g(K ) of distinct wavefunctions ψ, with wave number k not exceeding a given value K , may be written as g(K ) = ∑′ l,m,nf (l, m, n), (6) Traveling Wave Analysis of Partial Differential Equations © 2011 Elsevier Ltd. All rights reserved. 653 654 Appendices where f (l, m, n) = 1 for the numbers (l, m, n) belonging to the set (3) or (5), as the case may be; the summation ∑′ in each case is restricted by the condition ( l2 a2 + m2 b2 + n2 c2 ) ≤ K 2 π 2 . (7) We now deﬁne a sum G(K ) = ∑′ l,m,nf ∗(l, m, n), (8) where f ∗(l, m, n) = 1 for all integral values of l, m, and n (positive, negative, or zero), the restric- tion on the numbers (l, m, n) being the same as stated in (7). One can then show, by setting up correspondence of terms, that ∑′ l,m,nf (l, m, n) = 1 8 [∑′ l,m,nf ∗(l, m, n) ∓ {∑′ l,m f ∗(l, m, 0) + ∑′ l,n f ∗(l, 0, n) + ∑′ m,n f ∗(0, m, n)} + {∑′ l f ∗(l, 0, 0) + ∑′ m f ∗(0, m, 0) + ∑′ n f ∗(0, 0, n)} ∓ 1 ] ; (9) the upper and the lower signs here correspond, respectively, to the Dirichlet and the Neumann boundary conditions. Clearly, the ﬁrst sum on the right side of (9) denotes the number of lattice points in the ellipsoid1 (X 2/a2 + Y 2/b2 + Z 2/c2) = K 2/π 2, the next three sums denote the numbers of lattice points in the ellipses, which are cross-sections of this ellipsoid with the Z-, Y - and X -planes, while the last three sums denote the numbers of lattice points on the principal axes of the ellipsoid. Now, if a, b, and c are sufﬁciently large in comparison with π/K , one may replace these numbers by the corresponding volume, areas, and lengths, respectively, with the result g(K ) = K 3 6π 2 (abc) ∓ K 2 8π (ab + ca + bc) + K 4π (a + b + c) ∓ 1 8 + E(K ); (10) the term E(K ) here denotes the net error committed in making the aforementioned replacements. We thus ﬁnd that the main term of our result is directly proportional to the volume of the enclosure while the ﬁrst correction term is proportional to its surface area (and, hence, represents a “surface effect”); the next-order term(s) appear in the nature of an “edge effect” and a “corner effect.” Now, a reference to the literature dealing with the determination of the “number of lattice points in a given domain” reveals that the error term E(K ) in equation (10) is O(K α), where 1 < α < 1.4; hence, expression (10) for g(K ) is reliable only up to the surface term. In view of this, we may write g(K ) = K 3 6π 2 V ∓ K 2 16π S + a lower-order remainder; (11) 1By the term “in the ellipsoid” we mean “not external to the ellipsoid,” that is, the lattice points “on the ellipsoid” are also included. Other such expressions in the sequel carry a similar meaning. Appendix B 655 in terms of ε∗, where ε∗ = 8mL2 h2 ε = 4L2 h2 P2 = L2 π 2 K 2, (12) equation (11) reduces to equations (1.4.15) and (1.4.16) of the text. In the case of periodic boundary conditions, namely ψ(x, y, z) = ψ(x + a, y, z) = ψ(x, y + b, z) = ψ(x, y, z + c), (13) the appropriate wavefunctions are ψlmn(r) ∝ exp{i(k · r)}, (14) with k = 2π ( l a , m b , n c ) ; l, m, n = 0, ±1, ±2, . . . . (15) The number of free-particle states g(K ) is now given by g(K ) = ∑′ l,m,nf ∗(l, m, n), (16) such that (l2/a2 + m2/b 2 + n 2/c2) ≤ K 2/(4π 2). (17) This is precisely the number of lattice points in the ellipsoid with semiaxes Ka/2π, Kb/2π , and Kc/2π, which, allowing for the approximation made in the earlier cases, is just equal to the volume term in (11). Thus, in the case of periodic boundary conditions, we do not obtain a surface term in the expression for the density of states. For further information on this topic, see Fedosov (1963, 1964), Pathria (1966), Chaba and Pathria (1973), and Baltes and Hilf (1976). B Certain mathematical functions In this appendix we outline the main properties of certain mathematical functions that are of special importance to the subject matter of this text. We start with the gamma function 0(ν), which is identical with the factorial function (ν − 1)! and is deﬁned by the integral 0(ν) ≡ (ν − 1)! = ∞∫ 0 e−xxν−1dx; ν > 0. (1) First of all, we note that 0(1) ≡ 0! = 1. (2) 656 Appendices Next, integrating by parts, we obtain the recurrence formula 0(ν) = 1 ν 0(ν + 1), (3) from which it follows that 0(ν + 1) = ν(ν − 1) · · · (1 + p)p0(p), 0 < p ≤ 1, (4) p being the fractional part of ν. For integral values of ν (ν = n, say), we have the familiar representation 0(n + 1) ≡ n! = n(n − 1) · · · 2 · 1; (5) on the other hand, if ν is a half-odd integral (ν = m + 1 2 , say), then 0 (m + 1 2 ) ≡ (m − 1 2 ) ! = ( m − 1 2 ) (m − 3 2 ) · · · 3 2 · ( 1 2 ) 0 ( 1 2 ) = (2m − 1)(2m − 3) · · · 3 · 1 2m π 1/2, (6) where use has been made of equation (21), whereby 0 ( 1 2 ) ≡ (− 1 2 ) ! = π 1/2. (7) By repeated application of the recurrence formula (3), the deﬁnition of the function 0(ν) can be extended to all ν, except for ν = 0, −1, −2, . . . where the singularities of the function lie. The behavior of 0(ν) in the neighborhood of a singularity can be determined by setting ν = −n + ε, where n = 0, 1, 2, . . . and |ε| ≪ 1, and using formula (3) n + 1 times; we get 0(−n + ε) = 1 (−n + ε)(−n + 1 + ε) · · · (−1 + ε)ε 0(1 + ε) ≈ (−1)n n! ε . (8) Replacing x by αy2, equation (1) takes the form 0(ν) = 2αν ∞∫ 0 e−αy2 y2ν−1dy, ν > 0. (9) We thus obtain another closely related integral, namely I2ν−1 ≡ ∞∫ 0 e−αy2 y2ν−1dy = 1 2αν 0(ν), ν > 0; (10) by a change of notation, this can be written as Iν ≡ ∞∫ 0 e−αy2 yν dy = 1 2α(ν+1)/2 0 ( ν + 1 2 ) , ν > −1. (11) Appendix B 657 One can easily see that the foregoing integral satisﬁes the relationship Iν+2 = − ∂ ∂α Iν . (12) The integrals Iν appear so frequently in our study that we write down the values of some of them explicitly: I0 = 1 2 ( π α )1/2 , I2 = 1 4 ( π α3 )1/2 , I4 = 3 8 ( π α5 )1/2 · · · , (13a) while I1 = 1 2α , I3 = 1 2α2 , I5 = 1 α3 , · · · . (13b) In connection with these integrals, it may as well be noted that ∞∫ −∞ e−αy2 yν dy = 0 if ν is an odd integer = 2Iν if ν is an even integer. (14) Next, we consider the product of two gamma functions, say 0(µ) and 0(ν). Using representa- tion (9), with α = 1, we have 0(µ)0(ν) = 4 ∞∫ 0 ∞∫ 0 e−(x2+y2)x2µ−1y2ν−1dx dy, µ > 0, ν > 0. (15) Changing over to the polar coordinates (r, θ), equation (15) becomes 0(µ)0(ν) = 4 ∞∫ 0 e−r2 r2(µ+ν)−1dr π/2∫ 0 cos 2µ−1 θ sin2ν−1 θ dθ = 20(µ + ν) π/2∫ 0 cos2µ−1 θ sin2ν−1 θ dθ . (16) Now, deﬁning the beta function B(µ, ν) by the integral B(µ, ν) = 2 π/2∫ 0 cos 2µ−1 θ sin 2ν−1 θdθ , µ > 0, ν > 0, (17) we obtain an important relationship: B(µ, ν) = 0(µ)0(ν) 0(µ + ν) = B(ν, µ). (18) Substituting cos2 θ = η, equation (17) takes the standard form B(µ, ν) = 1∫ 0 ηµ−1(1 − η) ν−1dη, µ > 0, ν > 0, (19) 658 Appendices while the special case µ = ν = 1 2 gives B ( 1 2 , 1 2 ) = 2 π/2∫ 0 dθ = π. (20) Coupled with equations (2) and (18), equation (20) yields 0 ( 1 2 ) = π 1/2. (21) Stirling’s formula for ν! We now derive an asymptotic expression for the factorial function ν! = ∞∫ 0 e−xxν dx (22) for ν ≫ 1. It is not difﬁcult to see that, for ν ≫ 1, the major contribution to this integral comes from the region of x that lies around the point x = ν and has a width of order √ ν. In view of this, we invoke the substitution x = ν + ( √ν)u, (23) whereby equation (22) takes the form ν! = √ν ( ν e )ν ∞∫ − √ν e−( √ν)u (1 + u √ ν )ν du. (24) The integrand in (24) attains its maximum value, unity, at u = 0 and on both sides of the maximum it falls rapidly to zero, which suggests that it may be approximated by a Gaussian. We, therefore, expand the logarithm of the integrand around u = 0 and then reconstruct the integrand by taking the exponential of the resulting expression; this gives ν! = √ν ( ν e )ν ∞∫ − √ν exp { − u2 2 + u3 3 √ν − u4 4ν + · · · } du. (25) If ν is sufﬁciently large, the integrand in (25) may be replaced by the single factor exp(−u2/2); more- over, since the major contribution to this integral comes only from that range of u for which |u| is of order unity, the lower limit of integration may be replaced by −∞. We thus obtain the Stirling formula ν! ≈ √(2πν)(ν/e)ν , ν ≫ 1. (26) A more detailed analysis leads to the Stirling series ν! = √ (2πν) ( ν e )ν [1 + 1 12ν + 1 288ν2 − 139 51840ν3 − 571 2488320ν4 + · · · ] . (27) Appendix B 659 Next, we consider the function ln (ν! ). Corresponding to formula (27), we have, for large ν, ln (ν! ) = (ν + 1 2 ) ln ν − ν + 1 2 ln (2π) + [ 1 12ν − 1 360ν3 + 1 1260ν5 − 1 1680ν7 + · · · ] . (28) For most practical purposes, we may write ln(ν! ) ≈ (ν ln ν − ν). (29) We note that formula (29) can be obtained very simply by an application of the Euler–Maclaurin formula. Since ν is large, we may consider its integral values only; then, by deﬁnition, ln(n! ) = n∑ i=1(ln i). Replacing summation by integration, we obtain ln(n! ) ≃ n∫ 1 (ln x)dx = (x ln x − x) ∣ ∣ ∣ ∣ x=n x=1 ≈ (n ln n − n), which is identical to (29). We must, however, be warned that, whereas approximation (29) is ﬁne as it is, it would be wrong to take its exponential and write ν! ≈ (ν/e)ν , for that would affect the evaluation of ν! by a factor O(ν1/2), which can be considerably large; see (26). In the expression for ln(ν! ), the corresponding term is indeed negligible. The Dirac δ-function We start with the Gaussian distribution function p(x, x0, σ ) = 1 √(2π)σ e−(x−x0)2/2σ 2 , (30) which satisﬁes the normalization condition ∞∫ −∞ p(x, x0, σ )dx = 1. (31) The function p(x) is symmetric about the value x0 where it has a maximum; the height of this max- imum is inversely proportional to the parameter σ while its width is directly proportional to σ , the total area under the curve being a constant. As σ becomes smaller and smaller, the function p(x) becomes narrower and narrower in width and grows higher and higher at the central point x0, condition (31) being satisﬁed at all σ ; see Figure B.1. In the limit σ → 0, we obtain a function whose value at x = x0 is inﬁnitely large while at x ̸= x0 it is vanishingly small, the area under the curve being still equal to unity. This limiting form of the 660 Appendices \u00022 \u00021.5 \u00021 \u00020.5 0.5 1 1.5 2 4 1 0 p(x\u0002x0) \u0002 \u0003 1/10 \u0002 \u0003 1/3 \u0002 \u0003 1 (x\u0002x0) 3 2 FIGURE B.1 Gaussian distribution function (30) for different values of σ . function p(x, x0, σ ) is, in fact, the δ-function of Dirac. Thus, we may deﬁne this function as the one satisfying the following properties: (i) δ(x − x0) = 0 for all x ̸= x0, (32) (ii) ∞∫ −∞ δ(x − x0)dx = 1. (33) Conditions (32) and (33) inherently imply that, at x = x0, δ(x − x0) = ∞ and that the range of integra- tion in (33) need not extend all the way from −∞ to +∞; in fact, any range that includes the point x = x0 would sufﬁce. Thus, we may rewrite (33) as B∫ A δ(x − x0)dx = 1 if A < x0 < B. (34) It follows that, for any well-behaved function f (x), B∫ A f (x)δ(x − x0)dx = f (x0) if A < x0 < B. (35) Another limiting process frequently employed to represent the δ-function is the following: δ(x − x0) = Lim γ →0 γ π{(x − x0)2 + γ 2} . (36) Appendix B 661 To see the appropriateness of this representation, we note that, for x ̸= x0, this function vanishes like γ while, for x = x0, it diverges like γ −1; moreover, for all γ , ∞∫ −∞ γ π{(x − x0)2 + γ 2} dx = 1 π [tan −1 (x − x0) γ ]∞ −∞ = 1. (37) An integral representation of the δ-function is δ(x − x0) = 1 2π ∞∫ −∞ eik(x−x0)dk, (38) which means that the δ-function is the “Fourier transform of a constant.” We note that, for x = x0, the integrand in (38) is unity throughout, so the function diverges. On the other hand, for x ̸= x0, the oscillatory character of the integrand is such that it makes the integral vanish. And, ﬁnally, the integration of this function, over a range of x that includes the point x = x0, gives 1 2π ∞∫ −∞    x0+L∫ x0−L eik(x−x0)dx    dk = ∞∫ −∞ eikL − e−ikL 2π(ik) dk = ∞∫ −∞ sin(kL) π k dk = 1, (39) independently of the choice of L. It is instructive to see how the integral representation of the δ-function is related to its previous representations. For this, we introduce into the integrand of (38) a convergence factor exp(−γ k2), where γ is a small, positive number. The resulting function, in the limit γ → 0, should reproduce the δ-function; we thus expect that δ(x − x0) = 1 2π Lim γ →0 ∞∫ −∞ eik(x−x0)−γ k2 dk. (40) The integral in (40) is easy to evaluate if we recall that ∞∫ −∞ cos(kx)e−γ k2 dk = 2 ∞∫ 0 cos(kx)e−γ k2 dk = √( π γ ) e−x2/4γ , (41) while ∞∫ −∞ sin(kx)e−γ k2 dk = 0. (42) Accordingly, equation (40) becomes δ(x − x0) = Lim γ →0 1 √ (4πγ ) e−(x−x0)2/4γ , (43) 662 Appendices which is precisely the representation we started with.2 Finally, the notation of the δ-function can be readily extended to spaces with more than one dimension. For instance, in n dimensions, δ(r) = δ(x1) · · · δ(xn), (44) so that (i) δ(r) = 0 for all r ̸= 0, (45) (ii) ∞∫ −∞ · · · ∞∫ −∞ δ(r)dx1 · · · dxn = 1. (46) The integral representation of δ(r) is δ(r) = 1 (2π)n ∞∫ −∞ · · · ∞∫ −∞ ei(k·r)dnk. (47) Once again, we may write δ(r) = 1 (2π)n Lim γ →0 ∞∫ −∞ · · · ∞∫ −∞ ei(k·r)−γ k2 dnk (48) = Lim γ →0 ( 1 4πγ )n/2 e−r2/4γ . (49) C “Volume” and “surface area” of an n-dimensional sphere of radius R Consider an n-dimensional space in which the position of a point is denoted by the vector r, with Cartesian components (x1, . . . , xn). The “volume element” dVn in this space would be dnr = n∏ i=1(dxi); accordingly, the “volume” Vn of a sphere of radius R would be given by Vn(R) = ∫ · · · ∫ 0≤ n∑ i=1 x2 i ≤R2 n∏ i=1(dxi). (1) 2The reader may check that the introduction into (38) of a convergence factor exp(−γ |k|), rather than exp(−γ k2), leads to the representation (36). Appendix C 663 Obviously, Vn will be proportional to Rn, so let us write it as Vn(R) = CnRn, (2) where Cn is a constant that depends only on the dimensionality of the space. Clearly, the “volume element” dVn can also be written as dVn = Sn(R)dR = nCnRn−1dR, (3) where Sn(R) denotes the “surface area” of the sphere. To evaluate Cn, we make use of the formula ∞∫ −∞ exp(−x2)dx = π 1/2. (4) Multiplying n such integrals, one for each xi, we obtain π n/2 = xi=∞∫ · · · ∫ xi=−∞ exp ( − n∑ i=1 x2 i ) n∏ i=1 (dxi) = ∞∫ 0 exp(−R2)nCnRn−1dR = nCn · 1 2 0 ( n 2 ) = ( n 2 ) ! Cn; (5) here, use has been made of formula (B.11), with α = 1. Thus, Cn = π n/2∕ ( n 2 ) ! , (6) so that Vn(R) = π n/2 (n/2)! Rn and Sn(R) = 2π n/2 0(n/2) Rn−1, (7a,b) which are the desired results. Alternatively, one may prefer to use spherical polar coordinates right from the beginning — as, for instance, in the evaluation of the Fourier transform I(k) = ∫ f (r)eik·rdnr. (8) In that case, dnr = rn−1(sin θ1)n−2 · · · (sin θn−2) 1dr dθ1 · · · dθn−2dφ, (9) where the θi range from 0 to π while φ ranges from 0 to 2π . Choosing our polar axis to be in the direction of k, equation (8) takes the form I(k) = ∫ f (r)eikr cos θ1 rn−1(sin θ1)n−2 · · · (sin θn−2) 1dr dθ1 · · · dθn−2dφ. (10) 664 Appendices Integration over the angular coordinates θ1, θ2, θ3, . . . , θn−2 and φ yields factors π 1/20 ( n − 1 2 ) ( 2 kr )(n−2)/2 J(n−2)/2(kr) × B ( n − 2 2 , 1 2 ) · B ( n − 3 2 , 1 2 ) · · · B ( 1, 1 2 ) · 2π, where Jν (x) is the ordinary Bessel function while B(µ, ν) is the beta function; see equations (B.17) and (B.18). Equation (10) now becomes I(k) = (2π)n/2 ∞∫ 0 f (r) ( 1 kr )(n−2)/2 J(n−2)/2(kr)rn−1dr, (11) which is our main result. In the limit k → 0, Jν (kr) → ( 1 2 kr)ν /0(ν + 1), so that I(0) = 2π n/2 0(n/2) ∞∫ 0 f (r)rn−1dr, (12) consistent with (3) and (7b). On the other hand, if we take f (r) to be a constant, say 1/(2π)n, we should obtain another representation of the Dirac δ-function in n dimensions; see equations (8) and (B.47). We thus have, from (11), δ(k) = 1 (2π)n/2 ∞∫ 0 ( 1 kr )(n−2)/2 J(n−2)/2(kr)rn−1dr. (13) As a check, we introduce a factor exp(−αr2) in the integrand of (13) and obtain δ(k) = Lim α→0 1 (2π)n/2 ∞∫ 0 e−αr2 ( 1 kr )(n−2)/2 J(n−2)/2(kr)rn−1dr = Lim α→0 ( 1 4πα )n/2 e−k2/4α, (14) in complete agreement with (B.49). If, on the other hand, we use the factor exp(−αr) rather than exp(−αr2), we get δ(k) = Lim α→0 0 ( n + 1 2 ) α {π(k2 + α2)}(n+1)/2 , (15) which generalizes (B.36). D On Bose–Einstein functions In the theory of Bose–Einstein systems we come across integrals of the type Gν (z) = ∞∫ 0 xν−1dx z−1ex − 1 (0 ≤ z < 1, ν > 0; z = 1, ν > 1). (1) Appendix D 665 In this appendix we study the behavior of Gν (z) over the stated range3 of the parameter z. First of all, we note that Lim z→0 Gν (z) = ∞∫ 0 ze−xxν−1dx = z0(ν). (2) Hence, it appears useful to introduce another function, gν (z), such that gν (z) ≡ 1 0(ν) Gν (z) = 1 0(ν) ∞∫ 0 xν−1dx z−1ex − 1 . (3) For small z, the integrand in (3) may be expanded in powers of z, with the result gν (z) = 1 0(ν) ∞∫ 0 xν−1 ∞∑ l=1(ze−x) ldx = ∞∑ l=1 zl lν = z + z2 2ν + z3 3ν + · · · ; (4) thus, for z ≪ 1, the function gν (z), for all ν, behaves like z itself. Moreover, gν (z) is a monotonically increasing function of z whose largest value in the physical range of interest obtains when z → 1; then, for ν > 1, gν (z) approaches the Riemann zeta function ζ (ν): gν (1) = ∞∑ l=1 1 lν = ζ (ν) (ν > 1). (5) The numerical values of some of the ζ (ν) are ζ (2) = π 2 6 ≃ 1.64493, ζ (4) = π 4 90 ≃ 1.08232, ζ (6) = π 6 945 ≃ 1.01734, ζ ( 3 2 ) ≃ 2.61238, ζ ( 5 2 ) ≃ 1.34149, ζ ( 7 2 ) ≃ 1.12673, and, ﬁnally, ζ (3) ≃ 1.20206, ζ (5) ≃ 1.03693, ζ (7) ≃ 1.00835. For ν ≤ 1, the function gν (z) diverges as z → 1. The case ν = 1 is rather simple, for the function gν (z) now assumes a closed form: g1(z) = ∞∫ 0 dx z−1ex − 1 = ln(1 − ze−x) ∣ ∣ ∣∞ 0 = − ln(1 − z). (6) As z → 1, g1(z) diverges logarithmically. Setting z = e−α, we have g1(e−α) = − ln(1 − e−α) −−−−−→ α→0 ln(1/α). (7) 3The behavior of Gν (z) for z > 1 has been discussed by Clunie (1954). 666 Appendices For ν < 1, the behavior of gν (e−α), as α → 0, can be determined as follows: gν (e−α) = 1 0(ν) ∞∫ 0 xν−1dx eα+x − 1 ≈ 1 0(ν) ∞∫ 0 xν−1dx α + x . Setting x = α tan2 θ and making use of equation (B.17), we obtain gν (e−α) ≈ 0(1 − ν) α1−ν (0 < ν < 1). (8) Expression (8) isolates the singularity of the function gν (e−α) at α = 0; the remainder of the function can be expanded in powers of α, with the result (see Robinson, 1951) gν (e−α) = 0(1 − ν) α1−ν + ∞∑ i=0 (−1)i i! ζ (ν − i)αi, (9) ζ (s) being the Riemann zeta function analytically continued to all s ̸= 1. A simple differentiation of gν (z) brings out the recurrence relation z ∂ ∂z [gν (z)] ≡ ∂ ∂(ln z) gν (z) = gν−1(z). (10) This relation follows readily from the series expansion (4) but can also be derived from the deﬁning integral (3). We thus have z ∂ ∂z [gν (z)] = z 0(ν) ∞∫ 0 exxν−1dx (ex − z)2 . Integrating by parts, we get z ∂ ∂z [ gν (z) ] = z 0(ν)  − xν−1 ex − z ∣ ∣ ∣ ∞ 0 + (ν − 1) ∞∫ 0 xν−2dx ex − z   . The integrated part vanishes at both limits (provided that ν > 1), while the part yet to be integrated yields precisely gν−1(z). The validity of the recurrence relation (10) is thus established for all ν > 1. Adopting (10) as a part of the deﬁnition of the function gν (z), the notion of this function may be extended to all ν, including ν ≤ 0. Proceeding in this manner, Robinson showed that equation (9) applied to all ν < 1 and to all nonintegral ν > 1. For ν = m, a positive integer, we have instead gm(e−α) = (−1)m−1 (m − 1)! [ m−1∑ i=1 1 i − ln α ] αm−1 + ∞∑ i=0 i̸=m−1 (−1)i i! ζ (m − i)αi. (11) Equations (9) and (11) together provide a complete description of the function gν (e−α) for small α; it may be checked that both these expressions conform to the recurrence relation ∂ ∂α gν (e−α) = −gν−1(e−α). (12) Appendix E 667 For the special cases ν = 5 2 , 3 2 , and 1 2 we obtain from (9) g5/2(α) = 2.36α3/2 + 1.34 − 2.61α − 0.730α2 + 0.0347α3 + · · ·, (13a) g3/2(α) = −3.54α1/2 + 2.61 + 1.46α − 0.104α2 + 0.00425α3 + · · ·, (13b) g1/2(α) = 1.77α−1/2 − 1.46 + 0.208α − 0.0128α2 + · · · . (13c) The terms quoted here are sufﬁcient to yield a better than 1 percent accuracy for all α ≤ 1. The numerical values of these functions have been tabulated by London (1954) over the range 0 ≤ α ≤ 2. The values of several important integrals involving relativistic bosons in Chapters 7 and 9 are: ∞∫ 0 x2 ln(1 − e−x)dx = −2ζ (4) = − π 4 45 , (14a) ∞∫ 0 x2 ex − 1 dx = 2ζ (3) ≃ 2.40411, (14b) ∞∫ 0 x3 ex − 1 dx = 6ζ (4) = π 4 15 . (14c) E On Fermi–Dirac functions In the theory of Fermi–Dirac systems we come across integrals of the type Fν (z) = ∞∫ 0 xν−1dx z−1ex + 1 (0 ≤ z < ∞, ν > 0). (1) In this appendix we study the behavior of Fν (z) over the entire range of the parameter z. For the same reason as in the case of Bose–Einstein integrals, we introduce here another function, fν (z), such that fν (z) ≡ 1 0(ν) Fν (z) = 1 0(ν) ∞∫ 0 xν−1dx z−1ex + 1 . (2) For small z, the integrand in (2) may be expanded in powers of z, with the result fν (z) = 1 0(ν) ∞∫ 0 xν−1 ∞∑ l=1(−1) l−1(ze−x)ldx = ∞∑ l=1(−1)l−1 zl lν = z − z2 2ν + z3 3ν − · · · ; (3) thus, for z ≪ 1, the function fν (z), for all ν, behaves like z itself. The functions fν (z) are related to the Bose–Einstein functions gν (z) as follows: fν (z) = gν (z) − 2 1−ν gν (z2) (0 ≤ z < 1, ν > 0; z = 1, ν > 1). (4) 668 Appendices This is useful for determining the values of relativistic Fermi–Dirac integrals needed in Chapter 9: ∞∫ 0 x2 ln(1 + e−x)dx = 7π 4 360 , (5a) ∞∫ 0 x2 ex + 1 dx = 3ζ (3) 2 ≃ 1.80309, (5b) ∞∫ 0 x3 ex + 1 dx = 7π 4 120 . (5c) The functions fν (z) and fν−1(z) are connected through the recurrence relation z ∂ ∂z [ fν (z)] ≡ ∂ ∂(ln z) fν (z) = fν−1(z); (6) this relation follows readily from the series expansion (3) but can also be derived from the deﬁning integral (2). To study the behavior of Fermi–Dirac integrals for large z, we introduce the variable ξ = ln z, (7) so that Fν (e ξ ) ≡ 0(ν)fν (e ξ ) = ∞∫ 0 xν−1dx ex−ξ + 1 . (8) For large ξ , the situation in (8) is primarily controlled by the factor (ex−ξ + 1)−1, whose departure from its limiting values — namely, zero (as x → ∞) and almost unity (as x → 0) — is signiﬁcant only in the neighborhood of the point x = ξ ; see Figure E.1. The width of this “region of signiﬁcance” is O(1) and hence much smaller than the total, effective range of integration, which is O(ξ ). Therefore, in the lowest approximation, we may replace the actual curve of Figure E.1 by a step function, as 1.0 0.5 0 0 \u000224 \u000222 \u000212\u0002 \u000214 x(ex2\u000211)21FIGURE E.1 Appendix E 669 shown by the dotted line. Equation (8) then reduces to Fν (e ξ ) ≈ ξ∫ 0 xν−1dx = ξ ν ν (9) and, accordingly, fν (e ξ ) ≈ ξ ν 0(ν + 1) . (10) For a better approximation, we rewrite (8) as Fν (e ξ ) = ξ∫ 0 xν−1 [1 − 1 eξ −x + 1 ] dx + ∞∫ ξ xν−1 1 ex−ξ + 1 dx (11) and substitute in the respective integrals x = ξ − η1 and x = ξ + η2, (12) with the result Fν (e ξ ) = ξ ν ν − ξ∫ 0 (ξ − η1)ν−1dη1 eη1 + 1 + ∞∫ 0 (ξ + η2)ν−1dη2 eη2 + 1 . (13) Since ξ ≫ 1 while our integrands are signiﬁcant only for η of order unity, the upper limit in the ﬁrst integral may be replaced by ∞. Moreover, one may use the same variable η in both the integrals, with the result Fν (e ξ ) ≈ ξ ν ν + ∞∫ 0 (ξ + η)ν−1 − (ξ − η)ν−1 eη + 1 dη (14) = ξ ν ν + 2 ∑ j=1,3,5,... ( ν − 1 j )  ξ ν−1−j ∞∫ 0 η j eη + 1 dη   ; (15) in the last step the numerator in the integrand of (14) has been expanded in powers of η. Now, 1 0( j + 1) ∞∫ 0 η j eη + 1 dη = 1 − 1 2 j+1 + 1 3 j+1 − · · · = ( 1 − 1 2 j ) ζ ( j + 1); (16) see equations (2) and (3), with ν = j + 1 and z = 1. Substituting (16) into (15), we obtain fν (eξ ) = ξ ν 0(ν + 1)  1 + 2ν ∑ j=1,3,5.... { (ν − 1) · · · (ν − j) ( 1 − 1 2 j ) ζ ( j + 1) ξ j+1 }   = ξ ν 0(ν + 1) [ 1 + ν(ν − 1) π 2 6 1 ξ 2 + ν(ν − 1)(ν − 2)(ν − 3) 7π 4 360 1 ξ 4 + · · · ] , (17) 670 Appendices which is the desired asymptotic formula — commonly known as Sommerfeld’s lemma (see Sommer- feld, 1928).4 By the same procedure, one can derive the following asymptotic result, which is clearly a generalization of (17): ∞∫ 0 φ(x)dx ex−ξ + 1 = ξ∫ 0 φ(x)dx + π 2 6 ( dφ dx ) x=ξ + 7π 4 360 ( d3φ dx3 ) x=ξ + 31π 6 15120 ( d5φ dx5 ) x=ξ + · · · , (18) where φ(x) is any well-behaved function of x. It may be noted that the numerical coefﬁcients in this expansion approach the limiting value 2. Blakemore (1962) has tabulated numerical values of the function fν (e ξ ) in the range −4 ≤ ξ ≤ +10; his tables cover all integral orders from 0 to +5 and all half-odd integral orders from − 1 2 to + 9 2 . F A rigorous analysis of the ideal Bose gas and the onset of Bose–Einstein condensation In this appendix we study the problem of the ideal Bose gas without arbitrarily extracting the conden- sate term (ε = 0) from the original sum for N in equation (7.2.1) and approximating the remainder by an integral ranging from ε = 0 to ε = ∞. We will instead evaluate the original sum as it is with the help of certain mathematical identities dating back to Poisson and Jacobi in the early nine- teenth century. Luckily, these identities obviate the necessity of approximating sums by integrals and yield results valid for arbitrary values of N (though, for all practical purposes, we may assume that N ≫ 1). For pertinent details of this procedure, see Pathria (1983) and the references quoted therein. We consider an ideal Bose gas consisting of particles of mass m conﬁned to the cubic geometry L × L × L and subject to periodic boundary conditions so that the single-particle energy eigenvalues are given by ε = h2 2mL2 (n 2 1 + n 2 2 + n 2 3) , (ni = 0, ±1, ±2, . . .) . (1) 4A more careful analysis carried out by Rhodes (1950), and followed by Dingle (1956), shows that the passage from equation (13) to (14) omits a term which, for large ξ , is of order e−ξ . This term turns out to be cos{(ν − 1)π} Fν (e−ξ ) ≡ cos{(ν − 1)π}Fν (1/z). For large z, this would be very nearly equal to cos{(ν − 1)π}/z and hence negligible in comparison with any of the terms appearing in (17). Of course, for ν = 1 2 , 3 2 , 5 2 , . . ., which are the values occurring in most of the important applications of Fermi–Dirac statistics, the missing term is identically zero. For ν = 2, the inclusion of the missing term leads to the identity f2(e ξ ) + f2(e−ξ ) = 1 2 ξ 2 + π 2 6 , which is relevant to the contents of Section 8.3.B. Appendix F 671 The sum (7.1.2) then takes the form N = ∑ ε (e α+βε − 1 )−1 = ∑ ε ∞∑ j=1 e−j(α+βε) = ∞∑ j=1 e−jα   ∑ n1 e−jwn2 1 ∑ n2 e−jwn2 2 ∑ n3 e−jwn2 3  , (2) where α = −µ/kT , β = 1/kT , and w = βh2 2mL2 = π ( λ L )2 , (3) λ (= h/ √2πmkT ) being the mean thermal wavelength of the particles. To evaluate the sums in (2), we make use of the Poisson summation formula (see Schwartz, 1966): ∞∑ n=−∞ f (n) = ∞∑ q=−∞ F(q); F(q) = ∞∫ −∞ f (x)e2πiqxdx. (4) The function F(q) is, of course, the Fourier transform of the original function f (n). Choosing f (n) = e−jwn2 , we obtain the remarkable identity ∞∑ n=−∞ e−jwn2 = √ π jw ∞∑ q=−∞ e−π 2q2/jw. (5) It is instructive to note that the q = 0 term in (5) is precisely the result one would obtain if the summation over n were replaced by integration, as is customarily done in the treatment of this problem. Terms with q ̸= 0, therefore, represent corrections that arise from the discreteness of the single-particle states. Using equation (5) for each of the three summations in (2), we obtain N = ∞∑ j=1 e−jα 3∏ i=1   √ π jw ∑ qi e−π 2q2 i /jw   = ( π w )3/2 ∑ q ∞∑ j=1 e−jα j3/2 exp [ − π 2 jw ( q2 1 + q2 2 + q2 3)] = L3 λ3 ∞∑ j=1   e−jα j3/2 + ∑ q ′ e−jα j3/2 exp ( − π 2 jw (q2 1 + q2 2 + q2 3) )  , (6) where the primed summation in the second set of terms implies that the term with q = 0 has been taken out of this sum. The q = 0 term in (6) is precisely the bulk result for the total number of particles in the excited states of the system, namely Vg3/2(e−α)/λ3. In the second set of terms, the summation over j may be 672 Appendices carried out with the help of a straightforward generalization of identity (4), namely b∑ n=a f (n) = 1 2 f (a) + 1 2 f (b) + ∞∑ l=−∞ Fa,b(l); Fa,b(l) = b∫ a f (x)e2π ilxdx, (7) where a and b are integers such that b > a. Applying (7) to the primed sum in (6), we obtain ∞∑ j=1 j−3/2e−jαe−γ (q)/j = ∞∑ j=0 j−3/2e−jαe−γ (q)/j = √ π γ (q) ∞∑ l=−∞ exp [ −2 √ γ (q) ( α + 2πil)1/2] , (8) where γ (q) = π 2q2 w = πL2q2 λ2 > 0. We readily note that, whatever the value of α, terms with l ̸= 0 are at most of order exp(−L/λ) which, for L ≫ λ, are altogether negligible. As a consequence, no errors of order (λ/L)n are committed if we retain only the term with l = 0. We thus obtain N ≈ L3 λ3 [ g3/2 ( e−α) + π 1/2α1/2S ( y)] , (9) where S( y) = ∑ q ′ e−2R(q) R(q) ; R(q) = y√ q2 1 + q2 2 + q2 3, (10) while y is given by y = π 1/2α1/2 L λ . (11) In view of equation (13.6.36), the parameter y is a measure of the lateral dimension L of the system in terms of its correlation length ξ — to be precise, y = L/2ξ . We, therefore, expect that, as we lower the temperature of the system and enter the region of phase transition, this parameter will go from very large values to very small values over an inﬁnitesimally small range of temperatures around the transition point. We’ll examine this aspect of the problem a little later. At this point, it is worthwhile to note that if the summation over q that appears in equation (10) is replaced by integration, which is justiﬁable only in the limit y → 0, we obtain from equation (9) N ≈ L3 λ3 [ g3/2 ( e−α) + π 1/2α1/2 ( π y3 )] = L3 λ3 g3/2 ( e−α) + 1 α , (12) Appendix F 673 in perfect agreement with the bulk result obtained in Section 7.1, with α ≪ 1. To have an idea of the “degree of error” committed in making this replacement, we must evaluate this sum more accurately. For this, we make use of another mathematical identity, ﬁrst established by Chaba and Pathria (1975), namely ∑ q ′ [ y2 q2 ( y2 + π 2q2) + π q e−2yq] = 2πy + π 2 y2 + C3, (13) where C3 = π lim y→0   ∑ q ′ e−2yq q − ∫ all q e−2yq q dq    ≃ −8.9136. (14) It is important to note that the constant C3 is directly related to the Madelung constant of a simple cubic lattice; see, for instance, Harris and Monkhorst (1970). Now, since the second part of the sum appearing on the left side of (13) is directly proportional to S( y), we can rewrite (9) in the form N ≈ L3 λ3 g3/2 ( e−α) + L2 λ2 π y2 + L2 λ2   C3 π + 2y − y2 π ∑ q ′ 1 q2 ( y2 + π 2q2)  . (15) We observe that the second term on the right side of (15) is equal to 1/α — which is precisely N0 when α ≪ 1. The condensate, therefore, emerges naturally in our analysis and does not have to be extracted prematurely, as is done in the customary treatment. Now, in view of the fact that, for small α, g3/2 ( e−α) ≈ ζ ( 3 2 ) − 2π 1/2α1/2, (16) equation (15) is further simpliﬁed to N ≈ L3 λ3 ζ (3/2) + N0 + L2 λ2   C3 π − y2 π ∑ q ′ 1 q2 (y2 + π 2q2)   . (17) Introducing the bulk critical temperature Tc(∞), as deﬁned in equation (7.1.24), Tc(∞) = h2 2πmk   N L3ζ ( 3 2 )   2/3 = T λ2 L2   N ζ ( 3 2 )   2/3 ; (18) we obtain from (17) the desired result, namely N0 = N [ 1 − ( T Tc(∞) )3/2] + L2 λ2  − C3 π + y2 π ∑ q ′ 1 q2 ( y2 + π 2q2)  . (19) 674 Appendices The ﬁrst part of this expression is the standard bulk result for N0, while the second part represents the “ﬁnite-size correction” to this quantity. More important, while the main term here is of order N, the correction term is of order N 2/3. In the thermodynamic limit, the correction term loses its importance altogether and we are left with the conventional result following from the customary treatment. Finally, we study the variation of the scaling parameter y as a function of T ; this will also enable us to examine the manner in which the correlation length ξ and the condensate fraction f (= N0/N) build up as we move from temperatures above Tc(∞) to those below Tc(∞). For this, we introduce a scaled temperature, deﬁned by t = [T − Tc(∞)]/Tc(∞), and study the problem in three distinct regimes: (a) For t > 0, such that 1 ≫ t ≫ N −1/3, we make use of the result for α, as stated in Problem 7.3. Combining this result with equation (11), we get y ≈ 3 4 [ζ ( 3 2 )]2/3 N 1/3t, (20a) ξ ≈ 2 3 [ζ ( 3 2 )]−2/3 ℓt−1, (20b) f ≈ 16π 9 [ζ ( 3 2 )]−2 N −1t−2, (20c) where ℓ (= L/N 1/3) is the mean interatomic distance in the system. (b) For |t| = O(N −1/3), the parameter y = O(1) and its value has to be determined numerically. At t = 0, this value is determined by the equation S( y0) = 2; see equations (9) and (16). We thus get: y0 ≃ 0.973. The correlation length ξ in this regime is O(L) and the condensate fraction is O(N −1/3). (c) For t < 0, such that 1 ≫ |t| ≫ N −1/3, we get y ≈ √ 2π 3 [ ζ ( 3 2 )]−1/3 N −1/6|t| −1/2, (21a) ξ ≈ √ 3 8π [ ζ ( 3 2 )]1/3 L3/2 ℓ1/2 |t| 1/2 , (21b) f ≈ 3 2 |t|. (21c) We thus see how, over an inﬁnitesimally small range of temperatures O(N −1/3) around t = 0, the parameter y descends from values O(N 1/3) to values O(N −1/6) while the correlation length ξ grows from values O(ℓ) to values O(L3/2/ℓ1/2), and the condensate fraction f grows from values O(N −1) to values O(1). As N → ∞, the transition region collapses onto a singular point t = 0 and the phenomenon of Bose–Einstein condensation becomes a critical one. Appendix G 675 G On Watson functions In this appendix we examine the asymptotic behavior of the functions Wd(φ) = ∞∫ 0 e−φx [ e−xI0(x) ]d dx (1) for 0 ≤ φ ≪ 1. First of all, we note that if we set φ = 0 the resulting integral converges only if d > 2. To see this, we observe that, with φ = 0, convergence problems may arise in the limit of large x where the integrand [e−xI0(x)]d ≈ (2πx) −d/2 (x ≫ 1). (2) Clearly, the integral will converge if d > 2; otherwise, it will diverge. We, therefore, conclude that Wd(0) = ∞∫ 0 [e−xI0(x)]d dx (3) exists for d > 2. Next we look at the derivative W ′ d(φ) = − ∞∫ 0 e−φx[e−xI0(x)]dx dx. (4) By the same argument as above, we conclude that W ′ d(0) = − ∞∫ 0 [ e−xI0(x) ]d x dx (5) exists for d > 4. The manner in which W ′ d(φ) diverges for d < 4, as φ → 0, can be seen as follows: W ′ d(φ) = − ∞∫ 0 e−y [ e−y/φI0( y/φ) ]d 1 φ2 y dy ≈ − 1 (2π)d/2φ(4−d)/2 ∞∫ 0 e−yy(2−d)/2dy (φ ≪ 1) = − 0{(4 − d)/2} (2π)d/2φ(4−d)/2 . (6) 676 Appendices Integrating (6) with respect to φ, and remembering the comments made earlier about Wd(0), we obtain the desired results: Wd(φ) ≈    (2π)−d/20{(2 − d)/2}φ−(2−d)/2 + const. for d < 2 (7a) (2π)−1ln(1/φ) + const. for d = 2 (7b) Wd(0) − (2π)−d/2|0{(2 − d)/2}|φ(d−2)/2 for 2 < d < 4. (7c) For d > 4, we have a simpler result: Wd(φ) ≈ Wd(0) − |W ′ d(0)|φ, (8) for, in this case, both Wd(0) and W ′ d(0) exist. The borderline case d = 4 presents some problems that can be simpliﬁed by splitting the integral in (4) into two parts: ∞∫ 0 = 1∫ 0 + ∞∫ 1 . (9) The ﬁrst part is clearly ﬁnite; the divergence of the function W ′ 4(φ), as φ → 0, arises from the second part which, for φ ≪ 1, can be written as ≈ ∞∫ 1 e−φx(2π x) −2x dx = 1 4π 2 E1(φ), (10) where E1(φ) is the exponential integral; see Abramowitz and Stegun (1964), Chapter 5. Since E1(φ) ≈ − ln φ for φ ≪ 1, we conclude that W ′ 4(φ) ≈ 1 4π 2 ln φ. (11) Integrating (11) with respect to φ, we obtain W4(φ) ≈ W4(0) − 1 4π 2 φ ln(1/φ). (12) Equations (7), (8), and (12) constitute the main results of this appendix. For the record, we quote a couple of numbers: W3(0) = 0.50546, W4(0) = 0.30987. (13) H Thermodynamic relationships The following four equations relating partial derivatives are sometimes known as the Four Famous Formulae. They make it easy to derive thermodynamic relations in any one assembly or to convert Appendix H 677 relations from one assembly to another; by assembly we mean the set of thermodynamic parameters on which a system depends. If the quantities x, y, z are mutually related, then ( ∂x ∂y ) z = 1 ∕( ∂y ∂x ) z , (1a) ( ∂ ∂z ( ∂y ∂x ) z ) x = ( ∂ ∂x ( ∂y ∂z ) x ) z , (1b) ( ∂x ∂y ) z ( ∂y ∂z ) x ( ∂z ∂x ) y = −1, (1c) ( ∂x ∂y ) w = ( ∂x ∂y ) z + ( ∂x ∂z ) y ( ∂z ∂y ) w . (1d) Entropy S(N, V , U) and the microcanonical ensemble The entropy describes a closed, isochoric, adiabatic assembly, so it is a function of internal energy, volume, and number of molecules: dS = 1 T dU + P T dV − µ T dN, (2a) 1 T = ( ∂S ∂U ) V ,N , (2b) P T = ( ∂S ∂V ) U,N , (2c) µ T = − ( ∂S ∂N ) U,V . (2d) The Maxwell relations for the entropy are ( ∂(1/T ) ∂V ) U,N = ( ∂(P/T ) ∂U ) V ,N , (3a) ( ∂(1/T ) ∂N ) U,V = − ( ∂(µ/T ) ∂U ) V ,N , (3b) ( ∂(P/T ) ∂N ) U,V = − ( ∂(µ/T ) ∂V ) U,N . (3c) The entropy is determined from the number of microstates in the microcanonical ensemble 0(N, V , U; 1U) = Tr (11U (H − U) ), (4) where H is the Hamiltonian of the system and 11U (x) is the step function that is unity in the range 0 to 1U and zero otherwise. The quantity 0(N, V , U; 1U) here denotes the number of discrete 678 Appendices quantum states in the energy range between U and U + 1U. The entropy is then given by S(N, V , U) = k ln 0(N, V , U; 1U). (5) The bulk value of the entropy does not depend on the value chosen for 1U. Helmholtz free energy A(N, V , T ) = U − TS and the canonical ensemble The Helmholtz free energy describes a closed, isochoric, isothermal assembly, so it is a function of temperature, volume, and number of molecules: dA = −SdT − PdV + µdN, (6a) S = − ( ∂A ∂T ) V ,N , (6b) P = − ( ∂A ∂V ) T ,N , (6c) µ = ( ∂A ∂N ) T ,V . (6d) The Maxwell relations for the Helmholtz free energy are ( ∂S ∂V ) T ,N = ( ∂P ∂T ) V ,N , (7a) ( ∂S ∂N ) T ,V = − ( ∂µ ∂T ) V ,N , (7b) ( ∂P ∂N ) T ,V = − ( ∂µ ∂V ) T ,N . (7c) The Helmholtz free energy is determined from the canonical partition function QN (V , T ) = Tr (exp(−βH )) = ∫ e−βU { 1 1U 0(N, V , U; 1U)} dU. (8) The Helmholtz free energy is given by A(N, V , T ) = −kT ln QN (V , T ). (9) Appendix H 679 Thermodynamic potential 5(µ, V , T ) = −A + µN = PV and the grand canonical ensemble The thermodynamic potential describes an open, isochoric, isothermal assembly, so it is a function of temperature, volume, and chemical potential: d5 = SdT + PdV + Ndµ , (10a) S = ( ∂5 ∂T ) V ,µ , (10b) P = ( ∂5 ∂V ) T ,µ , (10c) N = ( ∂5 ∂µ ) T ,V . (10d) The Maxwell relations for the thermodynamic potential are ( ∂S ∂V ) T ,µ = ( ∂P ∂T ) V ,µ , (11a) ( ∂S ∂µ ) T ,V = ( ∂N ∂T ) V ,µ , (11b) ( ∂P ∂µ ) T ,V = ( ∂N ∂V ) T ,µ . (11c) The thermodynamic potential is a function only of a single extensive quantity, V , so 5(µ, V , T ) = P(µ, T )V , that is, the pressure is the thermodynamic potential per unit volume. Therefore, we can write simpler thermodynamic relations in terms of pressure P, entropy density s = S/V , and number density n = n/V : dP = sdT + ndµ , (12a) s = ( ∂P ∂T ) µ , (12b) n = ( ∂P ∂µ ) T , (12c) ( ∂s ∂µ ) T = ( ∂n ∂T ) µ . (12d) The thermodynamic potential and pressure are determined from the grand canonical partition function Q(µ, V , T ) = Tr (exp(−βH + βµN) ) = ∞∑ N=0 eβµN QN (V , T ), (13) 680 Appendices with the result P(µ, T ) = 5(µ, V , T ) V = kT V ln Q(µ, V , T ). (14) Gibbs free energy G(N, P, T ) = A + PV = U − TS + PV = µN and the isobaric ensemble The Gibbs free energy describes a closed, isobaric, isothermal assembly, so it is a function of temperature, pressure, and number of molecules: dG = −SdT + VdP + µdN, (15a) S = − ( ∂G ∂T ) P,N , (15b) V = ( ∂G ∂P ) T ,N , (15c) µ = ( ∂G ∂N ) T ,P . (15d) The Maxwell relations for the Gibbs free energy are ( ∂S ∂P ) T ,N = − ( ∂V ∂T ) P,N , (16a) ( ∂S ∂N ) T ,P = − ( ∂µ ∂T ) P,N , (16b) ( ∂V ∂N ) T ,P = ( ∂µ ∂P ) T ,N . (16c) The Gibbs free energy is a function only of a single extensive quantity, N, so G(N, P, T ) = Nµ(P, T ), that is, the chemical potential is the Gibbs free energy per particle. Therefore, we can write sim- pler thermodynamic relations in terms of the pressure P, entropy per particle s = S/N, and speciﬁc volume v = V /N: dµ = −sdT + vdP, (17a) s = − ( ∂µ ∂T ) P , (17b) v = ( ∂µ ∂P ) T , (17c) ( ∂s ∂P ) T = − ( ∂v ∂T ) P . (17d) The Gibbs free energy and the chemical potential are determined from the isobaric partition function YN (P, T ) = Tr ( exp(−βH − βPV ) ) = 1 λ3 ∞∫ 0 e−βPV QN (V , T )dV ; (18) Appendix H 681 the cube of the thermal deBroglie wavelength is employed here to make the partition function dimensionless and is irrelevant in the classical thermodynamic limit. This leads us to the result G(N, P, T ) = Nµ(P, T ) = −kT ln YN (P, T ). (19) The isobaric ensemble is often used in computer simulations to avoid two-phase regions that are present at ﬁrst-order phase transitions. Internal Energy U(N, V , S) The internal energy describes a closed, isochoric, adiabatic assembly, so it is a function of entropy, volume, and number of molecules: dU = TdS − PdV + µdN, (20a) T = ( ∂U ∂S ) V ,N , (20b) P = − ( ∂U ∂V ) S,N , (20c) µ = ( ∂U ∂N ) S,V . (20d) Maxwell relations for the internal energy are ( ∂T ∂V ) S,N = − ( ∂P ∂S ) V ,N , (21a) ( ∂T ∂N ) S,V = ( ∂µ ∂S ) V ,N , (21b) ( ∂P ∂N ) S,V = − ( ∂µ ∂V ) S,N . (21c) Enthalpy H(N, P, S) = U + PV The enthalpy describes a closed, isobaric, adiabatic assembly, so it is a function of entropy, pressure, and number of molecules. dH = TdS + VdP + µdN, (22a) T = ( ∂H ∂S ) P,N , (22b) V = ( ∂H ∂P ) S,N , (22c) µ = ( ∂H ∂N ) S,P . (22d) 682 Appendices The Maxwell relations for the enthalpy are ( ∂T ∂P ) S,N = ( ∂V ∂S ) P,N , (23a) ( ∂T ∂N ) S,P = ( ∂µ ∂S ) P,N , (23b) ( ∂V ∂N ) S,P = ( ∂µ ∂P ) S,N . (23c) This assembly is often used by chemists to describe chemical reactions that take place rapidly in the laboratory at ﬁxed pressure where the speed of the reaction is too fast to allow a substantial heat exchange with the environment. Magnetic free energy F(T , H) = U(S, M) − TS − HM The magnetic free energy describes a system with a ﬁxed number of magnetic dipoles, at tempera- ture T and magnetic ﬁeld H. The thermodynamic relations and Maxwell relations are dF = −SdT − MdH, (24a) S = − ( ∂F ∂T ) H , (24b) M = − ( ∂F ∂H ) T , (24c) ( ∂S ∂H ) T = ( ∂M ∂T ) H . (24d) This assembly is deﬁned by the ﬁxed-ﬁeld canonical ensemble where the canonical partition function for spins {si} with dipole moment µ and exchange energies Jij is QN (T , H) = Tr (exp(−βH)) = ∑ {s} exp   ∑ (i,j) Kijsi · sj + h ∑ i sz,i  , (25) where the coupling constants are Kij = Jij/kT and the ﬁeld coupling is h = µH/kT . The magnetic free energy is then given by F(T , H) = −kT ln QN (T , H). (26) Convexity and variances The convexity of the entropy S that follows from the second law of thermodynamics requires that all second derivatives of free energies have a unique sign. These derivatives are all proportional to variances of different statistical quantities. A few important examples are the heat capacity, the Appendix I 683 isothermal compressibility, and the magnetic susceptibility: CV = T ( ∂S ∂T ) V ,N = − ( ∂ 2A ∂T 2 ) V ,N = 〈 H 2〉 − ⟨H⟩2 kT 2 ≥ 0, (27) κT = 1 n2 ( ∂n ∂µ ) T = 1 n2 ( ∂ 2P ∂µ2 ) T = ( 1 nkT ) 〈 N 2〉 − ⟨N⟩2 ⟨N⟩ ≥ 0, (28) χT = ( ∂M ∂H ) T = − ( ∂ 2F ∂H 2 ) T = 〈 M 2〉 − ⟨M⟩2 kT ≥ 0. (29) I Pseudorandom numbers The random numbers used in computer simulations are not truly random but rather pseudorandom. They are intended to display as many of the characteristics of a random sequence as possible but are generated using simple integer algorithms. “Anyone who considers arithmetical methods of producing random digits is, of course, in a state of sin. For, as has been pointed out several times, there is no such thing as a random number — there are only methods to produce random numbers, and a strict arithmetic procedure of course is not such a method” (von Neumann, 1951). von Neumann’s quip was not intended to dissuade the use of pseudorandom numbers but rather to encourage users to understand how such numbers are generated, their statistical properties and potential weaknesses. Pseudorandom number generators are essential in computer simulations in many ﬁelds but a generator should not blindly be trusted unless it has been thoroughly tested. There is an extensive literature on theoretical methods for creating and empirically testing pseudorandom number generators; see Knuth (1997), L’Ecuyer (1988, 1999), and Press et al. (2007). The most commonly used and tested classes of pseudorandom number generators are based on integer arithmetic modulo large, usually prime, numbers. The simplest class of generators is the prime modulus linear congruential method that generates pseudo- random numbers in the range [1, 2, . . . , m − 1], where m is a prime number. Each new number is based on the previous number according to the formula rj = a rj−1mod m, (1) where the multiplier a is a carefully chosen and empirically tested integer less than m. If a is chosen properly, the generator will produce a sequence of integers that includes every integer in the range [1, 2, . . . , m − 1] exactly once before the sequence begins to repeat after m − 1 calls to the generator. Pseudorandom ﬂoating-point numbers in the open range (0, 1) are produced by a ﬂoating-point multiplication by m−1. This produces a uniformly distributed set of ﬂoating-point numbers on a comb of m − 1 values between zero and one. The ﬂoating-point numbers 0.0 and 1.0 will not appear in the sequence. Often, in imple- mentations, the modulus chosen is less than 231 to allow for the integers to be represented 684 Appendices by four-byte words. Generators of this form will repeat after about two billion calls. This may be ﬁne for some applications but is often inadequate for a scientiﬁc code. Even a modest simulation can exhaust such a simple generator. However, linear congruential gen- erators with different moduli and multipliers can be combined to give much longer periods and less statistical correlation (L’Ecuyer, 1988). The following algorithm to generate a uni- formly distributed pseudorandom ﬂoating-point number r using two linear congruential generators gives a much longer sequence before repeating than does a single generator. ALGORITHM qj = a1 qj−1 mod m1 sj = a2 sj−1 mod m2 z = (qj − sj) if z ≤ 0, then z = z + m1 − 1 r = z m −1 1 The length of the period of the combined generator is equal to the product of the non- common prime factors of m1 − 1 and m2 − 1. L’Ecuyer (1988) recommended the follow- ing multiplers and moduli: m1 = 2147483563 = 231 − 85, a1 = 40014, m2 = 2147483399 = 231 − 249, and a2 = 40692. The two individual generators do well on the spectral test and other tests of correlations (Knuth, 1997) and (m1 − 1)/2 and (m2 − 1)/2 are relatively prime, so the period of the generator is 2.3 × 1018. This can be implemented very easily in high- level languages using IEEE double precision ﬂoating-point arithmetic since aimi < 253. L’Ecuyer (1988) and Press et al. (2007) also showed how the generators can be imple- mented using four-byte integer arithmetic. The exact order of the pseudorandom numbers can also be shufﬂed to improve statistics (Bays and Durham, 1976). There are several other classes of pseudorandom number algorithms and many good generators available that have been extensively tested in the computing literature and are in wide use in the scientiﬁc literature; for summaries, see Newman and Barkema (1999), Gentle (2003), and Landau and Binder (2009). However, note that subtle correlations in a pseudorandom sequence can produce very large deviations compared to exact results, so care is warranted; see Ferrenberg, Landau, and Wong (1992), Beale (1996), and Figure I.1. Different classes of generators have different correlation properties, so substituting a gen- erator based on a different algorithm can sometimes be a useful strategy for testing a computer code. Gaussian distributed pseudorandom numbers One often needs pseudorandom numbers that are drawn from a Gaussian distribu- tion centered at the origin with unit variance: P(g) = exp (−g2/2 ) /√ 2π . The following algorithm for generating Gaussian-distributed pseudorandom numbers from pairs of uniformly distributed pseudorandom numbers is based on an algorithm by Box and Muller (1958). Appendix I 685 10\u00022 10\u00023 10\u00024 10\u00025 10\u00026 50 100 150 (a) (b) 200 250 k kPk 20 10 0 \u000210 \u000220 \u0002300 50 100 150 200 250 300Deviation/uncertainty Feed-back shift-register Numerical recipes’ ran2( ) FIGURE I.1 (a) The exact energy distribution for a 32 × 32 Ising lattice at the critical temperature (solid line) and the distribution calculated from 10 7 conﬁgurations using the Wolff Monte Carlo algorithm with the R250 feedback shift-register pseudorandom number generator (error bars).5 The distribution calculated using the Wolff algorithm with Numerical Recipes ran2( ) (Press et al., 2007) is also shown, but is almost indistinguishable from the exact solid curve on this scale. (b) Deviation of the Monte Carlo results from the exact distribution in units of the statistical uncertainty of each point. The +′s indicate the ran2( ) results and the ×′s indicate the feedback shift-register results. The χ 2-value for the two cases yields χ 2 = 190 for 210 nonzero points and χ 2 = 2.8 × 10 4 for 217 nonzero points, giving deviations of −0.95σ and 1300σ , respectively; see Section 13.4.A and Beale (1996). ALGORITHM To generate pairs of Gaussian pseudorandom numbers g1 and g2 from uniformly dis- tributed pseudorandom numbers x and y. REPEAT x = 2 rand() − 1.0 y = 2 rand() − 1.0 s = x2 + y2 UNTIL s < 1 w = √ −2 ln s s g1 = x w g2 = y w 5An example of a widely used and trusted pseudorandom number generator whose subtle correlations have been shown to adversely affect the results of some MC simulations is the R250 feedback shift-register generator. R250 gener- ates a pseudorandom positive four-byte integer 0 ≤ ri < 231 by taking an exclusive or of two previous random integers kept in a 250 element table: ri = ri−103 ∧ rj−250. As with other generators, the ﬂoating-point numbers on [0, 1] are pro- duced by dividing the pseudorandom integer by 231. This particular feedback shift-register algorithm is very fast and produces fairly uncorrelated random pairs 〈 rkrk−i〉 = 1/4 for i ̸= 0. Triplets are also uncorrelated 〈rkrk−irk−j〉 = 1/8, except for one particular triplet correlation, ⟨rkrk−103rk−250⟩, which can be shown to give (6/7)(1/8) rather than the correct value of 1/8; see Heuer, Dunweg, and Ferrenberg (1997). All higher order correlations that involve these same triplets are sim- ilarly affected. This triplet correlation being off by 14% can greatly affect Monte Carlo results (Ferrenberg, Landau, and Wong, 1992; Beale, 1996). Bibliography Abe, R. (1972). Prog. Theor. Phys. Japan 48, 1414. Abe, R. (1973). Prog. Theor. Phys. Japan 49, 113, 1851. Abe, R., and Hikami, S. (1973). Prog. Theor. Phys. Japan 49, 442. Abraham, D. B. (1986). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 10, pp. 1–74. Abramowitz, M., and Stegun, I. A. (eds.) (1964). Handbook of Mathematical Functions (National Bureau of Standards, Washington, DC). Abrikosov, A. A., Gorkov, L. P., and Dzyaloshinskii, I. Y. (1965). Quantum Field Theoretical Methods in Statistical Physics (Pergamon Press, Oxford). Abrikosov, A. A., and Khalatnikov, I. M. (1957). J. Exptl. Theoret. Phys. USSR 33, 1154; English transl. Soviet Phys. JETP 6, 888 (1958). Adare, A., et al. (2010). Phys. Rev. Lett. 104, 132301. Aharony, A. (1976). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 6, pp. 357–424. Ahlers, G. (1980). Rev. Mod. Phys. 52, 489. Alder, B. J., and Wainwright, T. E. (1957). J. Chem. Phys. 27, 1208. Alder, B. J., and Wainwright, T. E. (1959). J. Chem. Phys. 31, 459. Allen, M. B., and Tildesley, D. J. (1990). Computer Simulations of Liquids, 2nd ed. (Oxford University Press, Oxford). Allen, S., and Pathria, R. K. (1989). Can. J. Phys. 67, 952. Allen, S., and Pathria, R. K. (1991). Can. J. Phys. 69, 753. Alpher, R. A., Bethe, H. A., and Gamow, G. (1948). Phys. Rev. 73, 803. Alpher, R. A., and Herman, R. C. (1948). Nature 162, 774. Alpher, R. A., and Herman, R. C. (1950). Rev. Mod. Phys. 22, 153. Alpher, R. A., and Herman, R. C. (2001). Genesis of the Big Bang (Oxford University Press, New York). Als-Nielsen, J. (1976). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 5a, pp. 87–164. Als-Nielsen, J., and Birgeneau, R. J. (1977). Am. J. Phys. 45, 554. Anderson, M. H., Ensher, J. R., Matthews, M. R., Wieman, C. E., and Cornell, E. E. (1995). Science 269, 198. Anderson, P. W. (1984). Basic Notions of Condensed Matter Physics (Benjamin/Cummings, Menlo Park, CA). Anderson, W. (1929). Z. Phys. 56, 851. Arnold, V. I. (1963). Russian Math. Survey 18, 13. Ashcroft, N. W., and Mermin, N. D. (1976). Sold State Physics (Holt, Rinehart, & Winston, New York). Auluck, F. C., and Kothari, D. S. (1946). Proc. Camb. Phil. Soc. 42, 272. Traveling Wave Analysis of Partial Differential Equations © 2011 Elsevier Ltd. All rights reserved. 687 688 Bibliography Au-Yang, H., and Perk, J. H. H. (1984). Phys. Lett. A 104, 131. Bagnato, V., Pritchard, D. E., and Kleppner, D. (1987). Phys. Rev. A 35, 4354. Bahm, C. J., and Pethick, C. J. (1996). Phys. Rev. Lett. 76, 6. Bak, P., Krinsky, S., and Mukamel, D. (1976). Phys. Rev. Lett. 36, 52. Baker, G. A., Jr. (1990). Quantitative Theory of Critical Phenomena (Academic Press, New York). Balian, R., and Toulouse, G. (1973). Phys. Rev. Lett. 30, 544. Baltes, H. P., and Hilf, E. R. (1976). Spectra of Finite Systems (Bibliographisches Institut AG, Z ¨urich). Band, W. (1955). An Introduction to Quantum Statistics (Van Nostrand, Princeton). Barber, M. N. (1983). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 8, pp. 145–266. Barber, M. N., and Fisher, M. E. (1973). Ann. Phys. (N.Y.) 77, 1. Bardeen, J., Cooper, L. N., and Schrieffer, J. R. (1957). Phys. Rev. 108, 1175. Barnett, S. J. (1944). Proc. Am. Acad. Arts & Sci. 75, 109. Barouch, E., McCoy, B. M., and Wu, T. T. (1973). Phys. Rev. Lett. 31, 1409. Baxter, R. J. (1982). Exactly Solved Models in Statistical Mechanics (Academic Press, London). Bays, C., and Durham, S. D. (1976). ACM Trans. Math. Software 2, 59. Beale, P. D. (1996). Phys. Rev. Lett. 76, 79. Belinfante, F. J. (1939). Physica 6, 849, 870. Berche, B., Sanchez, A. I. F., and Paredes, V. (2002). Europhys. Lett. 60, 539. Berezinskii, V. (1970). Zh. Eksp. Teor. Fiz. 59, 907; (1971) Engl. transl. Sov. Phys., JETP 32, 493. Berlin, T. H., and Kac, M. (1952). Phys. Rev. 86, 821. Bernoulli, D. (1738). Hydrodynamica (Argentorati). Beth, E., and Uhlenbeck, G. E. (1937). Physica 4, 915. Bethe, H. A. (1935). Proc. R. Soc. Lond. A 150, 552. Betts, D. D. (1974). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 3, pp. 569–652. Betts, D. D., and Lee, M. H. (1968). Phys. Rev. Lett. 20, 1507. Betts, D. D. et al. (1969). Phys. Lett. 29A, 150; (1970) ibid. 32A, 152. Betts, D. D. et al. (1970). Can. J. Phys. 48, 1566; (1971) ibid. 49, 1327; (1973) ibid. 51, 2249. Betts, D. S. (1969). Contemp. Phys. 10, 241. Bijl, A. (1940). Physica 7, 869. Binder, K. (1983). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 8, pp. 1–144. Binder, K. (ed.) (1986). Monte Carlo Methods in Statistical Physics, 2nd ed., Topics in Current Physics (Springer-Verlag, Berlin), Vol. 7. Binder, K. (ed.) (1987). Applications of the Monte Carlo Method in Statistical Physics, 2nd ed., Topics in Current Physics (Springer-Verlag, Berlin), Vol. 36. Binder, K. (ed.) (1992). The Monte Carlo Method in Condensed Matter Physics, Topics in Applied Physics (Springer-Verlag, Berlin), Vol. 71. Binder, K., and Heermann, D. W. (2002). Monte Carlo Simulation in Statistical Physics, 4th ed., (Springer- Verlag, Berlin). Bibliography 689 Blakemore, J. S. (1962). Semiconductor Statistics (Pergamon Press, Oxford). Bloch, F. (1928). Z. Phys. 52, 555. Bogoliubov, N. N. (1947). J. Phys. USSR 11, 23. Bogoliubov, N. N. (1962). Phys. Abhandl. S.U. 6, 113. Bogoliubov, N. N. (1963). Lectures on Quantum Statistics (Gordon & Breach, New York). Boltzmann, L. (1868). Wien. Ber. 58, 517. Boltzmann, L. (1871). Wien. Ber. 63, 397, 679, 712. Boltzmann, L. (1872). Wien. Ber. 66, 275. Boltzmann, L. (1875). Wien. Ber. 72, 427. Boltzmann, L. (1876). Wien. Ber. 74, 503. Boltzmann, L. (1877). Wien. Ber. 76, 373. Boltzmann, L. (1879). Wien. Ber. 78, 7. Boltzmann, L. (1884). Ann. Phys. 22, 31, 291, 616. Boltzmann, L. (1896, 1898). Vorlesungen ¨uber Gastheorie, 2 vols. (J. A. Barth, Leipzig). English transl. (1964) Lectures on Gas Theory (University of California Press, Berkeley, CA). Boltzmann, L. (1899). Amsterdam Ber. 477; see also (1909) Wiss. Abhandl. von L. Boltzmann III, 658. Borner, G. (2003). The Early Universe (Springer, New York). Bose, S. N. (1924). Z. Physik 26, 178. Box, G. E. P., and Muller, M. E. (1958). Ann. Math. Stat. 29, 610. Bragg, W. L., and Williams, E. J. (1934). Proc. R. Soc. Lond. A 145, 699. Bragg, W. L., and Williams, E. J. (1935). Proc. R. Soc. Lond. A 151, 540; 152, 231. Br´ezin, E., le Guillou, J. C., and Zinn-Justin, J. (1976). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 6, pp. 125–247. Brueckner, K. A., and Gammel, J. L. (1958). Phys. Rev. 109, 1040. Brueckner, K. A., and Sawada, K. (1957). Phys. Rev. 106, 1117, 1128. Brush, S. G. (1957). Ann. Sci. 13, 188, 273. Brush, S. G. (1958). Ann. Sci. 14, 185, 243. Brush, S. G. (1961a). Am. J. Phys. 29, 593. Brush, S. G. (1961b). Am. Scientist 49, 202. Brush, S. G. (1965–66). Kinetic Theory, 3 vols. (Pergamon Press, Oxford). Brush, S. G. (1967). Rev. Mod. Phys. 39, 883. Buckingham, M. J., and Gunton, J. D. (1969). Phys. Rev. 178, 848. Bush, V., and Caldwell, S. H. (1931). Phys. Rev. 38, 1898. Callen, H. B., and Welrton, T. R. (1951). Phys. Rev. 83, 34. Cardy, J. L. (1987). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 11, pp. 55–126. Cardy, J. L. (ed.) (1988). Finite-Size Scaling (North-Holland, Amsterdam). Carnahan, N. F., and Starling, J. (1969). J. Chem. Phys. 51, 635. Chaba, A. N., and Pathria, R. K. (1973). Phys. Rev. A 8, 3264. Chaba, A. N., and Pathria, R. K. (1975). Phys. Rev. B 12, 3697. 690 Bibliography Chandrasekhar, S. (1939). Introduction to the Study of Stellar Structure (University of Chicago Press, Chicago); now available in a Dover edition. Chandrasekhar, S. (1943). Rev. Mod. Phys. 15, 1. Chandrasekhar, S. (1949). Rev. Mod. Phys. 21, 383. Chang, C. H. (1952). Phys. Rev. 88, 1422. Chang, T. S. (1939). Proc. Camb. Phil. Soc. 35, 265. Chapman, S. (1916). Trans. R. Soc. Lond. A 216, 279. Chapman, S. (1917). Trans. R. Soc. Lond. A 217, 115. Chapman, S., and Cowling, T. G. (1939). The Mathematical Theory of Non-uniform Gases (Cambridge University Press, Cambridge, UK). Chisholm, J. S. R., and Borde, A. H. (1958). An Introduction to Statistical Mechanics (Pergamon Press, New York). Chr´etien, M., Gross, E. P., and Deser, S. (eds.) (1968). Statistical Physics, Phase Transitions and Superﬂuidity, 2 vols. (Gordon & Breach, New York). Clausius, R. (1857). Ann. Phys. 100, 353; also published in (1857) Phil. Mag. 14, 108. Clausius, R. (1859). Ann. Phys. 105, 239; also published in (1859) Phil. Mag. 17, 81. Clausius, R. (1870). Ann. Phys. 141, 124; also published in (1870) Phil. Mag. 40, 122. Clunie, J. (1954). Proc. Phys. Soc. A 67, 632. Cohen, E. G. D., and van Leeuwen, J. M. J. (1960). Physica 26, 1171. Cohen, E. G. D., and van Leeuwen, J. M. J. (1961). Physica 27, 1157. Cohen, E. G. D. (ed.) (1962). Fundamental Problems in Statistical Mechanics (John Wiley, New York). Cohen, M., and Feynman R. P. (1957). Phys. Rev. 107, 13. Compton, A. H. (1923a). Phys. Rev. 21, 207, 483. Compton, A. H. (1923b). Phil. Mag. 46, 897. Cooper, L. N. (1956). Phys. Rev. 104, 1189. Cooper, L. N. (1960). Am. J. Phys. 28, 91. Copi, C. J., Schramm, D. N., and Turner, M. S. (1997). Phys. Rev. D. 55, 3389. Corak, W. S., Garfunkel, M. P., Satterthwaite, C. B., and Wexler, A. (1955). Phys. Rev. 98, 1699. Cummins, H. Z., and Gammon, R. W. (1966). J. Chem. Phys. 44, 2785. Darwin, C. G., and Fowler, R. H. (1922a). Phil. Mag. 44, 450, 823. Darwin, C. G., and Fowler, R. H. (1922b). Proc. Camb. Phil. Soc. 21, 262. Darwin, C. G., and Fowler, R. H. (1923). Proc. Camb. Phil. Soc. 21, 391, 730; see also Fowler, R. H. (1923) Phil. Mag. 45, 1, 497; (1925) Proc. Camb. Phil. Soc. 22, 861; (1926) Phil. Mag. 1, 845; (1926) Proc. R. Soc. Lond. A 113, 432. Davis, K. B., Mewes, M.-O., Andrews, M. R., van Druten, N. J., Durfee, D. S., Kurn, D. M., and Ketterle, W. (1995). Phys. Rev. Lett. 75, 3969. Debye, P. (1912). Ann. Phys. 39, 789. de Gennes, P.-G. (1972). Phys. Lett. 38A, 339. de Gennes, P.-G. (1979). Scaling Concepts in Polymer Physics (Cornell University Press, Ithaca, NY). de Groot, S. R. (1951). Thermodynamics of Irreversible Processes (North-Holland, Amsterdam). de Groot, S. R., and Mazur, P. (1962). Non-equilibrium Thermodynamics (North-Holland, Amsterdam). Bibliography 691 de Groot, S. R., Hooyman, G. J., and ten Seldam, C. A. (1950). Proc. R. Soc. London A, 203, 266. de Klerk, D., Hudson, R. P., and Pellam, J. R. (1953). Phys. Rev. 89, 326, 662. DeMarco, B., and Jin, D. (1999). Science 285, 1703. Dennison, D. M. (1927). Proc. R. Soc. Lond. A 115, 483. des Cloizeaux, J. (1974). Phys. Rev. A 10, 1665. des Cloizeaux, J. (1982). In Phase Transitions: Cargese 1980, eds. M. Levy et al. (Plenum Press, New York), pp. 371–394. Diehl, H. W. (1986). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 10, pp. 75–267. Dingle, R. B. (1956). J. App. Res. B 6, 225. Dirac, P. A. M. (1926). Proc. R. Soc. Lond. A 112, 661, 671. Dirac, P. A. M. (1929). Proc. Camb. Phil. Soc. 25, 62. Dirac, P. A. M. (1930). Proc. Camb. Phil. Soc. 26, 361, 376. Dirac, P. A. M. (1931). Proc. Camb. Phil. Soc. 27, 240. Domb, C. (1960). Advan. Phys. 9, 150. Domb, C. (1974). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 3, pp. 357–484. Domb, C. (1985). Contemp. Phys. 26, 49. Domb, C., and Green, M. S. (eds.) (1972–1976). Phase Transitions and Critical Phenomena (Academic Press, London), Vols. 1–6. Domb, C., and Hunter, D. L. (1965). Proc. Phys. Soc. 86, 1147. Domb, C., and Lebowitz, J. L. (eds.) (1983–1992). Phase Transitions and Critical Phenomena (Academic Press, London), Vols. 7–15. Drude, P. (1900). Ann. Phys. 1, 566; 3, 369. Dukovski, I., Machta, J., and Chayes, L. (2002). Phys. Rev. E 65, 026702. Ehrenfest, P. (1905). Wiener Ber. 114, 1301. Ehrenfest, P. (1906). Phys. Zeits. 7, 528. Ehrenfest, P., and Ehrenfest, T. (1912). Enzyklop¨adie der mathematischen Wissenschaften, Vol. IV (Teubner, Leipzig). English transl. (1959) The Conceptual Foundations of the Statistical Approach in Mechanics (Cornell University Press, Ithaca, NY). Einstein, A. (1902). Ann. Phys. 9, 417. Einstein, A. (1903). Ann. Phys. 11, 170. Einstein, A. (1905a). Ann. Phys. 17, 132; see also (1906b) ibid. 20, 199. Einstein, A. (1905b). Ann. Phys. 17, 549; see also (1906a) ibid. 19, 289, 371. Einstein, A. (1905c). Ann. Phys. 17, 891; see also (1905d) ibid. 18, 639 and (1906c) ibid. 20, 627. Einstein, A. (1907). Jb. Radioakt. 4, 411. Einstein, A. (1909). Physik Z. 10, 185. Einstein, A. (1910). Ann. Phys. 33, 1275. Einstein, A. (1924). Berliner Ber. 22, 261. Einstein, A. (1925). Berliner Ber. 1, 3. 692 Bibliography Eisenschitz, R. (1958). Statistical Theory of Irreversible Processes (Oxford University Press, Oxford). Elcock, E. W., and Landsberg, P. T. (1957). Proc. Phys. Soc. 70, 161. Ensher, J. R., Jin, D. S., Matthews, M. R., Wieman, C. E., and Cornell, E. A. (1996). Phys. Rev. Lett. 77, 4984. Enskog, D. (1917). Kinetische Theorie der Vorg¨ange in m¨assig verd ¨unnten Gasen, dissertation (Almquist & Wiksell, Uppsala). Eyring, H., Henderson, D., Stover, B. J., and Eyring, E. M. (1963). Statistical Mechanics and Dynamics (John Wiley, New York). Ezawa, Z. F. (2000). Quantum Hall Effects: Field Theorectical Approach and Related Topics (World Scientiﬁc, Singapore). Farquhar, I. E. (1964). Ergodic Theory in Statistical Mechanics (Interscience Publishers, New York). Fay, J. A. (1965). Molecular Thermodynamics (Addison-Wesley, Reading, MA). Fedosov, B. V. (1963). Dokl. Akad. Nauk SSSR 151, 786; English transl. 1963: Sov. Math. (Doklady) 4, 1092. Fedosov, B. V. (1964). Dokl. Akad. Nauk SSSR 157, 536; English transl. 1964: Sov. Math. (Doklady) 5, 988. Ferdinand, A. E., and Fisher, M. E. (1969). Phys. Rev. 185, 832. Fermi, E. (1926). Z. Physik 36, 902. Fermi, E. (1928). Zeit. f ¨ur Phys. 48, 73; see also (1927) Ace. Lencei 6, 602. Fermi, E. (1936). Thermodynamics (Dover, New York). Fermi, E., Pasta, J. G., and Ulam, S. M. (1955). LASL Report LA-1940. Ferrenberg, A. M., Landau, D. P., and Wong, Y. J. (1992). Phys. Rev. Lett. 69, 3382. Ferrenberg, A. M., and Swendsen, R. H. (1988). Phys. Rev. Lett. 61, 2635. Fetter, A. L. (1963). Phys. Rev. Lett. 10, 507. Fetter, A. L. (1965). Phys. Rev. 138, A 429. Feynman, R. P. (1953). Phys. Rev. 91, 1291, 1301. Feynman, R. P. (1954). Phys. Rev. 94, 262. Feynman, R. P. (1955). Progress in Low Temperature Physics, ed. C. J. Gorter (North-Holland, Amsterdam), Vol. 1, p. 17 Feynman, R. P., and Cohen, M. (1956). Phys. Rev. 102, 1189. Fisher, M. E. (1959). Physica 25, 521. Fisher, M. E. (1964). J. Math. Phys. 5, 944. Fisher, M. E. (1967). Rep. Prog. Phys. 30, 615. Fisher, M. E. (1969). Phys. Rev. 180, 594. Fisher, M. E. (1972). In Essays in Physics, eds. G. K. T. Conn and G. N. Fowler (Academic Press, London), Vol. 4, pp. 43–89. Fisher, M. E. (1973). Phys. Rev. Lett. 30, 679. Fisher, M. E. (1983). In Critical Phenomena, ed. F. J. W. Hahne (Springer-Verlag, Berlin), pp. 1–139. Fisher, M. E., Barber, M. N., and Jasnow, D. (1973). Phys. Rev. A 8, 1111. Fisher, M. E., and Privman, V. (1985). Phys. Rev. B 32, 447. Fixsen, D. J., Cheng, E. S., Gales, J. M., Mather, J. C., Shafer, R. A., and Wright, E. L. (1996). Astrophys. J. 473, 576. Fokker, A. D. (1914). Ann. Phys. 43, 812. Bibliography 693 Forster, D. (1975). Hydrodynamic Fluctuations, Broken Symmetry, and Correlation Functions (W. A. Benjamin, Reading, MA). Fowler, R. H. (1926). Mon. Not. R. Astron. Soc. 87, 114. Fowler, R. H. (1955). Statistical Mechanics, 2nd ed. (Cambridge University Press, Cambridge, UK). Fowler, R. H., and Guggenheim, E. A. (1940). Proc. R. Soc. Lond. A 174, 189. Fowler, R. H., and Guggenheim, E. A. (1960). Statistical Thermodynamics (Cambridge University Press, Cambridge, UK). Fowler, R. H., and Nordheim, L. (1928). Proc. R. Soc. Lond. A 119, 173. Freedman, W. L., Madore, B. F., Gibson, B. K., Ferrarese, L., Kelson, D. D., Sakai, S., Mould, J. R., Kennicutt, R. C., Jr., Ford, H. C., Graham, J. A., Huchra, J. P., Hughes, S. M. G., Illingworth, G. D., Macri, L. M., and Stetson, P. B. (2001). Astrophys. J. 553, 47. Frenkel, D., and Smit, B. (2002). Molecular Simulation (Academic, New York). Friedmann, A. (1922). Z. Phys. 16, 377. Friedmann, A. (1924). Z. Phys. 21, 326. Fujiwara, I., ter Haar, D., and Wergeland, H. (1970). J. Stat. Phys. 2, 329. Galitskii, V. M. (1958). J. Exptl. Theor. Phys. USSR 34, 151; English transl. (1958) Soviet Physics JETP-USSR 7, 104–112. Gaunt, D. S., and Guttmann, A. J. (1974). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 3, pp. 181–243. Gelmini, G. B. (2005). Phys. Scr. T121, 131. Gentle, J. E. (2003). Random Number Generation and Monte Carlo Methods (Springer-Verlag, New York). Giardeau, M. (1960). J. Math. Phys. 1, 516. Gibbs, J. W. (1902). Elementary Principles in Statistical Mechanics (Yale University Press, New Haven); reprinted by Dover Publications, New York (1960). See also A Commentary on the Scientiﬁc Writings of J. Willard Gibbs, ed. A. Haas, Yale University Press, New Haven (1936), Vol. II. Ginzburg, V. L. (1960). Sov. Phys. Solid State 2, 1824. Glasser, M. L. (1970). Ann. J. Phys. 38, 1033. Goldman, I. I., Krivchenkov, V. D., Kogan V. I., and Galitskii V. M. (1960). Problems in Quantum Mechanics, translated by D. ter Haar (Academic Press, New York). Gomb´as, P. (1949). Die statistische Theorie des Atoms und ihre Anwendungen (Springer, Vienna). Gomb´as, P. (1952). Ann. Phys. 10, 253. Gradshteyn, I. S., and Ryzhik, I. M. (1965). Table of Integrals, Series and Products (Academic Press, New York). Green, H. S., and Hurst, C. A. (1964). Order–Disorder Phenomena (Interscience Publishers, New York). Greenspoon, S., and Pathria, R. K. (1974). Phys. Rev. A 9, 2103. Greiner, M., Regal, C. A., and Jin, D. S. (2003). Nature 426, 537. Grifﬁths, R. B. (1965a). Phys. Rev. Lett. 14, 623. Grifﬁths, R. B. (1965b). J. Chem. Phys. 43, 1958. Grifﬁths, R. B. (1970). Phys. Rev. Lett. 24, 715. Grifﬁths, R. B. (1972). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 1, pp. 7–109. 694 Bibliography Gross, E. P. (1961). Nuovo Cim. 20, 454. Gross, E. P. (1963). J. Math. Phys. 4, 195. Guggenheim, E. A. (1935). Proc. R. Soc. Lond. A 148, 304. Guggenheim, E. A. (1938). Proc. R. Soc. Lond. A 169, 134. Guggenheim, E. A. (1959). Boltzmann’s Distribution Law (North-Holland, Amsterdam). Guggenheim, E. A. (1960). Elements of the Kinetic Theory of Gases (Pergamon Press, Oxford). Gunton, J. D., and Buckingham, M. J. (1968). Phys. Rev. 166, 152. Gupta, H. (1947). Proc. Nat. Ins. Sci. India 13, 35. Gurarie, V., and Radzihovsky, L. (2007). Ann. Phys. 322, 2. Guttmann, A. J. (1989). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 13, pp. 1–234. Haber, H. E., and Weldon, H. A. (1981). Phys. Rev. Lett. 46, 1497. Haber, H. E., and Weldon, H. A. (1982). Phys. Rev. D 25, 502. Halperin, B. I., and Nelson, D. R. (1978). Phys Rev. Lett. 41, 121. Han, Y., Alsayed, A. M., Nobili, M., Zhang, J., Lubensky, T. C., and Yodh, A. G. (2006). Science 314, 626. Hanbury Brown, R., and Twiss, R. Q. (1956). Nature 177, 27; 178, 1447. Hanbury Brown, R., and Twiss, R. Q. (1957). Proc. R. Soc. Lond. A 242, 300; 243, 291. Hanbury Brown, R., and Twiss, R. Q. (1958). Proc. R. Soc. Lond. A 248, 199, 222. Hansen, J. P., and McDonald, I. R. (1986). Theory of Simple Liquids (Academic, New York). Harris, F. E., and Monkhorst, H. K. (1970). Phys. Rev. B 2, 4400. Harrison, S. F., and Mayer, J. E. (1938). J. Chem. Phys. 6, 101. Hasenbusch, M., and Pinn, K. (1997). J. Phys. A 30, 63. Haugerud, H., Haugest, T., and Ravndal, F. (1997). Phys. Lett. A 225, 18. Heisenberg, W. (1928). Z. Physik 49, 619. Heller, P. (1967). Rep. Prog. Phys. 30, 731. Henry, W. E. (1952). Phys. Rev. 88, 561. Henshaw, D. G. (1960). Phys. Rev. 119, 9. Henshaw, D. G., and Woods, A. D. B. (1961). Phys. Rev. 121, 1266. Herapath, J. (1821). Ann. Philos. 1, 273, 340, 401. Heuer, A., Dunweg, B., and Ferrenberg, A. M. (1997). Comp. Phys. Comm. 103, 1. Hill, T. L. (1953). J. Phys. Chem. 57, 324. Hill, T. L. (1956). Statistical Mechanics (McGraw-Hill, New York). Hill, T. L. (1960). Introduction to Statistical Thermodynamics (Addison-Wesley, Reading, MA). Hillebrandt, W., and Niemeyer, J. C. (2000). Annu. Rev. Astron. Astrophys. 38, 191. Hirschfelder, J. O., Curtiss, C. F., and Bird, R. B. (1954). Molecular Theory of Gases and Liquids (John Wiley, New York). Hohenberg, P. C., and Halperin, B. I. (1977). Rev. Mod. Phys. 49, 435. Holland, M., and Cooper, J. (1996). Phys. Rev. A 53, R1954. Holland, M. J., Jin, D. S., Chiofalo, M. L., and Cooper, J. (1997). Phys. Rev. Lett. 78, 3801. Bibliography 695 Holliday, D., and Sage, M. L. (1964). Ann. Phys. 29, 125. Huang, K. (1959). Phys. Rev. 115, 765. Huang, K. (1960). Phys. Rev. 119, 1129. Huang, K. (1963). Statistical Mechanics, 1st ed. (John Wiley, New York). Huang, K. (1987). Statistical Mechanics, 2nd ed. (John Wiley, New York). Huang, K., and Klein, A. (1964). Ann. Phys. 30, 203. Huang, K., and Yang, C. N. (1957). Phys. Rev. 105, 767. Huang, K., Yang, C. N., and Luttinger, J. M. (1957). Phys. Rev. 105, 776. Hupse, J. C. (1942). Physica 9, 633. Hurst, C. A., and Green, H. S. (1960). J. Chem. Phys. 33, 1059. Ising, E. (1925). Z. Physik 31, 253. Jackson, H. W., and Feenberg, E. (1962). Rev. Mod. Phys. 34, 686. Jackson, J. D. (1999). Electrodynamics, 3rd ed. (John Wiley, New York). Jasnow, D. (1986). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 10, pp. 269–363. Jeans, J. H. (1905). Phil. Mag. 10, 91. Jin, D. (2002). Phys. World 15, 27. Jochim, S., Bartenstein, M., Altmeyer, A., Hendl, G., Riedl, S., Chin, C., Denschlag, J. H., and Grimm, R. (2003). Science 302, 2101. Johnson, J. B. (1927a). Nature 119, 50. Johnson, J. B. (1927b). Phys. Rev. 29, 367. Johnson, J. B. (1928). Phys. Rev. 32, 97. Josephson, B. D. (1967). Proc. Phys. Soc. 92, 269, 276. Joule, J. P. (1851). Mem. Proc. Manchester Lit. Phil. Soc. 9, 107; also published in 1857, Phil. Mag. 14, 211. Joyce, G. S. (1972). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 2, pp. 375–442. Kac, M., and Thompson, C. J. (1971). Phys. Norveg. 5, 163. Kac, M., Uhlenbeck, G. E., and Hemmer, P. C. (1963). J. Math. Phys. 4, 216, 229; see also (1964) ibid. 5, 60. Kac, M., and Ward, J. C. (1952). Phys. Rev. 88, 1332. Kadanoff, L. P. (1966a). Nuovo Cim. 44, 276. Kadanoff, L. P. (1966b). Physics 2, 263. Kadanoff, L. P. (1976a). Ann. Phys. 100, 359. Kadanoff, L. P. (1976b). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 5a, pp. 1–34. Kadanoff, L. P. et al. (1967). Rev. Mod. Phys. 39, 395. Kahn, B. (1938). On the Theory of the Equation of State, Thesis, Utrecht; English translation appears in de Boer, J., and Uhlenbeck, G. E. (eds.) (1965) Studies in Statistical Mechanics, Vol. III (North-Holland, Amsterdam). Kahn, B., and Uhlenbeck, G. E. (1938). Physica 5, 399. Kalos, M. H., and Whitlock, P. A. (1986). Monte Carlo Methods (Wiley, New York). Kappler, E. (1931). Ann. Phys. 11, 233. 696 Bibliography Kappler, E. (1938). Ann. Phys. 31, 377, 619. Kasteleyn, P. W. (1963). J. Math. Phys. 4, 287. Katsura, S. (1959). Phys. Rev. 115, 1417. Kaufman, B. (1949). Phys. Rev. 76, 1232. Kaufman, B., and Onsager, L. (1949). Phys. Rev. 76, 1244. Kawatra, M. P., and Pathria, R. K. (1966). Phys. Rev. 151, 132. Keesom, P. H., and Pearlman, N. (1953). Phys. Rev. 91, 1354. Khalatnikov, I. M. (1965). Introduction to the Theory of Superﬂuidity (W. A. Benjamin, New York). Khintchine, A. (1934). Math. Ann. 109, 604. Kiess, E. (1987). Am. J. Phys. 55, 1006. Kilpatrick, J. E. (1953). J. Chem. Phys. 21, 274. Kilpatrick, J. E., and Ford, D. I. (1969). Am. J. Phys. 37, 881. Kim, E., and Chan, M. H. W. (2004). Nature 427, 225; (2004b) Science, 305, 1941. Kirkwood, J. G. (1965). Quantum Statistics and Cooperative Phenomena (Gordon & Breach, New York). Kirsten, K., and Toms, D. J. (1996) Phys. Rev. A 54, 4188. Kittel, C. (1958). Elementary Statistical Physics (John Wiley, New York). Kittel, C. (1969). Thermal Physics (John Wiley, New York). Klein, M. J., and Tisza, L. (1949). Phys. Rev. 76, 1861. Knobler, C. M., and Scott, R. L. (1984). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 9, pp. 163–231. Knuth, D. E. (1997). The Art of Computer Programming, Volume 2, Seminumerical Algorithms, 3rd ed. (Addison-Wesley, Reading, MA). Kolmogorov, A. N. (1954). Dokl. Akad. Nauk SSSR 98, 527. Komatsu, E., et al. (2010). Astrophys. J. (submitted): doi: arXiv.org/abs/1001.4538v3. Kosterlitz, J. M. (1974). J. Phys. C 7, 1046. Kosterlitz, J. M., and Thouless, D. J. (1972). J. Phys. C 5, L124. Kosterlitz, J. M., and Thouless, D. J. (1973). J. Phys. C 6, 1181. Kosterlitz, J. M., and Thouless, D. J. (1978). Prog. Low Temp. Phys. 78, 371. Kothari, D. S., and Auluck, F. C. (1957). Curr. Sci. 26, 169. Kothari, D. S., and Singh, B. N. (1941). Proc. R. Soc. Lond. A 178, 135. Kothari, D. S., and Singh, B. N. (1942). Proc. R. Soc. Lond. A 180, 414. Kramers, H. A. (1938). Proc. Kon. Ned. Akad. Wet. (Amsterdam) 41, 10. Kramers, H. A., and Wannier, G. H. (1941). Phys. Rev. 60, 252, 263. Kr¨onig, A. (1856). Ann. Phys. 99, 315. Kubo, R. (1956). Can. J. Phys. 34, 1274. Kubo, R. (1957). Proc. Phys. Soc. Japan 12, 570. Kubo, R. (1959). Some Aspects of the Statistical Mechanical Theory of Irreversible Processes, University of Colorado Lectures in Theoretical Physics (Interscience Publishers, New York), Vol. 1, p. 120. Kubo, R. (1965). Statistical Mechanics (Interscience Publishers, New York). Kubo, R. (1966). Rep. Prog. Phys. 29, 255. Bibliography 697 Landau, D. P., and Binder, K. (2009). Monte-Carlo Simulations in Statistical Physics, 3rd ed. (Cambridge University Press, New York). Landau, L. D. (1927). Z. Phys. 45, 430; reprinted in the Collected Papers of L. D. Landau, ed. D. ter Haar (Pergamon Press, Oxford), p. 8. Landau, L. D. (1930). Z. Phys. 64, 629. Landau, L. D. (1937). Phys. Z. Sowjetunion 11, 26. Landau, L. D. (1941). J. Phys. USSR 5, 71. Landau, L. D. (1947). J. Phys. USSR 11, 91. Landau, L. D. (1956). J. Exptl. Theoret. Phys. USSR 30, 1058; English transl. Soviet Physics JETP 3, 920. Landau, L. D., and Lifshitz, E. M. (1958). Statistical Physics (Pergamon Press, Oxford). Landau, L. D., and Placzek, G. (1934). Phys. Z. Sowjetunion 5, 172. Landsberg, P. T. (1954a). Proc. Natl. Acad. Sci. (U.S.A.) 40, 149. Landsberg, P. T. (1954b). Proc. Camb. Phil. Soc. 50, 65. Landsberg, P. T. (1961). Thermodynamics with Quantum Statistical Illustrations (Interscience Publishers, New York). Landsberg, P. T., and Dunning-Davies, J. (1965). Phys. Rev. 138, A1049; see also their article in the Statistical Mechanics of Equilibrium and Nonequilibrium (1965), ed. J. Meixner (North-Holland, Amsterdam). Langevin, P. (1905a). J. Phys. 4, 678. Langevin, P. (1905b). Ann. Chim. et Phys. 5, 70. Langevin, P. (1908). Comptes Rend. Acad. Sci. Paris 146, 530. Lawrie, I. D., and Sarbach, S. (1984). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 9, pp. 1–161. L’Ecuyer, P. (1988). Comm. ACM 31, 742. L’Ecuyer, P. (1999). Math. Comput. 68, 249. Lee, J. F., Sears, F. W., and Turcotte, D. L. (1963). Statistical Thermodynamics (Addison-Wesley, Reading, MA). Lee, T. D., Huang, K., and Yang, C. N. (1957). Phys. Rev. 106, 1135. Lee, T. D., and Yang, C. N. (1952). Phys. Rev. 87, 410; see also ibid. 404. Lee, T. D., and Yang, C. N. (1957). Phys. Rev. 105, 1119. Lee, T. D., and Yang, C. N. (1958). Phys. Rev. 112, 1419. Lee, T. D., and Yang, C. N. (1959a,b). Phys. Rev. 113, 1165; 116, 25. Lee, T. D., and Yang, C. N. (1960a,b,c). Phys. Rev. 117, 12, 22, 897. Leggett, A. J. (2006). Quantum Liquids (Oxford University Press, Oxford). Leib, E., and Liniger, W. (1963). Phys. Rev. 130, 1605. Lennard-Jones, J. E. (1924). Proc. R. Soc. Lond. A 106, 463. Lenz, W. (1920). Z. Physik 21, 613. Lenz, W. (1929). Z. Physik 56, 778. Levelt, J. M. H. (1960). Physica 26, 361. Lewis, H. W., and Wannier, G. H. (1952). Phys. Rev. 88, 682. Lieb, E. H., and Mattis, D. C. (1966). Mathematical Physics in One Dimension (Academic Press, New York). 698 Bibliography Lines, M. E., and Glass, A. M. (1977). Principles and Applications of Ferroelectrics and Related Materials (Clarendon Press, Oxford). Liouville, J. (1838). J. de Math. 3, 348. London, F. (1938a). Nature 141, 643. London, F. (1938b). Phys. Rev. 54, 947. London, F. (1954). Superﬂuids, Vols. 1 and 2 (John Wiley, New York); reprinted by Dover Publications, New York, 1964. Lorentz, H. A. (1904–1905). Proc. Kon. Ned Akad. Wet. Amsterdam 7, 438, 585, 684. See also (1909) The Theory of Electrons (Teubner, Leipzig), pp. 47–50; reprinted by Dover Publications, New York (1952). Loschmidt, J. (1876). Wien. Ber. 73, 139. Loschmidt, J. (1877). Wien. Ber. 75, 67. Luck, J. M. (1985). Phys. Rev. B 31, 3069. L ¨uders, G., and Zumino, B. (1958). Phys. Rev. 110, 1450. Ma, S.-K. (1973). Phys. Rev. A 7, 2712. Ma, S.-K. (1976a). Modern Theory of Critical Phenomena (Benjamin/Cummings, Reading, MA). Ma, S.-K. (1976b). Phys. Rev. Lett. 37, 461. Ma, S.-K. (1976c). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 6, pp. 249–292. MacDonald, D. K. C. (1948–49). Rep. Prog. Phys. 12, 56. MacDonald, D. K. C. (1950). Phil. Mag. 41, 814. MacDonald, D. K. C. (1962). Noise and Fluctuations: An Introduction (John Wiley, New York). MacDonald, D. K. C. (1963). Introductory Statistical Mechanics for Physicists (John Wiley, New York). Majumdar, R. (1929). Bull. Calcutta Math. Soc. 21, 107. Malijevsky, A., and Kolafa, J. (2008). In Theory and Simulation of Hard-Sphere Fluids and Related Systems, ed. A. Mulero (Springer, Berlin), pp. 27–36. Mandel, L., Sudarshan, E. C. G., and Wolf, E. (1964). Proc. Phys. Soc. Lond. 84, 435. Manoliu, A., and Kittel, C. (1979). Am. J. Phys. 47, 678. March, N. H. (1957). Adv. Phys. 6, 1. Martin, P. C. (1968). Measurements and Correlations (Gordon & Breach, New York). Martin, P. C., and De Dominicis, C. (1957). Phys. Rev. 105, 1417. Mather, J. C. et al. (1994). Astrophys. J. 420, 439. Mather, J. C. et al. (1999). Astrophys. J. 512, 511. Matsubara, T., and Matsuda, H. (1956). Prog. Theor. Phys. Japan 16, 416. Maxwell, J. C. (1860). Phil. Mag. 19, 19; 20, 1. Maxwell, J. C. (1867). Trans. R. Soc. Lond. 157, 49; also published in 1868 in Phil. Mag. 35, 129, 185. Maxwell, J. C. (1879). Camb. Phil. Soc. Trans. 12, 547. Mayer, J. E., and Ackermann, P. G. (1937). J. Chem. Phys. 5, 74. Mayer, J. E., and Harrison, S. F. (1938). J. Chem. Phys. 6, 87. Mayer, J. E., and Mayer, M. G. (1940). Statistical Mechanics (John Wiley, New York). Mayer, J. E. (1937). J. Chem. Phys. 5, 67. Bibliography 699 Mayer, J. E. (1942). J. Chem. Phys. 10, 629. Mayer, J. E. (1951). J. Chem. Phys. 19, 1024. Mazenko, G. F. (2006). Nonequilibrium Statistical Mechanics (John Wiley, New York). McCoy, B. M., and Wu, T. T. (1973). The Two-Dimensional Ising Model (Harvard University Press, Cambridge, MA). Mehra, J. M., and Pathria, R. K. (1994). In The Beat of a Different Drum: The Life and Science of Richard Feynman by J. Mehra (Clarendon Press, Oxford), Chap. 17, pp. 348–391. Mermin, N. D. (1968). Phys. Rev. 176, 250. Mermin, N. D., and Wagner, H. (1966). Phys. Rev. Lett. 17, 1133, 1307. Metropolis, N. (1987). Los Alamos Sci. 15, 125. Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. N., and Teller, E. (1953). J. Chem. Phys. 21, 1087, 1092. Milne, E. (1927). Proc. Camb. Phil. Soc. 23, 794. Minguzzi, A., Conti, S., and Tosi, M. P. (1997). J. Phys.: Condens. Matter 9, L33. Mohling, F. (1961). Phys. Rev. 122, 1062. Montroll, E. (1963). The Many-Body Problem, ed. J. K. Percus (Interscience Publishers, New York), pp. 525–533. Montroll, E. (1964). Applied Combinatorial Mathematics, ed. E. F. Beckenbach (John Wiley, New York). Morse, P. M. (1969). Thermal Physics, 2nd ed. (W. A. Benjamin, New York). Moser, J. K. (1962). Nach. Akad. Wiss. Gttingen, Math. Phys. Kl. II, 1, 1. Mukamel, D. (1975). Phys. Rev. Lett. 34, 481. Mulero, A., Galan, C. A., Parra, M. I., and Cuadros, F. (2008). In Theory and Simulation of Hard-Sphere Fluids and Related Systems, ed. A. Mulero (Springer, Berlin), pp. 111–132. Nelson, D. R. (1983). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 7, pp. 1–99. Newman, M. E. J., and Barkema, G. T. (1999). Monte Carlo Methods in Statistical Physics (Oxford University Press, Oxford). New Worlds, New Horizons in Astronomy and Astrophysics. (2010). (National Academies Press, Washing- ton). See www.nap.edu. Niemeijer, Th., and van Leeuwen, J. M. J. (1976). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 6, pp. 425–505. Nienhuis, B. (1987). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 11, pp. 1–53. Nozi`eres, P. (1964). Theory of Interacting Fermi Systems (W. A. Benjamin, New York). Nyquist, H. (1927). Phys. Rev. 29, 614. Nyquist, H. (1928). Phys. Rev. 32, 110. Ono, S. (1951). J. Chem. Phys. 19, 504. Onsager, L. (1931). Phys. Rev. 37, 405; 38, 2265. Onsager, L. (1944). Phys. Rev. 65, 117. Onsager, L. (1949). Nuovo Cim. 6 (Suppl. 2), 249, 261. Ornstein, L. S., and Zernike, F. (1914). Proc. Akad. Sci. Amsterdam 17, 793; reproduced in The Equilibrium Theory of Classical Fluids, eds. A. L. Frisch and J. L. Lebowitz (W. A. Benjamin, New York, 1964). 700 Bibliography Pais, A. M., and Uhlenbeck, G. E. (1959). Phys. Rev. 116, 250. Paredes, B., Widera, A., Murg, V., Mandel, O., Folling, S., Cirac, I., Shlyapnikov, G. V., and Hansch, T. W. (2004). Nature, 429, 277. Parker, W. S. (2008). Int. Stud. Philos. Sci. 22, 165. Patashinskii, A. Z., and Pokrovskii, V. L. (1966). Sov. Phys. JETP 23, 292. Pathria, R. K. (1966). Nuovo Cim. (Supp.), Ser. I, 4, 276. Pathria, R. K. (1972). Statistical Mechanics, 1st ed. (Pergamon Press, Oxford). Pathria, R. K. (1974). The Theory of Relativity, 2nd ed. (Pergamon Press, Oxford). Pathria, R. K. (1983). Can. J. Phys. 61, 228. Pathria, R. K. (1998). Phys. Rev. A 58, 1490. Pathria, R. K., and Kawatra, M. P. (1962). Prog. Theor. Phys. Japan 27, 638, 1085. Pauli, W. (1925). Z. Physik 31, 776. Pauli, W. (1927). Z. Physik 41, 81. Pauli, W. (1940). Phys. Rev. 58, 716. Pauli, W., and Belinfante, F. J. (1940). Physica 7, 177. Peierls, R. E. (1935). Ann. Inst. Henri Poincare 5, 177. Peierls, R. E. (1936). Proc. Camb. Phil. Soc. 32, 471, 477. Penrose, O., and Onsager, L. (1956). Phys. Rev. 104, 576. Penzias, A. A., and Wilson, R. W. (1965). Astrophys. J. 142, 419. Percus, J. K. (1963). The Many-Body Problem (Interscience Publishers, New York). Percus, J. K., and Yevick, G. J. (1958). Phys. Rev. 110, 1. Perrin, F. J. (1934). Phys. Radium V, 497. Perrin, F. J. (1936). Phys. Radium VII, 1. Pethick, C. J., and Smith, H. (2008). Bose–Einstein Condensation in Dilute Gases (Cambridge University Press, New York). Pines, D. (1962). The Many-Body Problem (W. A. Benjamin, New York). Pitaevskii, L. P. (1959). Sov. Phys. JETP 9, 830. Pitaevskii, L. P. (1961). Sov. Phys. JETP 13, 451. Pitaevskii, L. P., and Stringari, S. (2003). Bose–Einstein Condensation (Oxford University Press, Oxford). Planck, M. (1900). Verhandl. Deut. Phys. Ges. 2, 202, 237. Planck, M. (1908). Ann. Phys. 26, 1. Planck, M. (1917). Sitz. der Preuss. Akad. 324. Plischke, M., and Bergersen, B. (1989). Equilibrium Statistical Physics (Prentice-Hall, Englewood Cliffs, NJ). Pospiˇsil, W. (1927). Ann. Phys. 83, 735. Potts, R. B., and Ward, J. C. (1955). Prog. Theor. Phys. Japan 13, 38. Press, W. H., Teukolsky, S. A., Vetterling, W. T., and Flannery, B. P. (2007). Numerical Recipes: The Art of Scientiﬁc Computing, 3rd ed. (Cambridge University Press, New York). Prigogine, I. (1967). Introduction to Thermodynamics of Irreversible Processes, 3rd ed. (John Wiley, New York). Privman, V. (ed.) (1990). Finite Size Scaling and Numerical Simulation of Statistical Systems (World Scientiﬁc, Singapore). Bibliography 701 Privman, V., and Fisher, M. E. (1984). Phys. Rev. B 30, 322. Privman, V., Hohenberg, P. C., and Aharony, A. (1991). In Phase Transitions and Critical Phenomena, eds. C. Domb and J. L. Lebowitz (Academic Press, London), Vol. 14, pp. 1–134, 364–367. Purcell, E. M. (1956). Nature 178, 1449. Purcell, E. M., and Pound, R. V. (1951). Phys. Rev. 81, 279. Rahman, A. (1964). Phys. Rev. 136, A405. Ramsey, N. F. (1956). Phys. Rev. 103, 20. Rayleigh, L. (1900). Phil. Mag. 49, 539. Rayﬁeld, G. W., and Reif, F. (1964). Phys. Rev. 136, A1194; see also (1963) Phys. Rev. Lett. 11, 305. Ree, F. H., and Hoover, W. G. (1964). J. Chem. Phys. 40, 939. Regal, C. A., Greiner, M., and Jin, D. S. (2004). Phys. Rev. Lett. 92, 040403. Reif, F. (1965). Fundamentals of Statistical and Thermal Physics (McGraw-Hill, New York). Rhodes, P. (1950). Proc. R. Soc. Lond. A 204, 396. Riecke, E. (1898). Ann. Phys. 66, 353, 545. Riecke, E. (1900). Ann. Phys. 2, 835. Riess, A. G., Macri, L., Casertano, S., Sosey, M., Lampeitl, H., Ferguson, H. C., Filippenko, A. V., Jha, S. W., Li, W., Chornock, R., and Sarkar, D. (2009). Astrophys. J. 699, 539. Rintoul, M. D., and Torquato, S. (1996). J. Chem. Phys. 105, 9258. Roberts, J. L., Claussen, N. R., Cornish, S. L., Donley, E. A., Cornell, E. A., and Wieman, C. E. (2001). Phys. Rev. Lett. 86, 4211. Roberts, T. R., and Sydoriak, S. G. (1955). Phys. Rev. 98, 1672. Robinson, J. E. (1951). Phys. Rev. 83, 678. Rowley, L. A., Nicholson, D., and Parsonage, N. G. (1975). J. Comp. Phys. 17, 401. Rowlinson, J. S., and Swinton, F. L. (1982). Liquids Liquid Mixtures, 3rd ed. (Butterworth Scientiﬁc, London). Ruprecht, P. A., Holland, M. J., Burnett, K., and Edwards, M. (1995). Phys. Rev. A 51, 4704. Rushbrooke, G. S. (1938). Proc. R. Soc. Lond. A 166, 296. Rushbrooke, G. S. (1955). Introduction to Statistical Mechanics (Clarendon Press, Oxford). Rushbrooke, G. S. (1963). J. Chem. Phys. 39, 842. Rushbrooke, G. S., Baker, G. A., Jr., and Wood, P. J. (1974). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 3, pp. 245–356. Sackur, O. (1911). Ann. Phys. 36, 958. Sackur, O. (1912). Ann. Phys. 40, 67. Sakharov, A. D. (1967). JETP Lett. 5, 24. Schiff, L. I. (1968). Quantum Mechanics, 3rd ed. (McGraw-Hill, New York). Schramm, D. N., and Turner, M. S. (1998). Rev. Mod. Phys. 70, 303. Schr¨odinger, E. (1960). Statistical Thermodynamics (Cambridge University Press, Cambridge, UK). Schultz, T. D., Lieb, E. H., and Mattis, D. C. (1964). Rev. Mod. Phys. 36, 856. Schwartz, L. (1966). Mathematics of the Physical Sciences (Addison-Wesley, Reading, MA). Scott, G. G. (1951). Phys. Rev. 82, 542. Scott, G. G. (1952). Phys. Rev. 87, 697. 702 Bibliography Sells, R. L., Harris, C. W., and Guth, E. (1953). J. Chem. Phys. 21, 1422. Shannon, C. E. (1948). Bell Syst. Tech. J. 27, 379, 623. Shannon, C. E. (1949). The Mathematical Theory of Communication (University of Illinois Press, Urbana, IL). Simon, F. (1930). Ergeb. Exakt. Naturwiss. 9, 222. Singh, S. (2005). The Big Bang: The Origin of the Universe (Fourth Estate, New York). Singh, S., and Pandita, P. N. (1983). Phys. Rev. A 28, 1752. Singh, S., and Pathria, R. K. (1985a). Phys. Rev. B 31, 4483. Singh, S., and Pathria, R. K. (1985b). Phys. Rev. Lett. 55, 347. Singh, S., and Pathria, R. K. (1986a). Phys. Rev. Lett. 56, 2226. Singh, S., and Pathria, R. K. (1986b). Phys. Rev. B 34, 2045. Singh, S., and Pathria, R. K. (1987a). Phys. Rev. B 36, 3769. Singh, S., and Pathria, R. K. (1987b). J. Phys. A 20, 6357. Singh, S., and Pathria, R. K. (1988). Phys. Rev. B 38, 2740. Singh, S., and Pathria, R. K. (1992). Phys. Rev. B 45, 9759. Smith, B. L. (1969). Contemp. Phys. 10, 305. Smoluchowski, M. V. (1906). Ann. Phys. 21, 756. Smoluchowski, M. V. (1908). Ann. Phys. 25, 205. Sokal, A. D. (1981). J. Stat. Phys. 25, 25, 51. Sommerfeld, A. (1928). Z. Physik 47, 1; see also Sommerfeld and Frank (1931) Rev. Mod. Phys. 3, 1. Sommerfeld, A. (1932). Z. Physik 78, 283. Sommerfeld, A. (1956). Thermodynamics and Statistical Mechanics (Academic Press, New York). Speedy, R. J. (1997). J. Phys.: Condens. Matter 9, 8591. Squires, G. L. (1997). Introduction to the Theory of Thermal Neutron Scattering (Cambridge University Press, New York). Stanley, H. E. (1968). Phys. Rev. 176, 718. Stanley, H. E. (1969a). J. Phys. Soc. Japan 26S, 102. Stanley, H. E. (1969b). Phys. Rev. 179, 570. Stanley, H. E. (1971). Introduction to Phase Transitions and Critical Phenomena (Oxford University Press, Oxford). Stanley, H. E. (1974). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 3, pp. 485–567. Stefan, J. (1879). Wien. Ber. 79, 391. Steigman, G. (2006). Int. J. Mod. Phys E15, 1, doi: arXiv:astro-ph/0511534v1. Stierstadt, K. et al. (1990). Physics Data: Experimental Values of Critical Exponents and Amplitude Ratios of Magnetic Phase Transitions (Fachinformationszentrum, Karlsruhe, Germany). Stoner, E. C. (1929). Phil. Mag. 7, 63. Stoner, E. C. (1930). Phil. Mag. 9, 944. Swendsen, R. H., and Wang, J.-S. (1987). Phys. Rev. Lett. 58, 86. Takahashi, H. (1942). Proc. Phys. Math. Soc. (Japan) 24, 60. Bibliography 703 Tarko, H. B., and Fisher, M. E. (1975). Phys. Rev. B 11, 1217. ter Haar, D. (1954). Elements of Statistical Mechanics (Rinehart, New York). ter Haar, D. (1955). Rev. Mod. Phys. 27, 289. ter Haar, D. (1961). Rep. Prog. Phys. 24, 304. ter Haar, D. (1966). Elements of Thermostatistics (Holt, Rinehart & Winston, New York). ter Haar, D. (1967). The Old Quantum Theory (Pergamon Press, Oxford). ter Haar, D. (1968). On the History of Photon Statistics, Course 42 of the International School of Physics “Enrico Fermi” (Academic Press, New York). ter Haar, D., and Wergeland, H. (1966). Elements of Thermodynamics (Addison-Wesley, Reading, MA). Tetrode, H. (1912). Ann. Phys. 38, 434; corrections to this paper appear in (1912) ibid. 39, 255. Tetrode, H. (1915). Proc. Kon. Ned. Akad. Amsterdam 17, 1167. Thomas, L. H. (1927). Proc. Camb. Phil. Soc. 23, 542. Thompson, C. J. (1972a). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 1, pp. 177–226. Thompson, C. J. (1972b). Mathematical Statistical Mechanics (Princeton University Press, Princeton, NJ). Thompson, C. J. (1988). Classical Equilibrium Statistical Mechanics (Clarendon Press, Oxford). Tilley, D. R., and Tilley, J. (1990). Superﬂuidity and Superconductivity, 3rd ed. (Adam Hilger, Bristol). Tinkham, M. (1996). Introduction to Superconductivity (McGraw-Hill, New York). Tisza, L. (1938a). Nature 141, 913. Tisza, L. (1938b). Compt. Rend. Paris 207, 1035, 1186. Tolman, R. C. (1934). Relativity, Thermodynamics and Cosmology (Clarendon Press, Oxford). Tolman, R. C. (1938). The Principles of Statistical Mechanics (Oxford University Press, Oxford). Tonks, L. (1936). Phys. Rev. 50, 955. Tracy, C. A., and McCoy, B. M. (1973). Phys. Rev. Lett. 31, 1500. Tuttle, E. R., and Mohling, F. (1966). Ann. Phys. 38, 510. Uhlenbeck, G. E. (1966). In Critical Phenomena, eds. M. S. Green and J. V. Sengers (National Bureau of Standards, Washington, DC), pp. 3–6. Uhlenbeck, G. E., and Beth, E. (1936). Physica 3, 729. Uhlenbeck, G. E., and Ford, G. W. (1963). Lectures in Statistical Mechanics (American Mathematical Society, Providence, RI). Uhlenbeck, G. E., and Gropper, L. (1932). Phys. Rev. 41, 79. Uhlenbeck, G. E., and Ornstein, L. S. (1930). Phys. Rev. 36, 823. Ursell, H. D. (1927). Proc. Camb. Phil. Soc. 23, 685. van der Waals, J. D. (1873). Over de Continuiteit van den Gas-en Vloeistoftoestand, Thesis, Leiden. van Hove, L. (1949). Physica, 15, 951. Vdovichenko, N. V. (1965). Sov. Phys. JETP 20, 477; 21, 350. Verlet, L. (1967). Phys. Rev. 159, 98. Vinen, W. F. (1961). Proc. R. Soc. Lond. A 260, 218; see also Progress in Low Temperature Physics, Vol. III (1961), ed. C. J. Gorter (North-Holland, Amsterdam). Vinen, W. F. (1968). Rep. Prog. Phys. 31, 61. 704 Bibliography Vollhardt, D., and W¨olﬂe, P. (1990). The Superﬂuid Phases of Helium 3 (Taylor and Francis, London). von Neumann, J. (1927). Gottinger Nachr. 1, 24, 273. von Neumann, J. (1951). In Monte Carlo Method, eds. A. S. Householder, G. E. Forsythe, and H. H. Germond (NBS-Appl. Math. Ser, U. S. Government Printing Ofﬁce, Washington, DC). Voronel, A. V. (1976). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 5b, pp. 343–394. Walker, C. B. (1956). Phys. Rev. 103, 547. Wallace, D. J. (1976). In Phase Transitions and Critical Phenomena, eds. C. Domb and M. S. Green (Academic Press, London), Vol. 6, pp. 293–356. Walton, A. J. (1969). Contemp. Phys. 10, 181. Wang, F., and Landau, D. P. (2001). Phys. Rev. Lett. 86, 2050; Phys. Rev. E 64, 056101. Wannier, G. H. (1945). Rev. Mod. Phys. 17, 50. Wannier, G. H. (1966). Statistical Physics (John Wiley, New York). Waterston, J. J. (1892). Philos. Trans. R. Soc. Lond. A 183, 5, 79; reprinted in his collected papers (1928), ed. J. S. Haldane (Oliver & Boyd, Edinburgh), pp. 207, 318. An abstract of Waterston’s work did appear earlier; see Proc. R. Soc. Lond. A 5, 604 (1846). Watson, P. G. (1969). J. Phys. C 2, 1883, 2158. Wax, N. (ed.). (1954). Selected Papers on Noise and Stochastic Processes (Dover Publications, New York). Weeks, J. D., Chandler, D., and Andersen, H. C. (1971). Chem. Phys. 54, 5237. Weinberg, S. (1993). The First Three Minutes, 2nd ed. (Basic, New York). Weinberg, S. (2008). Cosmology (Oxford University Press, New York). Weinstock, R. (1969). Am. J. Phys. 37, 1273. Weller, W. (1963). Z. Naturforsch. 18A, 79. Wergeland, H. (1969). Lettere al Nuovo Cim. 1, 49. Wertheim, M. S. (1963). Phys. Rev. Lett. 10, 321. Whitmore, S. C., and Zimmermann, W. (1965). Phys. Rev. Lett. 15, 389. Widom, B. (1965). J. Chem. Phys. 43, 3892, 3898. Wiebes, N.-H., and Kramers (1957). Physica 23, 625. Wien, W. (1896). Ann. Phys. 58, 662. Wiener, N. (1930). Act. Math. Stockholm 55, 117. Wilczek, F. (1990). Fractional Statistics and Anyon Superconductivity (World Scientiﬁc, Singapore). Wilks, J. (1961). The Third Law of Thermodynamics (Oxford University Press, Oxford). Wilson, A. H. (1960). Thermodynamics and Statistical Mechanics (Cambridge University Press, Cam- bridge, UK). Wilson, K. G. (1971). Phys. Rev. B 4, 3174, 3184. Wilson, K. G. (1972). Phys. Rev. Lett. 28, 548. Wilson, K. G. (1975). Rev. Mod. Phys. 47, 773. Wilson, K. G., and Fisher, M. E. (1972). Phys. Rev. Lett. 28, 240. Wolff, U. (1989). Phys. Rev. Lett. 62, 361. Wood, W. W., and Parker, F. R. (1957). J. Chem. Phys. 27, 720. Bibliography 705 Woods, A. D. B. (1966). Quantum Fluids, ed. D. F. Brewer (North-Holland, Amsterdam), p. 239. Wright, E. L. et al. (1994). Astrophys. J. 420, 450. Wu, F. Y. (1982). Rev. Mod. Phys. 54, 235. Wu, T. T. (1959). Phys. Rev. 115, 1390. Wu, T. T., McCoy, B. M., Tracy, C. A., and Barouch, E. (1976). Phys. Rev. B 13, 316. Yang, C. N. (1952). Phys. Rev. 85, 808. Yang, C. N., and Lee, T. D. (1952). Phys. Rev. 87, 404; see also ibid., 410. Yang, C. N., and Yang, C. P. (1964). Phys. Rev. Lett. 13, 303. Yang, C. P. (1962). J. Math. Phys. 3, 797. Yarnell, J. L. et al. (1959). Phys. Rev. 113, 1379, 1386. Yarnell, J. L., Katz, M. J., Wenzel, R. G., and Koenig, S. H. (1973). Phys. Rev. A 7, 2130. Yeomans, J. M. (1992). Statistical Mechanics of Phase Transitions (Clarendon Press, Oxford). Young, A. P. (1979). Phys. Rev. B 19, 1855. Zasada, C. S., and Pathria, R. K. (1976). Phys. Rev. A 14, 1269. Zermelo, E. (1896). Ann. Phys. 57, 485; 59, 793. Zernike, F. (1916). Proc. Akad. Sci. Amsterdam 18, 1520; reproduced in The Equilibrium Theory of Classical Fluids, eds. A. L. Frisch and J. L. Lebowitz (W. A. Benjamin, New York, 1964). Zwierlein, M. W., Stan, C. A., Schunck, C. H., Raupach, S. M. F., Gupta, S., Hadzibabic, Z. M., and Ketterle, W. (2003). Phys. Rev. Lett. 91, 250401. Index A Adiabatic, 285, 289 processes, 11, 16, 23, 190, 340 Adiabats of blackbody radiation, 206 of a Bose gas, 190 of a Fermi gas, 190, 271 Adsorption, 112 Anharmonic oscillators, 87, 88 Antiferromagnetism, 401, 413 Anti-Stokes scattering, 625 Argon, 106–108, 338 Autocorrelation functions, 596, 610–611, 613–615, 617–618, 633–634 B Bardeen, Cooper, and Schrieffer (BCS), 108, 392–394 Barometric formula, 175 Baryon number density, 279, 286 Baryon-to-photon ratio, 279, 280, 281, 283, 289, 291, 292, 294 BCS/BEC crossover, 393, 394 Beta decay, 286 Beta function, 657 Beta-equilibrium, 285, 289 Bethe approximation to the Ising lattice, 427–428, 431, 433–434, 437, 466–467, 476, 479, 490, 498–499 Beth–Uhlenbeck formalism, 320–325, 342 Big Bang, 275–280, 287, 290, 295 Binary alloys, 414, 420 Binary collision method, 331, 357, 364, 385, 397 Binding energy of a Thomas–Fermi atom, 264–269 Blackbody radiation, 65, 130, 151, 200–205, 277, 278, 279n4, 281, 290 Bloch’s T3/2-law, 465 Block-spin transformation, 540 Bogoliubov transformation, 363, 366, 526 Bohr–van Leeuwen theorem, 90, 245 Boltzmann factor, 53, 59–60, 121, 138, 342, 501–502, 625 Boltzmannian systems classical, 9, 25, 54, 143–147, 150, 152, 299–314 quantum-mechanical, 331, 341 Bose condensation, 108 Bose gas, imperfect, 355–366 Bose liquids, energy spectrum of, 366–369 Bose-condensed fraction, 193, 194, 197 Bose-condensed peak, 196 Bose–Einstein condensation (BEC), 108, 181, 183–184, 188–189, 191–199, 223, 358–361 distribution function, 195 functions, 181, 664–667 with interactions, 355–358, 367, 395–396 statistics, 108, 132, 141–152, 165–167 Bose–Einstein systems, 133–138, 141–152, 179–229, 320–331 multidimensional, 519–526 nonuniform, 373–376 Boundary conditions, 653–655 Box–Muller algorithm, 651, 685 Bragg peak, 339 Bragg–Williams approximation to the Ising lattice, 420–427, 433, 434, 466–467, 494, 497–499 Brillouin function, 75–76 Brillouin scattering, 625 Brillouin zone, 625 Broad histogram method, 507, 642n5 Broken symmetry, 423 Brownian motion, 583, 587–605, 607–608, 619 of harmonic oscillator, 601–603 Traveling Wave Analysis of Partial Differential Equations © 2011 Elsevier Ltd. All rights reserved. 707 708 Index Brownian motion (continued) observation of, 587, 591, 599 of a suspended mirror, 607–608 C Canonical distribution, 49, 50, 88, 89 Canonical ensemble, 29, 39–83, 121–124, 133, 146, 334, 678, 679 Canonical partition function, 678, 679, 682 Canonical transformations, 37, 63 Carbon dioxide, 172 Carbon monoxide, 172 Carbon tetrachloride, 626 Carnahan–Starling equation of state, 314, 648 Catalyst, 168, 171, 172 Catalytic converter, 172 Cepheid variable stars, 275 Chandrasekhar limit, 264 Chemical equilibrium, 170–172 Chemical potential, 7, 51, 91–93, 109, 110, 158, 159, 161, 170, 171, 679–681 of a Bose gas, 357–358 of a classical gas, 19–20 of a Fermi gas, 237, 241–242, 252–253, 269–273 of a Fermi liquid, 389, 399 of a gas of phonons, 207 of a gas of photons, 207 see also Fugacity Circulation, quantized, 370–376 Classical limit, 22, 70, 127, 136–137, 141, 181, 186, 333, 366, 623 Classical systems, 9–16, 25–29, 54–58 in the canonical ensemble, 54–58, 145 in the grand canonical ensemble, 137, 145 interacting, 61–65, 299–314 in the microcanonical ensemble, 145 Clausius–Clapeyron equation, 109–111 Cluster expansions classical, 299–307 general, 315–319 quantum-mechanical, 325–331 Cluster functions, 328 Cluster integrals, 303–304, 307, 315–316, 324–325, 329–330 irreducible, 308, 317–318 Coexistence line, 106–107 Coexistence pressure, 109, 110 Combustion, 172 Complexions, see Microstates Compressibility adiabatic, 224, 270, 390, 468, 521, 586 equation of state, 336 isothermal, 104, 107, 224, 270, 335, 343, 390, 410, 435, 442, 452, 468, 472, 474, 521–522, 586, 647, 683 Computer simulation, 637–651 Condensation, 392–394, 402–407 in Fermi systems, 392–394 scaling hypothesis for, 468 of a van der Waals gas, 407–411 Yang–Lee theory of, 494 see also Bose–Einstein condensation Conductivity electrical, 247, 627 thermal, 247, 627 Conﬁguration integral, 300, 301, 306, 308, 315, 324, 326, 328 Conformal transformation, 569 Continuous transition, 107 Convexity, 682–683 Cooper pair, 392, 393 Cooperative phenomena, see Phase transitions Coordination number, 416–417, 489, 564 Correlation function of an n-vector model, 484–486 of a Bose gas, 524–525, 534 of a ﬂuid, 332–335, 370, 647, 649 of the Ising model, 481, 499–500, 533 in the mean-ﬁeld approximation, 453–455, 461 in the scaled form, 457, 576 of the spherical model, 515–517, 535 of the XY model, 527 Correlation length, 333, 334 of an n-vector model, 485–487, 533 of a Bose gas, 525, 534 Index 709 of the Ising model, 481–482, 499–500, 531, 532 in ﬂuids, 333–334 in the mean-ﬁeld approximation, 454–455, 462 of the spherical model, 516–517, 535 of the XY model, 526–527 Correlations, 107, 331–340 spatial, 137–139, 332, 583 spin-spin, 451, 462, 480, 516–518 statistical, 151–152, 585, 594, 596 time, 639 Corresponding states, law of, 409 Cosmic Background Explorer (COBE), 277, 278 Cosmic microwave background (CMB), 277–279, 293, 295 Covariance matrix, 632 Critical behavior of a Bose gas, 184–188, 522–524, 535–536 of a ﬂuid, 467 of the Ising model, 429–433, 480–482, 497–500, 533, 559, 560–563 of a magnetic system, 443–444, 448–449, 454–456, 467 of the spherical model, 512–515, 535 of a van der Waals gas, 408–411, 463 of the XY model, 526–527 Critical curve, 562–563, 566 Critical dimension lower, 570, 578 upper, 461, 528, 570, 578 Critical exponents of an n-vector model, 486–487, 530 of a Bose gas, 522–526 experimental values of, 437 hyperscaling relation among, 459, 570 of the Ising model, 480, 482, 500, 530, 559, 560 mean-ﬁeld values of, 455–456, 530, 557–558 of polymers, 529 scaling relations among, 457–459 of the spherical model, 512–513, 515–518, 535 theoretical values of, 529 thermodynamic inequalities for, 438–442 Critical opalescence, 104, 450, 583 Critical point, 106–108 Critical surface, 553, 555–556, 562 Critical temperature, 107, 108 Critical trajectories, 554 Critical velocity of superﬂow, 222–223, 376, 378 Crossover phenomena, 569 Crystalline solid, 331, 338–340 Curie temperature, 422, 430 Curie’s law, 73, 75, 89, 238–239, 246, 426 Curie–Weiss law, 425–426 D Dark ages, cosmic, 279n4, 282, 295 Dark energy, 279, 281 Dark matter, 279, 295 Darwin–Fowler method, 44, 94 deBroglie wavelength, 107 Debye function, 209–210 Debye temperature, 210–211, 249 Debye’s theory of speciﬁc heats, 210–211 Debye–Waller factor, 339 Decimation transformation, 541, 552, 579–580 Degeneracy criterion, 137, 156, 179 see also Classical limit Delta function, 69, 139 Density ﬂuctuations, 104–105, 342, 586–587 in the critical region, 586 Density function in phase space, 25–29 Density matrix, 115–121, 123–124, 621–622 of an electron, 122–123 of a free particle, 123–125 of a linear harmonic oscillator, 125–127 of a system of free particles, 133–138 of a system of interacting particles, 325–328 Density of states, 53, 57–58, 192, 234, 258 for a free particle, 33, 272, 653–655 for a system of harmonic oscillators, 68–69 Detailed balance, 118, 640, 642 Deuterium, 290, 292 Diamagnetism, Landau, 239, 243–247 Diatomic molecules, 88, 111, 158–168 Dietrici equation of state, 463 Diffusion Brownian motion in terms of, 591–592 710 Index Diffusion (continued) coefﬁcient, 591–592, 595, 618, 627 equation, 592, 606 Dimensionless parameters, 645 Dipole-dipole interaction, 89 Dirac delta function, 69, 139 Dispersion, 602 Dissipation, 602, 603 Dissipative phenomena, 583, 594, 617, 619 Doppler broadening, 174 Doppler red shift, 275 Duality transformation, 492–494 Dulong–Petit law, 207 Dynamical structure factor, 624–626 E ϵ-expansion, 563–567 Early universe, 275–295 Edge effects, 654 Effective mass, 222, 246, 248, 388 Effusion, 155 of electrons from metals, 247–257 of photons from a radiation cavity, 204 Einstein function, 207 Einstein’s relations, 583 Einstein–Smoluchowski theory of the Brownian motion, 587–593 Electron gas in metals, 247–257 Electron-positron annihilation, 287–289 Electrons, 282–285, 287–289 in a magnetic ﬁeld, 122–123 Elementary excitations in an imperfect Bose gas, 361–366, 395–396 in a Bose liquid, 366–376, 396–397 in a Fermi liquid, 385–392 in liquid helium II, 215–223 Energy cells, 141 density, 276, 278, 279n4, 281, 283, 284 distribution, 504, 506, 507 ﬂuctuations, 58–61, 103–105 hypersurface, 638, 644, 651 Ensemble average, 26, 29–31, 48, 54, 116, 122 Ensemble of Brownian particles, 592–593, 603, 606–607 Ensemble theory, 25–37 Enthalpy, 8, 681–682 Entropy, 677–678 of an Ising ferromagnet, 425, 465, 466, 533 density, 279n5, 283–285, 679 of mixing, 16–20 in nonequilibrium states, 584–586, 627–630 statistical interpretation of, 5, 51–52, 105, 119 Equation of state of a Bose gas, 181–182, 324–325 of classical systems, 9, 15, 64–65, 307–314, 317–319 of a Fermi gas, 233, 324–325 of a lattice gas, 464, 532–533 of quantum-mechanical systems, 317–319, 330 reduced, 409 see also van der Waals equation of state Equilibrium approach to, 3–6, 583, 603–608 average, 638, 644 constant, 171–172, 176–178, 401, 431 deviations from, 584–587, 632–633 persistence of, 583 probability distribution, 640 Equipartition theorem, 63–64, 67, 87, 160, 162, 169, 247, 487, 537, 602, 606, 614, 616, 646 Ergodic, 644 hypothesis, 31 Evaporative cooling, 192, 194 Exchange interaction, 413–414 Exclusion principle, 21, 132, 231, 236, 264, 350, 352, 604 Extensive variables, 1–2, 8, 16–17, 19 F Factorial function, 655, 658 Fermi degeneracy, 259 Fermi energy, 234, 242, 248–249, 252, 254, 257–258, 260, 271, 273, 399 Fermi gas, imperfect, 379–385, 399 Fermi liquids, energy spectrum of, 385–392 Fermi momentum, 234, 260, 265, 387 Index 711 Fermi oscillators, 88 Fermi temperature, 237, 248, 258, 260, 393 Fermi velocity, 271 Fermi–Dirac distribution, 247–248 Fermi–Dirac functions, 231, 381, 387, 667–670 Fermi–Dirac statistics, 108, 132, 138, 179, 212, 247–248 Fermi–Dirac systems, 133–138, 141–149, 231–273, 320–331 n-dimensional, 272 Ferromagnetism, 401, 411–413, 465, 488 see also Spontaneous magnetization Feshbach resonance, 359, 361, 393 Feynman’s circulation theorem, 370 Feynman’s theory of a Bose liquid, 367 Fick’s law of diffusion, 591 Field-theoretic approach, 345–355 Finite-size effects, 501, 579 Finite-size scaling, 570–579 First-order transition, 107 Fixed point, 313, 528, 553–557, 559–565, 568–569 Gaussian, 564–565 non-Gaussian, 564–565 Fluctuation–compressibility relation, 338 Fluctuation–dissipation theorem, 338, 452, 583, 603, 617–626, 630 Fluctuations in an electrical resistor, 619–620 in an (L, R)-circuit, 616–617 in the canonical ensemble, 47–48, 58–61, 86 critical, 104 frequency spectrum of, 609–617 in the grand canonical ensemble, 103–105 in a multiphase system, 406 of occupation numbers, 151–153 thermodynamic, 584–587 see also Brownian motion; Phase transitions Flux quantization in superconductors, 372 Fokker–Planck equation, 603–608 Four famous formulae, 676 Fourier analysis of ﬂuctuations, 609–617 Fowler plot, 257 Free volume, 85 Fugacity, 96, 101, 122, 148, 150, 180, 185, 193, 197–198, 198, 381, 520–521 of a Bose gas, 184–185, 358, 395 of a Fermi gas, 252, 272, 398 of a gas of phonons, 207 of a gas of photons, 207 of a lattice gas, 417–418, 532 of a two-phase system, 102 see also Chemical potential G Gamma function, 655, 657 Gaussian model, 508 Gibbs free energy, 8, 20, 51, 96, 109–111, 170–172, 680–681 Gibbs paradox, 16–20 Ginzburg criterion, 460 Goldstone modes, 488 Grand canonical ensemble, 91–110, 646n8, 679–680 Grand canonical partition function, 679 Grand partition function, 96, 103 of an ideal gas, 148–149, 180, 231 of an imperfect gas, 306, 315, 395, 399 of a lattice gas, 417 of a multiphase system, 403–407 Gross–Pitaevskii equation, 358, 359 Ground-state properties of a Bose gas, 355–361, 396 of a Fermi gas, 233–236, 239–240, 242, 246, 261, 269, 272–273, 384–385, 390–392, 397–398 H Hard disk ﬂuid, 334 Hard sphere ﬂuid, 85, 314, 333, 335, 341, 364, 471–473, 475, 647–650 Harmonic approximation, 169, 205 Harmonic oscillators, 33–35, 65–70, 98, 100–102, 125–127, 192–194, 200, 205–206, 358, 360, 601–603, 644 Heat capacity, 197, 199 Heisenberg model, 414, 427, 464–465, 488, 528 Helicity, 283 modulus, 469 Helium, 108 712 Index Helium-4, 108, 290–293; see also Liquid He4 Helium-3 (3He), 293; see also Liquid He3 Helmholtz free energy, 8, 20, 50, 97, 171, 678 Hexatic phase, 340 High temperature series, 504 H-theorem, 1 Hubble expansion, 276, 280 Hubble parameter, 276–278, 280 Hubble relation, 276 Hyperscaling relation, 459, 461, 482, 529, 557–558, 570 I Ice, 109 Ideal gas of bosons, 180–191, 519–526, 536 classical, 9–16, 32–35, 54–58, 60–61, 64, 98–99 of fermions, 231–247 quantum-mechanical, 128–132, 141–149 Importance sampling, 638, 640 Indistinguishability of particles, 20–21, 98, 119, 129, 136, 141, 179 of photons, 65 Inelastic scattering, 624–626 Inertial density of excitations, 212–215, 220, 228 Integrating factor for heat, 95 Intensive variables, 17, 100, 403 Internal energy, 196–199, 335, 681 Internal molecular ﬁeld, 422 see also Ferromagnetism Internal motions of molecules, 155–170 Ionization, 157 Irrelevant variables, 554–558, 565–566 dangerously, 565 Irreversible phenomena, 589, 628–629 Ising model, 414, 417, 419–435, 464 in one dimension, 471, 476–482, 501, 559–560 in three dimensions, 527–530 in two dimensions, 457, 488–507, 534, 537, 560–563 Isobaric ensemble, 471, 473–475, 646n9, 680–681 Isobaric partition function, 680 Isothermal processes, 16 see also Compressibility Isotherms of a Bose gas, 189 of a multiphase system, 403–407 of a van der Waals gas, 408 J Joule–Thomson coefﬁcient, 340–341 K Kinetic coefﬁcients, 627 Kinetic pressure, 154 Kirkwood approximation, 466 Kosterlitz–Thouless transition, 340, 526–527 Kramers’ q-potential, 95 see also q-potential Kramers–Kronig relation, 623 Kubo’s theorem, 620 L Lagrange multipliers, method of, 43, 201, 359 Lambda-transition in liquid He4, 108, 188–189, 222 Landau diamagnetism, 239, 243–247 Landau–Placzek ratio, 626 Landau’s condition for superﬂow, 223 see also Critical velocity of superﬂow Landau’s spectrum for elementary excitations in a Bose liquid, 366–369 Landau’s theory of a Fermi liquid, 385–392 Landau’s theory of phase transitions, 442–445 Langevin function, 72, 245 Langevin random force, 646n9 Langevin’s theory of the Brownian motion, 593–603 as applied to a resistor, 619 Langmuir equation, 112 Laser cooling, 191–192, 258 Last scattering, 276n3, 278, 282, 294, 295 Latent heat of melting, 112 of sublimation, 112 of vaporization, 110 Index 713 Lattice gas, 417–420, 464, 532–534 Law of mass action, 171, 431 Leap-frog algorithm, 644 Length transformation, 528, 539 Lennard-Jones interaction, 645 Lennard-Jones potential, 309, 311–312 Light scattering by a ﬂuid, 450 Light-year, 276, 277 Linear congruential method, 683 Linear response theory, 621–623 Liouville’s theorem classical, 272–279 quantum-mechanical, 117 Liquid He3, speciﬁc heat of, 189 Liquid He4 elementary excitations in, 366–369 normal fraction in, 189, 216 speciﬁc heat of, 189 Liquid phase, 107, 108 Liquid-crystal, 331 Liquid–vapor coexistence, 106–108 Long-range interactions, 519, 569, 643 Long-range order, 331–332, 339, 340, 420 in the Bethe approximation, 428–429 in a binary alloy, 465–466 in a Bose gas, 525 in the Heisenberg model, 464–465 in the spherical model, 518–519 in a square lattice, 498–499 in the Weiss ferromagnet, 422–425 see also Spontaneous magnetization Lorenz number, 247, 250 Low temperature series, 502, 505, 506, 507n2 M Macrostates, 11 Magnetic ﬁeld, 682 Magnetic Helmholtz free energy, 678 Magnetic systems, thermodynamics of, 77–83 see also Diamagnetism; Ferromagnetism; Paramagnetism Magnetic trap, 191–193, 258 Marginal variables, 555 Markovian processes, 604 Mass motion, 212–214, 221–222, 228, 370 nonuniform, 370–376 Mass-radius relationship for white dwarfs, 263–265 Master equation, 603–604 Maxwell distribution, 645 Maxwell relation, 677–682 Maxwell–Boltzmann statistics, 1, 5, 31, 143, 145, 147, 150, 152, 173, 200, 248 see also Classical limit; Classical systems Maxwell’s construction, 404, 408, 443, 445 Mayer’s function, 300–301, 328, 343 Mayer’s theory of cluster expansions, 315–319 Mean ﬁeld theories, 420, 422, 427–430, 453, 456, 497, 500, 508 limitations of, 460–463 Mean values, method of, 44–49 Megaparsec, 276, 277 Meissner effect in superconductors, 372 Memory functions, see Autocorrelation functions Mermin–Wagner theorem, 526 Methane, 178 Metropolis method, 641–643 Microcanonical ensemble, 29–35, 39, 52, 58–61, 103, 119–121, 141–145, 643–644, 646, 677–678 Microcanonical entropy, 506, 507 Microstates, 2–5, 11–14, 33, 119, 129–130, 141–145, 638–641, 643, 644 of an Ising ferromagnet, 425, 464, 531 of a binary alloy, 465–466 “correct” enumeration of, 20–22 Migdal–Kadanoff transformation, 580 Mobility, 583, 595, 605, 618 Molecular dynamics simulations, 643–646 Monte Carlo simulations, 473, 506, 529, 640–643, 650 Monte Carlo Renormalization Group, 642n5, 650 Monte Carlo sweep, 639, 642, 643 Most probable distribution, 42, 84, 144 Most probable values, method of, 42–44, 149 Mulholland’s formula, 162 Multicanonical Monte Carlo, 642n5 714 Index N N´eel temperature, 465 Negative temperatures, 77–83 Nernst heat theorem, see Third law of thermodynamics Nernst relation, 595 Neutrino, 279n4, 282–285, 289–290 Neutron, 285–287, 292 Neutron scattering, 107, 338 Newton’s equations of motion, 638, 643 Noise, 452 in an (L, R)-circuit, 616–617 white, 612, 615–617, 621 Nonequilibrium properties, 617 see also Fluctuation–dissipation theorem Normal modes of a liquid, 211 of a solid, 206–210, 227–228 n-particle density, 332 Nucleosynthesis, 279n6, 287, 290–293, 294 Number density, 278, 279, 283, 284, 286–288, 291, 679 Number of molecules, 677, 678, 680, 681 Nyquist theorem, 616 O Occupation numbers, 21–22, 149–152, 202, 206–207, 213, 219, 221, 234, 381 One-body density, 332 One-dimensional ﬂuid, 471–475 Onsager relations, 626–632 Order parameter, 435, 437, 442, 445, 452, 469, 471, 497, 524, 526, 529, 576 Ortho- and para-components, 166–167 P Pad´e approximants, 528 Pair correlation function, 332–338, 332–336, 338, 343, 368, 472–473, 473, 475, 524, 647–649 see also Correlation function; Correlations Pair distribution function, 138–139 Parallel tempering, 650 Paramagnetism, 70–76, 239–243, 247, 272 Particle simulations, 646–650 Particle-number representation, 351 Partition function of an interacting system, 300–304, 315, 320, 325–331 of an n-vector model, 483–484, 533 of a Bose gas, 357 of a classical ideal gas, 55–58, 85, 98, 147 of a Fermi gas, 240–241 of the Ising model, 477–478, 489–495, 531–533, 543–546, 549–552 of the lattice gas, 417 of the spherical model, 508–510, 547–548, 579 of a system of free particles, 133–138, 146–149 of a system of harmonic oscillators, 65, 66, 68, 82 of a system of magnetic dipoles, 70, 77, 78, 80, 81 of a two-phase system, 402–405 Pauli paramagnetism, 238–243, 272 Pauli repulsion, 645 Pauli’s exclusion principle, see Exclusion principle Percus–Yevick approximation, 333 Perturbation theory, 380 Phase diagram, 105–108 Phase equilibrium, 109–110 Phase separation in binary mixtures, 401, 411 Phase space, 25–29, 32–35, 38, 54, 136, 638, 643, 644 Phase transitions, 401–469, 500 and correlations, 430–431, 449–456, 539, 583 a dynamical model of, 411–417 in ﬁnite-sized systems, 570–579 ﬁrst-order, 107, 110, 642, 650 and ﬂuctuations, 449–456, 460–463, 519 interfacial, 569 Landau’s theory of, 442–445, 467 second-order, 107, 442, 578, 650 see also Critical behavior Phonons in a Bose ﬂuid, 366, 369 Index 715 effective mass of, 228 in liquid helium II, 214–216 in mass motion, 212–214, 221 Photoelectric emission from metals, 250, 255–257 Photons, 35–36, 200–204, 226–227 Plasma, 178, 277, 281, 293, 295 Poisson equation, 266 Polyatomic molecules, 168–170 Positron, 282–285, 287–289 Postulate of equal a priori probabilities, 2, 29, 119–120 Postulate of random a priori phases, 120 Potassium (K), 258, 259 Power spectrum, 603, 623 Power spectrum, of a stationary variable, 603, 610, 612–614, 623–624, 634 Predictability of a variable, 609, 611, 612 Pressure, 283, 284, 679–681 Probability density operator, 254–256 see also Density matrix Probability distribution, 640 for Brownian particles, 587–593, 604–607 for thermodynamic ﬂuctuations, 584–587, 632–633 Proton, 278, 285, 286, 290, 294 Pseudopotential approach, 355, 357, 364, 366, 385, 397 Pseudorandom numbers, 640–641, 683–685 Q q-potential, 95–96, 98 of an ideal gas, 145 of a two-phase system, 406–407 see also Grand partition function Quantized circulation in a Bose ﬂuid, 370–376, 396–397 Quantized ﬁelds, method of, 345–400 Quantized ﬂux, 372 Quantum statistics, 21, 97, 107, 115–140, 150, 238 see also Bose–Einstein systems; Fermi–Dirac systems Quark-gluon plasma, 282n7 Quasichemical approximation to the Ising lattice, 427, 431, 531 see also Bethe approximation to the Ising lattice Quasielastic scattering, 336 Quasi-long-range order, 331, 340 Quasiparticles, see Elementary excitations R Raman scattering, 625 Random close-packed, 650 Random mixing approximation, 426, 431, 432, 464 see also Mean ﬁeld theories Random walk problem, 588, 592 Randomness of phases, 120–121, 610 Ratio method, 528 Rayleigh scattering, 625 Rayleigh–Jeans law, 202–203 Recombination, 279n4, 282, 293–295 Relativistic gas, 38, 86, 175 of bosons, 526, 535–536 of electrons, 260–262, 273 of fermions, 236 Relativistic Heavy Ion Collider (RHIC), 282n7, 296 Relaxation time, 594, 599, 604–605, 607, 609, 615, 619, 634 Relevant variables, 555, 562, 565 Renormalization group approach, 528–529, 539–569 general formulation of, 552–558 to the Ising model, 543–546, 549–552, 559–562 to the spherical model, 547–549, 560 Renormalization group operator, 552, 556 linearized, 554, 580 Response function, 601–603, 623 Response time, 615–616 Richardson effect, 251–255 Riemann zeta function, 665–666 Rigid rotator, 37, 161 Rotational Brownian motion, 599 Rotons in a Bose ﬂuid, 367–369 in liquid helium II, 218–223 716 Index Rubidium (Rb), 191, 197, 199 Rydberg, 293 S Sackur–Tetrode equation, 19 Saddle-point method, 44, 46, 83, 509 Saha equation, 178, 291, 294 Scalar models, 456, 461, 482, 487, 499, 540, 578 Scaling ﬁelds, 555, 561 Scaling hypothesis, 446–449, 457, 468 Scaling relations, 457–458, 461, 468, 500, 529, 543, 558 Scaling theory, 540–543, 555–557 Scattering, 107, 331–340 of electromagnetic waves by a ﬂuid, 449–450, 455–456 form factor, 336 length, 358, 359, 393, 394 Schottky effect, 79, 254–255 Second quantization, 345–355 see also Quantized ﬁelds Second-order transition, 107 Shape scattering, 337 Short-range order, 331–332, 334, 427, 432, 466 Singularities in the thermodynamic functions, 224, 225, 357–358, 523–525 see also Critical behavior; Speciﬁc-heat singularity Smoluchowski equation, 589 Sodium (Na), 191 Solid phase, 106–108 Solid–liquid coexistence, 106, 108 Solid–vapor coexistence, 101, 106 Sommerfeld’s lemma, 236, 256, 670 Sommerfeld’s theory of metals, 248 Sound waves, 205–212 inertial density of, 212–215 see also Phonons Speciﬁc heat, 198, 199 of an imperfect gas, 395–397 of an Ising lattice, 432–433, 478–479, 495–497 of an n-vector model, 486–487 of blackbody radiation, 205 of a Bose gas, 182, 185–187, 190, 224, 521–524, 535 of a classical gas, 15 of diatomic gases, 158–168 of a Fermi gas, 233, 237–238, 248–249, 270–272 of liquid helium II, 188, 222 of magnetic materials, 77, 79, 83, 89 of polyatomic gases, 169 of solids, 207–212, 227, 249 of the spherical model, 511–518 of a system of harmonic oscillators, 68, 87–88, 207–212, 227 of the XY model, 526 Speciﬁc volume, 680 Speciﬁc-heat singularity, 447, 462, 467, 488, 495–497 Spectral analysis of ﬂuctuations, 609–617 Spherical constraint, 508, 509, 511–512, 534, 547, 548, 579 Spherical ﬁeld, 511 reduced, 512 Spherical model, 487, 508–519, 533–535, 547–549, 579 Spin and statistics, 132, 165–168, 341, 353 Spin degeneracy, 283 Spontaneous magnetization, 412, 415, 422, 424, 429–430, 439–440, 443, 499 in the Ising model, 428–429, 497–498, 533 in the spherical model, 511–518, 534 see also Long-range order Standard candle, 275, 276 Standard pressure, 171 Standard states, 171 Static structure factor, 336–338, 340 Stationary ensembles, 27, 596, 619 Stationary variables, Fourier analysis of, 609–617, 633–634 Statistical potential, 138, 324 Steepest descent, method of, 44, 509–510 Stefan–Boltzmann law, 203 Stirling’s formula, 658–659 Stochastic rate equation, 640 Stoichiometric coefﬁcients, 170 Stoichiometric point, 172 Index 717 Stokes law, 593 Stokes scattering, 625 Structure factor, 107, 337, 339, 475 of a liquid, 368–370 Sublimation, 106 Superconductor, 392 Supercritical phase, 107 Superﬂuid, 108 density near critical point, 468 in mass motion, 222, 370–379 transition in liquid He4, 188, 222, 469 Superﬂuidity breakdown of, 222, 376–379 Landau’s criterion for, 222–223, 378–379 see also Critical velocity of superﬂow Supernova, 264, 275, 295 Supersolid, 108 Surface effects, 653–655 Surface tension near critical point, 469, 500 Susceptibility, magnetic of an n-vector model, 533 of a Fermi gas, 239, 242, 245–246, 272, 399 of the Ising model, 425, 443, 467, 478, 533 of the spherical model, 511–518, 534 see also Singularities Sutherland potential, 340 Swendsen–Wang algorithm, 641n3 Symmetry properties of wavefunctions, 132, 136, 346–348, 627, 630 Symplectic, 644 T Takahashi method, 473 Temperature, 672–674, 678–680 Thermal deBroglie wavelength (equivalent to mean thermal wavelength), 107, 195, 286, 294 Thermal expansion, coefﬁcient of, 228 Thermal wavelength, mean, 125, 135–137, 139, 147, 179, 227, 231, 245, 300, 327, 354, 381, 520 Thermionic emission from metals, 251–255 Thermodynamic limit, 1, 40, 64, 70, 100, 111, 193, 337, 403, 472–473, 475, 486–487, 570 Thermodynamic potential, 679–680 Thermodynamic pressure, 7, 145, 152, 403 Thermodynamic temperature, 5 Thermodynamics of the early universe, 275–295 Thermostat, 644, 646 Third law of thermodynamics, 5, 52, 119, 238, 488 Thomas–Fermi equation, 359 Thomas–Fermi model of the atom, 264–269 Thomson scattering, 281 Tie line, 106–107 Time-of-ﬂight, 258, 360, 394 experiment, 194 T3-law of speciﬁc heats, 210–211 Tonks gas, 472 Transfer matrix, 501 method, 476, 482, 488, 501, 531–532, 579 Transition rate, 640, 641 Transport phenomena, 604 Trial state, 641–642 Tricritical point, 468 Triple point, 106, 107 Two-body density, 332 Two-ﬂuid model of superﬂuidity, 188, 215, 370 U Ultracold atomic gases, 191–199, 258–259, 358–361, 394 Universality, 445, 500, 568 classes, 449, 451, 457, 463, 471, 519, 526, 569, 571 Ursell functions, see Cluster functions V van der Waals attraction, 645 van der Waals equation of state, 310–311, 340, 404, 409, 426, 436, 446, 464 Vapor phase, 106–108 Vapor pressure of a solid, 102 Variance, 682–683 Vector models, 456, 482–488, 499, 519, 528 Verlet algorithm, 644 Virial, 335 coefﬁcients, 182, 307–317, 309–314, 319–325, 320–325 718 Index Virial (continued) equation of state, 335, 647, 648 expansion of the equation of state, 182, 233, 307–309 theorem, 63–64, 86, 273 Viscosity, 593–595, 601, 614, 616 Viscous drag, 593, 605 Volume, 662–664 Vortex motion in a Bose liquid, see Quantized circulation in a Bose ﬂuid W Water, 109, 110 Water vapor, 172 Watson functions, 513, 675–676 Weeks–Chandler–Andersen (WCA) potential, 652 Weiss theory of ferromagnetism, 412, 420–427 see also Mean ﬁeld theories White dwarf stars, 259–264 Wiedemann–Franz law, 247, 250 Wiener–Khintchine theorem, 583, 609–617 Wien’s distribution law, 202 Wilkinson Microwave Anisotropy Probe (WMAP), 277, 278, 279n4, 283n9 Wolff algorithm, 641n3, 684 Work function, 252, 257 X XY model, 414, 526 Y Yang–Lee theory of condensation, 407 Z Zero-point energy of a Bose system, 356, 365, 396 of a Fermi system, 234, 269, 272, 384, 398 of a solid, 205, 227 Zero-point pressure of a Bose system, 356, 365, 396 of a Fermi system, 261–262, 272, 384, 398 Zero-point susceptibility of a Fermi system, 239, 242, 246 Zeros of the grand partition function, 407 Zeroth law of thermodynamics, 5 Zeta function, 665–666","libVersion":"0.5.0","langs":""}